{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "                                              0.0/10.6 MB ? eta -:--:--\n",
      "                                              0.0/10.6 MB 1.3 MB/s eta 0:00:09\n",
      "                                              0.1/10.6 MB 1.7 MB/s eta 0:00:07\n",
      "     -                                        0.3/10.6 MB 2.2 MB/s eta 0:00:05\n",
      "     --                                       0.6/10.6 MB 3.5 MB/s eta 0:00:03\n",
      "     ----                                     1.3/10.6 MB 5.8 MB/s eta 0:00:02\n",
      "     ---------                                2.6/10.6 MB 9.7 MB/s eta 0:00:01\n",
      "     -------------------                      5.2/10.6 MB 16.6 MB/s eta 0:00:01\n",
      "     -----------------------------------      9.3/10.6 MB 25.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.6/10.6 MB 43.5 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.6/10.6 MB 43.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 10.6/10.6 MB 29.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\saurabh\\dataspellprojects\\pythonproject\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "                                              0.0/502.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 502.3/502.3 kB ? eta 0:00:00\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "                                              0.0/341.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 341.8/341.8 kB 22.1 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.21.0 (from pandas)\n",
      "  Downloading numpy-1.25.0-cp311-cp311-win_amd64.whl (15.0 MB)\n",
      "                                              0.0/15.0 MB ? eta -:--:--\n",
      "     ---------                                3.4/15.0 MB 71.9 MB/s eta 0:00:01\n",
      "     -------------------------               9.8/15.0 MB 104.5 MB/s eta 0:00:01\n",
      "     -------------------------------------  14.9/15.0 MB 131.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  15.0/15.0 MB 108.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  15.0/15.0 MB 108.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  15.0/15.0 MB 108.8 MB/s eta 0:00:01\n",
      "     --------------------------------------- 15.0/15.0 MB 40.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\saurabh\\dataspellprojects\\pythonproject\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.25.0 pandas-2.0.3 pytz-2023.3 tzdata-2023.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-06T08:14:26.603773Z",
     "start_time": "2023-07-06T08:13:48.898020500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-06T08:14:37.486279300Z",
     "start_time": "2023-07-06T08:14:35.510506600Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "qa_df = pd.read_csv(\"python_qa.csv\")\n",
    "questions, answers = qa_df['Body'],qa_df['Answer']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-06T08:23:45.175403Z",
     "start_time": "2023-07-06T08:23:45.020792200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "qa_openai_format = [{\"prompt\":q,\"completion\":a} for q,a in zip(questions,answers)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-06T08:25:46.443679Z",
     "start_time": "2023-07-06T08:25:46.440667Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'prompt': \"This is a difficult and open-ended question I know, but I thought I'd throw it to the floor and see if anyone had any interesting suggestions.\\n\\nI have developed a code-generator that takes our python interface to our C++ code (generated via SWIG) and generates code needed to expose this as WebServices.  When I developed this code I did it using TDD, but I've found my tests to be brittle as hell.  Because each test essentially wanted to verify that for a given bit of input code (which happens to be a C++ header) I'd get a given bit of outputted code I wrote a small engine that reads test definitions from XML input files and generates test cases from these expectations.\\n\\nThe problem is I dread going in to modify the code at all.  That and the fact that the unit tests themselves are a: complex, and b: brittle.\\n\\nSo I'm trying to think of alternative approaches to this problem, and it strikes me I'm perhaps tackling it the wrong way.  Maybe I need to focus more on the outcome, IE: does the code I generate actually run and do what I want it to, rather than, does the code look the way I want it to.\\n\\nHas anyone got any experiences of something similar to this they would care to share?\\n\",\n  'completion': \"I started writing up a summary of my experience with my own code generator, then went back and re-read your question and found you had already touched upon the same issues yourself, focus on the execution results instead of the code layout/look.\\n\\nProblem is, this is hard to test, the generated code might not be suited to actually run in the environment of the unit test system, and how do you encode the expected results?\\n\\nI've found that you need to break down the code generator into smaller pieces and unit test those. Unit testing a full code generator is more like integration testing than unit testing if you ask me.\\n\"},\n {'prompt': 'I\\'m creating an ZIP file with ZipFile in Python 2.5, it works ok so far:\\n\\nimport zipfile, os\\n\\nlocfile = \"test.txt\"\\nloczip = os.path.splitext (locfile)[0] + \".zip\"\\nzip = zipfile.ZipFile (loczip, \"w\")\\nzip.write (locfile)\\nzip.close()\\n\\n\\nbut I couldn\\'t find how to encrypt the files in the ZIP file.\\nI could use system and call PKZIP -s, but I suppose there must be a more \"Pythonic\" way.  I\\'m looking for an open source solution.\\n',\n  'completion': 'I created a simple library to create a password encrypted zip file in python. - here\\n\\nimport pyminizip\\n\\ncompression_level = 5 # 1-9\\npyminizip.compress(\"src.txt\", \"dst.zip\", \"password\", compression_level)\\n\\n\\nThe library requires zlib.\\n\\nI have checked that the file can be extracted in WINDOWS/MAC.\\n'},\n {'prompt': \"I've been trying to wrap my head around how threads work in Python, and it's hard to find good information on how they operate. I may just be missing a link or something, but it seems like the official documentation isn't very thorough on the subject, and I haven't been able to find a good write-up.\\n\\nFrom what I can tell, only one thread can be running at once, and the active thread switches every 10 instructions or so?\\n\\nWhere is there a good explanation, or can you provide one? It would also be very nice to be aware of common problems that you run into while using threads with Python.\\n\",\n  'completion': 'Yes, because of the Global Interpreter Lock (GIL) there can only run one thread at a time. Here are some links with some insights about this:\\n\\n\\nhttp://www.artima.com/weblogs/viewpost.jsp?thread=214235\\nhttp://smoothspan.wordpress.com/2007/09/14/guido-is-right-to-leave-the-gil-in-python-not-for-multicore-but-for-utility-computing/\\n\\n\\nFrom the last link an interesting quote:\\n\\n\\n  Let me explain what all that means. \\n  Threads run inside the same virtual\\n  machine, and hence run on the same\\n  physical machine.  Processes can run\\n  on the same physical machine or in\\n  another physical machine.  If you\\n  architect your application around\\n  threads, youâ\\x80\\x99ve done nothing to access\\n  multiple machines.  So, you can scale\\n  to as many cores are on the single\\n  machine (which will be quite a few\\n  over time), but to really reach web\\n  scales, youâ\\x80\\x99ll need to solve the\\n  multiple machine problem anyway.\\n\\n\\nIf you want to use multi core, pyprocessing defines an process based API to do real parallelization. The PEP also includes some interesting benchmarks.\\n'},\n {'prompt': \"A reliable coder friend told me that Python's current multi-threading implementation is seriously buggy - enough to avoid using altogether.  What can said about this rumor?\\n\",\n  'completion': \"Python threads are good for concurrent I/O programming. Threads are swapped out of the CPU as soon as they block waiting for input from file, network, etc. This allows other Python threads to use the CPU while others wait. This would allow you to write a multi-threaded web server or web crawler, for example.\\n\\nHowever, Python threads are serialized by the GIL when they enter interpreter core. This means that if two threads are crunching numbers, only one can run at any given moment. It also means that you can't take advantage of multi-core or multi-processor architectures.\\n\\nThere are solutions like running multiple Python interpreters concurrently, using a C based threading library. This is not for the faint of heart and the benefits might not be worth the trouble. Let's hope for an all Python solution in a future release.\\n\"},\n {'prompt': 'I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?\\n',\n  'completion': \"I loved Dive Into Python, especially if you're a quick study.  The beginning basics are all covered (and may move slowly for you), but the latter few chapters are great learning tools.\\n\\nPlus, Pilgrim is a pretty good writer.\\n\"},\n {'prompt': \"I am starting to use Python (specifically because of Django) and I would like to remove the burden for exhaustive testing by performing some static analysis.  What tools/parameters/etc. exist to detect issues at compile time that would otherwise show up during runtime? (type errors are probably the most obvious case of this, but undefined variables are another big one that could be avoided with an in-depth analysis of the AST.)\\n\\nObviously testing is important, and I don't imply that tests can be obviated entirely; however, there are many runtime errors in python that are not possible in other languages that perform stricter run-time checking -- I'm hoping that there are tools to bring at least some of these capabilities to python as well.\\n\",\n  'completion': \"pylint is the best such tool I've found. Due to Python's nature it's difficult to statically analyze it, but it will catch undefined variables, basic type errors, unused code, etc. You'll want to tweak the configuration file, as by default it outputs many warnings I consider useless or harmful.\\n\\nHere's part of my .pylintrc dealing with warning silencing:\\n\\n[MESSAGES CONTROL]\\n\\n# Brain-dead errors regarding standard language features\\n#   W0142 = *args and **kwargs support\\n#   W0403 = Relative imports\\n\\n# Pointless whinging\\n#   R0201 = Method could be a function\\n#   W0212 = Accessing protected attribute of client class\\n#   W0613 = Unused argument\\n#   W0232 = Class has no __init__ method\\n#   R0903 = Too few public methods\\n#   C0301 = Line too long\\n#   R0913 = Too many arguments\\n#   C0103 = Invalid name\\n#   R0914 = Too many local variables\\n\\n# PyLint's module importation is unreliable\\n#   F0401 = Unable to import module\\n#   W0402 = Uses of a deprecated module\\n\\n# Already an error when wildcard imports are used\\n#   W0614 = Unused import from wildcard\\n\\n# Sometimes disabled depending on how bad a module is\\n#   C0111 = Missing docstring\\n\\n# Disable the message(s) with the given id(s).\\ndisable=W0142,W0403,R0201,W0212,W0613,W0232,R0903,W0614,C0111,C0301,R0913,C0103,F0401,W0402,R0914\\n\\n\"},\n {'prompt': \"In python one can get a dictionary of all local and global variables in the current scope with the built-in functions locals() and globals().  Is there some equivalent way of doing this in javascript?  For instance, I would like to do something like the following:\\n\\nvar foo = function(){ alert('foo'); };\\nvar bar = function(){ alert('bar'); };\\n\\nvar s = 'foo';\\nlocals()[s](); // alerts 'foo'\\n\\n\\nIs this at all possible, or should I just be using a local object for the lookup?\\n\",\n  'completion': '\\nlocals() - No. \\nglobals() - Yes.\\n\\n\\nwindow is a reference to the global scope, like globals() in python.\\n\\nglobals()[\"foo\"]\\n\\n\\nis the same as:\\n\\nwindow[\"foo\"]\\n\\n'},\n {'prompt': \"Is there a way using Python's standard library to easily determine (i.e. one function call) the last day of a given month?\\n\\nIf the standard library doesn't support that, does the dateutil package support this?\\n\",\n  'completion': \"I didn't notice this earlier when I was looking at the documentation for the calendar module, but a method called monthrange provides this information:\\n\\n\\n  monthrange(year, month)\\n  \\xa0\\xa0\\xa0\\xa0Returns weekday of first day of the month and number of days in month, for the specified year and month. \\n\\n\\n>>> import calendar\\n>>> calendar.monthrange(2002,1)\\n(1, 31)\\n>>> calendar.monthrange(2008,2)\\n(4, 29)\\n>>> calendar.monthrange(2100,2)\\n(0, 28)\\n\\n\\nso:\\n\\ncalendar.monthrange(year, month)[1]\\n\\n\\nseems like the simplest way to go.\\n\\nJust to be clear, monthrange supports leap years as well:\\n\\n>>> from calendar import monthrange\\n>>> monthrange(2012, 2)\\n(2, 29)\\n\\n\\nMy previous answer still works, but is clearly suboptimal.\\n\"},\n {'prompt': \"In Django's template language, you can use {% url [viewname] [args] %} to generate a URL to a specific view with parameters. How can you programatically do the same in Python code?\\n\\nWhat I need is to create a list of menu items where each item has name, URL, and an active flag  (whether it's the current page or not). This is because it will be a lot cleaner to do this in Python than the template language.\\n\",\n  'completion': 'If you need to use something similar to the {% url %} template tag in your code, Django provides the django.core.urlresolvers.reverse(). The reverse function has the following signature:\\n\\nreverse(viewname, urlconf=None, args=None, kwargs=None)\\n\\n\\nhttps://docs.djangoproject.com/en/dev/ref/urlresolvers/\\n'},\n {'prompt': \"Let's say you want to save a bunch of files somewhere, for instance in BLOBs. Let's say you want to dish these files out via a web page and have the client automatically open the correct application/viewer.\\n\\nAssumption: The browser figures out which application/viewer to use by the mime-type (content-type?) header in the HTTP response.\\n\\nBased on that assumption, in addition to the bytes of the file, you also want to save the MIME type.\\n\\nHow would you find the MIME type of a file? I'm currently on a Mac, but this should also work on Windows. \\n\\nDoes the browser add this information when posting the file to the web page?\\n\\nIs there a neat python library for finding this information? A WebService or (even better) a downloadable database?\\n\",\n  'completion': 'The python-magic method suggested by toivotuo is outdated. Python-magic\\'s current trunk is at Github and based on the readme there, finding the MIME-type, is done like this.\\n\\n# For MIME types\\n>>> import magic\\n>>> mime = magic.Magic(mime=True)\\n>>> mime.from_file(\"testdata/test.pdf\")\\n\\'application/pdf\\'\\n>>>\\n\\n'},\n {'prompt': 'If possible I want to catch pressure sensitive input from a Wacom tablet in Python. Are there any Python libraries available that can do this?\\n',\n  'completion': 'You could perhaps take a look at the software described here. It is a gnome applet, written in Python.\\n\\nFrom the web site:\\n\\n\"The gnome wacom applet is a small gnome panel applet that shows how much pressure is being applied to your wacom tablet by the current device. Clicking on the panel icon brings up a dialog allowing you to select a different device and check what pressure and tilt information is being recieved from it. This dialog also contains a small drawing test area to give your pen a quick test.\"\\n\\nGoogle is your friend\\n'},\n {'prompt': \"I have 2 time values which have the type datetime.time. I want to find their difference. The obvious thing to do is t1 - t2, but this doesn't work. It works for objects of type datetime.datetime but not for datetime.time. So what is the best way to do this?\\n\",\n  'completion': 'Also a little silly, but you could try picking an arbitrary day and embedding each time in it, using datetime.datetime.combine, then subtracting:\\n\\n>>> import datetime\\n>>> t1 = datetime.time(2,3,4)\\n>>> t2 = datetime.time(18,20,59)\\n>>> dummydate = datetime.date(2000,1,1)\\n>>> datetime.datetime.combine(dummydate,t2) - datetime.datetime.combine(dummydate,t1)\\ndatetime.timedelta(0, 58675)\\n\\n'},\n {'prompt': 'Given a path such as \"mydir/myfile.txt\", how do I find the absolute filepath relative to the current working directory in Python? E.g. on Windows, I might end up with:\\n\\n\"C:/example/cwd/mydir/myfile.txt\"\\n\\n',\n  'completion': '>>> import os\\n>>> os.path.abspath(\"mydir/myfile.txt\")\\n\\n'},\n {'prompt': \"Dictionaries unlike lists are not ordered (and do not have the 'sort' attribute). Therefore, you can not rely on getting the items in the same order when first added. \\n\\nWhat is the easiest way to loop through a dictionary containing strings as the key value and retrieving them in ascending order by key?\\n\\nFor example, you had this:\\n\\nd = {'b' : 'this is b', 'a': 'this is a' , 'c' : 'this is c'}\\n\\n\\nI want to print the associated values in the following sequence sorted by key:\\n\\nthis is a\\nthis is b\\nthis is c\\n\\n\",\n  'completion': 'Do you mean that you need the values sorted by the value of the key?\\nIn that case, this should do it:\\n\\nfor key in sorted(d):\\n    print d[key]\\n\\n\\nEDIT: changed to use sorted(d) instead of sorted(d.keys()), thanks Eli!\\n'},\n {'prompt': \"The documentation for the round() function states that you pass it a number, and the positions past the decimal to round. Thus it should do this:\\n\\nn = 5.59\\nround(n, 1) # 5.6\\n\\n\\nBut, in actuality, good old floating point weirdness creeps in and you get:\\n\\n5.5999999999999996\\n\\n\\nFor the purposes of UI, I need to display 5.6. I poked around the Internet and found some documentation that this is dependent on my implementation of Python. Unfortunately, this occurs on both my Windows dev machine and each Linux server I've tried. See here also.\\n\\nShort of creating my own round library, is there any way around this?\\n\",\n  'completion': 'Formatting works correctly even without having to round:\\n\\n\"%.1f\" % n\\n\\n'},\n {'prompt': \"I'm writing a small web server in Python, using BaseHTTPServer and a custom subclass of BaseHTTPServer.BaseHTTPRequestHandler. Is it possible to make this listen on more than one port?\\n\\nWhat I'm doing now:\\n\\nclass MyRequestHandler(BaseHTTPServer.BaseHTTPRequestHandler):\\n  def doGET\\n  [...]\\n\\nclass ThreadingHTTPServer(ThreadingMixIn, HTTPServer): \\n    pass\\n\\nserver = ThreadingHTTPServer(('localhost', 80), MyRequestHandler)\\nserver.serve_forever()\\n\\n\",\n  'completion': 'Sure; just start two different servers on two different ports in two different threads that each use the same handler.  Here\\'s a complete, working example that I just wrote and tested.  If you run this code then you\\'ll be able to get a Hello World webpage at both http://localhost:1111/ and http://localhost:2222/\\n\\nfrom threading import Thread\\nfrom SocketServer import ThreadingMixIn\\nfrom BaseHTTPServer import HTTPServer, BaseHTTPRequestHandler\\n\\nclass Handler(BaseHTTPRequestHandler):\\n    def do_GET(self):\\n        self.send_response(200)\\n        self.send_header(\"Content-type\", \"text/plain\")\\n        self.end_headers()\\n        self.wfile.write(\"Hello World!\")\\n\\nclass ThreadingHTTPServer(ThreadingMixIn, HTTPServer):\\n    pass\\n\\ndef serve_on_port(port):\\n    server = ThreadingHTTPServer((\"localhost\",port), Handler)\\n    server.serve_forever()\\n\\nThread(target=serve_on_port, args=[1111]).start()\\nserve_on_port(2222)\\n\\n'},\n {'prompt': \"I've created a python object, but I want to send signals on it.  I made it inherit from gobject.GObject, but there doesn't seem to be any way to create a new signal on my object.\\n\",\n  'completion': 'You can also define signals inside the class definition:\\n\\nclass MyGObjectClass(gobject.GObject):\\n    __gsignals__ = {\\n      \"some-signal\": (gobject.SIGNAL_RUN_FIRST, gobject.TYPE_NONE, (object, )),\\n    }\\n\\n\\nThe contents of the tuple are the the same as the three last arguments to gobject.signal_new.\\n'},\n {'prompt': 'Is there any performance difference between tuples and lists when it comes to instantiation and retrieval of elements? \\n',\n  'completion': 'In general, you might expect tuples to be slightly faster. However you should definitely test your specific case (if the difference might impact the performance of your program --  remember \"premature optimization is the root of all evil\").\\n\\nPython makes this very easy: timeit is your friend.\\n\\n$ python -m timeit \"x=(1,2,3,4,5,6,7,8)\"\\n10000000 loops, best of 3: 0.0388 usec per loop\\n\\n$ python -m timeit \"x=[1,2,3,4,5,6,7,8]\"\\n1000000 loops, best of 3: 0.363 usec per loop\\n\\n\\nand...\\n\\n$ python -m timeit -s \"x=(1,2,3,4,5,6,7,8)\" \"y=x[3]\"\\n10000000 loops, best of 3: 0.0938 usec per loop\\n\\n$ python -m timeit -s \"x=[1,2,3,4,5,6,7,8]\" \"y=x[3]\"\\n10000000 loops, best of 3: 0.0649 usec per loop\\n\\n\\nSo in this case, instantiation is almost an order of magnitude faster for the tuple, but item access is actually somewhat faster for the list! So if you\\'re creating a few tuples and accessing them many many times, it may actually be faster to use lists instead.\\n\\nOf course if you want to change an item, the list will definitely be faster since you\\'d need to create an entire new tuple to change one item of it (since tuples are immutable).\\n'},\n {'prompt': \"I am trying to use the import random statement in python, but it doesn't appear to have any methods in it to use.\\n\\nAm I missing something?\\n\",\n  'completion': \"You probably have a file named random.py or random.pyc in your working directory.  That's shadowing the built-in random module.  You need to rename random.py to something like my_random.py and/or remove the random.pyc file.\\n\\nTo tell for sure what's going on, do this:\\n\\n>>> import random\\n>>> print random.__file__\\n\\n\\nThat will show you exactly which file is being imported.\\n\"},\n {'prompt': 'What method do I call to get the name of a class?\\n',\n  'completion': \"In [1]: class test(object):\\n   ...:     pass\\n   ...: \\n\\nIn [2]: test.__name__\\nOut[2]: 'test'\\n\\n\"},\n {'prompt': \"I'm trying to use Python with ReportLab 2.2 to create a PDF report.\\nAccording to the user guide,\\n\\n\\n  Special TableStyle Indeces [sic]\\n  \\n  In any style command the first row index may be set to one of the special strings 'splitlast' or 'splitfirst' to indicate that the style should be used only for the last row of a split table, or the first row of a continuation. This allows splitting tables with nicer effects around the split.\\n\\n\\nI've tried using several style elements, including:\\n\\n('TEXTCOLOR', (0, 'splitfirst'), (1, 'splitfirst'), colors.black) \\n('TEXTCOLOR', (0, 'splitfirst'), (1, 0), colors.black) \\n('TEXTCOLOR', (0, 'splitfirst'), (1, -1), colors.black)\\n\\n\\nand none of these seems to work.  The first generates a TypeError with the message: \\n\\nTypeError: cannot concatenate 'str' and 'int' objects\\n\\n\\nand the latter two generate TypeErrors with the message:\\n\\nTypeError: an integer is required\\n\\n\\nIs this functionality simply broken or am I doing something wrong?  If the latter, what am I doing wrong?\\n\",\n  'completion': 'Well, it looks as if I will be answering my own question.\\n\\nFirst, the documentation flat out lies where it reads \"In any style command the first row index may be set to one of the special strings \\'splitlast\\' or \\'splitfirst\\' to indicate that the style should be used only for the last row of a split table, or the first row of a continuation.\"  In the current release, the \"splitlast\" and \"splitfirst\" row indices break with the aforementioned TypeErrors on the TEXTCOLOR and BACKGROUND commnds.\\n\\nMy suspicion, based on reading the source code, is that only the tablestyle line commands (GRID, BOX, LINEABOVE, and LINEBELOW) are currently compatible with the \\'splitfirst\\' and \\'splitlast\\' row indices.  I suspect that all cell commands break with the aforementioned TypeErrors.\\n\\nHowever, I was able to do what I wanted by subclassing the Table class and overriding the onSplit method.  Here is my code:\\n\\nclass XTable(Table):\\n    def onSplit(self, T, byRow=1):\\n        T.setStyle(TableStyle([\\n          (\\'TEXTCOLOR\\', (0, 1), (1, 1), colors.black)]))\\n\\n\\nWhat this does is apply the text color black to the first and second cell of the second row of each page.  (The first row is a header, repeated by the repeatRows parameter of the Table.)  More precisely, it is doing this to the first and second cell of each frame, but since I am using the SimpleDocTemplate, frames and pages are identical.\\n'},\n {'prompt': \"Since the Google App Engine Datastore is based on Bigtable and we know that's not a relational database, how do you design a database schema/*data model* for applications that use this type of database system?\\n\",\n  'completion': 'Designing a bigtable schema is an open process, and basically requires you to think about:\\n\\n\\nThe access patterns you will be using and how often each will be used\\nThe relationships between your types\\nWhat indices you are going to need\\nThe write patterns you will be using (in order to effectively spread load)\\n\\n\\nGAE\\'s datastore automatically denormalizes your data. That is, each index contains a (mostly) complete copy of the data, and thus every index adds significantly to time taken to perform a write, and the storage space used.\\n\\nIf this were not the case, designing a Datastore schema would be a lot more work: You would have to think carefully about the primary key for each type, and consider the effect of your decision on the locality of data. For example, when rendering a blog post you would probably need to display the comments to go along with it, so each comment\\'s key would probably begin with the associated post\\'s key.\\n\\nWith Datastore, this is not such a big deal: The query you use will look something like \"Select * FROM Comment WHERE post_id = N.\" (If you want to page the comments, you would also have a limit clause, and a possible suffix of \" AND comment_id > last_comment_id\".) Once you add such a query, Datastore will build the index for you, and your reads will be magically fast.\\n\\nSomething to keep in mind is that each additional index creates some additional cost: it is best if you can use as few access patterns as possible, since it will reduce the number of indices GAE will construct, and thus the total storage required by your data.\\n\\nReading over this answer, I find it a little vague. Maybe a hands-on design question would help to scope this down? :-)\\n'},\n {'prompt': 'I wonder why would a C++, C#, Java developer want to learn a dynamic language?\\n\\nAssuming the company won\\'t switch its main development language from C++/C#/Java to a dynamic one what use is there for a dynamic language?\\n\\nWhat helper tasks can be done by the dynamic languages faster or better after only a few days of learning than with the static language that you have been using for several years?\\n\\nUpdate\\n\\nAfter seeing the first few responses it is clear that there are two issues.\\nMy main interest would be something that is justifiable to the employer as an expense.\\nThat is, I am looking for justifications for the employer to finance the learning of a dynamic language. Aside from the obvious that the employee will have broader view, the\\nemployers are usually looking for some \"real\" benefit.\\n',\n  'completion': \"A lot of times some quick task comes up that isn't part of the main software you are developing.  Sometimes the task is one off ie compare this file to the database and let me know the differences.  It is a lot easier to do text parsing in Perl/Ruby/Python than it is in Java or C# (partially because it is a lot easier to use regular expressions).  It will probably take a lot less time to parse the text file using Perl/Ruby/Python (or maybe even vbscript cringe and then load it into the database than it would to create a Java/C# program to do it or to do it by hand.\\n\\nAlso, due to the ease at which most of the dynamic languages parse text, they are great for code generation.  Sure your final project must be in C#/Java/Transact SQL but instead of cutting and pasting 100 times, finding errors, and cutting and pasting another 100 times it is often (but not always) easier just to use a code generator.\\n\\nA recent example at work is we needed to get data from one accounting system into our accounting system.  The system has an import format, but the old system had a completely different format (fixed width although some things had to be matched).  The task is not to create a program to migrate the data over and over again.  It is to shove the data into our system and then maintain it there going forward.  So even though we are a C# and SQL Server shop, I used Python to convert the data into the format that could be imported by our application.  Ultimately it doesn't matter that I used python, it matters that the data is in the system.  My boss was pretty impressed.\\n\\nWhere I often see the dynamic languages used for is testing.  It is much easier to create a Python/Perl/Ruby program to link to a web service and throw some data against it than it is to create the equivalent Java program.  You can also use python to hit against command line programs, generate a ton of garbage (but still valid) test data, etc.. quite easily.\\n\\nThe other thing that dynamic languages are big on is code generation.  Creating the C#/C++/Java code.  Some examples follow:\\n\\nThe first code generation task I often see is people using dynamic languages to maintain constants in the system.  Instead of hand coding a bunch of enums, a dynamic language can be used to fairly easily parse a text file and create the Java/C# code with the enums.\\n\\nSQL is a whole other ball game but often you get better performance by cut and pasting 100 times instead of trying to do a function (due to caching of execution plans or putting complicated logic in a function causing you to go row by row instead of in a set).  In fact it is quite useful to use the table definition to create certain stored procedures automatically.\\n\\nIt is always better to get buy in for a code generator.  But even if you don't, is it more fun to spend time cutting/pasting or is it more fun to create a Perl/Python/Ruby script once and then have that generate the code?  If it takes you hours to hand code something but less time to create a code generator, then even if you use it once you have saved time and hence money.  If it takes you longer to create a code generator than it takes to hand code once but you know you will have to update the code more than once, it may still make sense.  If it takes you 2 hours to hand code, 4 hours to do the generator but you know you'll have to hand code equivalent work another 5 or 6 times than it is obviously better to create the generator.\\n\\nAlso some things are easier with dynamic languages than Java/C#/C/C++.  In particular regular expressions come to mind.  If you start using regular expressions in Perl and realize their value, you may suddenly start making use of the Java regular expression library if you haven't before.  If you have then there may be something else.\\n\\nI will leave you with one last example of a task that would have been great for a dynamic language.  My work mate had to take a directory full of files and burn them to various cd's for various customers.  There were a few customers but a lot of files and you had to look in them to see what they were.  He did this task by hand....A Java/C# program would have saved time, but for one time and with all the development overhead it isn't worth it.  However slapping something together in Perl/Python/Ruby probably would have been worth it.  He spent several hours doing it.  It would have taken less than one to create the Python script to inspect each file, match which customer it goes to, and then move the file to the appropriate place.....Again, not part of the standard job.  But the task came up as a one off.  Is it better to do it yourself, spend the larger amount of time to make Java/C# do the task, or spend a much smaller amount of time doing it in Python/Perl/Ruby.  If you are using C or C++ the point is even more dramatic due to the extra concerns of programming in C or C++ (pointers, no array bounds checking, etc.).\\n\"},\n {'prompt': \"Working with python interactively, it's sometimes necessary to display a result which is some arbitrarily complex data structure (like lists with embedded lists, etc.)\\nThe default way to display them is just one massive linear dump which just wraps over and over and you have to parse carefully to read it.\\n\\nIs there something that will take any python object and display it in a more rational manner. e.g.\\n\\n[0, 1,\\n    [a, b, c],\\n    2, 3, 4]\\n\\n\\ninstead of:\\n\\n[0, 1, [a, b, c], 2, 3, 4]\\n\\n\\nI know that's not a very good example, but I think you get the idea.\\n\",\n  'completion': \"from pprint import pprint\\na = [0, 1, ['a', 'b', 'c'], 2, 3, 4]\\npprint(a)\\n\\n\\nNote that for a short list like my example, pprint will in fact print it all on one line. However, for more complex structures it does a pretty good job of pretty printing data.\\n\"},\n {'prompt': 'Looking for an open source library, for C++, Java, C# or Python, for reading the data from Quicken .qdf files.\\n\\n@Swati:  Quicken .qif format is for transfer only and is not kept up to date by the application  like the .qdf file is.\\n',\n  'completion': \"QDF is proprietary and not really meant for reading other than my Quicken, probably for a reason as it is messy.  \\n\\nI would recommend finding a way to export the qdf into an OFX (Open Financial Exchange) or qif file.  I have done some financial and quickbooks automation and I did something similar.  The problem is if you don't export to an exchange format, each version differs and strange things happen for many conditions that since they aren't documented (QDF) it becomes a bad situation for the programmer.\\n\\nOFX is what allows online banking, brokerages and apps like mint.com securely get financial data.  It is a standard and consistent.  Finding a way to this is much better if at all possible.  \\n\"},\n {'prompt': \"I've gotten to grips with the basics of Python and I've got a small holiday which I want to use some of to learn a little more Python. The problem is that I have no idea what to learn or where to start. I'm primarily web development but in this case I don't know how much difference it will make.\\n\",\n  'completion': 'Well, there are great ressources for advanced Python programming :\\n\\n\\nDive Into Python (read it for free)\\nOnline python cookbooks (e.g. here and there)\\nO\\'Reilly\\'s Python Cookbook (see amazon)\\nA funny riddle game : Python Challenge \\n\\n\\nHere is a list of subjects you must master if you want to write \"Python\" on your resume :\\n\\n\\nlist comprehensions\\niterators and generators\\ndecorators\\n\\n\\nThey are what make Python such a cool language (with the standard library of course, that I keep discovering everyday).\\n'},\n {'prompt': \"I came back today to an old script I had for logging into Gmail via SSL. The script worked fine last time I ran it (several months ago) but now it dies immediately with:\\n\\n<urlopen error The read operation timed out>\\n\\n\\nIf I set the timeout (no matter how long), it dies even more immediately with:\\n\\n<urlopen error The connect operation timed out>\\n\\n\\nThe latter is reproducible with:\\n\\nimport socket\\nsocket.setdefaulttimeout(30000)\\nsock = socket.socket()\\nsock.connect(('www.google.com', 443))\\nssl = socket.ssl(sock)\\n\\n\\nreturning:\\n\\nsocket.sslerror: The connect operation timed out\\n\\n\\nbut I can't seem to reproduce the former and, after much stepping thru the code, I have no clue what's causing any of this.\\n\",\n  'completion': \"import socket\\nsocket.setdefaulttimeout(30000)\\nsock = socket.socket()\\nsock.connect(('www.google.com', 443))\\nssl = socket.ssl(sock)\\nssl.server()\\n--> '/C=US/ST=California/L=Mountain View/O=Google Inc/CN=www.google.com'\\n\\n\\nIt works just fine. I can't reproduce your error.\\n\"},\n {'prompt': \"Basically, something similar to System.Xml.XmlWriter - A streaming XML Writer that doesn't incur much of a memory overhead. So that rules out xml.dom and xml.dom.minidom. Suggestions?\\n\",\n  'completion': 'I think you\\'ll find XMLGenerator from xml.sax.saxutils is the closest thing to what you want.\\n\\n\\nimport time\\nfrom xml.sax.saxutils import XMLGenerator\\nfrom xml.sax.xmlreader import AttributesNSImpl\\n\\nLOG_LEVELS = [\\'DEBUG\\', \\'WARNING\\', \\'ERROR\\']\\n\\n\\nclass xml_logger:\\n    def __init__(self, output, encoding):\\n        \"\"\"\\n        Set up a logger object, which takes SAX events and outputs\\n        an XML log file\\n        \"\"\"\\n        logger = XMLGenerator(output, encoding)\\n        logger.startDocument()\\n        attrs = AttributesNSImpl({}, {})\\n        logger.startElementNS((None, u\\'log\\'), u\\'log\\', attrs)\\n        self._logger = logger\\n        self._output = output\\n        self._encoding = encoding\\n        return\\n\\n    def write_entry(self, level, msg):\\n        \"\"\"\\n        Write a log entry to the logger\\n        level - the level of the entry\\n        msg   - the text of the entry.  Must be a Unicode object\\n        \"\"\"\\n        #Note: in a real application, I would use ISO 8601 for the date\\n        #asctime used here for simplicity\\n        now = time.asctime(time.localtime())\\n        attr_vals = {\\n            (None, u\\'date\\'): now,\\n            (None, u\\'level\\'): LOG_LEVELS[level],\\n            }\\n        attr_qnames = {\\n            (None, u\\'date\\'): u\\'date\\',\\n            (None, u\\'level\\'): u\\'level\\',\\n            }\\n        attrs = AttributesNSImpl(attr_vals, attr_qnames)\\n        self._logger.startElementNS((None, u\\'entry\\'), u\\'entry\\', attrs)\\n        self._logger.characters(msg)\\n        self._logger.endElementNS((None, u\\'entry\\'), u\\'entry\\')\\n        return\\n\\n    def close(self):\\n        \"\"\"\\n        Clean up the logger object\\n        \"\"\"\\n        self._logger.endElementNS((None, u\\'log\\'), u\\'log\\')\\n        self._logger.endDocument()\\n        return\\n\\nif __name__ == \"__main__\":\\n    #Test it out\\n    import sys\\n    xl = xml_logger(sys.stdout, \\'utf-8\\')\\n    xl.write_entry(2, u\"Vanilla log entry\")\\n    xl.close()   \\n\\n\\n\\nYou\\'ll probably want to look at the rest of the article I got that from at http://www.xml.com/pub/a/2003/03/12/py-xml.html.\\n'},\n {'prompt': \"Simple question:\\n\\n\\nWhat Python GUI API's are out there and what are the advantages of any given API?\\n\\n\\nI'm not looking for a religious war here, I'm just wanting to get a good handle on all that is out there in terms of Python GUI APIs.\\n\",\n  'completion': \"Here's a good list.\\n\"},\n {'prompt': \"I need to read selected files, matching on the file name, from a remote zip archive using Python. I don't want to save the full zip to a temporary file (it's not that large, so I can handle everything in memory).\\n\\nI've already written the code and it works, and I'm answering this myself so I can search for it later. But since evidence suggests that I'm one of the dumber participants on Stackoverflow, I'm sure there's room for improvement.\\n\",\n  'completion': 'Here\\'s how I did it (grabbing all files ending in \".ranks\"):\\n\\nimport urllib2, cStringIO, zipfile\\n\\ntry:\\n    remotezip = urllib2.urlopen(url)\\n    zipinmemory = cStringIO.StringIO(remotezip.read())\\n    zip = zipfile.ZipFile(zipinmemory)\\n    for fn in zip.namelist():\\n        if fn.endswith(\".ranks\"):\\n            ranks_data = zip.read(fn)\\n            for line in ranks_data.split(\"\\\\n\"):\\n                # do something with each line\\nexcept urllib2.HTTPError:\\n    # handle exception\\n\\n'},\n {'prompt': \"Given a datetime.time value in Python, is there a standard way to add an integer number of seconds to it, so that 11:34:59 + 3 = 11:35:02, for example?\\n\\nThese obvious ideas don't work:\\n\\n>>> datetime.time(11, 34, 59) + 3\\nTypeError: unsupported operand type(s) for +: 'datetime.time' and 'int'\\n>>> datetime.time(11, 34, 59) + datetime.timedelta(0, 3)\\nTypeError: unsupported operand type(s) for +: 'datetime.time' and 'datetime.timedelta'\\n>>> datetime.time(11, 34, 59) + datetime.time(0, 0, 3)\\nTypeError: unsupported operand type(s) for +: 'datetime.time' and 'datetime.time'\\n\\n\\nIn the end I have written functions like this:\\n\\ndef add_secs_to_time(timeval, secs_to_add):\\n    secs = timeval.hour * 3600 + timeval.minute * 60 + timeval.second\\n    secs += secs_to_add\\n    return datetime.time(secs // 3600, (secs % 3600) // 60, secs % 60)\\n\\n\\nI can't help thinking that I'm missing an easier way to do this though.\\n\\nRelated\\n\\n\\npython time + timedelta equivalent\\n\\n\",\n  'completion': \"You can use full datetime variables with timedelta, and by providing a dummy date then using time to just get the time value.\\n\\nFor example:\\n\\nimport datetime\\na = datetime.datetime(100,1,1,11,34,59)\\nb = a + datetime.timedelta(0,3) # days, seconds, then other fields.\\nprint a.time()\\nprint b.time()\\n\\n\\nresults in the two values, three seconds apart:\\n\\n11:34:59\\n11:35:02\\n\\n\\nYou could also opt for the more readable\\n\\nb = a + datetime.timedelta(seconds=3)\\n\\n\\nif you're so inclined.\\n\\n\\n\\nIf you're after a function that can do this, you can look into using addSecs below:\\n\\nimport datetime\\n\\ndef addSecs(tm, secs):\\n    fulldate = datetime.datetime(100, 1, 1, tm.hour, tm.minute, tm.second)\\n    fulldate = fulldate + datetime.timedelta(seconds=secs)\\n    return fulldate.time()\\n\\na = datetime.datetime.now().time()\\nb = addSecs(a, 300)\\nprint a\\nprint b\\n\\n\\nThis outputs:\\n\\n 09:11:55.775695\\n 09:16:55\\n\\n\"},\n {'prompt': \"How do you generate all the permutations of a list in Python, independently of the type of elements in that list?\\n\\nFor example:\\n\\npermutations([])\\n[]\\n\\npermutations([1])\\n[1]\\n\\npermutations([1, 2])\\n[1, 2]\\n[2, 1]\\n\\npermutations([1, 2, 3])\\n[1, 2, 3]\\n[1, 3, 2]\\n[2, 1, 3]\\n[2, 3, 1]\\n[3, 1, 2]\\n[3, 2, 1]\\n\\n\\nEDIT:\\nEliben pointed to a solution that's similar to mine although simpler, so I'm choosing it as the accepted answer, although Python 2.6+ has a builtin solution in the itertools module:\\n\\nimport itertools\\nitertools.permutations([1, 2, 3])\\n\\n\",\n  'completion': 'And in Python 2.6 onwards:\\n\\nimport itertools\\nitertools.permutations([1,2,3])\\n\\n\\n(returned as a generator.  Use list(permutations(l)) to return as a list.)\\n'},\n {'prompt': \"What's the difference between file and open in Python?  When should I use which one?  (Say I'm in 2.5)\\n\",\n  'completion': 'You should always use open().\\n\\nAs the documentation states:\\n\\n\\n  When opening a file, it\\'s preferable\\n  to use open() instead of invoking this\\n  constructor directly. file is more\\n  suited to type testing (for example,\\n  writing \"isinstance(f, file)\").\\n\\n\\nAlso, file() has been removed since Python 3.0.\\n'},\n {'prompt': 'One of the basic data structures in Python is the dictionary, which allows one to record \"keys\" for looking up \"values\" of any type.  Is this implemented internally as a hash table?  If not, what is it?\\n',\n  'completion': 'Yes, it is a hash mapping or hash table. You can read a description of python\\'s dict implementation, as written by Tim Peters, here.\\n\\nThat\\'s why you can\\'t use something \\'not hashable\\' as a dict key, like a list:\\n\\n>>> a = {}\\n>>> b = [\\'some\\', \\'list\\']\\n>>> hash(b)\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nTypeError: list objects are unhashable\\n>>> a[b] = \\'some\\'\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nTypeError: list objects are unhashable\\n\\n\\nYou can read more about hash tables or check how it has been implemented in python and why it is implemented that way.\\n'},\n {'prompt': \"For example, the standard division symbol '/' rounds to zero:\\n\\n>>> 4 / 100\\n0\\n\\n\\nHowever, I want it to return 0.04. What do I use?\\n\",\n  'completion': 'There are three options:\\n\\n>>> 4 / float(100)\\n0.04\\n>>> 4 / 100.0\\n0.04\\n\\n\\nwhich is the same behavior as the C, C++, Java etc, or \\n\\n>>> from __future__ import division\\n>>> 4 / 100\\n0.04\\n\\n\\nYou can also activate this behavior by passing the argument -Qnew to the Python interpreter:\\n\\n$ python -Qnew\\n>>> 4 / 100\\n0.04\\n\\n\\nThe second option will be the default in Python 3.0. If you want to have the old integer division, you have to use the // operator. \\n\\nEdit: added section about -Qnew, thanks to Î¤Î\\x96Î©Î¤Î\\x96Î\\x99Î\\x9fÎ¥!\\n'},\n {'prompt': 'I\\'m trying to teach Komodo to fire up IDLE when I hit the right keystrokes.  I can use the exact path of the shortcut in start menu in the Windows Explorer location bar to launch IDLE so I was hoping Komodo would be able to use it as well.  But, giving this path to Komodo causes it to say that 1 is returned.  This appears to be a failure as IDLE doesn\\'t start up.\\n\\nI thought I\\'d avoid the shortcut and just use the exact path.  I go to the start menu, find the shortcut for IDLE, right click to look at the properties.  The target is grayed out, but says \"Python 2.5.2\".  The \"Start in\" is set to, \"C:\\\\Python25\\\\\".  The \"Open File Location\" button is also grayed out.\\n\\nHow do I find out where this shortcut is really pointing?  I have tried starting python.exe and pythonw.exe both in C:\\\\Python25, but neither starts up IDLE.\\n',\n  'completion': \"There's a file called idle.py in your Python installation directory in Lib\\\\idlelib\\\\idle.py\\n\\nIf you run that file with Python, then IDLE should start.\\n\\n\\n  c:\\\\Python25\\\\pythonw.exe c:\\\\Python25\\\\Lib\\\\idlelib\\\\idle.py\\n\\n\"},\n {'prompt': \"This came up in  Hidden features of Python, but I can't see good documentation or examples that explain how the feature works.\\n\",\n  'completion': \"The ellipsis is used to slice higher-dimensional data structures. \\n\\nIt's designed to mean at this point, insert as many full slices (:) to extend the multi-dimensional slice to all dimensions.\\n\\nExample:\\n\\n>>> from numpy import arange\\n>>> a = arange(16).reshape(2,2,2,2)\\n\\n\\nNow, you have a 4-dimensional matrix of order 2x2x2x2. To select all first elements in the 4th dimension, you can use the ellipsis notation\\n\\n>>> a[..., 0].flatten()\\narray([ 0,  2,  4,  6,  8, 10, 12, 14])\\n\\n\\nwhich is equivalent to\\n\\n>>> a[:,:,:,0].flatten()\\narray([ 0,  2,  4,  6,  8, 10, 12, 14])\\n\\n\\nIn your own implementations, you're free to ignore the contract mentioned above and use it for whatever you see fit.\\n\"},\n {'prompt': \"Python allocates integers automatically based on the underlying system architecture. Unfortunately I have a huge dataset which needs to be fully loaded into memory. \\n\\nSo, is there a way to force Python to use only 2 bytes for some integers (equivalent of C++ 'short')?\\n\",\n  'completion': 'Nope.  But you can use short integers in arrays:\\n\\nfrom array import array\\na = array(\"h\") # h = signed short, H = unsigned short\\n\\n\\nAs long as the value stays in that array it will be a short integer.\\n\\n\\ndocumentation for the array module\\n\\n'},\n {'prompt': \"My Apache server runs on some non-default (not-root) account. When it tries to run a python script which in turn executes a subversion check-out command, 'svn checkout' fails with the following error message:\\n\\nsvn: Can't open file '/root/.subversion/servers': Permission denied\\n\\n\\nAt the same time running that python script with subversion checkout command inside from command line under the same user account goes on perfectly well.\\n\\nApache server 2.2.6 with mod_python 3.2.8 runs on Fedora Core 6 machine.\\n\\nCan anybody help me out? Thanks a lot.\\n\",\n  'completion': 'It sounds like the environment you apache process is running under is a little unusual.  For whatever reason, svn seems to think the user configuration files it needs are in /root.  You can avoid having svn use the root versions of the files by specifying on the command line which config directory to use, like so:\\n\\nsvn --config-dir /home/myuser/.subversion checkout http://example.com/path\\n\\n\\nWhile not fixing your enviornment, it will at least allow you to have your script run properly...\\n'},\n {'prompt': 'If I open an image with open(\"image.jpg\"), how can I get the RGB values of a pixel, if I have the coordinates of the pixel?\\n\\nThen how can I do the reverse of this? Starting with a blank graphic, \\'write\\' a pixel with a certain RGB value?\\n\\nIt would be so much better if I didn\\'t have to download any additional libraries.\\n',\n  'completion': 'It\\'s probably best to use the Python Image Library to do this which I\\'m afraid is a separate download.\\n\\nThe easiest way to do what you want is via the load() method on the Image object which returns a pixel access object which you can manipulate like an array:\\n\\nfrom PIL import Image\\nim = Image.open(\"dead_parrot.jpg\") #Can be many different formats.\\npix = im.load()\\nprint im.size #Get the width and hight of the image for iterating over\\nprint pix[x,y] #Get the RGBA Value of the a pixel of an image\\npix[x,y] = value # Set the RGBA Value of the image (tuple)\\n\\n\\nAlternatively, look at ImageDraw which gives a much richer API for creating images.\\n'},\n {'prompt': 'is it possible to extend vim functionality via custom extension (preferably, written in Python)?\\n\\nWhat I need ideally is custom command when in command mode. E.g.\\n\\nESC\\n\\n:do_this\\n\\n:do_that\\n',\n  'completion': 'vim supports scripting in python (and in perl as well, I think).\\n\\nYou just have to make sure that the vim distribution you are using has been compiled with python support.\\n\\nIf you are using a Linux system, you can download the source and then compile it with\\n\\n./configure --enable-pythoninterp \\nmake\\nsudo make install\\n\\n\\nInside vim, you can type\\n\\n:version\\n\\n\\nto list the available features; if it has python support, you should see a \\'+python\\' somewhere (a \\'-python\\' otherwise).\\n\\nThen, to check the usage of the python module, you can type\\n\\n:help python\\n\\n\\nP.S: if you\\'re going to compile the vim sources, make sure to check the available configure options, you might need to specify --with-python-config-dir as well.\\n\\nP.P.S: to create a \"custom command in command mode\" (if I understand correctly what you mean), you can create a function \"MyFunction\" in a vim script (using python or the vim scripting language) and then invoke it with \\n\\n:Call MyFunction()\\n\\n\\nCheck \\n\\n:help user-functions\\n\\n\\nfor details\\n'},\n {'prompt': \"I have a python module installed on my system and I'd like to be able to see what functions/classes/methods are available in it.   \\n\\nI want to call the doc function on each one. In ruby I can do something like ClassName.methods to get a list of all the methods available on that class. Is there something similar in python?\\n\\neg. something like:\\n\\nfrom somemodule import foo\\nprint foo.methods # or whatever is the correct method to call\\n\\n\",\n  'completion': 'You can use dir(module) to see all available methods/attributes.  Also check out PyDocs.\\n'},\n {'prompt': 'What would be the quickest way to construct a python binding to a C or C++ library?\\n\\n(using windows if this matters)\\n',\n  'completion': 'I like ctypes a lot, swig always tended to give me problems. Also ctypes has the advantage that you don\\'t need to satisfy any compile time dependency on python, and your binding will work on any python that has ctypes, not just the one it was compiled against.\\n\\nSuppose you have a simple C++ example class you want to talk to in a file called foo.cpp:\\n\\n#include <iostream>\\n\\nclass Foo{\\n    public:\\n        void bar(){\\n            std::cout << \"Hello\" << std::endl;\\n        }\\n};\\n\\n\\nSince ctypes can only talk to C functions, you need to provide those declaring them as extern \"C\"\\n\\nextern \"C\" {\\n    Foo* Foo_new(){ return new Foo(); }\\n    void Foo_bar(Foo* foo){ foo->bar(); }\\n}\\n\\n\\nNext you have to compile this to a shared library\\n\\ng++ -c -fPIC foo.cpp -o foo.o\\ng++ -shared -Wl,-soname,libfoo.so -o libfoo.so  foo.o\\n\\n\\nAnd finally you have to write your python wrapper (e.g. in fooWrapper.py)\\n\\nfrom ctypes import cdll\\nlib = cdll.LoadLibrary(\\'./libfoo.so\\')\\n\\nclass Foo(object):\\n    def __init__(self):\\n        self.obj = lib.Foo_new()\\n\\n    def bar(self):\\n        lib.Foo_bar(self.obj)\\n\\n\\nOnce you have that you can call it like\\n\\nf = Foo()\\nf.bar() #and you will see \"Hello\" on the screen\\n\\n'},\n {'prompt': \"I have Eclipse setup with PyDev and love being able to debug my scripts/apps.  I've just started playing around with Pylons and was wondering if there is a way to start up the paster server through Eclipse so I can debug my webapp?\\n\",\n  'completion': 'Create a new launch configuration (Python Run)\\n\\nMain tab\\n\\nUse paster-script.py as main module (you can find it in the Scripts sub-directory in your python installation directory)\\n\\nDon\\'t forget to add the root folder of your application in the PYTHONPATH zone\\n\\nArguments\\nSet the base directory to the root folder also.\\n\\nAs Program Arguments use \"serve development.ini\" (or whatever you use to debug your app\")\\n\\nCommon Tab\\n\\nCheck allocate console and launch in background\\n'},\n {'prompt': \"What is the best way to check whether a given object is of a given type? How about checking whether the object inherits from a given type?\\n\\nLet's say I have an object o. How do I check whether it's a str?\\n\",\n  'completion': 'To check if the type of o is exactly str:\\n\\ntype(o) is str\\n\\n\\nTo check if o is an instance of str or any subclass of str (this would be the \"canonical\" way):\\n\\nisinstance(o, str)\\n\\n\\nThe following also works, and can be useful in some cases:\\n\\nissubclass(type(o), str)\\ntype(o) in ([str] + str.__subclasses__())\\n\\n\\nSee Built-in Functions in the Python Library Reference for relevant information.\\n\\nOne more note: in this case, you may actually want to use:\\n\\nisinstance(o, basestring)\\n\\n\\nbecause this will also catch Unicode strings (unicode is not a subclass of str; both str and unicode are subclasses of basestring).\\n\\nAlternatively, isinstance accepts a tuple of classes. This will return True if x is an instance of any subclass of any of (str, unicode):\\n\\nisinstance(o, (str, unicode))\\n\\n'},\n {'prompt': 'Is there a framework equivalent to Guice (http://code.google.com/p/google-guice) for Python?\\n',\n  'completion': \"Spring Python is an offshoot of the Java-based Spring Framework and Spring Security, targeted for Python. This project currently contains the following features:\\n\\n\\nInversion Of Control (dependency injection) - use either classic XML, or the python @Object decorator (similar to the Spring JavaConfig subproject) to wire things together. While the @Object format isn't identical to the Guice style (centralized wiring vs. wiring information in each class), it is a valuable way to wire your python app.\\nAspect-oriented Programming - apply interceptors in a horizontal programming paradigm (instead of vertical OOP inheritance) for things like transactions, security, and caching.\\nDatabaseTemplate - Reading from the database requires a monotonous cycle of opening cursors, reading rows, and closing cursors, along with exception handlers. With this template class, all you need is the SQL query and row-handling function. Spring Python does the rest.\\nDatabase Transactions - Wrapping multiple database calls with transactions can make your code hard to read. This module provides multiple ways to define transactions without making things complicated.\\nSecurity - Plugin security interceptors to lock down access to your methods, utilizing both authentication and domain authorization.\\nRemoting - It is easy to convert your local application into a distributed one. If you have already built your client and server pieces using the IoC container, then going from local to distributed is just a configuration change.\\nSamples - to help demonstrate various features of Spring Python, some sample applications have been created:\\n\\nPetClinic - Spring Framework's sample web app has been rebuilt from the ground up using python web containers including: CherryPy. Go check it out for an example of how to use this framework. (NOTE: Other python web frameworks will be added to this list in the future).\\nSpring Wiki - Wikis are powerful ways to store and manage content, so we created a simple one as a demo!\\nSpring Bot - Use Spring Python to build a tiny bot to manage the IRC channel of your open source project.\\n\\n\\n\"},\n {'prompt': 'I\\'m just trying to time a piece of code. The pseudocode looks like:\\n\\nstart = get_ticks()\\ndo_long_code()\\nprint \"It took \" + (get_ticks() - start) + \" seconds.\"\\n\\n\\nHow does this look in Python?\\n\\nMore specifically, how do I get the number of ticks since midnight (or however Python organizes that timing)?\\n',\n  'completion': 'In the time module, there are two timing functions: time and clock. time gives you \"wall\" time, if this is what you care about.\\n\\nHowever, the python docs say that clock should be used for benchmarking. Note that clock behaves different in separate systems:\\n\\n\\non MS Windows, it uses the Win32 function QueryPerformanceCounter(), with \"resolution typically better than a microsecond\". It has no special meaning, it\\'s just a number (it starts counting the first time you call clock in your process).\\n\\n\\n\\n    # ms windows\\n    t0= time.clock()\\n    do_something()\\n    t= time.clock() - t0 # t is wall seconds elapsed (floating point)\\n\\n\\n\\non *nix, clock reports CPU time. Now, this is different, and most probably the value you want, since your program hardly ever is the only process requesting CPU time (even if you have no other processes, the kernel uses CPU time now and then). So, this number, which typically is smallerÂ¹ than the wall time (i.e. time.time() - t0), is more meaningful when benchmarking code:\\n\\n\\n\\n    # linux\\n    t0= time.clock()\\n    do_something()\\n    t= time.clock() - t0 # t is CPU seconds elapsed (floating point)\\n\\n\\nApart from all that, the timeit module has the Timer class that is supposed to use what\\'s best for benchmarking from the available functionality.\\n\\nÂ¹ unless threading gets in the wayâ\\x80¦\\n\\nÂ² Python â\\x89¥3.3: there are time.perf_counter() and time.process_time(). perf_counter is being used by the timeit module.\\n'},\n {'prompt': 'I have one thread that writes results into a Queue.\\n\\nIn another thread (GUI), I periodically (in the IDLE event) check if there are results in the queue, like this:\\n\\ndef queue_get_all(q):\\n    items = []\\n    while 1:\\n        try:\\n            items.append(q.get_nowait())\\n        except Empty, e:\\n            break\\n    return items\\n\\n\\nIs this a good way to do it ? \\n\\nEdit:\\n\\n\\n  I\\'m asking because sometimes the\\n  waiting thread gets stuck for a few\\n  seconds without taking out new\\n  results.\\n\\n\\nThe \"stuck\" problem turned out to be because I was doing the processing in the idle event handler, without making sure that such events are actually generated by calling wx.WakeUpIdle, as is recommended.\\n',\n  'completion': \"If you're always pulling all available items off the queue, is there any real point in using a queue, rather than just a list with a lock?  ie:\\n\\nfrom __future__ import with_statement\\nimport threading\\n\\nclass ItemStore(object):\\n    def __init__(self):\\n        self.lock = threading.Lock()\\n        self.items = []\\n\\n    def add(self, item):\\n        with self.lock:\\n            self.items.append(item)\\n\\n    def getAll(self):\\n        with self.lock:\\n            items, self.items = self.items, []\\n        return items\\n\\n\\nIf you're also pulling them individually, and making use of the blocking behaviour for empty queues, then you should use Queue, but your use case looks much simpler, and might be better served by the above approach.\\n\\n[Edit2]  I'd missed the fact that you're polling the queue from an idle loop, and from your update, I see that the problem isn't related to contention, so the below approach isn't really relevant to your problem.  I've left it in in case anyone finds a blocking variant of this useful:\\n\\nFor cases where you do want to block until you get at least one result, you can modify the above code to wait for data to become available through being signalled by the producer thread.  Eg.\\n\\nclass ItemStore(object):\\n    def __init__(self):\\n        self.cond = threading.Condition()\\n        self.items = []\\n\\n    def add(self, item):\\n        with self.cond:\\n            self.items.append(item)\\n            self.cond.notify() # Wake 1 thread waiting on cond (if any)\\n\\n    def getAll(self, blocking=False):\\n        with self.cond:\\n            # If blocking is true, always return at least 1 item\\n            while blocking and len(self.items) == 0:\\n                self.cond.wait()\\n            items, self.items = self.items, []\\n        return items\\n\\n\"},\n {'prompt': 'Coming from a C# background the naming convention for variables and method names are usually either CamelCase or Pascal Case:\\n\\n// C# example\\nstring thisIsMyVariable = \"a\"\\npublic void ThisIsMyMethod()\\n\\n\\nIn Python, I have seen the above but I have also seen underscores being used:\\n\\n# python example\\nthis_is_my_variable = \\'a\\'\\ndef this_is_my_function():\\n\\n\\nIs there a more preferable, definitive coding style for Python?\\n',\n  'completion': \"See Python PEP 8.\\n\\n\\n  Function names should be lowercase,\\n  with words separated by underscores as\\n  necessary to improve readability.\\n  \\n  mixedCase is allowed only in contexts\\n  where that's already the prevailing\\n  style\\n\\n\\nVariables...\\n\\n\\n  Use the function naming rules:\\n  lowercase with words separated by\\n  underscores as necessary to improve\\n  readability.\\n\\n\\nPersonally, I deviate from this because I also prefer mixedCase over lower_case for my own projects.\\n\"},\n {'prompt': 'I\\'ve done some Python but have just now starting to use Ruby\\nI could use a good explanation of the difference between \"self\" in these two languages.  \\n\\nObvious on first glance:\\nSelf is not a keyword in Python, but there is a \"self-like\" value no matter what you call it.\\nPython methods receive self as an explicit argument, whereas Ruby does not.\\nRuby sometimes has methods explicitly defined as part of self using dot notation.\\n\\nInitial Googling reveals\\nhttp://rubylearning.com/satishtalim/ruby_self.html\\nhttp://www.ibiblio.org/g2swap/byteofpython/read/self.html  \\n',\n  'completion': 'Python is designed to support more than just object-oriented programming. Preserving the same interface between methods and functions lets the two styles interoperate more cleanly.\\n\\nRuby was built from the ground up to be object-oriented. Even the literals are objects (evaluate 1.class and you get Fixnum). The language was built such that self is a reserved keyword that returns the current instance wherever you are.\\n\\nIf you\\'re inside an instance method of one of your class, self is a reference to said instance. \\n\\nIf you\\'re in the definition of the class itself (not in a method), self is the class itself:\\n\\nclass C\\n  puts \"I am a #{self}\"\\n  def instance_method\\n    puts \\'instance_method\\'\\n  end\\n  def self.class_method\\n    puts \\'class_method\\'\\n  end\\nend\\n\\n\\nAt class definition time, \\'I am a C\\' will be printed.\\n\\nThe straight \\'def\\' defines an instance method, whereas the \\'def self.xxx\\' defines a class method.\\n\\nc=C.new\\n\\nc.instance_method\\n#=> instance_method\\nC.class_method\\n#=> class_method\\n\\n'},\n {'prompt': 'The standalone flashplayer takes no arguments other than a .swf file when you launch it from the command line. I need the player to go full screen, no window borders and such. This can be accomplished by hitting ctrl+f once the program has started. I want to do this programmatically as I need it to launch into full screen without any human interaction.\\n\\nMy guess is that I need to some how get a handle to the window and then send it an event that looks like the \"ctrl+f\" keystroke. \\n\\nIf it makes any difference, it looks like flashplayer is a gtk application and I have python with pygtk installed.\\n\\nUPDATE (the solution I used... thanks to ypnos\\' answer):\\n\\n./flashplayer http://example.com/example.swf & sleep 3 && ~/xsendkey -window \"Adobe Flash Player 10\" Control+F\\n\\n',\n  'completion': 'You can use a dedicated application which sends the keystroke to the window manager, which should then pass it to flash, if the window starts as being the active window on the screen. This is quite error prone, though, due to delays between starting flash and when the window will show up.\\n\\nFor example, your script could do something like this:\\nflashplayer *.swf\\nsleep 3 && xsendkey Control+F\\n\\nThe application xsendkey can be found here: http://people.csail.mit.edu/adonovan/hacks/xsendkey.html\\nWithout given a specific window, it will send it to the root window, which is handled by your window manager. You could also try to figure out the Window id first, using xprop or something related to it.\\n\\nAnother option is a Window manager, which is able to remember your settings and automatically apply them. Fluxbos for example provides this feature. You could set fluxbox to make the Window decor-less and stretch it over the whole screen, if flashplayer supports being resized. This is also not-so-nice, as it would probably affect all the flashplayer windows you open ever.\\n'},\n {'prompt': 'How do I write a decorator that restores the current working directory to what it was before the decorated function was called?  In other words, if I use the decorator on a function that does an os.chdir(), the cwd will not be changed after the function is called.\\n',\n  'completion': 'The answer for a decorator has been given; it works at the function definition stage as requested.\\n\\nWith Python 2.5+, you also have an option to do that at the function call stage using a context manager:\\n\\nfrom __future__ import with_statement # needed for 2.5 â\\x89¤ Python < 2.6\\nimport contextlib, os\\n\\n@contextlib.contextmanager\\ndef remember_cwd():\\n    curdir= os.getcwd()\\n    try: yield\\n    finally: os.chdir(curdir)\\n\\n\\nwhich can be used if needed at the function call time as:\\n\\nprint \"getcwd before:\", os.getcwd()\\nwith remember_cwd():\\n    walk_around_the_filesystem()\\nprint \"getcwd after:\", os.getcwd()\\n\\n\\nIt\\'s a nice option to have.\\n\\nEDIT: I added error handling as suggested by codeape. Since my answer has been voted up, it\\'s fair to offer a complete answer, all other issues aside.\\n'},\n {'prompt': \"I'm writing a simulator in Python, and am curious about options and opinions regarding basic 2D animations. By animation, I'm referring to rendering on the fly, not displaying prerendered images.\\n\\nI'm currently using matplotlib (Wxagg backend), and it's possible that I'll be able to continue using it, but I suspect it won't be able to sufficiently scale in terms of performance or capabilities.\\n\\nRequirements are:\\n\\n\\nCross-platform (Linux, MacOS X,\\nWindows)\\nLow complexity overhead\\nPlays well with wxpython (at least won't step on each other's toes unduly)\\nInteractivity. Detect when objects are clicked on, moused over, etc. \\n\\n\\nNote that high performance isn't on the list, but the ability to handle ~100 bitmap objects on the screen would be good.\\n\\nYour thoughts?\\n\",\n  'completion': \"I am a fan of pyglet which is a completely self contained library for doing graphical work under win32, linux, and OS X. \\n\\nIt has very low overhead, and you can see this for yourself from the tutorial on the website. It should play well with wxpython, or at least I seem to recall posts to the mailing list about wxpython and pyglet being used together.\\n\\nIt however does not offer selection of objects via mouse clicks - this you will have to handle yourself. Generally speaking for a 2D application this is not too difficult to do.\\n\\nmactorii is an OS X application of mine written in pure python+pyglet, and has some basic animation (scrolling) and click detection. It doesn't use wxpython, but perhaps it will give you an idea of what is involved. Note however mactorii is using the old pyglet api, so the run loop I have in there is obsolete. I will get around to updating it one day... :P\\n\"},\n {'prompt': \"I'm developing a website (in Django) that uses OpenID to authenticate users. As I'm currently only running on my local machine I can't authenticate using one of the OpenID providers on the web. So I figure I need to run a local OpenID server that simply lets me type in a username and then passes that back to my main app.\\n\\nDoes such an OpenID dev server exist? Is this the best way to go about it?\\n\",\n  'completion': 'The libraries at OpenID Enabled ship with examples that are sufficient to run a local test provider.  Look in the examples/djopenid/ directory of the python-openid source distribution.  Running that will give you an instance of this test provider.\\n'},\n {'prompt': \"This is really two questions, but they are so similar, and to keep it simple, I figured I'd just roll them together:\\n\\n\\nFirstly: Given an established python project, what are some decent ways to speed it up beyond just plain in-code optimization?\\nSecondly:  When writing a program from scratch in python, what are some good ways to greatly improve performance?\\n\\n\\nFor the first question, imagine you are handed a decently written project and you need to improve performance, but you can't seem to get much of a gain through refactoring/optimization.  What would you do to speed it up in this case short of rewriting it in something like C?\\n\",\n  'completion': 'Regarding \"Secondly: When writing a program from scratch in python, what are some good ways to greatly improve performance?\"\\n\\nRemember the Jackson rules of optimization: \\n\\n\\nRule 1: Don\\'t do it.\\nRule 2 (for experts only): Don\\'t do it yet.\\n\\n\\nAnd the Knuth rule:\\n\\n\\n\"Premature optimization is the root of all evil.\"\\n\\n\\nThe more useful rules are in the General Rules for Optimization.\\n\\n\\nDon\\'t optimize as you go.  First get it right.  Then get it fast.  Optimizing a wrong program is still wrong.\\nRemember the 80/20 rule.\\nAlways run \"before\" and \"after\" benchmarks.  Otherwise, you won\\'t know if you\\'ve found the 80%.\\nUse the right algorithms and data structures.  This rule should be first.  Nothing matters as much as algorithm and data structure.\\n\\n\\nBottom Line\\n\\nYou can\\'t prevent or avoid the \"optimize this program\" effort.  It\\'s part of the job.  You have to plan for it and do it carefully, just like the design, code and test activities.\\n'},\n {'prompt': 'I have a list string tag.\\n\\nI am trying to initialize a dictionary with the key as the tag string and values as the array index.\\n\\nfor i, ithTag in enumerate(tag):\\n    tagDict.update(ithTag=i)\\n\\n\\nThe above returns me {\\'ithTag\\': 608}  608 is the 608th index\\n\\nMy problem is that while the i is being interpreted as a variable, Python is treating the \"ithTag\" as a string instead of a variable.\\n\\nI\\'m confused, it is kind of hard to google these kind of specific questions.  I hope I worded the title of this question correctly,\\n\\nThanks!\\n',\n  'completion': 'You actually want to do this:\\n\\nfor i, tag in enumerate(tag):\\n    tagDict[tag] = i\\n\\n\\nThe .update() method is used for updating a dictionary using another dictionary, not for changing a single key/value pair.\\n'},\n {'prompt': \"py2exe does not work with the standard email module\\n\\nHello. I am trying to use py2exe for converting a script into an exe. The build process shows this:\\n\\n\\n\\nThe following modules appear to be missing\\n\\n['email.Encoders', 'email.Generator', 'email.Iterators', 'email.MIMEBase', 'email.MIMEMultipart', 'email.MIMEText', 'email.Utils', 'email.base64MIME']\\n\\nThe executable does not work. The referenced modules are not included. I researched this on the Internet and I found out that py2exe has a problem with the Lazy import used in the standard lib email module. Unfortunately I have not succeeded in finding a workaround for this problem. Can anyone help?\\n\\nThank you,\\n\\nP.S.\\nImports in the script look like this:\\n\\nCode: Select all\\n    import string,time,sys,os,smtplib\\n    from email.MIMEMultipart import MIMEMultipart\\n    from email.MIMEBase import MIMEBase\\n    from email.MIMEText import MIMEText\\n    from email import Encoders\\n\",\n  'completion': 'Have a look at this question how-to-package-twisted-program-with-py2exe it seems to be the same problem.\\n\\nThe answer given there is to explicitly include the modules on the command line to py2exe.\\n'},\n {'prompt': \"I've discovered that cElementTree is about 30 times faster than xml.dom.minidom and I'm rewriting my XML encoding/decoding code. However, I need to output XML that contains CDATA sections and there doesn't seem to be a way to do that with ElementTree.\\n\\nCan it be done?\\n\",\n  'completion': 'After a bit of work, I found the answer myself. Looking at the ElementTree.py source code, I found there was special handling of XML comments and preprocessing instructions. What they do is create a factory function for the special element type that uses a special (non-string) tag value to differentiate it from regular elements.\\n\\ndef Comment(text=None):\\n    element = Element(Comment)\\n    element.text = text\\n    return element\\n\\n\\nThen in the _write function of ElementTree that actually outputs the XML, there\\'s a special case handling for comments:\\n\\nif tag is Comment:\\n    file.write(\"<!-- %s -->\" % _escape_cdata(node.text, encoding))\\n\\n\\nIn order to support CDATA sections, I create a factory function called CDATA, extended the ElementTree class and changed the _write function to handle the CDATA elements.\\n\\nThis still doesn\\'t help if you want to parse an XML with CDATA sections and then output it again with the CDATA sections, but it at least allows you to create XMLs with CDATA sections programmatically, which is what I needed to do.\\n\\nThe implementation seems to work with both ElementTree and cElementTree.\\n\\nimport elementtree.ElementTree as etree\\n#~ import cElementTree as etree\\n\\ndef CDATA(text=None):\\n    element = etree.Element(CDATA)\\n    element.text = text\\n    return element\\n\\nclass ElementTreeCDATA(etree.ElementTree):\\n    def _write(self, file, node, encoding, namespaces):\\n        if node.tag is CDATA:\\n            text = node.text.encode(encoding)\\n            file.write(\"\\\\n<![CDATA[%s]]>\\\\n\" % text)\\n        else:\\n            etree.ElementTree._write(self, file, node, encoding, namespaces)\\n\\nif __name__ == \"__main__\":\\n    import sys\\n\\n    text = \"\"\"\\n    <?xml version=\\'1.0\\' encoding=\\'utf-8\\'?>\\n    <text>\\n    This is just some sample text.\\n    </text>\\n    \"\"\"\\n\\n    e = etree.Element(\"data\")\\n    cdata = CDATA(text)\\n    e.append(cdata)\\n    et = ElementTreeCDATA(e)\\n    et.write(sys.stdout, \"utf-8\")\\n\\n'},\n {'prompt': 'I use a 3rd party tool that outputs a file in Unicode format.  However, I prefer it to be in ASCII. The tool does not have settings to change the file format.\\n\\nWhat is the best way to convert the entire file format using Python?\\n',\n  'completion': 'You can convert the file easily enough just using the unicode function, but you\\'ll run into problems with Unicode characters without a straight ASCII equivalent.\\n\\nThis blog recommends the unicodedata  module, which seems to take care of roughly converting characters without direct corresponding ASCII values, e.g.\\n\\n>>> title = u\"KlÃ¼ft skrÃ¤ms infÃ¶r pÃ¥ fÃ©dÃ©ral Ã©lectoral groÃ\\x9fe\"\\n\\n\\nis typically converted to \\n\\nKlft skrms infr p fdral lectoral groe\\n\\n\\nwhich is pretty wrong. However, using the unicodedata module, the result can be much closer to the original text:\\n\\n>>> import unicodedata\\n>>> unicodedata.normalize(\\'NFKD\\', title).encode(\\'ascii\\',\\'ignore\\')\\n\\'Kluft skrams infor pa federal electoral groe\\'\\n\\n'},\n {'prompt': \"Sometimes I break long conditions in IFs to several lines. The most obvious way to do this is:\\n\\n  if (cond1 == 'val1' and cond2 == 'val2' and\\n      cond3 == 'val3' and cond4 == 'val4'):\\n      do_something\\n\\n\\nIsn't very very appealing visually, because the action blends with the conditions. However, it is the natural way using correct Python indentation of 4 spaces.\\n\\nFor the moment I'm using:\\n\\n  if (    cond1 == 'val1' and cond2 == 'val2' and\\n          cond3 == 'val3' and cond4 == 'val4'):\\n      do_something\\n\\n\\nBut this isn't very pretty. :-)\\n\\nCan you recommend an alternative way ?\\n\",\n  'completion': \"You don't need to use 4 spaces on your second conditional line.  Maybe use:\\n\\nif (cond1 == 'val1' and cond2 == 'val2' and \\n       cond3 == 'val3' and cond4 == 'val4'):\\n    do_something\\n\\n\\nAlso, don't forget the whitespace is more flexible than you might think:\\n\\nif (   \\n       cond1 == 'val1' and cond2 == 'val2' and \\n       cond3 == 'val3' and cond4 == 'val4'\\n   ):\\n    do_something\\nif    (cond1 == 'val1' and cond2 == 'val2' and \\n       cond3 == 'val3' and cond4 == 'val4'):\\n    do_something\\n\\n\\nBoth of those are fairly ugly though.\\n\\nMaybe lose the brackets (the Style Guide discourages this though)?\\n\\nif cond1 == 'val1' and cond2 == 'val2' and \\\\\\n   cond3 == 'val3' and cond4 == 'val4':\\n    do_something\\n\\n\\nThis at least gives you some differentiation.\\n\\nOr even:\\n\\nif cond1 == 'val1' and cond2 == 'val2' and \\\\\\n                       cond3 == 'val3' and \\\\\\n                       cond4 == 'val4':\\n    do_something\\n\\n\\nI think I prefer:\\n\\nif cond1 == 'val1' and \\\\\\n   cond2 == 'val2' and \\\\\\n   cond3 == 'val3' and \\\\\\n   cond4 == 'val4':\\n    do_something\\n\\n\\nHere's the Style Guide, which (since 2010) recommends using brackets.\\n\"},\n {'prompt': \"Still 'diving in' to Python, and want to make sure I'm not overlooking something. I wrote a script that extracts files from several zip files, and saves the extracted files together in one directory. To prevent duplicate filenames from being over-written, I wrote this little function - and I'm just wondering if there is a better way to do this?\\nThanks!\\n\\ndef unique_filename(file_name):\\ncounter = 1\\nfile_name_parts = os.path.splitext(file_name) # returns ('/path/file', '.ext')\\nwhile os.path.isfile(file_name): \\n    file_name = file_name_parts[0] + '_' + str(counter) + file_name_parts[1]\\n    counter += 1\\nreturn file_name\\n\\n\\nI really do require the files to be in a single directory, and numbering duplicates is definitely acceptable in my case, so I'm not looking for a more robust method (tho' I suppose any pointers are welcome), but just to make sure that what this accomplishes is getting done the right way.\\n\",\n  'completion': 'One issue is that there is a race condition in your above code, since there is a gap between testing for existance, and creating the file.  There may be security implications to this (think about someone maliciously inserting a symlink to a sensitive file which they wouldn\\'t be able to overwrite, but your program running with a higher privilege could)  Attacks like these are why things like os.tempnam() are deprecated.\\n\\nTo get around it, the best approach is to actually try create the file in such a way that you\\'ll get an exception if it fails, and on success, return the actually opened file object.  This can be done with the lower level os.open functions, by passing both the os.O_CREAT and os.O_EXCL flags.  Once opened, return the actual file (and optionally filename) you create.  Eg, here\\'s your code modified to use this approach (returning a (file, filename) tuple):\\n\\ndef unique_file(file_name):\\n    counter = 1\\n    file_name_parts = os.path.splitext(file_name) # returns (\\'/path/file\\', \\'.ext\\')\\n    while 1:\\n        try:\\n            fd = os.open(file_name, os.O_CREAT | os.O_EXCL | os.O_RDRW)\\n            return os.fdopen(fd), file_name\\n        except OSError:\\n            pass\\n        file_name = file_name_parts[0] + \\'_\\' + str(counter) + file_name_parts[1]\\n        counter += 1\\n\\n\\n[Edit]  Actually, a better way, which will handle the above issues for you, is probably to use the tempfile module, though you may lose some control over the naming.  Here\\'s an example of using it (keeping a similar interface):\\n\\ndef unique_file(file_name):\\n    dirname, filename = os.path.split(file_name)\\n    prefix, suffix = os.path.splitext(filename)\\n\\n    fd, filename = tempfile.mkstemp(suffix, prefix+\"_\", dirname)\\n    return os.fdopen(fd), filename\\n\\n>>> f, filename=unique_file(\\'/home/some_dir/foo.txt\\')\\n>>> print filename\\n/home/some_dir/foo_z8f_2Z.txt\\n\\n\\nThe only downside with this approach is that you will always get a filename with some random characters in it, as there\\'s no attempt to create an unmodified file (/home/some_dir/foo.txt) first.\\nYou may also want to look at tempfile.TemporaryFile and NamedTemporaryFile, which will do the above and also automatically delete from disk when closed.\\n'},\n {'prompt': 'In the Python documentation\\nit says:\\n\\n\\n  A thread can be flagged as a \"daemon thread\". The significance of this\\n  flag is that the entire Python program exits when only daemon threads\\n  are left. The initial value is inherited from the creating thread.\\n\\n\\nDoes anyone have a clearer explanation of what that means or a practical example showing where you would want to set threads as daemonic?\\n\\n\\n\\nTo clarify for me:\\n\\nso the only time you wouldn\\'t set threads as daemonic is if you wanted them to continue running after the main thread exits?\\n',\n  'completion': \"Some threads do background tasks, like sending keepalive packets, or performing periodic garbage collection, or whatever. These are only useful when the main program is running, and it's okay to kill them off once the other, non-daemon, threads have exited.\\n\\nWithout daemon threads, you'd have to keep track of them, and tell them to exit, before your program can completely quit. By setting them as daemon threads, you can let them run and forget about them, and when your program quits, any daemon threads are killed automatically.\\n\"},\n {'prompt': \"dir(re.compile(pattern)) \\n\\n\\ndoes not return pattern as one of the lists's elements. Namely it returns:\\n\\n['__copy__', '__deepcopy__', 'findall', 'finditer', 'match', 'scanner', 'search', 'split', 'sub', 'subn']\\n\\n\\nAccording to the manual, it is supposed to contain \\n\\n\\n  the object's attributes' names, the\\n  names of its class's attributes, and\\n  recursively of the attributes of its\\n  class's base classes.\\n\\n\\nIt says also that\\n\\n\\n  The list is not necessarily complete.\\n\\n\\nIs there a way to get the complete list? I always assumed that dir returns a complete list but apparently it does not...\\n\\nAlso: is there a way to list only attributes? Or only methods?\\n\\nEdit: this is actually a bug in python -> supposedly it is fixed in the 3.0 branch (and perhaps also in 2.6)\\n\",\n  'completion': 'For the complete list of attributes, the short answer is: no. The problem is that the attributes are actually defined as the arguments accepted by the getattr built-in function. As the user can reimplement __getattr__, suddenly allowing any kind of attribute, there is no possible generic way to generate that list. The dir function returns the keys in the __dict__ attribute, i.e. all the attributes accessible if the __getattr__ method is not reimplemented.\\n\\nFor the second question, it does not really make sense. Actually, methods are callable attributes, nothing more. You could though filter callable attributes, and, using the inspect module determine the class methods, methods or functions.\\n'},\n {'prompt': 'How, in the simplest possible way, distinguish between Windows XP and Windows Vista, using Python and pywin32 or wxPython?\\n\\nEssentially, I need a function that called will return True iff current OS is Vista:\\n\\n>>> isWindowsVista()\\nTrue\\n\\n',\n  'completion': \"Python has the lovely 'platform' module to help you out.\\n\\n>>> import platform\\n>>> platform.win32_ver()\\n('XP', '5.1.2600', 'SP2', 'Multiprocessor Free')\\n>>> platform.system()\\n'Windows'\\n>>> platform.version()\\n'5.1.2600'\\n>>> platform.release()\\n'XP'\\n\\n\\nNOTE: As mentioned in the comments proper values may not be returned when using older versions of python.\\n\"},\n {'prompt': \"I have a dict, which I need to pass key/values as keyword arguments.. For example..\\n\\nd_args = {'kw1': 'value1', 'kw2': 'value2'}\\nexample(**d_args)\\n\\n\\nThis works fine, but if there are values in the d_args dict that are not accepted by the example function, it obviously dies.. Say, if the example function is defined as def example(kw2):\\n\\nThis is a problem since I don't control either the generation of the d_args, or the example function.. They both come from external modules, and example only accepts some of the keyword-arguments from the dict..\\n\\nIdeally I would just do\\n\\nparsed_kwargs = feedparser.parse(the_url)\\nvalid_kwargs = get_valid_kwargs(parsed_kwargs, valid_for = PyRSS2Gen.RSS2)\\nPyRSS2Gen.RSS2(**valid_kwargs)\\n\\n\\nI will probably just filter the dict, from a list of valid keyword-arguments, but I was wondering: Is there a way to programatically list the keyword arguments the a specific function takes?\\n\",\n  'completion': \"A little nicer than inspecting the code object directly and working out the variables is to use the inspect module.\\n\\n>>> import inspect\\n>>> def func(a,b,c=42, *args, **kwargs): pass\\n>>> inspect.getargspec(func)\\n(['a', 'b', 'c'], 'args', 'kwargs', (42,))\\n\\n\\nIf you want to know if its callable with a particular set of args, you need the args without a default already specified.  These can be got by:\\n\\ndef getRequiredArgs(func):\\n    args, varargs, varkw, defaults = inspect.getargspec(func)\\n    if defaults:\\n        args = args[:-len(defaults)]\\n    return args   # *args and **kwargs are not required, so ignore them.\\n\\n\\nThen a function to tell what you are missing from your particular dict is:\\n\\ndef missingArgs(func, argdict):\\n    return set(getRequiredArgs(func)).difference(argdict)\\n\\n\\nSimilarly, to check for invalid args, use:\\n\\ndef invalidArgs(func, argdict):\\n    args, varargs, varkw, defaults = inspect.getargspec(func)\\n    if varkw: return set()  # All accepted\\n    return set(argdict) - set(args)\\n\\n\\nAnd so a full test if it is callable is :\\n\\ndef isCallableWithArgs(func, argdict):\\n    return not missingArgs(func, argdict) and not invalidArgs(func, argdict)\\n\\n\\n(This is good only as far as python's arg parsing.  Any runtime checks for invalid values in kwargs obviously can't be detected.)\\n\"},\n {'prompt': \"The only thing I can get python omnicomplete to work with are system modules. I get nothing for help with modules in my site-packages or modules that I'm currently working on.\\n\",\n  'completion': \"Once I generated ctags for one of my site-packages, it started working for that package -- so I'm guessing that the omnicomplete function depends on ctags for non-sys modules.\\n\\nEDIT: Not true at all.\\n\\nHere's the problem -- poor testing on my part -- omnicomplete WAS working for parts of my project, just not most of it.\\n\\nThe issue was that I'm working on a django project, and in order to import django.db, you need to have an environment variable set. Since I couldn't import django.db, any class that inherited from django.db, or any module that imported a class that inherited from django.db wouldn't complete.\\n\"},\n {'prompt': 'In many symbolic math systems, such as Matlab or Mathematica, you can use a variable like Ans or % to retrieve the last computed value. Is there a similar facility in the Python shell?\\n',\n  'completion': 'Underscore.\\n\\n>>> 5+5\\n10\\n>>> _\\n10\\n>>> _ + 5\\n15\\n>>> _\\n15\\n\\n'},\n {'prompt': \"Is there any meaningful distinction between:\\n\\nclass A(object):\\n    foo = 5   # some default value\\n\\n\\nvs.\\n\\nclass B(object):\\n    def __init__(self, foo=5):\\n        self.foo = foo\\n\\n\\nIf you're creating a lot of instances, is there any difference in performance or space requirements for the two styles? When you read the code, do you consider the meaning of the two styles to be significantly different?\\n\",\n  'completion': 'Beyond performance considerations, there is a significant semantic difference.  In the class attribute case, there is just one object referred to.  In the instance-attribute-set-at-instantiation, there can be multiple objects referred to.  For instance\\n\\n>>> class A: foo = []\\n>>> a, b = A(), A()\\n>>> a.foo.append(5)\\n>>> b.foo\\n[5]\\n>>> class A:\\n...  def __init__(self): self.foo = []\\n>>> a, b = A(), A()\\n>>> a.foo.append(5)\\n>>> b.foo    \\n[]\\n\\n'},\n {'prompt': \"I currently do my textfile manipulation through a bunch of badly remembered AWK, sed, Bash and a tiny bit of Perl.\\n\\nI've seen mentioned a few places that python is good for this kind of thing, I know a little and I would like to know more. Is Python a good choice for this, and is there a good book or guide to learning how to use Python to replace shell scripting, AWK, sed and friends?\\n\",\n  'completion': 'Any shell has several sets of features.\\n\\n\\nThe Essential Linux/Unix commands.  All of these are available through the subprocess library.  This isn\\'t always the best first choice for doing all external commands.  Look also at shutil for some commands that are separate Linux commands, but you could probably implement directly in your Python scripts.  Another huge batch of Linux commands are in the os library; you can do these more simply in Python.\\n\\nAnd -- bonus! -- more quickly.  Each separate Linux command in the shell (with a few exceptions) forks a subprocess.  By using Python shutil and os modules, you don\\'t fork a subprocess.\\nThe shell environment features.  This includes stuff that sets a command\\'s environment (current directory and environment variables and what-not).  You can easily manage this from Python directly.\\nThe shell programming features.  This is all the process status code checking, the various logic commands (if, while, for, etc.) the test command and all of it\\'s relatives.  The function definition stuff.  This is all much, much easier in Python.  This is one of the huge victories in getting rid of bash and doing it in Python.\\nInteraction features.  This includes command history and what-not.  You don\\'t need this for writing shell scripts.  This is only for human interaction, and not for script-writing.\\nThe shell file management features.  This includes redirection and pipelines.  This is trickier.  Much of this can be done with subprocess.  But some things that are easy in the shell are unpleasant in Python.  Specifically stuff like (a | b; c ) | something >result.  This runs two processes in parallel (with output of a as input to b), followed by a third process.  The output from that sequence is run in parallel with something and the output is collected into a file named result.  That\\'s just complex to express in any other language.\\n\\n\\nSpecific programs (awk, sed, grep, etc.) can often be rewritten as Python modules.  Don\\'t go overboard.  Replace what you need and evolve your \"grep\" module.  Don\\'t start out writing a Python module that replaces \"grep\".\\n\\nThe best thing is that you can do this in steps.\\n\\n\\nReplace AWK and PERL with Python.  Leave everything else alone.\\nLook at replacing GREP with Python.  This can be a bit more complex, but your version of GREP can be tailored to your processing needs.\\nLook at replacing FIND with Python loops that use os.walk.  This is a big win because you don\\'t spawn as many processes.\\nLook at replacing common shell logic (loops, decisions, etc.) with Python scripts.\\n\\n'},\n {'prompt': \"Imagine that you have:\\n\\nkeys = ('name', 'age', 'food')\\nvalues = ('Monty', 42, 'spam')\\n\\n\\nWhat is the simplest way to produce the following dictionary ?\\n\\ndict = {'name' : 'Monty', 'age' : 42, 'food' : 'spam'}\\n\\n\\nThis code works, but I'm not really proud of it :\\n\\ndict = {}\\njunk = map(lambda k, v: dict.update({k: v}), keys, values)\\n\\n\",\n  'completion': \"Like this:\\n\\n>>> keys = ['a', 'b', 'c']\\n>>> values = [1, 2, 3]\\n>>> dictionary = dict(zip(keys, values))\\n>>> print dictionary\\n{'a': 1, 'b': 2, 'c': 3}\\n\\n\\nVoila :-)  The pairwise dict constructor and zip function are awesomely useful: https://docs.python.org/2/library/functions.html#func-dict\\n\"},\n {'prompt': \"When using __import__ with a dotted name, something like: somepackage.somemodule, the module returned isn't somemodule, whatever is returned seems to be mostly empty! what's going on here?\\n\",\n  'completion': 'From the python docs on __import__:\\n\\n\\n__import__( name[, globals[, locals[, fromlist[, level]]]])\\n\\n  \\n  ...\\n  \\n  When the name variable is of the form\\n  package.module, normally, the\\n  top-level package (the name up till\\n  the first dot) is returned, not the\\n  module named by name. However, when a\\n  non-empty fromlist argument is given,\\n  the module named by name is returned.\\n  This is done for compatibility with\\n  the bytecode generated for the\\n  different kinds of import statement;\\n  when using \"import spam.ham.eggs\", the\\n  top-level package spam  must be placed\\n  in the importing namespace, but when\\n  using \"from spam.ham import eggs\", the\\n  spam.ham subpackage must be used to\\n  find the eggs variable. As a\\n  workaround for this behavior, use\\n  getattr() to extract the desired\\n  components. For example, you could\\n  define the following helper:\\n\\ndef my_import(name):\\n    mod = __import__(name)\\n    components = name.split(\\'.\\')\\n    for comp in components[1:]:\\n        mod = getattr(mod, comp)\\n    return mod\\n\\n\\n\\nTo paraphrase:\\n\\nWhen you ask for somepackage.somemodule, __import__ returns somepackage.__init__.py, which is often empty.\\n\\nIt will return somemodule if you provide fromlist (a list of the variable names inside somemodule you want, which are not actually returned)\\n\\nYou can also, as I did, use the function they suggest.\\n\\nNote: I asked this question fully intending to answer it myself. There was a big bug in my code, and having misdiagnosed it, it took me a long time to figure it out, so I figured I\\'d help the SO community out and post the gotcha I ran into here.\\n'},\n {'prompt': \"How do I get the inverse of a matrix in python? I've implemented it myself, but it's pure python, and I suspect there are faster modules out there to do it.\\n\",\n  'completion': 'You should have a look at numpy if you do matrix manipulation. This is a module mainly written in C, which will be much faster than programming in pure python. Here is an example of how to invert a matrix, and do other matrix manipulation.\\n\\nfrom numpy import matrix\\nfrom numpy import linalg\\nA = matrix( [[1,2,3],[11,12,13],[21,22,23]]) # Creates a matrix.\\nx = matrix( [[1],[2],[3]] )                  # Creates a matrix (like a column vector).\\ny = matrix( [[1,2,3]] )                      # Creates a matrix (like a row vector).\\nprint A.T                                    # Transpose of A.\\nprint A*x                                    # Matrix multiplication of A and x.\\nprint A.I                                    # Inverse of A.\\nprint linalg.solve(A, x)     # Solve the linear equation system.\\n\\n\\nYou can also have a look at the array module, which is a much more efficient implementation of lists when you have to deal with only one data type.\\n'},\n {'prompt': \"From what I understand, the parent attribute of a db.Model (typically defined/passed in the constructor call) allows you to define hierarchies in your data models. As a result, this increases the size of the entity group. However, it's not very clear to me why we would want to do that. Is this strictly for ACID compliance? I would like to see scenarios where each is best suited or more appropriate.\\n\",\n  'completion': 'There are several differences:\\n\\n\\nAll entities with the same ancestor are in the same entity group. Transactions can only affect entities inside a single entity group.\\nAll writes to a single entity group are serialized, so throughput is limited.\\nThe parent entity is set on creation and is fixed. References can be changed at any time.\\nWith reference properties, you can only query for direct relationships, but with parent properties you can use the .ancestor() filter to find everything (directly or indirectly) descended from a given ancestor.\\nEach entity has only a single parent, but can have multiple reference properties.\\n\\n'},\n {'prompt': \"I have a Bluehost account where I can run Python scripts as CGI. I guess it's the simplest CGI, because to run I have to define the following in .htaccess:\\n\\nOptions +ExecCGI\\nAddType text/html py\\nAddHandler cgi-script .py\\n\\n\\nNow, whenever I look up web programming with Python, I hear a lot about WSGI and how most frameworks use it. But I just don't understand how it all fits together, especially when my web server is given (Apache running at a host's machine) and not something I can really play with (except defining .htaccess commands).\\n\\nHow are WSGI, CGI, and the frameworks all connected? What do I need to know, install, and do if I want to run a web framework (say web.py or CherryPy) on my basic CGI configuration? How to install WSGI support?\\n\",\n  'completion': 'How WSGI, CGI, and the frameworks are all connected ?\\n\\nApache listens on port 80.  It gets an HTTP request.  It parses the request to find a way to respond.  Apache has a LOT of choices for responding.   One way to respond is to use CGI to run a script.  Another way to respond is to simply serve a file.  \\n\\nIn the case of CGI, Apache prepares an environment and invokes the script through the CGI protocol.  This is a standard Unix Fork/Exec situation -- the CGI subprocess inherits an OS environment including the socket and stdout.  The CGI subprocess writes a response, which goes back to Apache; Apache sends this response to the browser.\\n\\nCGI is primitive and annoying.  Mostly because it forks a subprocess for every request, and subprocess must exit or close stdout and stderr to signify end of response.\\n\\nWSGI is an interface that is based on the CGI design pattern.  It is not necessarily CGI -- it does not have to fork a subprocess for each request.  It can be CGI, but it doesn\\'t have to be.\\n\\nWSGI adds to the CGI design pattern in several important ways.  It parses the HTTP Request Headers for you and adds these to the environment.  It supplies any POST-oriented input as a file-like object in the environment.  It also provides you a function that will formulate the response, saving you from a lot of formatting details.\\n\\nWhat do I need to know / install / do if I want to run a web framework (say web.py or cherrypy) on my basic CGI configuration ?\\n\\nRecall that forking a subprocess is expensive.  There are two ways to work around this.\\n\\n\\nEmbedded mod_wsgi or mod_python embeds Python inside Apache; no process is forked.  Apache runs the Django application directly.\\nDaemon mod_wsgi or mod_fastcgi allows Apache to interact with a separate daemon (or \"long-running process\"), using the WSGI protocol.  You start your long-running Django process, then you configure Apache\\'s mod_fastcgi to communicate with this process.\\n\\n\\nNote that mod_wsgi can work in either mode: embedded or daemon.\\n\\nWhen you read up on mod_fastcgi, you\\'ll see that Django uses flup to create a WSGI-compatible interface from the information provided by mod_fastcgi.  The pipeline works like this.\\n\\nApache -> mod_fastcgi -> FLUP (via FastCGI protocol) -> Django (via WSGI protocol)\\n\\n\\nDjango has several \"django.core.handlers\" for the various interfaces.\\n\\nFor mod_fastcgi, Django provides a manage.py runfcgi that integrates FLUP and the handler.\\n\\nFor mod_wsgi, there\\'s a core handler for this.\\n\\nHow to install WSGI support ?\\n\\nFollow these instructions.\\n\\nhttp://code.google.com/p/modwsgi/wiki/IntegrationWithDjango\\n\\nFor background see this\\n\\nhttp://docs.djangoproject.com/en/dev/howto/deployment/#howto-deployment-index\\n'},\n {'prompt': \"I'd like to write Python scripts that drive Visual Studio 2008 and Visual C++ 2008.  All the examples I've found so far use win32com.client.Dispatch.  This works fine for Excel 2007 and Word 2007 but fails for Visual Studio 2008:\\n\\nimport win32com.client\\napp1 = win32com.client.Dispatch( 'Excel.Application' ) # ok\\napp2 = win32com.client.Dispatch( 'Word.Application' )  # ok\\napp3 = win32com.client.Dispatch( 'MSDev.Application' ) # error\\n\\n\\nAny ideas?  Does Visual Studio 2008 use a different string to identify itself?  Is the above method out-dated?\\n\",\n  'completion': 'Depending on what exactly you\\'re trying to do, AutoIt may meet your needs.  In fact, I\\'m sure it will do anything you need it to do.\\n\\nTaken from my other post about how to use AutoIt with Python:\\n\\nimport win32com.client\\noAutoItX = win32com.client.Dispatch( \"AutoItX3.Control\" )\\n\\noAutoItX.Opt(\"WinTitleMatchMode\", 2) #Match text anywhere in a window title\\n\\nwidth = oAutoItX.WinGetClientSizeWidth(\"Firefox\")\\nheight = oAutoItX.WinGetClientSizeHeight(\"Firefox\")\\n\\nprint width, height\\n\\n\\nYou can of course use any of the AutoItX functions (note that that link goes to the AutoIt function reference, the com version of AutoIt - AutoItX has a subset of that list...the documentation is included in the download) in this way.  I don\\'t know what you\\'re wanting to do, so I can\\'t point you towards the appropriate functions, but this should get you started.\\n'},\n {'prompt': \"I need to perform a filtered query from within a django template, to get a set of objects equivalent to python code within a view:\\n\\nqueryset = Modelclass.objects.filter(somekey=foo)\\n\\n\\nIn my template I would like to do\\n\\n{% for object in data.somekey_set.FILTER %}\\n\\n\\nbut I just can't seem to find out how to write FILTER.\\n\",\n  'completion': \"You can't do this, which is by design.  The Django framework authors intended a strict separation of presentation code from data logic.  Filtering models is data logic, and outputting HTML is presentation logic.\\n\\nSo you have several options.  The easiest is to do the filtering, then pass the result to render_to_response.  Or you could write a method in your model so that you can say {% for object in data.filtered_set %}.  Finally, you could write your own template tag, although in this specific case I would advise against that.\\n\"},\n {'prompt': 'Say I have a form like:\\n\\nclass GeneralForm(forms.Form):\\n    field1 = forms.IntegerField(required=False)\\n    field2 = forms. IntegerField(required=False)\\n\\n\\nAnd I want to show it twice on a page within one form tag each time with a different prefix e.g.,:\\n\\nrest of page ...\\n<form ..>\\nGeneralForm(data,prefix=\"form1\").as_table()\\nGeneralForm(data,prefix=\"form2\").as_table()\\n<input type=\"submit\" />\\n</form>\\nrest of page ...\\n\\n\\nWhen the user submits this, how do I get the submitted form back into two separate forms to do validation, and redisplay it?\\n\\nThis was the only documentation I could find and it\\'s peckish.\\n',\n  'completion': \"You process each form as you normally would, ensuring that you create instances which have the same prefixes as those used to generate the form initially.\\n\\nHere's a slightly awkward example using the form you've given, as I don't know what the exact use case is:\\n\\ndef some_view(request):\\n    if request.method == 'POST':\\n        form1 = GeneralForm(request.POST, prefix='form1')\\n        form2 = GeneralForm(request.POST, prefix='form2')\\n        if all([form1.is_valid(), form2.is_valid()]):\\n            pass # Do stuff with the forms\\n    else:\\n        form1 = GeneralForm(prefix='form1')\\n        form2 = GeneralForm(prefix='form2')\\n    return render_to_response('some_template.html', {\\n        'form1': form1,\\n        'form2': form2,\\n    })\\n\\n\\nHere's some real-world sample code which demonstrates processing forms using the prefix:\\n\\nhttp://collingrady.wordpress.com/2008/02/18/editing-multiple-objects-in-django-with-newforms/\\n\"},\n {'prompt': 'So I\\'m teaching myself Python, and I\\'m having an issue with lists. I want to pass my function a list and pop items off it while retaining the original list. How do I make python \"instance\" the passed list rather that passing a pointer to the original one?\\n\\nExample:\\n\\ndef burninate(b):\\n    c = []\\n    for i in range(3):\\n    \\tc.append(b.pop())\\n    return c\\n\\na = range(6)\\nd = burninate(a)\\nprint a, d\\n\\n\\nOutput: [0, 1, 2] [5, 4, 3]\\nDesired output: [0, 1, 2, 3, 4, 5] [5, 4, 3]\\n\\nThanks!\\n',\n  'completion': \"As other answers have suggested, you can provide your function with a copy of the list.\\n\\nAs an alternative, your function could take a copy of the argument:\\n\\ndef burninate(b):\\n    c = []\\n    b = list(b)\\n    for i in range(3):\\n        c.append(b.pop())\\n    return c\\n\\n\\nBasically, you need to be clear in your mind (and in your documentation) whether your function will change its arguments.  In my opinion, functions that return computed values should not change their arguments, and functions that change their arguments should not return anything.  See python's [].sort(), [].extend(), {}.update(), etc. for examples.  Obviously there are exceptions (like .pop()).\\n\\nAlso, depending on your particular case, you could rewrite the function to avoid using pop() or other functions that modify the argument.  e.g.\\n\\ndef burninante(b):\\n    return b[:-4:-1]   # return the last three elements in reverse order\\n\\n\"},\n {'prompt': 'As an example, lets say I wanted to list the frequency of each letter of the alphabet in a string. What would be the easiest way to do it?\\n\\nThis is an example of what I\\'m thinking of... the question is how to make allTheLetters equal to said letters without something like allTheLetters = \"abcdefg...xyz\". In many other languages I could just do letter++ and increment my way through the alphabet, but thus far I haven\\'t come across a way to do that in python.\\n\\ndef alphCount(text):\\n  lowerText = text.lower()\\n  for letter in allTheLetters:  \\n    print letter + \":\", lowertext.count(letter)\\n\\n',\n  'completion': 'The question you\\'ve asked (how to iterate through the alphabet) is not the same question as the problem you\\'re trying to solve (how to count the frequency of letters in a string).\\n\\nYou can use string.lowercase, as other posters have suggested:\\n\\nimport string\\nallTheLetters = string.lowercase\\n\\n\\nTo do things the way you\\'re \"used to\", treating letters as numbers, you can use the \"ord\" and \"chr\" functions.  There\\'s absolutely no reason to ever do exactly this, but maybe it comes closer to what you\\'re actually trying to figure out:\\n\\ndef getAllTheLetters(begin=\\'a\\', end=\\'z\\'):\\n    beginNum = ord(begin)\\n    endNum = ord(end)\\n    for number in xrange(beginNum, endNum+1):\\n        yield chr(number)\\n\\n\\nYou can tell it does the right thing because this code prints True:\\n\\nimport string\\nprint \\'\\'.join(getAllTheLetters()) == string.lowercase\\n\\n\\nBut, to solve the problem you\\'re actually trying to solve, you want to use a dictionary and collect the letters as you go:\\n\\nfrom collections import defaultdict    \\ndef letterOccurrances(string):\\n    frequencies = defaultdict(lambda: 0)\\n    for character in string:\\n        frequencies[character.lower()] += 1\\n    return frequencies\\n\\n\\nUse like so:\\n\\noccs = letterOccurrances(\"Hello, world!\")\\nprint occs[\\'l\\']\\nprint occs[\\'h\\']\\n\\n\\nThis will print \\'3\\' and \\'1\\' respectively.\\n\\nNote that this works for unicode as well:\\n\\n# -*- coding: utf-8 -*-\\noccs = letterOccurrances(u\"hÃ©ÄºÄºÃ³, áº\\x83Ã³Å\\x95Äºd!\")\\nprint occs[u\\'l\\']\\nprint occs[u\\'Äº\\']\\n\\n\\nIf you were to try the other approach on unicode (incrementing through every character) you\\'d be waiting a long time; there are millions of unicode characters.\\n\\nTo implement your original function (print the counts of each letter in alphabetical order) in terms of this:\\n\\ndef alphCount(text):\\n    for character, count in sorted(letterOccurrances(text).iteritems()):\\n        print \"%s: %s\" % (character, count)\\n\\nalphCount(\"hello, world!\")\\n\\n'},\n {'prompt': 'I\\'m running Python 2.6 on Unix and when I run the interactive prompt (SQLite is supposed to be preinstalled) I get:\\n\\n[root@idev htdocs]# python\\nPython 2.6 (r26:66714, Oct 23 2008, 16:25:34)\\n[GCC 3.2.2 20030222 (Red Hat Linux 3.2.2-5)] on linux2\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> import sqlite\\nTraceback (most recent call last):\\nFile \"<stdin>\", line 1, in <module>\\nImportError: No module named sqlite\\n>>>\\n\\n\\nHow do I resolve this?\\n',\n  'completion': \"The error: \\n\\nImportError: No module named _sqlite3\\n\\n\\nmeans that SQLite 3 does not find the associated shared library. On Mac OS X it's _sqlite3.so and it should be the same on other Unix systems. \\n\\nTo resolve the error you have to locate the _sqlite3.so library on your computer and then check your PYTHONPATH for this directory location. \\n\\nTo print the Python search path enter the following in the Python shell:\\n\\nimport sys\\nprint sys.path\\n\\n\\nIf the directory containing your library is missing you can try adding it interactively with \\n\\nsys.path.append('/your/dir/here')\\n\\n\\nand try \\n\\nimport sqlite3\\n\\n\\nagain. If this works you have to add this directory permanently to your PYTHONPATH environment variable. \\n\\nPS: If the library is missing you should (re-)install the module.\\n\"},\n {'prompt': 'Is there a simple way to support wildcards (\"*\") when searching strings - without using RegEx?\\n\\nUsers are supposed to enter search terms using wildcards, but should not have to deal with the complexity of RegEx:\\n\\n\"foo*\"   =>  str.startswith(\"foo\")\\n\"*foo\"   =>  str.endswith(\"foo\")\\n\"*foo*\"  =>  \"foo\" in str\\n\\n\\n(it gets more complicated when there are multiple search terms though, e.g. \"foo*bar*baz\")\\n\\nThis seems like a common issue, so I wonder whether there\\'s a ready-made solution for it.\\n\\nAny help would be greatly appreciated!\\n',\n  'completion': \"You could try the fnmatch module, it's got a shell-like wildcard syntax.\\n\"},\n {'prompt': \"I have a third-party product, a terminal emulator, which provides a DLL that can be linked to a C program to basically automate the driving of this product (send keystrokes, detect what's on the screen and so forth).\\n\\nI want to drive it from a scripting language (I'm comfortable with Python and slightly less so with Perl) so that we don't have to compile and send out executables to our customers whenever there's a problem found.\\n\\nWe also want the customers to be able to write their own scripts using ours as baselines and they won't entertain the idea of writing and compiling C code.\\n\\nWhat's a good way of getting Python/Perl to interface to a Windows DLL. My first thought was to write a server program and have a Python script communicate with it via TCP but there's got to be an easier solution.\\n\",\n  'completion': 'One way to call C libraries from Python is to use ctypes:\\n\\n>>> from ctypes import *\\n>>> windll.user32.MessageBoxA(None, \"Hello world\", \"ctypes\", 0);\\n\\n'},\n {'prompt': \"Is there explicit support for Single Table Inheritance in Django? Last I heard, the feature was still under development and debate. \\n\\nAre there libraries/hacks I can use in the meantime to capture the basic behavior? I have a hierarchy that mixes different objects. The canonical example of a corporation structure with an Employee class, subclasses for types of employees, and a manager_id (parent_id) would be a good approximation of the problem I am solving. \\n\\nIn my case, I would like to represent the idea that an employee can manage other employees while being managed by a different employee. There are not separate classes for Manager and Worker, which makes this hard to spread across tables. Sub-classes would represent types of employees-programmers, accountants, sales, etc and would be independent of who supervises who (OK, I guess it's no longer a typical corporation in some respect). \\n\",\n  'completion': \"There are currently two forms of inheritance in Django - MTI (model table inheritance) and ABC (abstract base classes).\\n\\nI wrote a tutorial on what's going on under the hood.\\n\\nYou can also reference the official docs on model inheritance.\\n\"},\n {'prompt': 'Emacs does not recognize my correct python path. I think it is a general problem with emacs not recognizing my environment variables. I have GNU Emacs 22.1.1 (i386-apple-darwin8.9.1, Carbon Version 1.6.0) of 2007-06-17 installed.\\n\\nI have set the PYTHONPATH in my ~/.bashrc. Maybe I should set it somewhere else?\\n',\n  'completion': '.bashrc only gets read when a shell starts; it won\\'t affect Carbon Emacs. Instead, use setenv in your .emacs:\\n\\n(setenv \"PYTHONPATH\" \"PATH_STRING_HERE\")\\n\\n\\nYou can set PYTHONPATH for the entire Mac OS session, by adding it to ~/.MacOSX/environment.plist (more here). You probably don\\'t want to do this unless you have XCode (and its property list editor) installed.\\n\\n(Via Procrastiblog)\\n'},\n {'prompt': 'I\\'m planning to write gateway web application, which would need \"terminal window\" with VT100/ANSI escape code support. Are there any AJAX based alternatives for such a task?\\n\\nI\\'m thinking something like this: http://tryruby.hobix.com/\\n\\nMy preferred backend for the system is Python/Twisted/Pylons, but since I\\'m just planning, I will explore every option.\\n',\n  'completion': 'Try\\n\\nAnyTerm\\n\\nAjaxTerm\\n\\nWebShell\\n'},\n {'prompt': \"I want to detect whether module has changed. Now, using inotify is simple, you just need to know the directory you want to get notifications from.\\n\\nHow do I retrieve a module's path in python?\\n\",\n  'completion': 'import a_module\\nprint a_module.__file__\\n\\n\\nWill actually give you the path to the .pyc file that was loaded, at least on Mac OS X. So I guess you can do\\n\\nimport os\\npath = os.path.dirname(amodule.__file__)\\n\\n\\nYou can also try\\n\\npath = os.path.abspath(amodule.__file__)\\n\\n\\nTo get the directory to look for changes.\\n'},\n {'prompt': 'Recently I wrote a function to generate certain sequences with nontrivial constraints. The problem came with a natural recursive solution. Now it happens that, even for relatively small input, the sequences are several thousands, thus I would prefer to use my algorithm as a generator instead of using it to fill a list with all the sequences.\\n\\nHere is an example. Suppose we want to compute all the permutations of a string with a recursive function. The following naive algorithm takes an extra argument \\'storage\\' and appends a permutation to it whenever it finds one:\\n\\ndef getPermutations(string, storage, prefix=\"\"):\\n   if len(string) == 1:\\n      storage.append(prefix + string)   # <-----\\n   else:\\n      for i in range(len(string)):\\n         getPermutations(string[:i]+string[i+1:], storage, prefix+string[i])\\n\\nstorage = []\\ngetPermutations(\"abcd\", storage)\\nfor permutation in storage: print permutation\\n\\n\\n(Please don\\'t care about inefficiency, this is only an example.)\\n\\nNow I want to turn my function into a generator, i.e. to yield a permutation instead of appending it to the storage list:\\n\\ndef getPermutations(string, prefix=\"\"):\\n   if len(string) == 1:\\n      yield prefix + string             # <-----\\n   else:\\n      for i in range(len(string)):\\n         getPermutations(string[:i]+string[i+1:], prefix+string[i])\\n\\nfor permutation in getPermutations(\"abcd\"):\\n   print permutation\\n\\n\\nThis code does not work (the function behaves like an empty generator).\\n\\nAm I missing something?\\nIs there a way to turn the above recursive algorithm into a generator without replacing it with an iterative one?\\n',\n  'completion': 'def getPermutations(string, prefix=\"\"):\\n    if len(string) == 1:\\n        yield prefix + string\\n    else:\\n        for i in xrange(len(string)):\\n            for perm in getPermutations(string[:i] + string[i+1:], prefix+string[i]):\\n                yield perm\\n\\n\\nOr without an accumulator:\\n\\ndef getPermutations(string):\\n    if len(string) == 1:\\n        yield string\\n    else:\\n        for i in xrange(len(string)):\\n            for perm in getPermutations(string[:i] + string[i+1:]):\\n                yield string[i] + perm\\n\\n'},\n {'prompt': 'I have a Django model with a large number of fields and 20000+ table rows.  To facilitate human readable URLs and the ability to break down the large list into arbitrary sublists, I would like to have a URL that looks like this:\\n\\n/browse/<name1>/<value1>/<name2>/<value2>/ .... etc ....\\n\\n\\nwhere \\'name\\' maps to a model attribute and \\'value\\' is the search criteria for that attribute.  Each \"name\" will be treated like a category to return subsets of the model instances where the categories match.\\n\\nNow, this could be handled with GET parameters, but I prefer more readable URLs for both the user\\'s sake and the search engines.  These URLs subsets will be embedded on each page that displays this model, so it seems worth the effort to make pretty URLs.\\n\\nIdeally each name/value pair will be passed to the view function as a parameter named name1, name2, etc.  However, I don\\'t believe it\\'s possible to defined named patterns via a regex\\'s matched text.  Am I wrong there?\\n\\nSo, it seems I need to do something like this:\\n\\nurlpatterns = patterns(\\'\\',\\n    url(r\\'^browse/(?:([\\\\w]+)/([\\\\w]+)/)+$\\', \\'app.views.view\\', name=\"model_browse\"),\\n)\\n\\n\\nIt seems this should match any sets of two name/value pairs.  While it matches it successfully, it only passes the last name/value pair as parameters to the view function.  My guess is that each match is overwriting the previous match.  Under the guess that the containing (?:...)+ is causing it, I tried a simple repeating pattern instead:\\n\\nurlpatterns = patterns(\\'\\',\\n    url(r\\'^browse/([\\\\w]+/)+$\\', \\'app.views.view\\', name=\"model_browse\"),\\n)\\n\\n\\n... and got the same problem, but this time *args only includes the last matched pattern.\\n\\nIs this a limitation of Django\\'s url dispatcher, and/or Python\\'s regex support?  It seems either of these methods should work.  Is there a way to achieve this without hardcoding each possible model attribute in the URL as an optional (.*) pattern?\\n',\n  'completion': \"A possibility that you might consider is matching the entire string of possible values within the url pattern portion and pull out the specific pieces within your view.  As an example:\\n\\nurlpatterns = patterns('',\\n    url(r'^browse/(?P<match>.+)/$', 'app.views.view', name='model_browse'),\\n)\\n\\ndef view(request, match):\\n    pieces = match.split('/')\\n    # even indexed pieces are the names, odd are values\\n    ...\\n\\n\\nNo promises about the regexp I used, but I think you understand what I mean.\\n\\n(Edited to try and fix the regexp.)\\n\"},\n {'prompt': \"I don't care what the differences are.  I just want to know whether the contents are different.\\n\",\n  'completion': 'The low level way:\\n\\nfrom __future__ import with_statement\\nwith open(filename1) as f1:\\n   with open(filename2) as f2:\\n      if f1.read() == f2.read():\\n         ...\\n\\n\\nThe high level way:\\n\\nimport filecmp\\nif filecmp.cmp(filename1, filename2, shallow=False):\\n   ...\\n\\n'},\n {'prompt': 'In my website, users have the possibility to store links.\\n\\nDuring typing the internet address into the designated field I would like to display a suggest/autocomplete box similar to Google Suggest or the Chrome Omnibar.\\n\\nExample:\\n\\nUser is typing as URL:\\n\\nhttp://www.sta\\n\\n\\nSuggestions which would be displayed:\\n\\nhttp://www.staples.com\\nhttp://www.starbucks.com\\nhttp://www.stackoverflow.com\\n\\n\\nHow can I achieve this while not reinventing the wheel? :)\\n',\n  'completion': 'You could try with\\nhttp://google.com/complete/search?output=toolbar&q=keyword\\n\\nand then parse the xml result.\\n'},\n {'prompt': 'Considering the criteria listed below, which of Python, Groovy or Ruby would you use?\\n\\n\\nCriteria (Importance out of 10, 10 being most important)\\nRichness of API/libraries available (eg. maths, plotting, networking) (9)\\nAbility to embed in desktop (java/c++) applications (8)\\nEase of deployment (8)\\nAbility to interface with DLLs/Shared Libraries (7)\\nAbility to generate GUIs (7)\\nCommunity/User support (6)\\nPortability (6)\\nDatabase manipulation (3)\\nLanguage/Semantics (2)\\n\\n',\n  'completion': \"I think it's going to be difficult to get an objective comparison.  I personally prefer Python.  To address one of your criteria, Python was designed from the start to be an embeddable language.  It has a very rich C API, and the interpreter is modularized to make it easy to call from C.  If Java is your host environment, you should look at Jython, an implementation of Python inside the Java environment (VM and libs).\\n\"},\n {'prompt': \"Most of the documentation available for building Python extension modules\\nuses distutils, but I would like to achieve this by using the appropriate\\npython autoconf & automake macros instead.\\n\\nI'd like to know if there is an open source project out there that does\\nexactly this. Most of the ones I've found end up relying on a setup.py file.\\nUsing that approach works, but unfortunately ends up rebuilding the entire\\nsource tree any time I make a modification to the module source files.\\n\",\n  'completion': 'Supposing that you have a project with a directory called src, so let\\'s follow the follow steps to get a python extension built and packaged using autotools:\\n\\nCreate the Makefile.am files\\n\\nFirst, you need to create one Makefile.am in the root of your project, basically (but not exclusively) listing the subdirectories that should also be processed. You will end up with something like this:\\n\\nSUBDIRS = src\\n\\n\\nThe second one, inside the src directory will hold the instructions to actually compile your python extension. It will look like this:\\n\\nmyextdir = $(pkgpythondir)\\nmyext_PYTHON = file1.py file2.py\\n\\npyexec_LTLIBRARIES = _myext.la\\n\\n_myext_la_SOURCES = myext.cpp\\n_myext_la_CPPFLAGS = $(PYTHON_CFLAGS)\\n_myext_la_LDFLAGS = -module -avoid-version -export-symbols-regex initmyext\\n_myext_la_LIBADD = $(top_builddir)/lib/libhollow.la\\n\\nEXTRA_DIST = myext.h\\n\\n\\nWrite the configure.ac\\n\\nThis file must be created in the root directory of the project and must list all libraries, programs or any kind of tool that your project needs to be built, such as a compiler, linker, libraries, etc.\\n\\nLazy people, like me, usually don\\'t create it from scratch, I prefer to use the autoscan tool, that looks for things that you are using and generate a configure.scan file that can be used as the basis for your real configure.ac.\\n\\nTo inform automake that you will need python stuff, you can add this to your configure.ac:\\n\\ndnl python checks (you can change the required python version bellow)\\nAM_PATH_PYTHON(2.7.0)\\nPY_PREFIX=`$PYTHON -c \\'import sys ; print sys.prefix\\'`\\nPYTHON_LIBS=\"-lpython$PYTHON_VERSION\"\\nPYTHON_CFLAGS=\"-I$PY_PREFIX/include/python$PYTHON_VERSION\"\\nAC_SUBST([PYTHON_LIBS])\\nAC_SUBST([PYTHON_CFLAGS])\\n\\n\\nWrap up\\n\\nBasically, automake has a built-in extension that knows how to deal with python stuff, you just need to add it to your configure.ac file and then take the advantage of this feature in your Makefile.am.\\n\\nPyGtk is definitely an awesome example, but it\\'s pretty big, so maybe you will want to check another project, like Guake\\n'},\n {'prompt': 'It seems like there should be a simpler way than:\\n\\nimport string\\ns = \"string. With. Punctuation?\" # Sample string \\nout = s.translate(string.maketrans(\"\",\"\"), string.punctuation)\\n\\n\\nIs there?\\n',\n  'completion': 'From an efficiency perspective, you\\'re not going to beat translate() - it\\'s performing raw string operations in C with a lookup table - there\\'s not much that will beat that but writing your own C code.\\nIf speed isn\\'t a worry, another option though is:\\n\\nexclude = set(string.punctuation)\\ns = \\'\\'.join(ch for ch in s if ch not in exclude)\\n\\n\\nThis is faster than s.replace with each char, but won\\'t perform as well as non-pure python approaches such as regexes or string.translate, as you can see from the below timings.  For this type of problem, doing it at as low a level as possible pays off.\\n\\nTiming code:\\n\\nimport re, string, timeit\\n\\ns = \"string. With. Punctuation\"\\nexclude = set(string.punctuation)\\ntable = string.maketrans(\"\",\"\")\\nregex = re.compile(\\'[%s]\\' % re.escape(string.punctuation))\\n\\ndef test_set(s):\\n    return \\'\\'.join(ch for ch in s if ch not in exclude)\\n\\ndef test_re(s):  # From Vinko\\'s solution, with fix.\\n    return regex.sub(\\'\\', s)\\n\\ndef test_trans(s):\\n    return s.translate(table, string.punctuation)\\n\\ndef test_repl(s):  # From S.Lott\\'s solution\\n    for c in string.punctuation:\\n        s=s.replace(c,\"\")\\n    return s\\n\\nprint \"sets      :\",timeit.Timer(\\'f(s)\\', \\'from __main__ import s,test_set as f\\').timeit(1000000)\\nprint \"regex     :\",timeit.Timer(\\'f(s)\\', \\'from __main__ import s,test_re as f\\').timeit(1000000)\\nprint \"translate :\",timeit.Timer(\\'f(s)\\', \\'from __main__ import s,test_trans as f\\').timeit(1000000)\\nprint \"replace   :\",timeit.Timer(\\'f(s)\\', \\'from __main__ import s,test_repl as f\\').timeit(1000000)\\n\\n\\nThis gives the following results:\\n\\nsets      : 19.8566138744\\nregex     : 6.86155414581\\ntranslate : 2.12455511093\\nreplace   : 28.4436721802\\n\\n'},\n {'prompt': 'I\\'m writing some mail-processing software in Python that is encountering strange bytes in header fields.  I suspect this is just malformed mail; the message itself claims to be us-ascii, so I don\\'t think there is a true encoding, but I\\'d like to get out a unicode string approximating the original one without throwing a UnicodeDecodeError .\\n\\nSo, I\\'m looking for a function that takes a str and optionally some hints and does its darndest to give me back a unicode.  I could write one of course, but if such a function exists its author has probably thought a bit deeper about the best way to go about this.\\n\\nI also know that Python\\'s design prefers explicit to implicit and that the standard library is designed to avoid implicit magic in decoding text. I just want to explicitly say \"go ahead and guess\".\\n',\n  'completion': 'You may be interested in Universal Encoding Detector.\\n'},\n {'prompt': \"I saw this the other day (scroll all the way down to see some of the clever stuff): \\n\\n\\n  http://www.mono-project.com/docs/tools+libraries/tools/repl/\\n\\n\\nAnd wondered whether something like this exists for Python.\\n\\nSo, is there a good Python GUI shell that can do stuff like that C# shell can do?\\n\\nEdit: Here are links to screenshots from the article, showing what I'm interested in doing.\\n\\nAn example of the type of things I'm interested: \\n\\nhttp://www.mono-project.com/archived/images/7/75/GSharpPlot.png\\n\\nThey are able to add hooks to produce GUI elements like the plot, or even do silly things like:\\n\\nhttp://www.mono-project.com/archived/images/b/bf/GSharpRenderHandler.png\\n\\nI don't think this is possible with any of the console shells I've tried (the regular python shell, ipython).\\n\\nEdit: I'm not looking for an IDE. If you look at the link, you'll get an idea of what I want.\\n\",\n  'completion': \"One project I'm aware of that provides similar features (inline plotting, customisable rendering) is Reinteract.  Another (though possibly a bit heavyweight for general usage) is SAGE which provides functionality for web-based notebooks.\\n\\nThese aren't quite shells - they're designed more as a mathematical notebook (so for instance, you can modify an earlier result and have the change propogate to later calculations), but they're close to what you're looking for, and could probably be modified to be used as such.\\n\"},\n {'prompt': \"In .Net, I found this great library, HtmlAgilityPack that allows you  to easily parse non-well-formed HTML using XPath.  I've used this for a couple years in my .Net sites, but I've had to settle for more painful libraries for my Python, Ruby and other projects.  Is anyone aware of similar libraries for other languages?\\n\",\n  'completion': \"I'm surprised there isn't a single mention of lxml. It's blazingly fast and will work in any environment that allows CPython libraries.\\n\\nHere's how you can parse HTML via XPATH using lxml.\\n\\n>>> from lxml import etree\\n>>> doc = '<foo><bar></bar></foo>'\\n>>> tree = etree.HTML(doc)\\n\\n>>> r = tree.xpath('/foo/bar')\\n>>> len(r)\\n1\\n>>> r[0].tag\\n'bar'\\n\\n>>> r = tree.xpath('bar')\\n>>> r[0].tag\\n'bar'\\n\\n\"},\n {'prompt': \"I have a huge text file (~1GB) and sadly the text editor I use won't read such a large file.  However, if I can just split it into two or three parts I'll be fine, so, as an exercise I wanted to write a program in python to do it.  \\n\\nWhat I think I want the program to do is to find the size of a file, divide that number into parts, and for each part, read up to that point in chunks, writing to a filename.nnn output file, then read up-to the next line-break and write that, then close the output file, etc.  Obviously the last output file just copies to the end of the input file.\\n\\nCan you help me with the key filesystem related parts: filesize, reading and writing in chunks and reading to a line-break?\\n\\nI'll be writing this code test-first, so there's no need to give me a complete answer, unless its a one-liner ;-)\\n\",\n  'completion': 'linux has a split command\\n\\nsplit -l 100000 file.txt\\n\\nwould split into files of equal 100,000 line size\\n'},\n {'prompt': \"I need to set my process to run under 'nobody', I've found os.setuid(), but how do I find uid if I have login?\\n\\nI've found out that uids are in /etc/passwd, but maybe there is a more pythonic way than scanning /etc/passwd. Anybody?\\n\",\n  'completion': 'You might want to have a look at the pwd module in the python stdlib, for example:\\n\\nimport pwd\\npw = pwd.getpwnam(\"nobody\")\\nuid = pw.pw_uid\\n\\n\\nit uses /etc/passwd (well, technically it uses the posix C API, so I suppose it might work on an OS if it didn\\'t use /etc/passwd but exposed the needed functions) but is cleaner than parsing it manually\\n'},\n {'prompt': 'What is and how can it be used in C#.\\nCan you use the same concept in Python/Perl?\\n',\n  'completion': 'A partial type (it doesn\\'t have to be a class; structs and interfaces can be partial too) is basically a single type which has its code spread across multiple files.\\n\\nThe main use for this is to allow a code generator (e.g. a Visual Studio designer) to \"own\" one file, while hand-written code is put in another.\\n\\nI\\'ve no idea whether Python/Perl have the same capabilities, I\\'m afraid.\\n'},\n {'prompt': \"We're looking into transport/protocol solutions and were about to do various performance tests, so I thought I'd check with the community if they've already done this:\\n\\nHas anyone done server performance tests for simple echo services as well as serialization/deserialization for various messages sizes comparing EJB3, Thrift, and Protocol Buffers on Linux?\\n\\nPrimarily languages will be Java, C/C++, Python, and PHP.\\n\\nUpdate: I'm still very interested in this, if anyone has done any further benchmarks please let me know. Also, very interesting benchmark showing compressed JSON performing similar / better than Thrift / Protocol Buffers, so I'm throwing JSON into this question as well.\\n\",\n  'completion': 'Latest comparison available here at the thrift-protobuf-compare project wiki. It includes many other serialization libraries.\\n'},\n {'prompt': 'I am getting an \\'access is denied\\' error when I attempt to delete a folder that is not empty. I used the following command in my attempt: os.remove(\"/folder_name\"). \\n\\nWhat is the most effective way of removing/deleting a folder/directory that is not empty?\\n',\n  'completion': \"import shutil\\n\\nshutil.rmtree('/folder_name')\\n\\n\\nStandard Library Reference: shutil.rmtree.\\n\"},\n {'prompt': \"I am trying to write a decorator to do logging:\\n\\ndef logger(myFunc):\\n    def new(*args, **keyargs):\\n        print 'Entering %s.%s' % (myFunc.im_class.__name__, myFunc.__name__)\\n        return myFunc(*args, **keyargs)\\n\\n    return new\\n\\nclass C(object):\\n    @logger\\n    def f():\\n        pass\\n\\nC().f()\\n\\n\\nI would like this to print:\\n\\nEntering C.f\\n\\n\\nbut instead I get this error message:\\n\\nAttributeError: 'function' object has no attribute 'im_class'\\n\\n\\nPresumably this is something to do with the scope of 'myFunc' inside 'logger', but I've no idea what.\\n\",\n  'completion': 'Claudiu\\'s answer is correct, but you can also cheat by getting the class name off of the self argument.  This will give misleading log statements in cases of inheritance, but will tell you the class of the object whose method is being called.  For example:\\n\\nfrom functools import wraps  # use this to preserve function signatures and docstrings\\ndef logger(func):\\n    @wraps(func)\\n    def with_logging(*args, **kwargs):\\n        print \"Entering %s.%s\" % (args[0].__class__.__name__, func.__name__)\\n        return func(*args, **kwargs)\\n    return with_logging\\n\\nclass C(object):\\n    @logger\\n    def f(self):\\n        pass\\n\\nC().f()\\n\\n\\nAs I said, this won\\'t work properly in cases where you\\'ve inherited a function from a parent class; in this case you might say\\n\\nclass B(C):\\n    pass\\n\\nb = B()\\nb.f()\\n\\n\\nand get the message Entering B.f where you actually want to get the message Entering C.f since that\\'s the correct class.  On the other hand, this might be acceptable, in which case I\\'d recommend this approach over Claudiu\\'s suggestion.\\n'},\n {'prompt': \"Assume I have the following list:\\n\\nfoo = ['a', 'b', 'c', 'd', 'e']\\n\\n\\nWhat is the simplest way to retrieve an item at random from this list?\\n\",\n  'completion': \"Use random.choice:\\n\\nimport random\\n\\nfoo = ['a', 'b', 'c', 'd', 'e']\\nprint(random.choice(foo))\\n\\n\"},\n {'prompt': \"I'm a relatively new convert to Python.  I've written some code to grab/graph data from various sources to automate some weekly reports and forecasts.  I've been intrigued by the Jython concept, and would like to port some Python code that I've written to Jython.  In order to do this quickly, I need a NumPy clone for Jython (or Java).  Is there anything like this out there?\\n\",\n  'completion': \"I can't find anything that's a clone of numpy, but there's a long list of Java numerics packages here - these should all be usable from Jython. Which one meets your requirements depends on what you're doing with numpy, I guess.\\n\"},\n {'prompt': \"Is there a way to access a list(or tuple, or other iterable)'s next, or previous element while looping through with for loop?\\n\\nl=[1,2,3]\\nfor item in l:\\n    if item==2:\\n        get_previous(l,item)\\n\\n\",\n  'completion': 'Expressed as a generator function:\\n\\ndef neighborhood(iterable):\\n    iterator = iter(iterable)\\n    prev = None\\n    item = iterator.next()  # throws StopIteration if empty.\\n    for next in iterator:\\n        yield (prev,item,next)\\n        prev = item\\n        item = next\\n    yield (prev,item,None)\\n\\n\\nUsage:\\n\\nfor prev,item,next in neighborhood(l):\\n    print prev, item, next\\n\\n\\nEdit: I thought it would reduce the readability, but this way seem to look better.\\n'},\n {'prompt': 'If I want to split a list of words separated by a delimiter character, I can use\\n\\n>>> \\'abc,foo,bar\\'.split(\\',\\')\\n[\\'abc\\', \\'foo\\', \\'bar\\']\\n\\n\\nBut how to easily and quickly do the same thing if I also want to handle quoted-strings which can contain the delimiter character ?\\n\\nIn: \\'abc,\"a string, with a comma\",\"another, one\"\\'\\nOut: [\\'abc\\', \\'a string, with a comma\\', \\'another, one\\']\\n\\n\\nRelated question: How can i parse a comma delimited string into a list (caveat)?\\n',\n  'completion': 'import csv\\n\\ninput = [\\'abc,\"a string, with a comma\",\"another, one\"\\']\\nparser = csv.reader(input)\\n\\nfor fields in parser:\\n  for i,f in enumerate(fields):\\n    print i,f    # in Python 3 and up, print is a function; use: print(i,f)\\n\\n\\nResult:\\n\\n\\n0 abc\\n1 a string, with a comma\\n2 another, one\\n\\n'},\n {'prompt': 'I found the Computational Geometry Algorithms Library in my search for an algorithm to decompose a concave polygon into the minimum number of convex components.  Links off the site and numerous google results indicate there are python bindings for it, which would be really handy, but all the links are dead!  What happened to it?  Where can I get it now?\\n',\n  'completion': 'A rewrite of the CGAL-Python bindings has been done as part of the cgal-bindings project.  Check it out : http://code.google.com/p/cgal-bindings/\\n'},\n {'prompt': \"I'm using urllib2 to read in a page. I need to do a quick regex on the source and pull out a few variables but urllib2 presents as a file object rather than a string.\\n\\nI'm new to python so I'm struggling to see how I use a file object to do this. Is there a quick way to convert this into a string?\\n\",\n  'completion': \"You can use Python in interactive mode to search for solutions.\\n\\nif f is your object, you can enter dir(f) to see all methods and attributes. There's one called read. Enter help(f.read) and it tells you that f.read() is the way to retrieve a string from an file object.\\n\"},\n {'prompt': \"I have some flatpages with empty content field and their content inside the template (given with template_name field).\\n\\nWhy I am using django.contrib.flatpages\\n\\n\\nIt allows me to serve (mostly) static pages with minimal URL configuration.\\nI don't have to write views for each of them.\\n\\n\\nWhy I don't need the model FlatPage\\n\\n\\nI leave the content empty and just supply a template path. Therefore I can take advantage of having the source in a file;\\n\\nI can edit the source directly from the file system, without the help of a server (such as admin).\\nI can take advantage of syntax highlightning and other editor features.\\n\\nWith the model I have to maintain fixtures for flatpages.\\n\\nSo the data for the same entity is in two seperate places.\\nIf I move the content inside the fixture it'll be more difficult to edit.\\n\\nEven if fixture maintenance was a non-issue I'd still need to dump and load these fixtures again and again during development.\\n\\n\\n\\n\\nWhat I am looking for\\n\\nBasically; getting rid of FlatPage model while maintaining contrib.flatpages functionality. I don't have a clear idea how this should be solved. If there's a clean way of modifying (like add_to_class) FlatPages to get the information somewhere other than the database I'd prefer that. Maybe the metadata can be inserted to the templates and then a special manager that reads this data would replace the default manager of FlatPages.\\n\\nIf I don't prefer manual editing over admin functionality for flatpages, how can take the database out of the equation?\\n\",\n  'completion': \"Using the direct_to_template generic view would be a lot simpler.  You could use the passed in parameters on one view to specify the actual template in urls.py, if you don't want to add an entry for each page:\\n\\nr'^foo/(?P<template_name>.+)/$','direct_to_template', {'template': 'foo_index.html'}),\\n\\n\\nThen import the template in your foo_index.html:\\n\\n{% include template_name %}\\n\\n\"},\n {'prompt': 'How do I connect to Gmail and determine which messages have attachments?  I then want to download each attachment, printing out the Subject: and From: for each message as I process it.\\n',\n  'completion': 'Hard one :-)\\n\\nimport email, getpass, imaplib, os\\n\\ndetach_dir = \\'.\\' # directory where to save attachments (default: current)\\nuser = raw_input(\"Enter your GMail username:\")\\npwd = getpass.getpass(\"Enter your password: \")\\n\\n# connecting to the gmail imap server\\nm = imaplib.IMAP4_SSL(\"imap.gmail.com\")\\nm.login(user,pwd)\\nm.select(\"[Gmail]/All Mail\") # here you a can choose a mail box like INBOX instead\\n# use m.list() to get all the mailboxes\\n\\nresp, items = m.search(None, \"ALL\") # you could filter using the IMAP rules here (check http://www.example-code.com/csharp/imap-search-critera.asp)\\nitems = items[0].split() # getting the mails id\\n\\nfor emailid in items:\\n    resp, data = m.fetch(emailid, \"(RFC822)\") # fetching the mail, \"`(RFC822)`\" means \"get the whole stuff\", but you can ask for headers only, etc\\n    email_body = data[0][1] # getting the mail content\\n    mail = email.message_from_string(email_body) # parsing the mail content to get a mail object\\n\\n    #Check if any attachments at all\\n    if mail.get_content_maintype() != \\'multipart\\':\\n        continue\\n\\n    print \"[\"+mail[\"From\"]+\"] :\" + mail[\"Subject\"]\\n\\n    # we use walk to create a generator so we can iterate on the parts and forget about the recursive headach\\n    for part in mail.walk():\\n        # multipart are just containers, so we skip them\\n        if part.get_content_maintype() == \\'multipart\\':\\n            continue\\n\\n        # is this part an attachment ?\\n        if part.get(\\'Content-Disposition\\') is None:\\n            continue\\n\\n        filename = part.get_filename()\\n        counter = 1\\n\\n        # if there is no filename, we create one with a counter to avoid duplicates\\n        if not filename:\\n            filename = \\'part-%03d%s\\' % (counter, \\'bin\\')\\n            counter += 1\\n\\n        att_path = os.path.join(detach_dir, filename)\\n\\n        #Check if its already there\\n        if not os.path.isfile(att_path) :\\n            # finally write the stuff\\n            fp = open(att_path, \\'wb\\')\\n            fp.write(part.get_payload(decode=True))\\n            fp.close()\\n\\n\\nWowww! That was something. ;-) But try the same in Java, just for fun!\\n\\nBy the way, I tested that in a shell, so some errors likely remain.\\n\\nEnjoy\\n\\nEDIT:\\n\\nBecause mail-box names can change from one country to another, I recommend doing m.list() and picking an item in it before m.select(\"the mailbox name\") to avoid this error:\\n\\n\\n  imaplib.error: command SEARCH illegal in state AUTH, only allowed in\\n  states SELECTED\\n\\n'},\n {'prompt': \"Recently I needed to do weighted random selection of elements from a list, both with and without replacement. While there are well known and good algorithms for unweighted selection, and some for weighted selection without replacement (such as modifications of the resevoir algorithm), I couldn't find any good algorithms for weighted selection with replacement. I also wanted to avoid the resevoir method, as I was selecting a significant fraction of the list, which is small enough to hold in memory.\\n\\nDoes anyone have any suggestions on the best approach in this situation? I have my own solutions, but I'm hoping to find something more efficient, simpler, or both.\\n\",\n  'completion': \"One of the fastest ways to make many with replacement samples from an unchanging list is the alias method.  The core intuition is that we can create a set of equal-sized bins for the weighted list that can be indexed very efficiently through bit operations, to avoid a binary search.  It will turn out that, done correctly, we will need to only store two items from the original list per bin, and thus can represent the split with a single percentage.\\n\\nLet's us take the example of five equally weighted choices, (a:1, b:1, c:1, d:1, e:1)\\n\\nTo create the alias lookup:\\n\\n\\nNormalize the weights such that they sum to 1.0.  (a:0.2 b:0.2 c:0.2 d:0.2 e:0.2)  This is the probability of choosing each weight.\\nFind the smallest power of 2 greater than or equal to the number of variables, and create this number of partitions, |p|.  Each partition represents a probability mass of 1/|p|.  In this case, we create 8 partitions, each able to contain 0.125.\\nTake the variable with the least remaining weight, and place as much of it's mass as possible in an empty partition.  In this example, we see that a fills the first partition.  (p1{a|null,1.0},p2,p3,p4,p5,p6,p7,p8) with (a:0.075, b:0.2 c:0.2 d:0.2 e:0.2)\\nIf the partition is not filled, take the variable with the most weight, and fill the partition with that variable.  \\n\\n\\nRepeat steps 3 and 4, until none of the weight from the original partition need be assigned to the list.\\n\\nFor example, if we run another iteration of 3 and 4, we see \\n\\n(p1{a|null,1.0},p2{a|b,0.6},p3,p4,p5,p6,p7,p8) with (a:0, b:0.15 c:0.2 d:0.2 e:0.2) left to be assigned\\n\\nAt runtime:\\n\\n\\nGet a U(0,1) random number, say binary 0.001100000\\nbitshift it lg2(p), finding the index partition.  Thus, we shift it by 3, yielding 001.1, or position 1, and thus partition 2.\\nIf the partition is split, use the decimal portion of the shifted random number to decide the split. In this case, the value is 0.5, and 0.5 < 0.6, so return a.\\n\\n\\nHere is some code and another explanation, but unfortunately it doesn't use the bitshifting technique, nor have I actually verified it.\\n\"},\n {'prompt': \"I need a way to compute the nth root of a long integer in Python. \\n\\nI tried pow(m, 1.0/n), but it doesn't work:\\n\\n\\n  OverflowError: long int too large to convert to float\\n\\n\\nAny ideas?\\n\\nBy long integer I mean REALLY long integers like:\\n\\n\\n  11968003966030964356885611480383408833172346450467339251\\n  196093144141045683463085291115677488411620264826942334897996389\\n  485046262847265769280883237649461122479734279424416861834396522\\n  819159219215308460065265520143082728303864638821979329804885526\\n  557893649662037092457130509980883789368448042961108430809620626\\n  059287437887495827369474189818588006905358793385574832590121472\\n  680866521970802708379837148646191567765584039175249171110593159\\n  305029014037881475265618958103073425958633163441030267478942720\\n  703134493880117805010891574606323700178176718412858948243785754\\n  898788359757528163558061136758276299059029113119763557411729353\\n  915848889261125855717014320045292143759177464380434854573300054\\n  940683350937992500211758727939459249163046465047204851616590276\\n  724564411037216844005877918224201569391107769029955591465502737\\n  961776799311859881060956465198859727495735498887960494256488224\\n  613682478900505821893815926193600121890632\\n\\n\",\n  'completion': 'If it\\'s a REALLY big number. You could use a binary search.\\n\\ndef find_invpow(x,n):\\n    \"\"\"Finds the integer component of the n\\'th root of x,\\n    an integer such that y ** n <= x < (y + 1) ** n.\\n    \"\"\"\\n    high = 1\\n    while high ** n <= x:\\n        high *= 2\\n    low = high/2\\n    while low < high:\\n        mid = (low + high) // 2\\n        if low < mid and mid**n < x:\\n            low = mid\\n        elif high > mid and mid**n > x:\\n            high = mid\\n        else:\\n            return mid\\n    return mid + 1\\n\\n\\nFor example:\\n\\n>>> x = 237734537465873465\\n>>> n = 5\\n>>> y = find_invpow(x,n)\\n>>> y\\n2986\\n>>> y**n <= x <= (y+1)**n\\nTrue\\n>>>\\n>>> x = 119680039660309643568856114803834088331723464504673392511960931441>\\n>>> n = 45\\n>>> y = find_invpow(x,n)\\n>>> y\\n227661383982863143360L\\n>>> y**n <= x < (y+1)**n\\nTrue\\n>>> find_invpow(y**n,n) == y\\nTrue\\n>>>\\n\\n'},\n {'prompt': 'I\\'m doing a Python script where I need to spawn several ssh-copy-id processes, and they need for me to type in a password, so i\\'m using PExpect.\\n\\nI have basically this:\\n\\nchild = pexpect.spawn(\\'command\\')\\nchild.expect(\\'password:\\')\\nchild.sendline(\\'the password\\')\\n\\n\\nand then I want to spawn another process, I don\\'t care about this one anymore, whether it ended or not.\\n\\nchild = pexpect.spawn(\\'command2\\')\\nchild.expect(\\'password:\\')\\nchild.sendline(\\'the password\\')\\n\\n\\nAnd the code is hanging at the second \"spawn\"\\n\\nHowever, if I comment out the first call, the second one works, so i\\'m guessing that the fact that the first one is still running or something is keeping it from working.\\n\\nNow, the other thing I haven\\'t been able to do is wait until the first one stops.\\nI\\'ve tried:\\nchild.close() - it hangs (both with True and False as parameters)\\nchild.read(-1) - it hangs\\nchild.expect(pexpect.EOF) - it hangs.\\nchild.terminate() - it hangs  (both with True and False as parameters)\\n\\nAny ideas on what could be happening?\\nNOTE: I\\'m not a Python expert, and i have never used pexpect before, so ANY idea is more than welcome.\\n\\nThanks!\\n\\n\\n\\nUPDATE: This is definitely related to ssh-copy-id, because with other processes, spawn works well even if they don\\'t return.\\nAlso, apparently ssh-copy-id never returns an EOF.\\n',\n  'completion': 'Fortunately or not, but OpenSSH client seems to be very picky about passwords and where they come from.\\n\\nYou may try using Paramiko Python SSH2 library. Here\\'s a simple example how to use it with password authentication, then issue some shell commands (echo \"...\" >> $HOME/.ssh/authorized_keys being the simplest) to add your public key on remote host.\\n'},\n {'prompt': 'I\\'m looking for ways to watch mouse and keyboard events on Windows, Linux and Mac from Python.\\n\\nMy application is a time tracker. I\\'m not looking into the event, I just record the time when it happens. If there are no events for a certain time, say 10 minutes, I assume that the user has left and stop the current project.\\n\\nWhen the user returns (events come in again), I wait a moment (so this doesn\\'t get triggered by the cleaning crew or your pets or an earthquake). If the events persist over a longer period of time, I assume that the user has returned and I pop up a small, inactive window where she can choose to add the time interval to \"break\", the current project (meeting, etc) or a different project.\\n\\nI\\'ve solved the keylogger for Windows using the pyHook.\\n\\nOn Linux, I have found a solution but I don\\'t like it: I can watch all device nodes in /etc/input and update a timestamp somewhere in /var or /tmp every time I see an event. There are two drawbacks: 1. I can\\'t tell whether the event if from the user who is running the time tracker and 2. this little program needs to be run as root (not good).\\n\\nOn Mac, I have no idea, yet.\\n\\nQuestions:\\n\\n\\nIs there a better way to know whether the user is creating events than watching the event devices on Linux?\\nAny pointers how to do that on a Mac?\\n\\n',\n  'completion': 'There are couple of open source apps that might give you some pointers:\\n\\n\\nPyKeylogger is python keylogger for windows and linux\\nlogKext is a c++ keylogger for mac\\n\\n'},\n {'prompt': \"Currently my code is organized in the following tree structure:\\n\\nsrc/\\n    module1.py\\n    module2.py\\n    test_module1.py\\n    test_module2.py\\n    subpackage1/\\n        __init__.py\\n        moduleA.py\\n        moduleB.py\\n        test_moduleA.py\\n        test_moduleB.py\\n\\n\\nWhere the module*.py files contains the source code and the test_module*.py contains the TestCases for the relevant module.\\n\\nWith the following comands I can run the tests contained in a single file, for example:\\n\\n$ cd src\\n$ nosetests test_filesystem.py\\n..................\\n----------------------------------------------------------------------\\nRan 18 tests in 0.390s\\n\\nOK\\n\\n\\nHow can I run all tests? I tried with nosetests -m 'test_.*' but it doesn't work.\\n\\n$cd src\\n$ nosetests -m 'test_.*'\\n\\n----------------------------------------------------------------------\\nRan 0 tests in 0.000s\\n\\nOK\\n\\n\\nThanks\\n\",\n  'completion': \"Whether you seperate or mix tests and modules is probably a matter of taste, although I would strongly advocate for keeping them apart (setup reasons, code stats etc).\\n\\nWhen you're using nosetests, make sure that all directories with tests are real packages:\\n\\nsrc/\\n    module1.py\\n    module2.py\\n    subpackage1/\\n        __init__.py\\n        moduleA.py\\n        moduleB.py\\ntests/\\n    __init__.py\\n    test_module1.py\\n    test_module2.py\\n    subpackage1/\\n        __init__.py\\n        test_moduleA.py\\n        test_moduleB.py\\n\\n\\nThis way, you can just run nosetests in the toplevel directory and all tests will be found. You need to make sure that src/ is on the PYTHONPATH, however, otherwise all the tests will fail due to missing imports.\\n\"},\n {'prompt': 'just want to know what are the main differences among them? and the power of each language (where it\\'s better to use it).\\n\\nEdit: it\\'s not \"vs.\" like topic, just information.\\n',\n  'completion': 'In order of appearance, the languages are sed, awk, perl, python.\\n\\nThe sed program is a stream editor, and is designed to apply the actions from a script to each line (or, more generally, to specified ranges of lines) of the input file or files.  Its language is based on ed, the Unix editor, and although it has conditionals and so on, it is hard to work with for complex tasks.  You can work minor miracles with it - but at a cost to the hair on your head.  However, it is probably the fastest of the programs when attempting tasks within its remit.  (It has the least powerful regular expressions of the programs discussed - adequate for many purposes, but certainly not PCRE - Perl-Compatible Regular Expressions)\\n\\nThe awk program (name from the initials of its authors - Aho, Weinberger and Kernighan) is a tool originally for formatting reports.  It can be used as a souped up sed; in its more recent versions, it is computationally complete.  It uses an interesting idea - the program is based on \\'patterns matched\\' and \\'actions taken when the pattern matches\\'.  The patterns are fairly powerful (Extended Regular Expressions).  The language for the actions is similar to C.  One of the key features of awk is that it splits the input lines into fields automatically.\\n\\nPerl was written in part as an awk-killer and sed-killer.  Two of the programs provided with it are a2p and s2p for converting awk scripts and sed scripts into Perl.  Perl is one of the earliest of the next generation of scripting languages (Tcl/Tk can probably claim primacy).  It has powerful integrated regular expression handling with a vastly more powerful language.  It provides access to almost all system calls, and has the extensibility of the CPAN modules.  (Neither awk nor sed is extensible.)  One of Perl\\'s mottos is \"TMTOWTDI - There\\'s more than one way to do it\" (pronounced \"tim-toady\").  Perl has \\'objects\\', but it is more of an add-on than a fundamental part of the language.\\n\\nPython was written last, and probably in part as a reaction to Perl.  It has some interesting syntactic ideas (indenting to indicate levels - no braces or equivalents).  It is more fundamentally object-oriented than Perl; it is just as extensible as Perl.\\n\\nOK - when to use each?\\n\\n\\nsed - when you need to do simple text transforms on files.\\nawk - when you only need simple formatting and summarization or transformation of data.\\nperl - for almost any task, but especially when the task needs complex regular expressions.\\npython - for the same tasks that you could use Perl for.\\n\\n\\nI\\'m not aware of anything that Perl can do that Python can\\'t, nor vice versa.  The choice between the two would depend on other factors.  I learned Perl before there was a Python, so I tend to use it.  Python has less accreted syntax and is generally somewhat simpler to learn.  Perl 6, when it becomes available, will be a fascinating development.\\n\\n(Note that the \\'overviews\\' of Perl and Python, in particular, are woefully incomplete; whole books could be written on the topic.)\\n'},\n {'prompt': 'I\\'m interested in how much up front validation people do in the Python they write.\\n\\nHere are a few examples of simple functions:\\n\\ndef factorial(num):\\n    \"\"\"Computes the factorial of num.\"\"\"\\n\\ndef isPalindrome(inputStr):\\n    \"\"\"Tests to see if inputStr is the same backwards and forwards.\"\"\"\\n\\ndef sum(nums):\\n    \"\"\"Same as the built-in sum()... computes the sum of all the numbers passed in.\"\"\"\\n\\n\\nHow thoroughly do you check the input values before beginning computation, and how do you do your checking? Do you throw some kind of proprietary exception if input is faulty (BadInputException defined in the same module, for example)? Do you just start your calculation and figure it will throw an exception at some point if bad data was passed in (\"asd\" to factorial, for example)?\\n\\nWhen the passed in value is supposed to be a container do you check not only the container but all the values inside it?\\n\\nWhat about situations like factorial, where what\\'s passed in might be convertible to an int (e.g. a float) but you might lose precision when doing so?\\n',\n  'completion': \"I assert what's absolutely essential.\\n\\nImportant: What's absolutely essential.  Some people over-test things.\\n\\ndef factorial(num):\\n    assert int(num)\\n    assert num > 0\\n\\n\\nIsn't completely correct.  long is also a legal possibility.\\n\\ndef factorial(num):\\n    assert type(num) in ( int, long )\\n    assert num > 0\\n\\n\\nIs better, but still not perfect.  Many Python types (like rational numbers, or number-like objects) can also work in a good factorial function.  It's hard to assert that an object has basic integer-like properties without being too specific and eliminating future unthought-of classes from consideration.\\n\\nI never define unique exceptions for individual functions.  I define a unique exception for a significant module or package.  Usually, however, just an Error class or something similar.  That way the application says except somelibrary.Error,e: which is about all you need to know.  Fine-grained exceptions get fussy and silly.\\n\\nI've never done this, but I can see places where it might be necessary. \\n\\nassert all( type(i) in (int,long) for i in someList ) \\n\\n\\nGenerally, however, the ordinary Python built-in type checks work fine. They find almost all of the exceptional situations that matter almost all the time.   When something isn't the right type, Python raises a TypeError that always points at the right line of code.\\n\\nBTW.  I only add asserts at design time if I'm absolutely certain the function will be abused.  I sometimes add assertions later when I have a unit test that fails in an obscure way.\\n\"},\n {'prompt': \"I've had some experience with Pygame, but there seems to be a lot of buzz around Pyglet these days.\\n\\nHow do these two libraries compare? What would be the advantage of using one over the other, both in features and ease of use?\\n\\nFinally, would you say that one is more Pythonic than the other?\\n\",\n  'completion': 'Pygame: LGPL license\\n\\nPyglet: BSD license\\n\\nPygame relies on SDL libraries heavily\\n\\nPyglet is a pure python library with fewer dependencies, I think it requires better understanding of OpenGL\\n\\nPygame is around here for a long time, a lot of people used it\\n\\nPyglet is a new lib\\n\\nPygame is geared towards game development (cursors, sprites, joystick/gamepad support)\\n\\nPyglet is more general purpose (though it has a Sprite class)\\n\\nI found also this discussion on pyglet-users mailing list: from pygame+pyopengl to pyglet\\n\\nDisclaimer: I did not use either yet, only tried some tutorials ;-)\\n'},\n {'prompt': 'Is there a way to find the application name of the current active window at a given time on Mac OS X using Python?\\n',\n  'completion': \"This should work:\\n\\n#!/usr/bin/python\\n\\nfrom AppKit import NSWorkspace\\nactiveAppName = NSWorkspace.sharedWorkspace().activeApplication()['NSApplicationName']\\nprint activeAppName\\n\\n\\nOnly works on Leopard, or on Tiger if you have PyObjC installed and happen to point at the right python binary in line one (not the case if you've installed universal MacPython, which you'd probably want to do on Tiger). But Peter's answer with the Carbon way of doing this will probably be quite a bit faster, since importing anything from AppKit in Python takes a while, or more accurately, importing something from AppKit for the first time in a Python process takes a while.\\n\\nIf you need this inside a PyObjC app, what I describe will work great and fast, since you only experience the lag of importing AppKit once.  If you need this to work as a command-line tool, you'll notice the performance hit.  If that's relevant to you, you're probably better off building a 10 line Foundation command line tool in Xcode using Peter's code as a starting point.\\n\"},\n {'prompt': 'The best I can come up with for now is this monstrosity:\\n\\n>>> datetime.utcnow() \\\\\\n...   .replace(tzinfo=pytz.UTC) \\\\\\n...   .astimezone(pytz.timezone(\"Australia/Melbourne\")) \\\\\\n...   .replace(hour=0,minute=0,second=0,microsecond=0) \\\\\\n...   .astimezone(pytz.UTC) \\\\\\n...   .replace(tzinfo=None)\\ndatetime.datetime(2008, 12, 16, 13, 0)\\n\\n\\nI.e., in English, get the current time (in UTC), convert it to some other timezone, set the time to midnight, then convert back to UTC.\\n\\nI\\'m not just using now() or localtime() as that would use the server\\'s timezone, not the user\\'s timezone.\\n\\nI can\\'t help feeling I\\'m missing something, any ideas?\\n',\n  'completion': 'I think you can shave off a few method calls if you do it like this:\\n\\n>>> from datetime import datetime\\n>>> datetime.now(pytz.timezone(\"Australia/Melbourne\")) \\\\\\n            .replace(hour=0, minute=0, second=0, microsecond=0) \\\\\\n            .astimezone(pytz.utc)\\n\\n\\nBUTâ\\x80¦ there is a bigger problem than aesthetics in your code: it will give the wrong result on the day of the switch to or from Daylight Saving Time.\\n\\nThe reason for this is that neither the datetime constructors nor replace() take DST changes into account.\\n\\nFor example:\\n\\n>>> now = datetime(2012, 4, 1, 5, 0, 0, 0, tzinfo=pytz.timezone(\"Australia/Melbourne\"))\\n>>> print now\\n2012-04-01 05:00:00+10:00\\n>>> print now.replace(hour=0)\\n2012-04-01 00:00:00+10:00 # wrong! midnight was at 2012-04-01 00:00:00+11:00\\n>>> print datetime(2012, 3, 1, 0, 0, 0, 0, tzinfo=tz)\\n2012-03-01 00:00:00+10:00 # wrong again!\\n\\n\\nHowever, the documentation for tz.localize() states:\\n\\n\\n  This method should be used to construct localtimes, rather\\n  than passing a tzinfo argument to a datetime constructor.\\n\\n\\nThus, your problem is solved like so:\\n\\n>>> import pytz\\n>>> from datetime import datetime, date, time\\n\\n>>> tz = pytz.timezone(\"Australia/Melbourne\")\\n>>> the_date = date(2012, 4, 1) # use date.today() here\\n\\n>>> midnight_without_tzinfo = datetime.combine(the_date, time())\\n>>> print midnight_without_tzinfo\\n2012-04-01 00:00:00\\n\\n>>> midnight_with_tzinfo = tz.localize(midnight_without_tzinfo)\\n>>> print midnight_with_tzinfo\\n2012-04-01 00:00:00+11:00\\n\\n>>> print midnight_with_tzinfo.astimezone(pytz.utc)\\n2012-03-31 13:00:00+00:00\\n\\n\\nNo guarantees for dates before 1582, though.\\n'},\n {'prompt': 'Is there a Pythonic way to have only one instance of a program running? \\n\\nThe only reasonable solution I\\'ve come up with is trying to run it as a server on some port, then second program trying to bind to same port - fails. But it\\'s not really a great idea, maybe there\\'s something more lightweight than this?  \\n\\n(Take into consideration that program is expected to fail sometimes, i.e. segfault - so things like \"lock file\" won\\'t work)\\n\\nUpdate: the solutions offered are much more complex and less reliant than just having a port occupied with a non-existent server, so I\\'d have to go with that one.\\n',\n  'completion': 'The following code should do the job, it is cross-platform and runs on Python 2.4-3.2. I tested it on Windows, OS X and Linux.\\n\\nfrom tendo import singleton\\nme = singleton.SingleInstance() # will sys.exit(-1) if other instance is running\\n\\n\\nThe latest code version is available singleton.py. Please file bugs here.\\n\\nYou can install tend using one of the following methods:\\n\\n\\neasy_install tendo\\npip install tendo\\nmanually by getting it from http://pypi.python.org/pypi/tendo\\n\\n'},\n {'prompt': \"For example I can point the url '^/accounts/password/reset/$' to django.contrib.auth.views.password_reset with my template filename in the context but I think need to send more context details.\\n\\nI need to  know exactly what context to add for each of the password reset and change views.\\n\",\n  'completion': \"If you take a look at the sources for django.contrib.auth.views.password_reset you'll see that it uses RequestContext. The upshot is, you can use Context Processors to modify the context which may allow you to inject the information that you need.\\n\\nThe b-list has a good introduction to context processors.\\n\\nEdit (I seem to have been confused about what the actual question was):\\n\\nYou'll notice that password_reset takes a named parameter called template_name:\\n\\ndef password_reset(request, is_admin_site=False, \\n            template_name='registration/password_reset_form.html',\\n            email_template_name='registration/password_reset_email.html',\\n            password_reset_form=PasswordResetForm, \\n            token_generator=default_token_generator,\\n            post_reset_redirect=None):\\n\\n\\nCheck password_reset for more information.\\n\\n... thus, with a urls.py like:\\n\\nfrom django.conf.urls.defaults import *\\nfrom django.contrib.auth.views import password_reset\\n\\nurlpatterns = patterns('',\\n     (r'^/accounts/password/reset/$', password_reset, {'template_name': 'my_templates/password_reset.html'}),\\n     ...\\n)\\n\\n\\ndjango.contrib.auth.views.password_reset will be called for URLs matching '/accounts/password/reset' with the keyword argument template_name = 'my_templates/password_reset.html'.\\n\\nOtherwise, you don't need to provide any context as the password_reset view takes care of itself. If you want to see what context you have available, you can trigger a TemplateSyntax error and look through the stack trace find the frame with a local variable named context. If you want to modify the context then what I said above about context processors is probably the way to go.\\n\\nIn summary: what do you need to do to use your own template? Provide a template_name keyword argument to the view when it is called. You can supply keyword arguments to views by including a dictionary as the third member of a URL pattern tuple.\\n\"},\n {'prompt': 'When writing custom classes it is often important to allow equivalence by means of the == and != operators. In Python, this is made possible by implementing the __eq__ and __ne__ special methods, respectively. The easiest way I\\'ve found to do this is the following method:\\n\\nclass Foo:\\n    def __init__(self, item):\\n        self.item = item\\n\\n    def __eq__(self, other):\\n        if isinstance(other, self.__class__):\\n            return self.__dict__ == other.__dict__\\n        else:\\n            return False\\n\\n    def __ne__(self, other):\\n        return not self.__eq__(other)\\n\\n\\nDo you know of more elegant means of doing this? Do you know of any particular disadvantages to using the above method of comparing __dict__s?\\n\\nNote: A bit of clarification--when __eq__ and __ne__ are undefined, you\\'ll find this behavior:\\n\\n>>> a = Foo(1)\\n>>> b = Foo(1)\\n>>> a is b\\nFalse\\n>>> a == b\\nFalse\\n\\n\\nThat is, a == b evaluates to False because it really runs a is b, a test of identity (i.e., \"Is a the same object as b?\").\\n\\nWhen __eq__ and __ne__ are defined, you\\'ll find this behavior (which is the one we\\'re after):\\n\\n>>> a = Foo(1)\\n>>> b = Foo(1)\\n>>> a is b\\nFalse\\n>>> a == b\\nTrue\\n\\n',\n  'completion': \"You need to be careful with inheritance:\\n\\n>>> class Foo:\\n    def __eq__(self, other):\\n        if isinstance(other, self.__class__):\\n            return self.__dict__ == other.__dict__\\n        else:\\n            return False\\n\\n>>> class Bar(Foo):pass\\n\\n>>> b = Bar()\\n>>> f = Foo()\\n>>> f == b\\nTrue\\n>>> b == f\\nFalse\\n\\n\\nCheck types more strictly, like this:\\n\\ndef __eq__(self, other):\\n    if type(other) is type(self):\\n        return self.__dict__ == other.__dict__\\n    return False\\n\\n\\nBesides that, your approach will work fine, that's what special methods are there for.\\n\"},\n {'prompt': \"I have a friend who likes to use metaclasses, and regularly offers them as a solution.\\n\\nI am of the mind that you almost never need to use metaclasses. Why? because I figure if you are doing something like that to a class, you should probably be doing it to an object. And a small redesign/refactor is in order.\\n\\nBeing able to use metaclasses has caused a lot of people in a lot of places to use classes as some kind of second rate object, which just seems disastrous to me. Is programming to be replaced by meta-programming? The addition of class decorators has unfortunately made it even more acceptable.\\n\\nSo please, I am desperate to know your valid (concrete) use-cases for metaclasses in Python. Or to be enlightened as to why mutating classes is better than mutating objects, sometimes.\\n\\nI will start:\\n\\n\\n  Sometimes when using a third-party\\n  library it is useful to be able to\\n  mutate the class in a certain way.\\n\\n\\n(this is the only case I can think of, and it's not concrete)\\n\",\n  'completion': \"The purpose of metaclasses isn't to replace the class/object distinction with metaclass/class - it's to change the behaviour of class definitions (and thus their instances) in some way.  Effectively it's to alter the behaviour of the class statement in ways that may be more useful for your particular domain than the default.  The things I have used them for are:\\n\\n\\nTracking subclasses, usually to register handlers.  This is handy when using a plugin style setup, where you wish to register a handler for a particular thing simply by subclassing and setting up a few class attributes.  eg.  suppose you write a handler for various music formats, where each class implements appropriate methods (play / get tags etc) for its type.  Adding a handler for a new type becomes:\\n\\nclass Mp3File(MusicFile):\\n    extensions = ['.mp3']  # Register this type as a handler for mp3 files\\n    ...\\n    # Implementation of mp3 methods go here\\n\\n\\nThe metaclass then maintains a dictionary of {'.mp3' : MP3File, ... } etc, and constructs an object of the appropriate type when you request a handler through a factory function.\\nChanging behaviour.  You may want to attach a special meaning to certain attributes, resulting in altered behaviour when they are present.  For example, you may want to look for methods with the name _get_foo and _set_foo and transparently convert them to properties.  As a real-world example, here's a recipe I wrote to give more C-like struct definitions.  The metaclass is used to convert the declared items into a struct format string, handling inheritance etc, and produce a class capable of dealing with it.\\n\\nFor other real-world examples, take a look at various ORMs, like sqlalchemy's ORM or sqlobject.  Again, the purpose is to interpret defintions (here SQL column definitions) with a particular meaning.\\n\\n\"},\n {'prompt': 'Is there a way in Python to override a class method at instance level?\\nFor example:\\n\\nclass Dog:\\n    def bark(self):\\n        print \"WOOF\"\\n\\nboby = Dog()\\nboby.bark() # WOOF\\n# METHOD OVERRIDE\\nboby.bark() # WoOoOoF!!\\n\\n',\n  'completion': 'Yes, it\\'s possible:\\n\\nclass Dog:\\n    def bark(self):\\n        print \"Woof\"\\n\\ndef new_bark(self):\\n    print \"Woof Woof\"\\n\\nfoo = Dog()\\n\\nfuncType = type(Dog.bark)\\n\\n# \"Woof\"\\nfoo.bark()\\n\\n# replace bark with new_bark for this object only\\nfoo.bark = funcType(new_bark, foo, Dog)\\n\\nfoo.bark()\\n# \"Woof Woof\"\\n\\n'},\n {'prompt': 'I have the following classes: Ingredients, Recipe and RecipeContent...\\n\\nclass Ingredient(models.Model):\\n    name = models.CharField(max_length=30, primary_key=True)\\n    qty_on_stock = models.IntegerField()\\n\\n    def __unicode__(self):\\n        return self.name\\n\\nclass Recipe(models.Model):\\n    name = models.CharField(max_length=30, primary_key=True)\\n    comments = models.TextField(blank=True)\\n    ingredient = models.ManyToManyField(Ingredient)\\n\\n    def __unicode__(self):\\n        return self.name\\n\\nclass RecipeContent(models.Model):\\n    recipe = models.ForeignKey(Recipe)\\n    ingredients = models.ForeignKey(Ingredient)\\n    qty_used = models.IntegerField()\\n\\n\\nbut for __unicode__() in RecipeContent I would like to use the Recipe name to which this RecipeContent belongs to... is there a way to do it?\\n',\n  'completion': 'class RecipeContent(models.Model):\\n  ...\\n  def __unicode__(self):\\n    # You can access ForeignKey properties through the field name!\\n    return self.recipe.name\\n\\n'},\n {'prompt': 'I was just reading through \"Learning Python\" by Mark Lutz and came across this code sample:\\n\\n\\n>>> L = [\\'grail\\']\\n>>> L.append(L)\\n>>> L\\n[\\'grail\\', [...]]\\n\\n\\n\\nIt was identified as a cyclic data structure.\\n\\nSo I was wondering, and here is my question:\\n\\nWhat is a \\'cyclic data structure\\' used for in real life programming?\\n\\nThere seems to be a little confusion, which i think stems from the very brief code sample... here\\'s a few more lines using the same object L\\n\\n\\n>>> L[0]\\n\\'grail\\'\\n>>> L[1][0]\\n\\'grail\\'\\n>>> L[1][1][0]\\n\\'grail\\'\\n\\n\\n',\n  'completion': 'Lots of things.  Circular buffer, for example:  you have some collection of data with a front and a back, but an arbitrary number of nodes, and the \"next\" item from the last should take you back to the first.\\n\\nGraph structures are often cyclic; acyclicity is a special case.  Consider, for example, a graph containing all the cities and roads in a traveling salesman problem.\\n\\n\\n\\nOkay, here\\'s a particular example for you.  I set up a collection of towns here in Colorado:\\n\\nV=[\"Boulder\", \"Denver\", \"Colorado Springs\", \"Pueblo\", \"Limon\"]\\n\\n\\nI then set up pairs of cities where there is a road connecting them.\\n\\nE=[[\"Boulder\", \"Denver\"],\\n   [\"Denver\", \"Colorado Springs\"],\\n   [\"Colorado Springs\", \"Pueblo\"],\\n   [\"Denver\", \"Limon\"],\\n   [\"Colorado Springs\", \"Limon\"]]\\n\\n\\nThis has a bunch of cycles.  For example, you can drive from Colorado Springs, to Limon, to Denver, and back to Colorado Springs.\\n\\nIf you create a data structure that contains all the cities in V and all the roads in E, that\\'s a graph data structure.  This graph would have cycles.\\n'},\n {'prompt': \"I have the following data structure (a list of lists)\\n\\n[\\n ['4', '21', '1', '14', '2008-10-24 15:42:58'], \\n ['3', '22', '4', '2somename', '2008-10-24 15:22:03'], \\n ['5', '21', '3', '19', '2008-10-24 15:45:45'], \\n ['6', '21', '1', '1somename', '2008-10-24 15:45:49'], \\n ['7', '22', '3', '2somename', '2008-10-24 15:45:51']\\n]\\n\\n\\nI would like to be able to\\n\\n\\nUse a function to reorder the list so that I can group by each item in the list. For example I'd like to be able to group by the second column (so that all the 21's are together) \\nUse a function to only display certain values from each inner list. For example i'd like to reduce this list to only contain the 4th field value of '2somename' \\n\\n\\nso the list would look like this \\n\\n[\\n     ['3', '22', '4', '2somename', '2008-10-24 15:22:03'], \\n     ['7', '22', '3', '2somename', '2008-10-24 15:45:51']\\n]\\n\\n\",\n  'completion': \"For the first question, the first thing you should do is sort the list by the second field:\\n\\nx = [\\n ['4', '21', '1', '14', '2008-10-24 15:42:58'], \\n ['3', '22', '4', '2somename', '2008-10-24 15:22:03'], \\n ['5', '21', '3', '19', '2008-10-24 15:45:45'], \\n ['6', '21', '1', '1somename', '2008-10-24 15:45:49'], \\n ['7', '22', '3', '2somename', '2008-10-24 15:45:51']\\n]\\n\\nfrom operator import itemgetter\\n\\nx.sort(key=itemgetter(1))\\n\\n\\nThen you can use itertools' groupby function:\\n\\nfrom itertools import groupby\\ny = groupby(x, itemgetter(1))\\n\\n\\nNow y is an iterator containing tuples of (element, item iterator). It's more confusing to explain these tuples than it is to show code:\\n\\nfor elt, items in groupby(x, itemgetter(1)):\\n    print(elt, items)\\n    for i in items:\\n        print(i)\\n\\n\\nWhich prints:\\n\\n21 <itertools._grouper object at 0x511a0>\\n['4', '21', '1', '14', '2008-10-24 15:42:58']\\n['5', '21', '3', '19', '2008-10-24 15:45:45']\\n['6', '21', '1', '1somename', '2008-10-24 15:45:49']\\n22 <itertools._grouper object at 0x51170>\\n['3', '22', '4', '2somename', '2008-10-24 15:22:03']\\n['7', '22', '3', '2somename', '2008-10-24 15:45:51']\\n\\n\\nFor the second part, you should use list comprehensions as mentioned already here:\\n\\nfrom pprint import pprint as pp\\npp([y for y in x if y[3] == '2somename'])\\n\\n\\nWhich prints:\\n\\n[['3', '22', '4', '2somename', '2008-10-24 15:22:03'],\\n ['7', '22', '3', '2somename', '2008-10-24 15:45:51']]\\n\\n\"},\n {'prompt': 'Without having the full module path of a Django model, is it possible to do something like:\\n\\nmodel = \\'User\\' [in Django namespace]\\nmodel.objects.all()\\n\\n\\n...as opposed to:\\n\\nUser.objects.all().\\n\\n\\nEDIT: I am trying to make this call based on command-line input. Is it possible to avoid the import statement, e.g., \\n\\nmodel = django.authx.models.User\\n\\n\\nWithout Django returning the error:\\n\\n\"global name django is not defined.\"\\n\\n',\n  'completion': \"I think you're looking for this:\\n\\nfrom django.db.models.loading import get_model\\nmodel = get_model('app_name', 'model_name')\\n\\n\\nThere are other methods, of course, but this is the way I'd handle it if you don't know what models file you need to import into your namespace.  (Note there's really no way to safely get a model without first knowing what app it belongs to.  Look at the source code to loading.py if you want to test your luck at iterating over all the apps' models.)\\n\\nUpdate: According to Django's deprecation timeline, django.db.models.loading has been deprecated in Django 1.7 and will be removed in Django 1.9. As pointed out in Alasdair's answer, a new API for dynamically loading models was added to Django 1.7.\\n\"},\n {'prompt': \"According to setuptools documentation, setup.py develop is supposed to create the egg-link file and update easy_install.pth when installing into site-packages folder.  However, in my case it's only creating the egg-link file.  How does setuptools decide if it needs to update easy_install.pth?\\n\\nSome more info:\\nIt works when I have setuptools 0.6c7 installed as a folder under site-packages.  But when I use setuptools 0.6c9 installed as a zipped egg, it does not work.\\n\",\n  'completion': 'Reinstall setuptools with the command easy_install --always-unzip --upgrade setuptools. If that fixes it then the zipping was the problem.\\n'},\n {'prompt': \"I'm storing some additional per-user information using the AUTH_PROFILE_MODULE.\\n\\nWe can access the user in a Django template using {{ request.user }} but how do we access fields in the profile since the profile is only accessible via a function user.get_profile() ?\\n\\nIs it really required to explicitly pass the profile into the template every time?\\n\",\n  'completion': \"Use {{ request.user.get_profile.whatever }}. Django's templating language automatically calls things that are callable - in this case, the .get_profile() method.\\n\"},\n {'prompt': 'How to return more than one variable from a function in Python?\\n',\n  'completion': \"You separate the values you want to return by commas:\\n\\ndef get_name():\\n   # you code\\n   return first_name, last_name\\n\\n\\nThe commas indicate it's a tuple, so you could wrap your values by parentheses:\\n\\nreturn (first_name, last_name)\\n\\n\\nThen when you call the function you a) save all values to one variable as a tuple, or b) separate your variable names by commas\\n\\nname = get_name() # this is a tuple\\nfirst_name, last_name = get_name()\\n(first_name, last_name) = get_name() # You can put parentheses, but I find it ugly\\n\\n\"},\n {'prompt': 'I am interested in getting an install of Django running on IronPython, has anyone had any success getting this running with some level of success?  \\n\\nIf so can you please tell of your experiences, performance, suggest some tips, resources and gotchas?\\n',\n  'completion': \"Besides the Jeff Hardy blog post on Django + IronPython mentioned by Tony Meyer, it might be useful to also read Jeff's two other posts in the same series on his struggles with IronPython, easy_install and zlib. The first is Solving the zlib problem which discusses the absence of zlib for IronPython; hence, no easyinstall. Jeff reimplemented zlib based on ComponentAce's zlib.net. And finally, in easy_install on IronPython, Part Deux Jeff discusses some final tweaks that are needed before easy_install can be used with IronPython.\\n\"},\n {'prompt': 'I\\'m trying to unit test some code that looks like this:\\n\\ndef main():\\n    parser = optparse.OptionParser(description=\\'This tool is cool\\', prog=\\'cool-tool\\')\\n    parser.add_option(\\'--foo\\', action=\\'store\\', help=\\'The foo option is self-explanatory\\')\\n    options, arguments = parser.parse_args()\\n    if not options.foo:\\n        parser.error(\\'--foo option is required\\')\\n    print \"Your foo is %s.\" % options.foo\\n    return 0\\n\\nif __name__ == \\'__main__\\':\\n   sys.exit(main())\\n\\n\\nWith code that looks like this:\\n\\n@patch(\\'optparse.OptionParser\\')\\ndef test_main_with_missing_p4clientsdir_option(self, mock_optionparser):\\n    #\\n    # setup\\n    #\\n    optionparser_mock = Mock()\\n    mock_optionparser.return_value = optionparser_mock\\n    options_stub = Mock()\\n    options_stub.foo = None\\n    optionparser_mock.parse_args.return_value = (options_stub, sentinel.arguments)\\n    def parser_error_mock(message):\\n        self.assertEquals(message, \\'--foo option is required\\')\\n        sys.exit(2)\\n    optionparser_mock.error = parser_error_mock\\n\\n    #\\n    # exercise & verify\\n    #\\n    self.assertEquals(sut.main(), 2)\\n\\n\\nI\\'m using Michael Foord\\'s Mock, and nose to run the tests.\\n\\nWhen I run the test, I get:\\n\\n  File \"/Users/dspitzer/Programming/Python/test-optparse-error/tests/sut_tests.py\", line 27, in parser_error_mock\\n    sys.exit(2)\\nSystemExit: 2\\n\\n----------------------------------------------------------------------\\nRan 1 test in 0.012s\\n\\nFAILED (errors=1)\\n\\n\\nThe problem is that OptionParser.error does a sys.exit(2), and so main() naturally relies on that.  But nose or unittest detects the (expected) sys.exit(2) and fails the test.\\n\\nI can make the test pass by adding \"return 2\" under the parser.error() call in main() and removing the sys.exit() call from parser_error_mock(), but I find it distasteful to modify the code under test to allow a test to pass.  Is there a better solution?\\n\\nUpdate: df\\'s answer works, although the correct call is \"self.assertRaises(SystemExit, sut.main)\".\\n\\nWhich means the test passes whatever the number is in the sys.exit() in parser_error_mock(). Is there any way to test for the exit code?\\n\\nBTW, the test is more robust if I add:\\n\\nself.assertEquals(optionparser_mock.method_calls, [(\\'add_option\\', (\\'--foo\\',), {\\'action\\': \\'store\\', \\'help\\': \\'The foo option is self-explanatory\\'}), (\\'parse_args\\', (), {})])\\n\\n\\nat the end.\\n\\nUpdate 2: I can test for the exit code by replacing \"self.assertRaises(SystemExit, sut.main)\" with:\\n\\ntry:\\n    sut.main()\\nexcept SystemExit, e:\\n    self.assertEquals(type(e), type(SystemExit()))\\n    self.assertEquals(e.code, 2)\\nexcept Exception, e:\\n    self.fail(\\'unexpected exception: %s\\' % e)\\nelse:\\n    self.fail(\\'SystemExit exception expected\\')\\n\\n',\n  'completion': 'Will this work instead of assertEquals?\\n\\nself.assertRaises(SystemExit, sut.main, 2)\\n\\n\\nThis should catch the SystemExit exception and prevent the script from terminating.\\n'},\n {'prompt': \"I'm especially interested in solutions with source code available (django independency is a plus, but I'm willing to hack my way through)\\n\",\n  'completion': 'You can, of course, write your own handler. Other than that, your options currently are limited to:\\n\\n\\ngae-rest, which provides a RESTful interface to the datastore.\\napprocket, a tool for replicating between MySQL and App Engine.\\nThe amusingly named GAEBAR - Google App Engine Backup and Restore.\\n\\n'},\n {'prompt': 'I want to be able to run WSGI apps but my current hosting restricts it. Does anybody know a company that can accommodate my requirements?\\n',\n  'completion': \"My automatic response would be WebFaction.  \\n\\nI haven't personally hosted with them, but they are primarily Python-oriented (founded by the guy who wrote CherryPy, for example, and as far as I know they were the first to roll out Python 3.0 support).\\n\"},\n {'prompt': 'By default when Django runs against sqlite backend it creates a new in memory database for a test. That means for every class that derives from unittest.TestCase, I get a new database. Can this be changed so that it is cleared before every test method is run?\\n\\nExample: I am testing a manager class that provides additional abstraction on top of Django persistent objects. The code looks more-less like that\\n\\nclass TestForManager(unittest.TestCase):\\n  def testAddingBlah(self):\\n    manager = Manager()\\n    self.assertEquals(manager.getBlahs(), 0)\\n    manager.addBlah(...)\\n    self.assertEquals(manager.getBlahs(), 1)\\n\\n  def testAddingBlahInDifferentWay(self):\\n    manager = Manager()\\n    self.assertEquals(manager.getBlahs(), 0)\\n    manager.addBlahInDifferentWay(...)\\n    self.assertEquals(manager.getBlahs(), 1)\\n\\n\\nNow, the first assertion of second test fails, because the state of the database is preserved between test calls and there already is an instance of Blah in the database.\\n',\n  'completion': 'As always, solution is trivial: use django.test.TestCase not unittest.TestCase. And it works in all major versions of Django!\\n'},\n {'prompt': 'I know there is something buried in here.  But I was just wondering if there is an actual way built into Python to determine text file encoding?\\n\\nThanks for your help :)\\n\\nEdit:  As a side question, it can be ignored if you want but why is the type of encoding not put into the file so it could be detected easier?\\n',\n  'completion': \"Correctly detecting the encoding all times is impossible.\\n\\n(From chardet FAQ:)\\n\\n\\n  However, some encodings are optimized\\n  for specific languages, and languages\\n  are not random. Some character\\n  sequences pop up all the time, while\\n  other sequences make no sense. A\\n  person fluent in English who opens a\\n  newspaper and finds â\\x80\\x9ctxzqJv 2!dasd0a\\n  QqdKjvzâ\\x80\\x9d will instantly recognize that\\n  that isn't English (even though it is\\n  composed entirely of English letters).\\n  By studying lots of â\\x80\\x9ctypicalâ\\x80\\x9d text, a\\n  computer algorithm can simulate this\\n  kind of fluency and make an educated\\n  guess about a text's language.\\n\\n\\nThere is the chardet library that uses that study to try to detect encoding. chardet is a port of the auto-detection code in Mozilla. \\n\\nYou can also use UnicodeDammit. It will try the following methods:\\n\\n\\nAn encoding discovered in the document itself: for instance, in an XML declaration or (for HTML documents) an http-equiv META tag. If Beautiful Soup finds this kind of encoding within the document, it parses the document again from the beginning and gives the new encoding a try. The only exception is if you explicitly specified an encoding, and that encoding actually worked: then it will ignore any encoding it finds in the document.\\nAn encoding sniffed by looking at the first few bytes of the file. If an encoding is detected at this stage, it will be one of the UTF-* encodings, EBCDIC, or ASCII.\\nAn encoding sniffed by the chardet library, if you have it installed.\\nUTF-8\\nWindows-1252 \\n\\n\"},\n {'prompt': 'There seem to be many excellent web frameworks for Python.  Has anyone used any of these (Pylons, Web2Py, Django) with IronPython?\\n',\n  'completion': 'Django has been run on IronPython before, but as a proof-of-concept. I know the IronPython team are interested in Django support as a metric for Python-compatibility.\\n\\nSomewhat related is the possibility to use IronPython with ASP.NET and ASP.NET MVC, which is probably more mature.\\n'},\n {'prompt': \"Is there any reason to prefer unicode(somestring, 'utf8') as opposed to somestring.decode('utf8')?\\n\\nMy only thought is that .decode() is a bound method so python may be able to resolve it more efficiently, but correct me if I'm wrong.\\n\",\n  'completion': 'It\\'s easy to benchmark it:\\n\\n>>> from timeit import Timer\\n>>> ts = Timer(\"s.decode(\\'utf-8\\')\", \"s = \\'Ã©Ã©Ã©\\'\")\\n>>> ts.timeit()\\n8.9185450077056885\\n>>> tu = Timer(\"unicode(s, \\'utf-8\\')\", \"s = \\'Ã©Ã©Ã©\\'\") \\n>>> tu.timeit()\\n2.7656929492950439\\n>>> \\n\\n\\nObviously, unicode() is faster.\\n\\nFWIW, I don\\'t know where you get the impression that methods would be faster - it\\'s quite the contrary.\\n'},\n {'prompt': 'Is it possible to use the with statement directly with CSV files? It seems natural to be able to do something like this:\\n\\nimport csv\\nwith csv.reader(open(\"myfile.csv\")) as reader:\\n    # do things with reader\\n\\n\\nBut csv.reader doesn\\'t provide the __enter__ and __exit__ methods, so this doesn\\'t work. I can however do it in two steps:\\n\\nimport csv\\nwith open(\"myfile.csv\") as f:\\n    reader = csv.reader(f)\\n    # do things with reader\\n\\n\\nIs this second way the ideal way to do it? Why wouldn\\'t they make csv.reader directly compatible with the with statement?\\n',\n  'completion': 'The primary use of with statement is an exception-safe cleanup of an object used in the statement. with makes sure that files are closed, locks are released, contexts are restored, etc.\\n\\nDoes csv.reader have things to cleanup in case of exception?\\n\\nI\\'d go with:\\n\\nwith open(\"myfile.csv\") as f:\\n    for row in csv.reader(f):\\n        # process row\\n\\n\\nYou don\\'t need to submit the patch to use csv.reader and with statement together.\\n\\nimport contextlib\\n\\n\\nHelp on function contextmanager in module contextlib:\\n\\ncontextmanager(func)\\n    @contextmanager decorator.\\n\\n\\nTypical usage:\\n\\n    @contextmanager\\n    def some_generator(<arguments>):\\n        <setup>\\n        try:\\n            yield <value>\\n        finally:\\n            <cleanup>\\n\\n\\nThis makes this:\\n\\n    with some_generator(<arguments>) as <variable>:\\n        <body>\\n\\n\\nequivalent to this:\\n\\n    <setup>\\n    try:\\n        <variable> = <value>\\n        <body>\\n    finally:\\n        <cleanup>\\n\\n\\nHere\\'s a concrete example how I\\'ve used it: curses_screen.\\n'},\n {'prompt': \"I'm working on an attendance entry form for a band.  My idea is to have a section of the form to enter event information for a performance or rehearsal.  Here's the model for the event table:\\n\\nclass Event(models.Model):\\n    event_id = models.AutoField(primary_key=True)\\n    date = models.DateField()\\n    event_type = models.ForeignKey(EventType)\\n    description = models.TextField()\\n\\n\\nThen I'd like to have an inline FormSet that links the band members to the event and records whether they were present, absent, or excused:\\n\\nclass Attendance(models.Model):\\n    attendance_id = models.AutoField(primary_key=True)\\n    event_id = models.ForeignKey(Event)\\n    member_id = models.ForeignKey(Member)\\n    attendance_type = models.ForeignKey(AttendanceType)\\n    comment = models.TextField(blank=True)\\n\\n\\nNow, what I'd like to do is to pre-populate this inline FormSet with entries for all the current members and default them to being present (around 60 members).  Unfortunately, Django doesn't allow initial values in this case.\\n\\nAny suggestions?\\n\",\n  'completion': \"So, you're not going to like the answer, partly because I'm not yet done writing the code and partly because it's a lot of work.\\n\\nWhat you need to do, as I discovered when I ran into this myself, is:\\n\\n\\nSpend a lot of time reading through the formset and model-formset code to get a feel for how it all works (not helped by the fact that some of the functionality lives on the formset classes, and some of it lives in factory functions which spit them out). You will need this knowledge in the later steps.\\nWrite your own formset class which subclasses from BaseInlineFormSet and accepts initial. The really tricky bit here is that you must override __init__(), and you must make sure that it calls up to BaseFormSet.__init__() rather than using the direct parent or grandparent __init__() (since those are BaseInlineFormSet and BaseModelFormSet, respectively, and neither of them can handle initial data).\\nWrite your own subclass of the appropriate admin inline class (in my case it was TabularInline) and override its get_formset method to return the result of inlineformset_factory() using your custom formset class.\\nOn the actual ModelAdmin subclass for the model with the inline, override add_view and change_view, and replicate most of the code, but with one big change: build the initial data your formset will need, and pass it to your custom formset (which will be returned by your ModelAdmin's get_formsets() method).\\n\\n\\nI've had a few productive chats with Brian and Joseph about improving this for future Django releases; at the moment, the way the model formsets work just make this more trouble than it's usually worth, but with a bit of API cleanup I think it could be made extremely easy.\\n\"},\n {'prompt': \"In C, we can find the size of an int, char, etc. I want to know how to get size of objects like a string, integer, etc. in Python.\\n\\nRelated question: How many bytes per element are there in a Python list (tuple)?\\n\\nI am using an XML file which contains size fields that specify the size of value. I must parse this XML and do my coding. When I want to change the value of a particular field, I will check the size field of that value. Here I want to compare whether the new value that I'm gong to enter is of the same size as in XML. I need to check the size of new value. In case of a string I can say its the length. But in case of int, float, etc. I am confused.\\n\",\n  'completion': \"Just use the sys.getsizeof function defined in the sys module.\\n\\n\\n  sys.getsizeof(object[, default]):\\n  \\n  Return the size of an object in bytes.\\n  The object can be any type of object.\\n  All built-in objects will return\\n  correct results, but this does not\\n  have to hold true for third-party\\n  extensions as it is implementation\\n  specific.\\n  \\n  The default argument allows to define\\n  a value which will be returned if the\\n  object type does not provide means to\\n  retrieve the size and would cause a\\n  TypeError.\\n  \\n  getsizeof calls the objectâ\\x80\\x99s\\n  __sizeof__ method and adds an additional garbage collector overhead\\n  if the object is managed by the\\n  garbage collector.\\n\\n\\nUsage example, in python 3.0:\\n\\n>>> import sys\\n>>> x = 2\\n>>> sys.getsizeof(x)\\n14\\n>>> sys.getsizeof(sys.getsizeof)\\n32\\n>>> sys.getsizeof('this')\\n38\\n>>> sys.getsizeof('this also')\\n48\\n\\n\\nIf you are in python < 2.6 and don't have sys.getsizeof you can use this extensive module instead. Never used it though.\\n\"},\n {'prompt': \"I was looking at the builtin object methods in the Python documentation, and I was interested in the documentation for object.__repr__(self). Here's what it says:\\n\\n\\n  Called by the repr() built-in function\\n  and by string conversions (reverse\\n  quotes) to compute the â\\x80\\x9cofficialâ\\x80\\x9d\\n  string representation of an object. If\\n  at all possible, this should look like\\n  a valid Python expression that could\\n  be used to recreate an object with the\\n  same value (given an appropriate\\n  environment). If this is not possible,\\n  a string of the form <...some useful\\n  description...> should be returned.\\n  The return value must be a string\\n  object. If a class defines repr()\\n  but not str(), then repr() is\\n  also used when an â\\x80\\x9cinformalâ\\x80\\x9d string\\n  representation of instances of that\\n  class is required.\\n  \\n  This is typically used for debugging,\\n  so it is important that the\\n  representation is information-rich and\\n  unambiguous\\n\\n\\nThe most interesting part to me, was...\\n\\n\\n  If at all possible, this should look like a valid Python expression that could be used to recreate an object with the same value\\n\\n\\n... but I'm not sure exactly what this means. It says it should look like an expression which can be used to recreate the object, but does that mean it should just be an example of the sort of expression you could use, or should it be an actual expression, that can be executed (eval etc..) to recreate the object? Or... should it be just a rehasing of the actual expression which was used, for pure information purposes?\\n\\nIn general I'm a bit confused as to exactly what I should be putting here.\\n\",\n  'completion': \">>> from datetime import date\\n>>>\\n>>> repr(date.today())        # calls date.today().__repr__()\\n'datetime.date(2009, 1, 16)'\\n>>> eval(_)                   # _ is the output of the last command\\ndatetime.date(2009, 1, 16)\\n\\n\\nThe output is a string that can be parsed by the python interpreter and results in an equal object.\\n\\nIf that's not possible, it should return a string in the form of <...some useful description...>.\\n\"},\n {'prompt': \"I want to create a list of lambda objects from a list of constants in Python; for instance:\\n\\nlistOfNumbers = [1,2,3,4,5]\\nsquare = lambda x: x * x\\nlistOfLambdas = [lambda: square(i) for i in listOfNumbers]\\n\\n\\nThis will create a list of lambda objects, however, when I run them:\\n\\nfor f in listOfLambdas:\\n    print f(),\\n\\n\\nI would expect that it would print\\n\\n1 4 9 16 25\\n\\n\\nInstead, it prints:\\n\\n25 25 25 25 25\\n\\n\\nIt seems as though the lambdas have all been given the wrong parameter. Have I done something wrong, and is there a way to fix it? I'm in Python 2.4 I think.\\n\\nEDIT: a bit more of trying things and such came up with this:\\n\\nlistOfLambdas = []\\nfor num in listOfNumbers:\\n    action = lambda: square(num)\\n    listOfLambdas.append(action)\\n    print action()\\n\\n\\nPrints the expected squares from 1 to 25, but then using the earlier print statement:\\n\\nfor f in listOfLambdas:\\n    print f(),\\n\\n\\nstill gives me all 25s. How did the existing lambda objects change between those two print calls?\\n\\nRelated question: Why results of map() and list comprehension are different?\\n\",\n  'completion': 'You have:\\n\\nlistOfLambdas = [lambda: i*i for i in range(6)]\\n\\nfor f in listOfLambdas:\\n    print f()\\n\\n\\nOutput:\\n\\n25\\n25\\n25\\n25\\n25\\n25\\n\\n\\nYou need currying!  Aside from being delicious, use this default value \"hack\".\\n\\nlistOfLambdas = [lambda i=i: i*i for i in range(6)]\\n\\nfor f in listOfLambdas:\\n    print f()\\n\\n\\nOutput:\\n\\n0\\n1\\n4\\n9\\n16\\n25\\n\\n\\nNote the i=i.  That\\'s where the magic happens.  \\n'},\n {'prompt': 'I want to send a datetime.datetime object in serialized form from Python using JSON and de-serialize in JavaScript using JSON. What is the best way to do this?\\n',\n  'completion': 'You can add the \\'default\\' parameter to json.dumps to handle this:\\n\\ndate_handler = lambda obj: (\\n    obj.isoformat()\\n    if isinstance(obj, datetime.datetime)\\n    or isinstance(obj, datetime.date)\\n    else None\\n)\\njson.dumps(datetime.datetime.now(), default=date_handler)\\n\\'\"2010-04-20T20:08:21.634121\"\\'\\n\\n\\nWhich is ISO 8601 format. \\n\\nA more comprehensive default handler function:\\n\\ndef handler(obj):\\n    if hasattr(obj, \\'isoformat\\'):\\n        return obj.isoformat()\\n    elif isinstance(obj, ...):\\n        return ...\\n    else:\\n        raise TypeError, \\'Object of type %s with value of %s is not JSON serializable\\' % (type(obj), repr(obj))\\n\\n\\nUpdate:  Added output of type as well as value.\\nUpdate:  Also handle date \\n'},\n {'prompt': \"I'm using Python and Qt 4.4 and I have to print some pages. Initially I thought I'd use HTML with CSS to produce those pages. But HTML has some limitations.\\n\\nNow the question is: is there anything that's better than HTML but just (or almost) as easy to use? Additionally, it should be GPL-compatible.\\n\\nEdit:\\n\\nkdgregory & Mark G: The most obvious limitation is that I can't specify the printer margins. There is another problem: How do I add page numbers?\\n\\nJeremy French: One thing I have to print is a list of all the products someone ordered which can spread over a few pages.\\n\",\n  'completion': \"I have been fighting with printed (or PDF) output from Python for 8 years now and so far I came across the following approaches (in order of personal preference):\\n\\n\\nUsing JasperReports via pyJasper (written by me) or JasperServer. You can use the WYSIWYG design tool iReport to define your layout. Your Python code will contact the Java based Jasper engine via HTTP and make it render a PDF (pyJasper handles that). We use that for a few thousand pages a day.\\nUse plain text output. You can't get any faster. We use that for a few hundred pages per day.\\nUse XSLT-FO. You also have to call a Java based rendering engine like FOB. Might result in performance issues but can be mitigated by having a long running Java server process  - same approach than with Jasper. We use that for a few hundred pages per day but writing XSLT-FO documents made my head hurt. Not used for new code.\\nGenerate LaTeX source and use a latex software package to render to PDF. Getting LaTeX to look like you like is quite difficult. But as long as you go with the provided LaTeX styles, you are fine. Not used in production at my shop.\\nPDF generation with the ReportLab Toolkit. Somewhat low level. Even more low level: FPDF. We use FPDF-Ruby for a few hundred pages a day. Took a lot of fiddeling to get the layout we wanted.\\nDirectly generate Postscript. Strange but you nearly can't get more in terms of speed and control. We used that to generate contact sheets with a few hundred thousand Jpegs per day. Takes fiddling but is fun.\\nuse troff/groff to generate Postscript/PDF. Very low level bute nice to do simple, high volume things. Never used it thus in production.\\n\\n\\nFor orders, invoices and the like I highly recommend JasperReports. The ability to use a visual editor to define the layout is a huge time saver.\\n\"},\n {'prompt': \"Is there a standard way to associate version string with a python package in such way that I could do the following?\\n\\nimport foo\\nprint foo.version\\n\\n\\nI would imagine there's some way to retrieve that data without any extra hardcoding, since minor/major strings are specified in setup.py already. Alternative solution that I found was to have import __version__ in my foo/__init__.py and then have __version__.py generated by setup.py.\\n\",\n  'completion': 'Here is how I do this. Advantages of the following method:\\n\\n\\nIt provides a __version__ attribute.\\nIt provides the standard metadata version. Therefore it will be detected by pkg_resources or other tools that parse the package metadata (EGG-INFO and/or PKG-INFO, PEP 0345).\\nIt doesn\\'t import your package (or anything else) when building your package, which can cause problems in some situations. (See the comments below about what problems this can cause.)\\nThere is only one place that the version number is written down, so there is only one place to change it when the version number changes, and there is less chance of inconsistent versions.\\n\\n\\nHere is how it works: the \"one canonical place\" to store the version number is a .py file, named \"_version.py\" which is in your Python package, for example in myniftyapp/_version.py. This file is a Python module, but your setup.py doesn\\'t import it! (That would defeat feature 3.) Instead your setup.py knows that the contents of this file is very simple, something like:\\n\\n__version__ = \"3.6.5\"\\n\\n\\nAnd so your setup.py opens the file and parses it, with code like:\\n\\nimport re\\nVERSIONFILE=\"myniftyapp/_version.py\"\\nverstrline = open(VERSIONFILE, \"rt\").read()\\nVSRE = r\"^__version__ = [\\'\\\\\"]([^\\'\\\\\"]*)[\\'\\\\\"]\"\\nmo = re.search(VSRE, verstrline, re.M)\\nif mo:\\n    verstr = mo.group(1)\\nelse:\\n    raise RuntimeError(\"Unable to find version string in %s.\" % (VERSIONFILE,))\\n\\n\\nThen your setup.py passes that string as the value of the \"version\" argument to setup(), thus satisfying feature 2.\\n\\nTo satisfy feature 1, you can have your package (at run-time, not at setup time!) import the _version file from myniftyapp/__init__.py like this:\\n\\nfrom _version import __version__\\n\\n\\nHere is an example of this technique that I\\'ve been using for years.\\n\\nThe code in that example is a bit more complicated, but the simplified example that I wrote into this comment should be a complete implementation.\\n\\nHere is example code of importing the version.\\n\\nIf you see anything wrong with this approach, please let me know: zooko at zooko dot com. If you don\\'t see anything wrong with this approach then use it! Because the more packages come with their version numbers in the expected places the better!\\n'},\n {'prompt': \"I read in the manual of Numpy that there is function det(M) that can calculate the determinant. However, I can't find the det() method in Numpy.\\n\\nBy the way, I use Python 2.5. There should be no compatibility problems with Numpy.\\n\",\n  'completion': 'You can use numpy.linalg.det to compute the determinant of an array:\\n\\nIn [1]: import numpy\\n\\nIn [2]: M = [[1, 2], [3, 4]]\\n\\nIn [3]: print numpy.linalg.det(M)\\nOut[3]: -2.0000000000000004\\n\\n'},\n {'prompt': \"In PHP you can just use $_POST for POST and $_GET for GET (Query string) variables. What's the equivalent in Python?\\n\",\n  'completion': 'suppose you\\'re posting a html form with this:\\n\\n<input type=\"text\" name=\"username\">\\n\\n\\nIf using raw cgi:\\n\\nimport cgi\\nform = cgi.FieldStorage()\\nprint form[\"username\"]\\n\\n\\nIf using Django, Pylons, Flask or Pyramid: \\n\\nprint request.GET[\\'username\\'] # for GET form method\\nprint request.POST[\\'username\\'] # for POST form method\\n\\n\\nUsing Turbogears, Cherrypy:\\n\\nfrom cherrypy import request\\nprint request.params[\\'username\\']\\n\\n\\nWeb.py:\\n\\nform = web.input()\\nprint form.username\\n\\n\\nWerkzeug:\\n\\nprint request.form[\\'username\\']\\n\\n\\nIf using Cherrypy or Turbogears, you can also define your handler function taking a parameter directly:\\n\\ndef index(self, username):\\n    print username\\n\\n\\nGoogle App Engine:\\n\\nclass SomeHandler(webapp2.RequestHandler):\\n    def post(self):\\n        name = self.request.get(\\'username\\') # this will get the value from the field named username\\n        self.response.write(name) # this will write on the document\\n\\n\\nSo you really will have to choose one of those frameworks.\\n'},\n {'prompt': 'In Python compiled regex patterns have a findall method that does the following:\\n\\n\\n  Return all non-overlapping matches of\\n  pattern in string, as a list of\\n  strings. The string is scanned\\n  left-to-right, and matches are\\n  returned in the order found. If one or\\n  more groups are present in the\\n  pattern, return a list of groups; this\\n  will be a list of tuples if the\\n  pattern has more than one group. Empty\\n  matches are included in the result\\n  unless they touch the beginning of\\n  another match.\\n\\n\\nWhat\\'s the canonical way of doing this in Perl? A naive algorithm I can think of is along the lines of \"while a search and replace with the empty string is successful, do [suite]\". I\\'m hoping there\\'s a nicer way. :-)\\n\\nThanks in advance!\\n',\n  'completion': 'Use the /g modifier in your match. From the perlop manual:\\n\\n\\n  The \"/g\" modifier specifies global pattern matching--that is, matching as many times as possible within the string.  How it behaves depends on the context.  In list context, it returns a list of the substrings matched by any capturing parentheses in the regular expression.  If there are no parentheses, it returns a list of all the matched strings, as if there were parentheses around the whole pattern.\\n  \\n  In scalar context, each execution of \"m//g\" finds the next match, returning true if it matches, and false if there is no further match.  The position after the last match can be read or set using the pos() function; see \"pos\" in perlfunc.   A failed match normally resets the search position to the beginning of the string, but you can avoid that by adding the \"/c\" modifier (e.g. \"m//gc\").  Modifying the target string also resets the search position.\\n\\n'},\n {'prompt': \"I'm speaking of this module:\\nhttp://docs.python.org/library/operator.html\\n\\nFrom the article:\\n\\n\\n  The operator module exports a set of\\n  functions implemented in C\\n  corresponding to the intrinsic\\n  operators of Python. For example,\\n  operator.add(x, y) is equivalent to\\n  the expression x+y. The function names\\n  are those used for special class\\n  methods; variants without leading and\\n  trailing __ are also provided for\\n  convenience.\\n\\n\\nI'm not sure I understand the benefit or purpose of this module.\\n\",\n  'completion': 'Possibly the most popular usage is operator.itemgetter.  Given a list lst of tuples, you can sort by the ith element by: lst.sort(key=operator.itemgetter(i))\\n\\nCertainly, you could do the same thing without operator by defining your own key function, but the operator module makes it slightly neater.\\n\\nAs to the rest, python allows a functional style of programming, and so it can come up -- for instance, Greg\\'s reduce example.\\n\\nYou might argue: \"Why do I need operator.add when I can just do: add = lambda x, y: x+y?\" The answers are:\\n\\n\\noperator.add is (I think) slightly faster.\\nIt makes the code easier to understand for you, or another person later, looking at it.  They don\\'t need to look for the definition of add, because they know what the operator module does.\\n\\n'},\n {'prompt': \"I'm new to the MDX/OLAP and I'm wondering if there is any ORM similar like Django ORM for Python that would support OLAP.\\n\\nI'm a Python/Django developer and if there would be something that would have some level of integration with Django I would be much interested in learning more about it.\\n\",\n  'completion': \"Django has some OLAP features that are nearing release.\\n\\nRead http://www.eflorenzano.com/blog/post/secrets-django-orm/\\n\\nhttp://doughellmann.com/2007/12/30/using-raw-sql-in-django.html, also\\n\\nIf you have a proper star schema design in the first place, then one-dimensional results can have the following form.\\n\\nfrom myapp.models import SomeFact\\nfrom collections import defaultdict\\n\\nfacts = SomeFact.objects.filter( dimension1__attribute=this, dimension2__attribute=that )\\nmyAggregates = defaultdict( int )\\nfor row in facts:\\n    myAggregates[row.dimension3__attribute] += row.someMeasure\\n\\n\\nIf you want to create a two-dimensional summary, you have to do something like the following.\\n\\nfacts = SomeFact.objects.filter( dimension1__attribute=this, dimension2__attribute=that )\\nmyAggregates = defaultdict( int )\\nfor row in facts:\\n    key = ( row.dimension3__attribute, row.dimension4__attribute )\\n    myAggregates[key] += row.someMeasure\\n\\n\\nTo compute multiple SUM's and COUNT's and what-not, you have to do something like this.\\n\\nclass MyAgg( object ):\\n    def __init__( self ):\\n        self.count = 0\\n        self.thisSum= 0\\n        self.thatSum= 0\\n\\nmyAggregates= defaultdict( MyAgg )\\nfor row in facts:\\n    myAggregates[row.dimension3__attr].count += 1\\n    myAggregates[row.dimension3__attr].thisSum += row.this\\n    myAggregates[row.dimension3__attr].thatSum += row.that\\n\\n\\nThis -- at first blush -- seems inefficient.  You're trolling through the fact table returning lots of rows which you are then aggregating in your application.\\n\\nIn some cases, this may be faster than the RDBMS's native sum/group_by.  Why?  You're using a simple mapping, not the more complex sort-based grouping operation that the RDBMS often has to use for this.  Yes, you're getting a lot of rows; but you're doing less to get them.\\n\\nThis has the disadvantage that it's not so declarative as we'd like.  It has the advantage that it's pure Django ORM.\\n\"},\n {'prompt': 'I\\'ve just started using the PythonInterpreter from within my Java classes, and it works great! However, if I try to include python modules (re, HTMLParser, etc.), I\\'m receiving the following exception (for re):\\n\\n\\nException in thread \"main\" Traceback (innermost last):\\n  File \"\", line 1, in ?\\nImportError: no module named re\\n\\n\\nHow could I make the classes from the jython jar \"see\" the modules python has available?\\n',\n  'completion': 'You embed jython and you will use some Python-Modules somewere:\\n\\nif you want to set the path (sys.path) in your Java-Code :\\n\\npublic void init() {\\n        interp = new PythonInterpreter(null, new PySystemState());\\n\\n        PySystemState sys = Py.getSystemState();\\n        sys.path.append(new PyString(rootPath));\\n        sys.path.append(new PyString(modulesDir));\\n    }\\n\\n\\nPy is in org.python.core.\\n\\nrootPath and modulesDir is where YOU want !\\n\\nlet rootPath point where you located the standard-jython-lib\\n\\nHave a look at src/org/python/util/PyServlet.java in the Jython-Source-Code for example\\n'},\n {'prompt': 'I want to modify a few tiny details of Django\\'s built-in django.contrib.auth module.  Specifically, I want a different form that makes username an email field (and email an alternate email address.   (I\\'d rather not modify auth any more than necessary -- a simple form change seems to be all that\\'s needed.)\\n\\nWhen I use autodiscover with a customized ModelAdmin for auth I wind up conflicting with auth\\'s own admin interface and get an \"already registered\" error.\\n\\nIt looks like I have to create my own admin site, enumerating all of my Models.  It\\'s only 18 classes, but it seems like a DRY problem -- every change requires both adding to the Model and adding to the customized admin site.\\n\\nOr, should I write my own version of \"autodiscover with exclusions\" to essentially import all the admin modules except auth?\\n',\n  'completion': \"None of the above.  Just use admin.site.unregister().  Here's how I recently added filtering Users on is_active in the admin (n.b. is_active filtering is now on the User model by default in Django core; still works here as an example), all DRY as can be:\\n\\nfrom django.contrib import admin\\nfrom django.contrib.auth.admin import UserAdmin\\nfrom django.contrib.auth.models import User\\n\\nclass MyUserAdmin(UserAdmin):\\n    list_filter = UserAdmin.list_filter + ('is_active',)\\n\\nadmin.site.unregister(User)\\nadmin.site.register(User, MyUserAdmin)\\n\\n\"},\n {'prompt': 'What is the purpose of __slots__ in Python â\\x80\\x94 especially with respect to when would I want to use it and when not?\\n',\n  'completion': 'Quoting Jacob Hallen:\\n\\n\\n  The proper use of __slots__ is to save space in objects. Instead of having\\n  a dynamic dict that allows adding attributes to objects at anytime,\\n  there is a static structure which does not allow additions after creation.\\n  This saves the overhead of one dict for every object that uses slots. While this is sometimes a useful optimization, it would be completely\\n  unnecessary if the Python interpreter was dynamic enough so that it would\\n  only require the dict when there actually were additions to the object.\\n  \\n  Unfortunately there is a side effect to slots. They change the behavior of\\n  the objects that have slots in a way that can be abused by control freaks\\n  and static typing weenies. This is bad, because the control freaks should\\n  be abusing the metaclasses and the static typing weenies should be abusing\\n  decorators, since in Python, there should be only one obvious way of doing something.\\n  \\n  Making CPython smart enough to handle saving space without __slots__ is a major\\n  undertaking, which is probably why it is not on the list of changes for P3k (yet).\\n\\n'},\n {'prompt': 'Searching on Google reveals x2 code snippets. The first result is to this code recipe which has a lot of documentation and explanation, along with some useful discussion underneath. \\n\\nHowever, another code sample, whilst not containing so much documentation, includes sample code for passing commands such as start, stop and restart. It also creates a PID file which can be handy for checking if the daemon is already running etc.\\n\\nThese samples both explain how to create the daemon. Are there any additional things that need to be considered? Is one sample better than the other, and why?\\n',\n  'completion': 'There are many fiddly things to take care of when becoming a well-behaved daemon process:\\n\\n\\nprevent core dumps (many daemons run as root, and core dumps can contain sensitive information)\\nbehave correctly inside a chroot gaol\\nset UID, GID, working directory, umask, and other process parameters appropriately for the use case\\nrelinquish elevated suid, sgid privileges\\nclose all open file descriptors, with exclusions depending on the use case\\nbehave correctly if started inside an already-detached context, such as init, inetd, etc.\\nset up signal handlers for sensible daemon behaviour, but also with specific handlers determined by the use case\\nredirect the standard streams stdin, stdout, stderr since a daemon process no longer has a controlling terminal\\nhandle a PID file as a cooperative advisory lock, which is a whole can of worms in itself with many contradictory but valid ways to behave\\nallow proper cleanup when the process is terminated\\nactually become a daemon process without leading to zombies\\n\\n\\nSome of these are standard, as described in canonical Unix literature (Advanced Programming in the UNIX Environment, by the late W. Richard Stevens, Addison-Wesley, 1992). Others, such as stream redirection and PID file handling, are conventional behaviour most daemon users would expect but that are less standardised.\\n\\nAll of these are covered by the PEP 3143 â\\x80\\x9cStandard daemon process libraryâ\\x80\\x9d specification. The python-daemon reference implementation works on Python 2.7 or later, and Python 3.2 or later.\\n'},\n {'prompt': \"http://docs.djangoproject.com/en/dev/ref/templates/builtins/#regroup\\n\\nI can think of a few ways of doing it with loops but I'd particularly like to know if there is a neat one-liner.\\n\",\n  'completion': \"Combine itertools.groupby with operator.itemgetter to get a pretty nice solution:\\n\\nfrom operator import itemgetter\\nfrom itertools import groupby\\n\\nkey = itemgetter('gender')\\niter = groupby(sorted(people, key=key), key=key)\\n\\nfor gender, people in iter:\\n    print '===', gender, '==='\\n    for person in people:\\n        print person\\n\\n\"},\n {'prompt': 'I would like to know how to convert a string containing digits to a double.\\n',\n  'completion': '>>> x = \"2342.34\"\\n>>> float(x)\\n2342.3400000000001\\n\\n\\nThere you go.  Use float (which is almost always a C double).\\n'},\n {'prompt': \"Does the Python shelve module have any protection built in to make sure two processes aren't writing to a file at the same time?\\n\",\n  'completion': 'The shelve module uses an underlying database package (such as dbm, gdbm or bsddb) .\\n\\nThe restrictions pragraph says (my emphasis):\\n\\n\\n  The shelve module does not support concurrent read/write access to shelved objects. (Multiple simultaneous read accesses are safe.) When a program has a shelf open for writing, no other program should have it open for reading or writing. Unix file locking can be used to solve this, but this differs across Unix versions and requires knowledge about the database implementation used.\\n\\n\\nConclusion: it depends on OS and the underlying DB. To keep things portable, do not build on concurrency.\\n'},\n {'prompt': \"I have a range of dates and a measurement on each of those dates.  I'd like to calculate an exponential moving average for each of the dates.  Does anybody know how to do this?\\n\\nI'm new to python.  It doesn't appear that averages are built into the standard python library, which strikes me as a little odd.  Maybe I'm not looking in the right place.\\n\\nSo, given the following code, how could I calculate the moving weighted average of IQ points for calendar dates?\\n\\nfrom datetime import date\\ndays = [date(2008,1,1), date(2008,1,2), date(2008,1,7)]\\nIQ = [110, 105, 90]\\n\\n\\n(there's probably a better way to structure the data, any advice would be appreciated)\\n\",\n  'completion': 'EDIT:\\nIt seems that mov_average_expw() function from scikits.timeseries.lib.moving_funcs submodule from SciKits (add-on toolkits that complement SciPy) better suits the wording of your question.  \\n\\n\\n\\nTo calculate an exponential smoothing of your data with a smoothing factor alpha (it is (1 - alpha) in Wikipedia\\'s terms):\\n\\n>>> alpha = 0.5\\n>>> assert 0 < alpha <= 1.0\\n>>> av = sum(alpha**n.days * iq \\n...     for n, iq in map(lambda (day, iq), today=max(days): (today-day, iq), \\n...         sorted(zip(days, IQ), key=lambda p: p[0], reverse=True)))\\n95.0\\n\\n\\nThe above is not pretty, so let\\'s refactor it a bit:\\n\\nfrom collections import namedtuple\\nfrom operator    import itemgetter\\n\\ndef smooth(iq_data, alpha=1, today=None):\\n    \"\"\"Perform exponential smoothing with factor `alpha`.\\n\\n    Time period is a day.\\n    Each time period the value of `iq` drops `alpha` times.\\n    The most recent data is the most valuable one.\\n    \"\"\"\\n    assert 0 < alpha <= 1\\n\\n    if alpha == 1: # no smoothing\\n        return sum(map(itemgetter(1), iq_data))\\n\\n    if today is None:\\n        today = max(map(itemgetter(0), iq_data))\\n\\n    return sum(alpha**((today - date).days) * iq for date, iq in iq_data)\\n\\nIQData = namedtuple(\"IQData\", \"date iq\")\\n\\nif __name__ == \"__main__\":\\n    from datetime import date\\n\\n    days = [date(2008,1,1), date(2008,1,2), date(2008,1,7)]\\n    IQ = [110, 105, 90]\\n    iqdata = list(map(IQData, days, IQ))\\n    print(\"\\\\n\".join(map(str, iqdata)))\\n\\n    print(smooth(iqdata, alpha=0.5))\\n\\n\\nExample:\\n\\n$ python26 smooth.py\\nIQData(date=datetime.date(2008, 1, 1), iq=110)\\nIQData(date=datetime.date(2008, 1, 2), iq=105)\\nIQData(date=datetime.date(2008, 1, 7), iq=90)\\n95.0\\n\\n'},\n {'prompt': 'While I like to think of myself as a reasonably competent Python coder, one aspect of the language I\\'ve never been able to grok is decorators.\\n\\nI know what they are (superficially), I\\'ve read tutorials, examples, questions on Stack Overflow, and I understand the syntax, can write my own, occasionally use @classmethod and @staticmethod, but it never occurs to me to use a decorator to solve a problem in my own Python code.  I never encounter a problem where I think, \"Hmm...this looks like a job for a decorator!\"\\n\\nSo, I\\'m wondering if you guys might offer some examples of where you\\'ve used decorators in your own programs, and hopefully I\\'ll have an \"A-ha!\" moment and get them.\\n',\n  'completion': 'I use decorators mainly for timing purposes\\n\\ndef time_dec(func):\\n\\n  def wrapper(*arg):\\n      t = time.clock()\\n      res = func(*arg)\\n      print func.func_name, time.clock()-t\\n      return res\\n\\n  return wrapper\\n\\n\\n@time_dec\\ndef myFunction(n):\\n    ...\\n\\n'},\n {'prompt': \"i have:\\n\\nfor i in range(2,n):\\n    if(something):\\n       do something\\n    else:\\n       do something else\\n       i = 2 **restart the loop\\n\\n\\nBut that doesn't seem to work. Is there a way to restart that loop? \\n\\nThanks\\n\",\n  'completion': 'You may want to consider using a different type of loop where that logic is applicable, because it is the most obvious answer.\\n\\nperhaps a:\\n\\ni=2\\nwhile i < n:\\n    if something:\\n       do something\\n       i += 1\\n    else: \\n       do something else  \\n       i = 2 #restart the loop\\n\\n'},\n {'prompt': 'Is Django a good choice for a security critical application?\\n\\nI am asking this because most of the online banking software is built using Java. Is there any real reason for this?\\n',\n  'completion': 'Actually, the security in Java and Python is the same.  Digest-only password handling, cookies that timeout rapidly, careful deletion of sessions, multi-factor authentication.  None of this is unique to a Java framework or a Python framework like Django.\\n\\nDjango, indeed, has a security backend architecture that allows you to add your own LDAP (or AD) connection, possibly changing the digest technique used.  \\n\\nDjango has a Profile model where you can keep additional authentication factors.\\n\\nDjango offers a few standard decorators for view function authorization checking.  Since Python is so flexible, you can trivially write your own decorator functions to layer in different or additional authentication checking.\\n\\nSecurity is a number of first-class features in Django.\\n'},\n {'prompt': \"First of all,I'm not into web programming. I bumped into django and read a bit about models. I was intrigued by the following code ( from djangoproject.com ) :\\n\\n\\nclass Person(models.Model):\\n    first_name = models.CharField(max_length=50)\\n    last_name = models.CharField(max_length=50)\\n\\n    def __str__(self):\\n        # Note use of django.utils.encoding.smart_str() here because\\n        # first_name and last_name will be unicode strings.\\n        return smart_str('%s %s' % (self.first_name, self.last_name))\\n\\n\\nBy my understanding of python , first_name and last_name are class variables , right ? How is that used in code ( because I guess that setting Person.first_name or Person.last_name will affect all Person instances ) ? Why is it used that way ?\\n\",\n  'completion': 'The essence of your question is \"how come these class variables (which I assign Field objects to) suddenly become instance variables (which I assign data to) in Django\\'s ORM\"?  The answer to that is the magic of Python metaclasses.\\n\\nA metaclass allows you to hook into and modify the process of creating a Python class (not the creation of an instance of that class, the creation of the class itself).\\n\\nDjango\\'s Model object (and thus also your models, which are subclasses) has a ModelBase metaclass.  It looks through all the class attributes of your model, and any that are instances of a Field subclass it moves into a fields list.  That list is assigned as an attribute of the _meta object, which is a class attribute of the model.  Thus you can always get to the actual Field objects via MyModel._meta.fields, or MyModel._meta.get_field(\\'field_name\\').\\n\\nThe Model.__init__ method is then able to use the _meta.fields list to determine what instance attributes should be initialized when a model instance is created.\\n\\nDon\\'t be afraid to dive into the Django source code; it\\'s a great source of education!\\n'},\n {'prompt': 'I would like to know similar, concrete simulations, as the simulation about watering a field here.\\n\\nWhat is your favorite library/internet page for such simulations in Python?\\n\\nI know little Simpy, Numpy and Pygame. I would like to get examples about them.\\n',\n  'completion': 'If you are looking for some game physics (collisions, deformations, gravity, etc.) which looks real and is reasonably fast consider re-using some physics engine libraries.\\n\\nAs a first reference, you may want to look into pymunk, a Python wrapper of Chipmunk 2D physics library. You can find a list of various Open Source physics engines (2D and 3D) in Wikipedia.\\n\\nIf you are looking for physically correct simulations, no matter what language you want to use, it will be much slower (almost never real-time), and you need to use some numerical analysis software (and probably to write something yourself). Exact answer depends on the problem you want to solve. It is a fairly complicated field (of math).\\n\\nFor example, if you need to do simulations in continuum mechanics or electromagnetism, you probably need Finite Difference, Finite Volume or Finite Element methods. For Python, there are some ready-to-use libraries, for example: FiPy (FVM), GetFem++ (FEM), FEniCS/DOLFIN (FEM), and some other.\\n'},\n {'prompt': 'I am looking for a Python3.0 version of \"py2exe\". I tried running 2to3 on the source for py2exe but the code remained broken.\\n\\nAny ideas?\\n',\n  'completion': \"Update 2014-05-15\\n\\npy2exe for Python 3.x is now released! Get it on PyPI.\\n\\nOld information\\n\\nHave a look at the py2exe SourceForge project SVN repository at:\\n\\nhttp://py2exe.svn.sourceforge.net/\\n\\nThe last I looked at it, it said the last update was August 2009. But keep an eye on that to see if there's any Python 3 work in-progress.\\n\\nI've also submitted two feature requests on the py2exe tracker. So far, no feedback on them:\\n\\n\\nSupport Python 3.x\\nProject roadmap\\n\\n\"},\n {'prompt': \"Does anyone know where information about writing gedit plugins can be found ? I'm interested in writing them in Python. I know of Gedit/PythonPluginHowTo\\n , but it isn't very good . Besides the code of writing a plugin that does nothing , I can't seem to find more information . I started to look at other people's code , but I think this shouldn't be the natural way of writing plugins . Can someone help ?\\n\",\n  'completion': \"When I started working on my gedit plugin, I used the howto you gave a link to, also startign with this URL. Then it was looking at other plugins code... I'm sorry to say that, but for me this topic is poorly documented and best and fastest way is to get a pluging done that actually does something.\\n\"},\n {'prompt': \"I found the following behavior at least weird:\\n\\ndef errors():\\n    try:\\n        ErrorErrorError\\n    finally:\\n        return 10\\n\\nprint errors()\\n# prints: 10\\n# It should raise: NameError: name 'ErrorErrorError' is not defined\\n\\n\\nThe exception disappears when you use return inside a finally clause. Is that a bug? Is that documented anywhere?\\n\\nBut the real question (and the answer I will mark as correct) is:\\nWhat is the python developers' reason to allow that odd behavior?\\n\",\n  'completion': '\\n  The exception disappears when you use return inside a finally clause. .. Is that documented anywhere?\\n\\n\\nIt is:\\n\\n\\n  If finally is present, it specifies a â\\x80\\x98cleanupâ\\x80\\x99 handler. The try clause is executed, including any except and else clauses. If an exception occurs in any of the clauses and is not handled, the exception is temporarily saved. The finally clause is executed. If there is a saved exception, it is re-raised at the end of the finally clause. If the finally clause raises another exception or executes a return or break statement, the saved exception is lost.\\n\\n'},\n {'prompt': \"Like most Python developers, I typically keep a console window open with the Python interpreter running to test commands, dir() stuff, help() stuff, etc.\\n\\nLike any console, after a while the visible backlog of past commands and prints gets to be cluttered, and sometimes confusing when re-running the same command several times.  I'm wondering if, and how, to clear the Python interpreter console.\\n\\nI've heard about doing a system call and either calling cls on Windows or clear on Linux, but I was hoping there was something I could command the interpreter itself to do.\\n\\nNote: I'm running on Windows, so Ctrl+L doesn't work.\\n\",\n  'completion': \"As you mentioned, you can do a system call:\\n\\n>>> import os\\n>>> clear = lambda: os.system('cls')\\n>>> clear()\\n\\n\\nI am not sure of any other way in Windows.\\n\"},\n {'prompt': 'I have downloaded the Pyscripter and learning Python. But I have no Idea if it has any job value , especially in India. I am learning Python as a Hobby. But it would be comforting to know if Python programmers are in demand in India.\\n',\n  'completion': \"Everywhere. It's used extensively by google for one.\\n\\nSee list of python software for more info, and also who uses python on the web?\\n\"},\n {'prompt': \"Today I was thinking about a Python project I wrote about a year back where I used logging pretty extensively. I remember having to comment out a lot of logging calls in inner-loop-like scenarios (the 90% code) because of the overhead (hotshot indicated it was one of my biggest bottlenecks).\\n\\nI wonder now if there's some canonical way to programmatically strip out logging calls in Python applications without commenting and uncommenting all the time. I'd think you could use inspection/recompilation or bytecode manipulation to do something like this and target only the code objects that are causing bottlenecks. This way, you could add a manipulator as a post-compilation step and use a centralized configuration file, like so:\\n\\n[Leave ERROR and above]\\nmy_module.SomeClass.method_with_lots_of_warn_calls\\n\\n[Leave WARN and above]\\nmy_module.SomeOtherClass.method_with_lots_of_info_calls\\n\\n[Leave INFO and above]\\nmy_module.SomeWeirdClass.method_with_lots_of_debug_calls\\n\\n\\nOf course, you'd want to use it sparingly and probably with per-function granularity -- only for code objects that have shown logging to be a bottleneck. Anybody know of anything like this?\\n\\nNote: There are a few things that make this more difficult to do in a performant manner because of dynamic typing and late binding. For example, any calls to a method named debug may have to be wrapped with an if not isinstance(log, Logger). In any case, I'm assuming all of the minor details can be overcome, either by a gentleman's agreement or some run-time checking. :-)\\n\",\n  'completion': \"What about using logging.disable?\\n\\nI've also found I had to use logging.isEnabledFor if the logging message is expensive to create.\\n\"},\n {'prompt': 'I\\'m trying to add two images together using NumPy and PIL. The way I would do this in MATLAB would be something like:\\n\\n>> M1 = imread(\\'_1.jpg\\');\\n>> M2 = imread(\\'_2.jpg\\');\\n>> resM = M1 + M2;\\n>> imwrite(resM, \\'res.jpg\\');\\n\\n\\nI get something like this:\\n\\n\\n\\nUsing a compositing program and adding the images the MATLAB result seems to be right.\\n\\nIn Python I\\'m trying to do the same thing like this:\\n\\nfrom PIL import Image\\nfrom numpy import *\\n\\nim1 = Image.open(\\'/Users/rem7/Desktop/_1.jpg\\')\\nim2 = Image.open(\\'/Users/rem7/Desktop/_2.jpg\\')\\n\\nim1arr = asarray(im1)\\nim2arr = asarray(im2)\\n\\naddition = im1arr + im2arr\\n\\nresultImage = Image.fromarray(addition)\\nresultImage.save(\\'/Users/rem7/Desktop/a.jpg\\')\\n\\n\\nand I get something like this:\\n\\n\\n\\nWhy am I getting all those funky colors? I also tried using ImageMath.eval(\"a+b\", a=im1, b=im2), but I get an error about RGB unsupported.\\n\\nI also saw that there is an Image.blend() but that requires an alpha.\\n\\nWhat\\'s the best way to achieve what I\\'m looking for?\\n\\nSource Images (images have been removed):\\n\\n\\n\\n\\nHumm, OK, well I added the source images using the add image icon and they show up when I\\'m editing the post, but for some reason the images don\\'t show up in the post. \\n\\n(images have been removed) 2013 05 09\\n',\n  'completion': \"As everyone suggested already, the weird colors you're observing are overflow. And as you point out in the comment of schnaader's answer you still get overflow if you add your images like this:\\n\\naddition=(im1arr+im2arr)/2\\n\\n\\nThe reason for this overflow is that your NumPy arrays (im1arr  im2arr) are of the uint8 type (i.e. 8-bit). This means each element of the array can only hold values up to 255, so when your sum exceeds 255, it loops back around 0:\\n\\n>>>array([255,10,100],dtype='uint8') +  array([1,10,160],dtype='uint8')\\narray([ 0, 20,  4], dtype=uint8)\\n\\n\\nTo avoid overflow, your arrays should be able to contain values beyond 255. You need to convert them to floats for instance, perform the blending operation and convert the result back to uint8:\\n\\nim1arrF = im1arr.astype('float')\\nim2arrF = im2arr.astype('float')\\nadditionF = (im1arrF+im2arrF)/2\\naddition = additionF.astype('uint8')\\n\\n\\nYou should not do this:\\n\\naddition = im1arr/2 + im2arr/2\\n\\n\\nas you lose information, by squashing the dynamic of the image (you effectively make the images 7-bit) before you perform the blending information.\\n\\nMATLAB note: the reason you don't see this problem in MATLAB, is probably because MATLAB takes care of the overflow implicitly in one of its functions.\\n\"},\n {'prompt': 'Background: I have a small Python application that makes life for developers releasing software in our company a bit easier. I build an executable for Windows using py2exe. The application as well as the binary are checked into Subversion. Distribution happens by people just checking out the directory from SVN. The program has about 6 different Python library dependencies (e.g. ElementTree, Mako)\\n\\nThe situation: Developers want to hack on the source of this tool and then run it without having to build the binary. Currently this means that they need a python 2.6 interpreter (which is fine) and also have the 6 libraries installed locally using easy_install.\\n\\nThe Problem\\n\\n\\nThis is not a public, classical open source environment: I\\'m inside a corporate network, the tool will never leave the \"walled garden\" and we have seriously inconvenient barriers to getting to the outside internet (NTLM authenticating proxies and/or machines without direct internet access).\\nI want the hurdles to starting to hack on this tool to be minimal: nobody should have to hunt for the right dependency in the right version, they should have to execute as little setup as possible. Optimally the prerequisites would be having a Python installation and just checking out the program from Subversion.\\n\\n\\nAnecdote: The more self-contained the process is the easier it is to repeat it. I had my machine swapped out for a new one and went through the unpleasant process of having to reverse engineer the dependencies, reinstall distutils, hunting down the libraries online and getting them to install (see corporate internet restrictions above). \\n',\n  'completion': 'Just use virtualenv - it is a tool to create isolated Python environments. You can create a set-up script and distribute the whole bunch if you want.\\n'},\n {'prompt': 'I know that you can prepopulate admin form fields based on other fields. For example, I have a slug field that is automatically populated based on the title field.\\n\\nHowever, I would also like to make other automatic prepopulations based on the date. For example, I have an URL field, and I want it to automatically be set to http://example.com/20090209.mp3 where 20090209 is YYYYMMDD. \\n\\nI would also like to have a text field that automatically starts with something like \"Hello my name is author\" where author is the current user\\'s name. Of course, I also want the person to be able to edit the field. The point is to just make it so the user can fill out the admin form more easily, and not just to have fields that are completely automatic.\\n',\n  'completion': 'I know that you can prepopulate some values via GET, it will be something like this\\n\\nhttp://localhost:8000/admin/app/model/add/?model_field=hello\\n\\n\\nI got some problems with date fields but, maybe this could help you.\\n'},\n {'prompt': \"The purpose of my question is to strengthen my knowledge base with Python and get a better picture of it, which includes knowing its faults and surprises.  To keep things specific, I'm only interested in the CPython interpreter.\\n\\nI'm looking for something similar to what learned from my PHP landmines\\nquestion where some of the answers were well known to me but a couple were borderline horrifying.\\n\\nUpdate:\\n   Apparently one maybe two people are upset that I asked a question that's already partially answered outside of Stack Overflow.  As some sort of compromise here's the URL\\nhttp://www.ferg.org/projects/python_gotchas.html\\n\\nNote that one or two answers here already are original from what was written on the site referenced above.\\n\",\n  'completion': 'Expressions in default arguments are calculated when the function is defined, not when itâ\\x80\\x99s called. \\n\\nExample: consider defaulting an argument to the current time:\\n\\n>>>import time\\n>>> def report(when=time.time()):\\n...     print when\\n...\\n>>> report()\\n1210294387.19\\n>>> time.sleep(5)\\n>>> report()\\n1210294387.19\\n\\n\\nThe when argument doesn\\'t change. It is evaluated when you define the function. It won\\'t change until the application is re-started.\\n\\nStrategy: you won\\'t trip over this if you default arguments to None and then do something useful when you see it:\\n\\n>>> def report(when=None):\\n...     if when is None:\\n...         when = time.time()\\n...     print when\\n...\\n>>> report()\\n1210294762.29\\n>>> time.sleep(5)\\n>>> report()\\n1210294772.23\\n\\n\\nExercise: to make sure you\\'ve understood: why is this happening?\\n\\n>>> def spam(eggs=[]):\\n...     eggs.append(\"spam\")\\n...     return eggs\\n...\\n>>> spam()\\n[\\'spam\\']\\n>>> spam()\\n[\\'spam\\', \\'spam\\']\\n>>> spam()\\n[\\'spam\\', \\'spam\\', \\'spam\\']\\n>>> spam()\\n[\\'spam\\', \\'spam\\', \\'spam\\', \\'spam\\']\\n\\n'},\n {'prompt': 'I thought I was starting to get a grip on \"the Python way\" of programming. Methods of a class accept self as the first parameter to refer to the instance of the class whose context the method is being called in. The @classmethod decorator refers to a method whose functionality is associated with the class, but which doesn\\'t reference a specific instance.\\n\\nSo, what does the first parameter of a @classmethod (canonically \\'self\\') refer to if the method is meant to be called without an instance reference?\\n',\n  'completion': \"class itself:\\n\\n\\n  A class method receives the class as implicit first argument, just like an instance method receives the instance.\\n\\n\\nclass C:\\n    @classmethod\\n    def f(cls):\\n        print(cls.__name__, type(cls))\\n\\n>>> C.f()\\nC <class 'type'>\\n\\n\\nand it's cls canonically, btw\\n\"},\n {'prompt': 'Is there a function to extract the extension from a filename?\\n',\n  'completion': \"Yes. Use os.path.splitext:\\n\\n>>> import os\\n>>> filename, file_extension = os.path.splitext('/path/to/somefile.ext')\\n>>> filename\\n'/path/to/somefile'\\n>>> file_extension\\n'.ext'\\n\\n\"},\n {'prompt': \"I used to be a java developer and we used tools like ant or maven to manage our development/testing/UAT environments in a standardized way. This allowed us to handle library dependencies, setting OS variables, compiling, deploying, running unit tests, and all the required tasks. Also, the scripts generated guaranteed that all the environments were almost equally configured, and all the task were performed in the same way by all the members of the team. \\n\\nI'm starting to work in Python now and I'd like your advice in which tools should I use to accomplish the same as described for java.\\n\",\n  'completion': \"\\nvirtualenv to create a contained virtual environment (prevent different versions of Python or Python packages from stomping on each other). There is increasing buzz from people moving to this tool.  The author is the same as the older working-env.py mentioned by Aaron.\\npip to install packages inside a virtualenv.  The traditional is easy_install as answered by S. Lott, but pip works better with virtualenv.  easy_install still has features not found in pip though.\\nscons as a build tool, although you won't need this if you stay purely Python.\\nFabric paste, or paver for deployment.\\nbuildbot for continuous integration.\\nBazaar, mercurial, or git for version control.\\nNose as an extension for unit testing.\\nPyFit for FIT testing.\\n\\n\"},\n {'prompt': \"Does anybody know how to make the icon not show up? I'm looking for a way to have no icon at all.\\n\",\n  'completion': \"On Windows\\n\\nStep One:\\n\\nCreate a transparent icon using either an icon editor, or a site like rw-designer. Save it as transparent.ico.\\n\\nStep Two:\\n\\nfrom tkinter import *\\n\\ntk = Tk()\\ntk.iconbitmap(default='transparent.ico')\\nlab = Label(tk, text='Window with transparent icon.')\\nlab.pack()\\ntk.mainloop()\\n\\n\\nOn Unix\\n\\nSomething similar, but using an xbm icon. \\n\"},\n {'prompt': \"Am i able to overload the print function? and call the normal function? What i want to do is after a specific line i want print to call my print which will call the normal print and write a copy to file.\\n\\nAlso i dont know how to overload print. I dont know how to do variable length arguments. i'll look it up soon but  http://stackoverflow.com/questions/550470/overload-print-python/550477#550477 just told me i cant overload print in 2.x which is what i am using.\\n\",\n  'completion': 'For those reviewing the previously dated answers, as of version release \"Python 2.6\" there is a new answer to the original poster\\'s question.\\n\\nIn Python 2.6 and up, you can disable the print statement in favor of the print function, and then override the print function with your own print function:\\n\\nfrom __future__ import print_function\\n# This must be the first statement before other statements.\\n# You may only put a quoted or triple quoted string, \\n# Python comments, other future statements, or blank lines before the __future__ line.\\n\\ntry:\\n    import __builtin__\\nexcept ImportError:\\n    # Python 3\\n    import builtins as __builtin__\\n\\ndef print(*args, **kwargs):\\n    \"\"\"My custom print() function.\"\"\"\\n    # Adding new arguments to the print function signature \\n    # is probably a bad idea.\\n    # Instead consider testing if custom argument keywords\\n    # are present in kwargs\\n    __builtin__.print(\\'My overridden print() function!\\')\\n    return __builtin__.print(*args, **kwargs)\\n\\n\\nOf course you\\'ll need to consider that this print function is only module wide at this point. You could choose to override __builtin__.print, but you\\'ll need to save the original __builtin__.print; likely mucking with the __builtin__ namespace.\\n'},\n {'prompt': \"I need to load (de-serialize) a pre-computed list of integers from a file in a Python script (into a Python list). The list is large (upto millions of items), and I can choose the format I store it in, as long as loading is fastest.\\n\\nWhich is the fastest method, and why?\\n\\n\\nUsing import on a .py file that just contains the list assigned to a variable\\nUsing cPickle's load\\nSome other method (perhaps numpy?)\\n\\n\\nAlso, how can one benchmark such things reliably?\\n\\nAddendum: measuring this reliably is difficult, because import is cached so it can't be executed multiple times in a test. The loading with pickle also gets faster after the first time probably because page-precaching by the OS. Loading 1 million numbers with cPickle takes 1.1 sec the first time run, and 0.2 sec on subsequent executions of the script.\\n\\nIntuitively I feel cPickle should be faster, but I'd appreciate numbers (this is quite a challenge to measure, I think). \\n\\nAnd yes, it's important for me that this performs quickly.\\n\\nThanks\\n\",\n  'completion': 'I would guess cPickle will be fastest if you really need the thing in a list.\\n\\nIf you can use an array, which is a built-in sequence type, I timed this at a quarter of a second for 1 million integers:\\n\\nfrom array import array\\nfrom datetime import datetime\\n\\ndef WriteInts(theArray,filename):\\n    f = file(filename,\"wb\")\\n    theArray.tofile(f)\\n    f.close()\\n\\ndef ReadInts(filename):\\n    d = datetime.utcnow()\\n    theArray = array(\\'i\\')\\n    f = file(filename,\"rb\")\\n    try:\\n        theArray.fromfile(f,1000000000)\\n    except EOFError:\\n        pass\\n    print \"Read %d ints in %s\" % (len(theArray),datetime.utcnow() - d)\\n    return theArray\\n\\nif __name__ == \"__main__\":\\n    a = array(\\'i\\')\\n    a.extend(range(0,1000000))\\n    filename = \"a_million_ints.dat\"\\n    WriteInts(a,filename)\\n    r = ReadInts(filename)\\n    print \"The 5th element is %d\" % (r[4])\\n\\n'},\n {'prompt': 'Alright, this is probably a really silly question but I am new to Python/Django so I can\\'t really wrap my head around its scoping concepts just yet. Right now I am writing a middleware class to handle some stuff, and I want to set \\'global\\' variables that my views and templates can access. What is the \"right\" way of doing this? I considered doing something like this:\\n\\nmiddleware.py\\n\\nfrom django.conf import settings\\n\\nclass BeforeFilter(object):\\n    def process_request(self, request):\\n        settings.my_var = \\'Hello World\\'\\n        return None\\n\\n\\nviews.py\\n\\nfrom django.conf import settings\\nfrom django.http import HttpResponse\\n\\ndef myview(request):\\n    return HttpResponse(settings.my_var)\\n\\n\\nAlthough this works, I am not sure if it is the \"Django way\" or the \"Python way\" of doing this.\\n\\nSo, my questions are:\\n1. Is this the right way?\\n2. If it is the right way, what is the right way of adding variables that can be used in the actual template from the middleware? Say I want to evaluate something and I want to set a variable headername as \\'My Site Name\\' in the middleware, and I want to be able to do {{ headername }} in all templates. Doing it the way I have it now I\\'d have to add headername to the context inside every view. Is there anyway to bypass this? I am thinking something along the lines of CakePHP\\'s $this->set(\\'headername\\',\\'My Site Name\\');\\n3. I am using the middleware class as an equivalent of CakePHP\\'s beforeFilter that runs before every view (or controller in CakePHP) is called. Is this the right way of doing this?\\n4. Completely unrelated but it is a small question, what is a nice way of printing out the contents of a variable to the browser ala print_r? Say I want to see all the stuff inside the request that is passed into the view? Is pprint the answer?\\n',\n  'completion': \"\\nIt's not the best way. You could set my_var on the request rather than on the settings. Settings are global and apply to the whole site. You don't want to modify it for every request. There could be concurrency issues with multiple request updating/reading the variable at the same time.\\nTo access request.my_var in your templates you could do {{ request.my_var }}. To get access to the request variable in your template you will have to add django.core.context_processors.request to your TEMPLATE_CONTEXT_PROCESSORS setting.\\nYes. Other terminology to describe request middleware would be request pre-processor/filter/interceptor. \\n\\n\\nAlso, if you want to use a common Site name for the header in your templates, you might want to check out the Django Sites application which provides a site name variable for your use.\\n\"},\n {'prompt': 'How to do conditional compilation in Python ?\\n\\nIs it using DEF ?\\n',\n  'completion': 'Python isn\\'t compiled in the same sense as C or C++ or even Java, python files are compiled \"on the fly\", you can think of it as being similar to a interpreted language like Basic or Perl.1\\n\\nYou can do something equivalent to conditional compile by just using an if statement. For example:\\n\\nif FLAG:\\n    def f():\\n        print \"Flag is set\"\\nelse:\\n    def f():\\n        print \"Flag is not set\"\\n\\n\\nYou can do the same for the creation classes, setting of variables and pretty much everything.\\n\\nThe closest way to mimic IFDEF would be to use the hasattr function. E.g.:\\n\\nif hasattr(aModule, \\'FLAG\\'):\\n    # do stuff if FLAG is defined in the current module.\\n\\n\\nYou could also use a try/except clause to catch name errors, but the idiomatic way would be to set a variable to None at the top of your script.\\n\\n\\nPython code is byte compiled into an intermediate form like Java, however there generally isn\\'t a separate compilation step. The \"raw\" source files that end in .py are executable.\\n\\n'},\n {'prompt': 'I am using iPython to run my code. I wonder if there is any module or command which would allow me to check the memory usage of an object. For instance:\\n\\nIn [1]: a = range(10000)\\nIn [2]: %memusage a\\nOut[2]: 1MB\\n\\n\\nSomething like %memusage <object> and return the memory used by the object.\\n\\nDuplicate\\n\\n\\n  Find out how much memory is being used by an object in Python\\n\\n',\n  'completion': \"Unfortunately this is not possible, but there are a number of ways of approximating the answer:\\n\\n\\nfor very simple objects (e.g. ints, strings, floats, doubles) which are represented more or less as simple C-language types you can simply calculate the number of bytes as with John Mulder's solution.\\nFor more complex objects a good approximation is to serialize the object to a string using cPickle.dumps. The length of the string is a good approximation of the amount of memory required to store an object. \\n\\n\\nThere is one big snag with solution 2, which is that objects usually contain references to other objects. For example a dict contains string-keys and other objects as values. Those other objects might be shared. Since pickle always tries to do a complete serialization of the object it will always over-estimate the amount of memory required to store an object.\\n\"},\n {'prompt': 'Questions:\\n\\n\\nWhat is the best practice for \\nkeeping track of a tread\\'s \\nprogress without locking the GUI \\n(\"Not Responding\")?\\nGenerally, what are the best practices for\\nthreading as it applies to GUI\\ndevelopment?\\n\\n\\nQuestion Background:\\n\\n\\nI have a PyQt GUI for Windows.\\nIt is used to process sets of HTML\\ndocuments.\\nIt takes anywhere from three seconds\\nto three hours to process a set of\\ndocuments.\\nI want to be able to process\\nmultiple sets at the same time.\\nI don\\'t want the GUI to lock.\\nI\\'m looking at the threading module\\nto achieve this.\\nI am relatively new to threading.\\nThe GUI has one progress bar.\\nI want it to display the progress of\\nthe selected thread.\\nDisplay results of the selected\\nthread if it\\'s finished.\\nI\\'m using Python 2.5.\\n\\n\\nMy Idea: Have the threads emit a QtSignal when the progress is updated that triggers some function that updates the progress bar.  Also signal when finished processing so results can be displayed.\\n\\n#NOTE: this is example code for my idea, you do not have\\n#      to read this to answer the question(s).\\n\\nimport threading\\nfrom PyQt4 import QtCore, QtGui\\nimport re\\nimport copy\\n\\nclass ProcessingThread(threading.Thread, QtCore.QObject):\\n\\n    __pyqtSignals__ = ( \"progressUpdated(str)\",\\n                        \"resultsReady(str)\")\\n\\n    def __init__(self, docs):\\n        self.docs = docs\\n        self.progress = 0   #int between 0 and 100\\n        self.results = []\\n        threading.Thread.__init__(self)\\n\\n    def getResults(self):\\n        return copy.deepcopy(self.results)\\n\\n    def run(self):\\n        num_docs = len(self.docs) - 1\\n        for i, doc in enumerate(self.docs):\\n            processed_doc = self.processDoc(doc)\\n            self.results.append(processed_doc)\\n            new_progress = int((float(i)/num_docs)*100)\\n\\n            #emit signal only if progress has changed\\n            if self.progress != new_progress:\\n                self.emit(QtCore.SIGNAL(\"progressUpdated(str)\"), self.getName())\\n            self.progress = new_progress\\n            if self.progress == 100:\\n                self.emit(QtCore.SIGNAL(\"resultsReady(str)\"), self.getName())\\n\\n    def processDoc(self, doc):\\n        \\'\\'\\' this is tivial for shortness sake \\'\\'\\'\\n        return re.findall(\\'<a [^>]*>.*?</a>\\', doc)\\n\\n\\nclass GuiApp(QtGui.QMainWindow):\\n\\n    def __init__(self):\\n        self.processing_threads = {}  #{\\'thread_name\\': Thread(processing_thread)}\\n        self.progress_object = {}     #{\\'thread_name\\': int(thread_progress)}\\n        self.results_object = {}      #{\\'thread_name\\': []}\\n        self.selected_thread = \\'\\'     #\\'thread_name\\'\\n\\n    def processDocs(self, docs):\\n        #create new thread\\n        p_thread = ProcessingThread(docs)\\n        thread_name = \"example_thread_name\"\\n        p_thread.setName(thread_name)\\n        p_thread.start()\\n\\n        #add thread to dict of threads\\n        self.processing_threads[thread_name] = p_thread\\n\\n        #init progress_object for this thread\\n        self.progress_object[thread_name] = p_thread.progress  \\n\\n        #connect thread signals to GuiApp functions\\n        QtCore.QObject.connect(p_thread, QtCore.SIGNAL(\\'progressUpdated(str)\\'), self.updateProgressObject(thread_name))\\n        QtCore.QObject.connect(p_thread, QtCore.SIGNAL(\\'resultsReady(str)\\'), self.updateResultsObject(thread_name))\\n\\n    def updateProgressObject(self, thread_name):\\n        #update progress_object for all threads\\n        self.progress_object[thread_name] = self.processing_threads[thread_name].progress\\n\\n        #update progress bar for selected thread\\n        if self.selected_thread == thread_name:\\n            self.setProgressBar(self.progress_object[self.selected_thread])\\n\\n    def updateResultsObject(self, thread_name):\\n        #update results_object for thread with results\\n        self.results_object[thread_name] = self.processing_threads[thread_name].getResults()\\n\\n        #update results widget for selected thread\\n        try:\\n            self.setResultsWidget(self.results_object[thread_name])\\n        except KeyError:\\n            self.setResultsWidget(None)\\n\\n\\nAny commentary on this approach (e.g. drawbacks, pitfalls, praises, etc.) will be appreciated.\\n\\nResolution:\\n\\nI ended up using the QThread class and associated signals and slots to communicate between threads.  This is primarily because my program already uses Qt/PyQt4 for the GUI objects/widgets.  This solution also required fewer changes to my existing code to implement.\\n\\nHere is a link to an applicable Qt article that explains how Qt handles threads and signals, http://www.linuxjournal.com/article/9602. Excerpt below:\\n\\n\\n  Fortunately, Qt permits\\n  signals and slots to be connected\\n  across threadsâ\\x80\\x94as long as the threads\\n  are running their own event loops.\\n  This is a much cleaner method of\\n  communication compared to sending and\\n  receiving events, because it avoids\\n  all the bookkeeping and intermediate\\n  QEvent-derived classes that become\\n  necessary in any nontrivial\\n  application. Communicating between\\n  threads now becomes a matter of\\n  connecting signals from one thread to\\n  the slots in another, and the mutexing\\n  and thread-safety issues of exchanging\\n  data between threads are handled by\\n  Qt.\\n  \\n  Why is it necessary to run an event\\n  loop within each thread to which you\\n  want to connect signals? The reason\\n  has to do with the inter-thread\\n  communication mechanism used by Qt\\n  when connecting signals from one\\n  thread to the slot of another thread.\\n  When such a connection is made, it is\\n  referred to as a queued connection.\\n  When signals are emitted through a\\n  queued connection, the slot is invoked\\n  the next time the destination object\\'s\\n  event loop is executed. If the slot\\n  had instead been invoked directly by a\\n  signal from another thread, that slot\\n  would execute in the same context as\\n  the calling thread. Normally, this is\\n  not what you want (and especially not\\n  what you want if you are using a\\n  database connection, as the database\\n  connection can be used only by the\\n  thread that created it). The queued\\n  connection properly dispatches the\\n  signal to the thread object and\\n  invokes its slot in its own context by\\n  piggy-backing on the event system.\\n  This is precisely what we want for\\n  inter-thread communication in which\\n  some of the threads are handling\\n  database connections. The Qt\\n  signal/slot mechanism is at root an\\n  implementation of the inter-thread\\n  event-passing scheme outlined above,\\n  but with a much cleaner and\\n  easier-to-use interface.\\n\\n\\nNOTE: eliben also has a good answer, and if I weren\\'t using PyQt4, which handles thread-safety and mutexing, his solution would have been my choice.\\n',\n  'completion': \"If you want to use signals to indicate progress to the main thread then you should really be using PyQt's QThread class instead of the Thread class from Python's threading module.\\n\\nA simple example which uses QThread, signals and slots can be found on the PyQt Wiki:\\n\\nhttps://wiki.python.org/moin/PyQt/Threading,_Signals_and_Slots\\n\"},\n {'prompt': \"Is it possible to append elements to a python generator?\\n\\nI'm currently trying to get all images from a set of disorganized folders and write them to a new directory. To get the files, I'm using os.walk() which returns a list of image files in a single directory. While I can make a generator out of this single list, I don't know how to combine all these lists into one single generator. Any help would be much appreciated.\\n\\nRelated:\\n\\n\\nFlattening a shallow list in python\\n\\n\",\n  'completion': 'You are looking for itertools.chain. It will combine multiple iterables into a single one, like this:\\n\\n>>> for i in itertools.chain([1,2,3], [4,5,6]):\\n...  print i\\n... \\n1\\n2\\n3\\n4\\n5\\n6\\n\\n'},\n {'prompt': \"I have a try...except block in my code and When an exception is throw. I really just want to continue with the code because in that case, everything is still able to run just fine. The problem is if you leave the except: block empty or with a #do nothing, it gives you a syntax error. I can't use continue because its not in a loop. Is there a keyword i can use that tells the code to just keep going?\\n\",\n  'completion': 'except:\\n    pass\\n\\n'},\n {'prompt': \"Look at this simple function\\n\\ndef prime_factors(n):\\n    for i in range(2,n):\\n      if n % i == 0:\\n        return i, prime_factors(n / i)\\n    return n\\n\\n\\nHere's the result of prime_factors(120)\\n\\n(2, (2, (2, (3, 5))))\\n\\n\\nInstead of nested tuples, I want it to return one flat tuple or list.\\n\\n(2, 2, 2, 3, 5)\\n\\n\\nIs there a simple way to do that?\\n\",\n  'completion': 'def prime_factors(n):\\n  for i in range(2,n):\\n    if n % i == 0:\\n      return [i] + prime_factors(n / i)\\n  return [n]\\n\\n'},\n {'prompt': \"What is an easy way in Python to format integers into strings representing thousands with K, and millions with M, and leaving just couple digits after comma?\\n\\nI'd like to show 7436313 as 7.44M, and 2345 as 2,34K.\\n\\nIs there some % string formatting operator available for that? Or that could be done only by actually dividing by 1000 in a loop and constructing result string step by step?\\n\",\n  'completion': \"I don't think there's a built-in function that does that.  You'll have to roll your own, e.g.:\\n\\ndef human_format(num):\\n    magnitude = 0\\n    while abs(num) >= 1000:\\n        magnitude += 1\\n        num /= 1000.0\\n    # add more suffixes if you need them\\n    return '%.2f%s' % (num, ['', 'K', 'M', 'G', 'T', 'P'][magnitude])\\n\\nprint('the answer is %s' % human_format(7436313))  # prints 'the answer is 7.44M'\\n\\n\"},\n {'prompt': 'I am doing some prototyping for a new desktop app i am writing in Python, and i want to use SQLite and an ORM to store data.\\n\\nMy question is, are there any ORM libraries that support auto-generating/updating the database schema and work with SQLite?\\n',\n  'completion': 'SQLAlchemy is a great choice in the Python ORM space that supports SQLite.\\n'},\n {'prompt': 'Is there any way of writing a decorator such that the following would work?\\n\\nassert \\'z\\' not in globals()\\n\\n@my_decorator\\ndef func(x, y):\\n   print z\\n\\n\\n\\n\\nEDIT: moved from anwser\\n\\nIn answer to hop\\'s \"why?\": syntax sugar / DRY.\\n\\nIt\\'s not about caching, it\\'s about calculating z (and z1, z2, z3, ...) based upon the values of x & y.\\n\\nI have lots of functions which do related things, and I don\\'t want to do have to write\\n\\nz1, z2, z3=calculate_from(x, y)\\n\\n\\nat the beginning of every single function - I\\'ll get it wrong somewhere. If this were c I\\'d do this with cpp (if this were lisp, I\\'d do this with macros ...), but I wanted to see if decorators could do the same thing.\\n\\nIf it helps, I\\'d almost certainly call the decorator \"precalculate_z\", and it certainly wouldn\\'t be part of any public API.\\n\\nI could probably get a similar effect from using the class infrastructure as well, but I wanted to see if it was doable with raw functions.\\n',\n  'completion': 'Echoing Hop\\'s answer\\n\\n\\nDon\\'t do it.\\nSeriously, don\\'t do this.  Lisp and Ruby are more appropriate languages for writing your own custom syntax.  Use one of those.  Or find a cleaner way to do this\\nIf you must, you want dynamic scoped variables, not lexically scoped.\\n\\n\\nPython doesn\\'t have dynamically scoped variables, but you can simulate it.  Here\\'s an example that simulates it by creating a global binding, but restores the previous value on exit:\\n\\nhttp://codepad.org/6vAY8Leh\\n\\ndef adds_dynamic_z_decorator(f):\\n  def replacement(*arg,**karg):\\n    # create a new \\'z\\' binding in globals, saving previous\\n    if \\'z\\' in globals():\\n      oldZ = (globals()[\\'z\\'],)\\n    else:\\n      oldZ = None\\n    try:\\n      globals()[\\'z\\'] = None\\n      #invoke the original function\\n      res = f(*arg, **karg)\\n    finally:\\n      #restore any old bindings\\n      if oldZ:\\n        globals()[\\'z\\'] = oldZ[0]\\n      else:\\n        del(globals()[\\'z\\'])\\n    return res\\n  return replacement\\n\\n@adds_dynamic_z_decorator\\ndef func(x,y):\\n  print z\\n\\ndef other_recurse(x):\\n  global z\\n  print \\'x=%s, z=%s\\' %(x,z)\\n  recurse(x+1)\\n  print \\'x=%s, z=%s\\' %(x,z)\\n\\n@adds_dynamic_z_decorator\\ndef recurse(x=0):\\n  global z\\n  z = x\\n  if x < 3:\\n    other_recurse(x)\\n\\nprint \\'calling func(1,2)\\'\\nfunc(1,2)\\n\\nprint \\'calling recurse()\\'\\nrecurse()\\n\\n\\nI make no warranties on the utility or sanity of the above code.  Actually, I warrant that it is insane, and you should avoid using it unless you want a flogging from your Python peers.\\n\\nThis code is similar to both eduffy\\'s and John Montgomery\\'s code, but ensures that \\'z\\' is created and properly restored \"like\" a local variable would be -- for instance, note how \\'other_recurse\\' is able to see the binding for \\'z\\' specified in the body of \\'recurse\\'.  \\n'},\n {'prompt': 'If you invoke the cpython interpreter with the -i option, it will enter the interactive mode upon completing any commands or scripts it has been given to run.  Is there a way, within a program to get the interpreter to do this even when it has not been given -i? The obvious use case is in debugging by interactively inspecting the state when an exceptional condition has occurred.\\n',\n  'completion': 'You want the code module.\\n\\n#!/usr/bin/env python\\n\\nimport code    \\ncode.interact(\"Enter Here\")\\n\\n'},\n {'prompt': 'I have a view that accepts a form submission and updates a model.\\n\\nAfter updating the model, I want to redirect to another page, and I want a message such as \"Field X successfully updated\" to appear on this page.\\n\\nHow can I \"pass\" this message to the other page? HttpResponseRedirect only accepts a URL. I\\'ve seen this done before on other sites. How is this accomplished?\\n',\n  'completion': 'This is a built-in feature of Django, called \"messages\"\\n\\nSee http://docs.djangoproject.com/en/dev/topics/auth/#messages\\n\\nFrom the documentation:\\n\\n\\n  A message is associated with a User.\\n  There\\'s no concept of expiration or\\n  timestamps.\\n  \\n  Messages are used by the Django admin\\n  after successful actions. For example,\\n  \"The poll Foo was created\\n  successfully.\" is a message.\\n\\n'},\n {'prompt': \"I have a project where i'm trying to use weakrefs with callbacks, and I don't understand what I'm doing wrong. I have created simplified test that shows the exact behavior i'm confused with. \\n\\nWhy is it that in this test test_a works as expected, but the weakref for self.MyCallbackB disappears between the class initialization and calling test_b? I thought like as long as the instance (a) exists, the reference to self.MyCallbackB should exist, but it doesn't.\\n\\nimport weakref\\n\\nclass A(object):\\n    def __init__(self):\\n\\n        def MyCallbackA():\\n            print 'MyCallbackA'\\n        self.MyCallbackA = MyCallbackA\\n\\n        self._testA = weakref.proxy(self.MyCallbackA)\\n        self._testB = weakref.proxy(self.MyCallbackB)\\n\\n    def MyCallbackB(self):\\n        print 'MyCallbackB'\\n\\n    def test_a(self):\\n        self._testA()\\n\\n    def test_b(self):\\n        self._testB()\\n\\nif __name__ == '__main__':\\n    a = A()    \\n    a.test_a()\\n    a.test_b()\\n\\n\",\n  'completion': \"You want a WeakMethod. \\n\\nAn explanation why your solution doesn't work can be found in the discussion of the recipe:\\n\\n\\n  Normal weakref.refs to bound methods don't quite work the way one expects, because bound methods are first-class objects; weakrefs to bound methods are dead-on-arrival unless some other strong reference to the same bound method exists.\\n\\n\"},\n {'prompt': \"In my application I have to maintain some global application state and global application wide methods like currently connected users, total number of answers, create an application config file etc. There are two options:\\n\\n\\nMake a separate appstate.py file with global variables with functions over them. It looks fine initially but it seems that I am missing something in clarity of my code.\\nCreate a class AppState with class functions in a appstate.py file, all other modules have been defined by their specific jobs. This looks fine. But now I have to write longer line like appstate.AppState.get_user_list(). Moreover, the methods are not so much related to each other. I can create separate classes but that would be too many classes.\\n\\n\\nEDIT: If I use classes I will be using classmethods. I don't think there is a need to instantiate the class to an object.\\n\",\n  'completion': \"Sounds like the classic conundrum :-)  In Python, there's nothing dirty or shameful about choosing to use a module if that's the best approach. After all, modules, functions, and the like are, in fact, first-class citizens in the language, and offer introspection and other properties that many other languages use objects to obtain.\\n\\nThe way you've described your options, it kinda sounds like you're not too crazy about a class-based approach in this case.\\n\\nI don't know if you've used the Django framework, but if not have a look at their documentation on how they handle settings. These are app-wide, they are defined in a module, and they are available gobally. The way they parse the options and expose them globally is quite elegant, and you may find such an approach inspiring for your needs.\\n\"},\n {'prompt': 'What, in Your opinion is a meaningful docstring? What do You expect to be described there?\\n\\nFor example, consider this Python class\\'s __init__:\\n\\ndef __init__(self, name, value, displayName=None, matchingRule=\"strict\"):\\n    \"\"\"\\n    name - field name\\n    value - field value\\n    displayName - nice display name, if empty will be set to field name\\n    matchingRule - I have no idea what this does, set to strict by default\\n    \"\"\"\\n\\n\\nDo you find this meaningful? Post Your good/bad examples for all to know (and a general answer so it can be accepted).\\n',\n  'completion': 'I agree with \"Anything that you can\\'t tell from the method\\'s signature\". It might also mean to explain what a method/function returns.\\n\\nYou might also want to use Sphinx (and reStructuredText syntax) for documentation purposes inside your docstrings. That way you can include this in your documentation easily. For an example check out e.g. repoze.bfg which uses this extensively (example file, documentation example).\\n\\nAnother thing one can put in docstrings is also doctests. This might make sense esp. for module or class docstrings as you can also show that way how to use it and have this testable at the same time.\\n'},\n {'prompt': \"I have implemented a class in C++. I want to use it with Python.\\nPlease suggest step by step method and elaborate each step.\\nSomthing like this...\\n\\nclass Test{\\n     private:\\n        int n;\\n     public:\\n        Test(int k){\\n            n=k;\\n        }\\n        void setInt(int k){\\n            n = k; \\n        }\\n        int getInt(){\\n            return n;\\n        }\\n};\\n\\n\\nNow, in Python \\n\\n>>> T1 = Test(12)\\n>>> T1.getInt()\\n12\\n>>> T1.setInt(32)\\n>>> T1.getInt()\\n32\\n\\n\\nPlease suggest.How can I do this ?\\nNOTE: I would like to know manual way to do that. I don't want any third party library dependency.\\n\",\n  'completion': \"Look into Boost.Python. It's a library to write python modules with C++.\\n\\nAlso look into SWIG which can also handle modules for other scripting languages. I've used it in the past to write modules for my class and use them within python. Works great.\\n\\nYou can do it manually by using the Python/C API, writing the interface yourself. It's pretty lowlevel, but you will gain a lot of additional knowledge of how Python works behind the scene (And you will need it when you use SWIG anyway).\\n\"},\n {'prompt': 'I have a string that can be a hex number prefixed with \"0x\" or a decimal number without a special prefix except for possibly a minus sign. \"0x123\" is in base 16 and \"-298\" is in base 10.\\n\\nHow do I convert this to an int or long in Python?\\n\\nI don\\'t want to use eval() since it\\'s unsafe and overkill.\\n',\n  'completion': 'int(\"0x123\", 0)\\n\\n\\n(why doesn\\'t int(\"0x123\") do that?)\\n'},\n {'prompt': 'Is there a way to debug a regular expression in Python? And I\\'m not referring to the process of trying and trying till they work :)\\n\\nEDIT: here is how regexes can be debugged in perl :\\n\\n\\nuse re \\'debug\\';\\n\\nmy $str = \"GET http://some-site.com HTTP/1.1\";\\nif($str =~/get\\\\s+(\\\\S+)/i) {\\n    print \"MATCH:$1\\\\n\";\\n}\\n\\n\\nThe code above produces the following output on my computer when ran :\\n\\n\\nCompiling REx \"get\\\\s+(\\\\S+)\"\\nFinal program:\\n   1: EXACTF  (3)\\n   3: PLUS (5)\\n   4:   SPACE (0)\\n   5: OPEN1 (7)\\n   7:   PLUS (9)\\n   8:     NSPACE (0)\\n   9: CLOSE1 (11)\\n  11: END (0)\\nstclass EXACTF  minlen 5\\nMatching REx \"get\\\\s+(\\\\S+)\" against \"GET http://some-site.com HTTP/1.1\"\\nMatching stclass EXACTF  against \"GET http://some-site.com HTTP/1.1\" (33 chars)\\n   0           |  1:EXACTF (3)\\n   3        |  3:PLUS(5)\\n                                  SPACE can match 1 times out of 2147483647...\\n   4       |  5:  OPEN1(7)\\n   4       |  7:  PLUS(9)\\n                                    NSPACE can match 20 times out of 2147483647...\\n  24       |  9:    CLOSE1(11)\\n  24       | 11:    END(0)\\nMatch successful!\\nMATCH:http://some-site.com\\nFreeing REx: \"get\\\\s+(\\\\S+)\"\\n\\n\\n',\n  'completion': \"\\n\\n>>> p = re.compile('.*', re.DEBUG)\\nmax_repeat 0 65535\\n  any None\\n>>>                         \\n\\n\\n\\nhttp://stackoverflow.com/questions/580993/regex-operator-vs-separate-runs-for-each-sub-expression/582227#582227\\n\"},\n {'prompt': 'I`m currently studying C++ and want to learn another language.\\nFor work I use C# + ASP (just started learning it, actually), but I want something \"less Microsoft\" and powerful.\\nI have heard Python is a popular and powerful language, not so complicated as C++. But many people mentioned it was hard for them to get back to C++/Java from Python because they started thinking in it, get used to absence of memory management, etc.\\nWhat do you recommend?\\n',\n  'completion': \"There's no right or wrong answer, really.  But I think you'll benefit more from learning Python.  Given the similarities between C# and C++, you'll learn a different way of thinking from Python.  The more ways you learn to think about a problem, the better it makes you as a programmer, regardless of the language.\\n\"},\n {'prompt': \"I've been hacking classes in Python like this:\\n\\ndef hack(f,aClass) :\\n  class MyClass(aClass) :\\n     def f(self) :\\n       f()\\n  return MyClass\\n\\nA = hack(afunc,A)\\n\\n\\nWhich looks pretty clean to me. It takes a class, A, creates a new class derived from it that has an extra method, calling f, and then reassigns the new class to A.\\n\\nHow does this differ from metaclass hacking in Python? What are the advantages of using a metaclass over this?\\n\",\n  'completion': 'The definition of a class in Python is an instance of type (or an instance of a subclass of type). In other words, the class definition itself is an object. With metaclasses, you have the ability to control the type instance that becomes the class definition.\\n\\nWhen a metaclass is invoked, you have the ability to completely re-write the class definition. You have access to all the proposed attributes of the class, its ancestors, etc. More than just injecting a method or removing a method, you can radically alter the inheritance tree, the type, and pretty much any other aspect. You can also chain metaclasses together for a very dynamic and totally convoluted experience.\\n\\nI suppose the real benefit, though is that the class\\'s type remains the class\\'s type. In your example, typing:\\n\\na_inst = A()\\ntype(a_inst)\\n\\n\\nwill show that it is an instance of MyClass. Yes, isinstance(a_inst, aClass) would return True, but you\\'ve introduced a subclass, rather than a dynamically re-defined class. The distinction there is probably the key.\\n\\nAs rjh points out, the anonymous inner class also has performance and extensibility implications. A metaclass is processed only once, and the moment that the class is defined, and never again. Users of your API can also extend your metaclass because it is not enclosed within a function, so you gain a certain degree of extensibility.\\n\\nThis slightly old article actually has a good explanation that compares exactly the \"function decoration\" approach you used in the example with metaclasses, and shows the history of the Python metaclass evolution in that context: http://www.ibm.com/developerworks/linux/library/l-pymeta.html\\n'},\n {'prompt': 'When I have created a table with an auto-incrementing primary key, is there a way to obtain what the primary key would be (that is, do something like reserve the primary key) without actually committing?\\n\\nI would like to place two operations inside a transaction however one of the operations will depend on what primary key was assigned in the previous operation.\\n',\n  'completion': 'You don\\'t need to commit, you just need to flush.  Here\\'s some sample code.  After the call to flush you can access the primary key that was assigned.  Note this is with SA 0.4.8.\\n\\nfrom sqlalchemy import *\\nfrom sqlalchemy.databases.mysql import *\\nimport sqlalchemy.ext.declarative\\n\\nBase = sqlalchemy.ext.declarative.declarative_base()\\n\\nclass User(Base):\\n    __tablename__ = \\'user\\'\\n    user_id = Column(\\'user_id\\', Integer, primary_key=True)\\n    name = Column(\\'name\\', String)\\n\\nif __name__ == \\'__main__\\':\\n    import unittest\\n    from sqlalchemy.orm import *\\n    import datetime\\n\\n    class Blah(unittest.TestCase):\\n        def setUp(self):\\n            self.engine = create_engine(\\'sqlite:///:memory:\\', echo=True)\\n            self.sessionmaker = scoped_session(sessionmaker(bind=self.engine))\\n            Base.metadata.bind = self.engine\\n            Base.metadata.create_all()\\n            self.now = datetime.datetime.now()\\n\\n        def test_pkid(self):\\n            user = User(name=\"Joe\")\\n            session = self.sessionmaker()\\n            session.save(user)\\n            session.flush()\\n            print \\'user_id\\', user.user_id\\n            session.commit()\\n            session.close()\\n\\n    unittest.main()\\n\\n'},\n {'prompt': \"I have this code:\\n\\n>>> class G:\\n...   def __init__(self):\\n...     self.x = 20\\n...\\n>>> gg = G()\\n>>> gg.x\\n20\\n>>> gg.y = 2000\\n\\n\\nAnd this code:\\n\\n>>> from datetime import datetime\\n>>> my_obj = datetime.now()\\n>>> my_obj.interesting = 1\\n*** AttributeError: 'datetime.datetime' object has no attribute 'interesting'\\n\\n\\nFrom my Python knowledge, I would say that datetime overrides setattr/getattr, but I am not sure. Could you shed some light here?\\n\\nEDIT: I'm not specifically interested in datetime. I was wondering about objects in general.\\n\",\n  'completion': \"My guess, is that the implementation of datetime uses __slots__ for better performance.\\n\\nWhen using __slots__, the interpreter reserves storage for just the attributes listed, nothing else. This gives better performance and uses less storage, but it also means you can't add new attributes at will.\\n\\nRead more here: http://docs.python.org/reference/datamodel.html\\n\"},\n {'prompt': 'I have been playing around with writing some simple card games in Python for fun and I would like to add a graphical user interface (GUI) to the games. Which library would you recommend for writing the GUI for a simple card game?\\n',\n  'completion': \"If all you want is a GUI, wxPython should do the trick.\\n\\nIf you're looking to add sound, controller input, and take it beyond a simple card game, then you may want to use pygame.\\n\"},\n {'prompt': '\\nI\\'m trying to add a simple \"page x of y\" to a report made with ReportLab.. I found this old post about it, but maybe six years later something more straightforward has emerged? ^^;\\nI found this recipe too, but when I use it, the resulting PDF is missing the images..\\n',\n  'completion': 'I was able to implement the NumberedCanvas approach from ActiveState.  It was very easy to do and did not change much of my existing code. All I had to do was add that NumberedCanvas class and add the canvasmaker attribute when building my doc.  I also changed the measurements of where the \"x of y\" was displayed:\\n\\nself.doc.build(pdf)\\n\\n\\nbecame \\n\\nself.doc.build(pdf, canvasmaker=NumberedCanvas)\\n\\n\\ndoc is a BaseDocTemplate and pdf is my list of flowable elements.\\n'},\n {'prompt': \"I am in the field of data crunching and very soon might make a move to the world of web programming. Although I am fascinated both by Python and Ruby as both of them seem to be having every similar styles when it comes to writing business logic or data crunching logic.\\n\\nBut when I start googling for web development I start inclining towards Ruby on Rails my question is why is the web world obsessed with ruby on rails and active records so much?\\n\\nThere seem to be so many screencasts to learn Ruby on Rails and plethora of good books too \\nwhy is Python not able to pull the crowd  when it comes to creating screencasts or ORM's like active record.\\n\",\n  'completion': \"Ruby and Python are languages.\\n\\nRails is a framework.\\n\\nSo it is not really sensible to compare Ruby on Rails vs Python.\\n\\nThere are Python Frameworks out there you should take a look at for a more direct comparison - http://wiki.python.org/moin/WebFrameworks (e.g. I know Django gets a lot of love, but there are others)\\n\\nEdit: I've just had a google, there seem to be loads of Django Screencasts.\\n\"},\n {'prompt': 'I was wondering if someone could help me out.  In some web application, the app will send out emails, say when a new message has been posted.  Then instead of signing into the application to post a reply you can just simply reply to the email and it will automatically update the web app with your response.\\n\\nMy question is, how is this done and what is it called?\\n\\nThanks\\n',\n  'completion': \"Generally:\\n\\n1) Set up a dedicated email account for the purpose.\\n\\n2) Have a programm monitor the mailbox (let's say fetchmail, since that's what I do).\\n\\n3) When an email arrives at the account, fetchmail downloads the email, writes it to disk, and calls script or program you have written with the email file as an argument.\\n\\n4) Your script or program parses the email and takes an appropriate action.\\n\\nThe part that's usually mysterious to people is the fetchmail part (#2).\\n\\nSpecifically on Mail Servers (iff you control the mailserver enough to redirect emails to scripts):\\n\\n1-3) Configure an address to be piped to a script you have written.\\n\\n4) Same as above.\\n\"},\n {'prompt': \"Right now I have a central module in a framework that spawns multiple processes using the Python 2.6 multiprocessing module. Because it uses multiprocessing, there is module-level multiprocessing-aware log, LOG = multiprocessing.get_logger(). Per the docs, this logger has process-shared locks so that you don't garble things up in sys.stderr (or whatever filehandle) by having multiple processes writing to it simultaneously.\\n\\nThe issue I have now is that the other modules in the framework are not multiprocessing-aware. The way I see it, I need to make all dependencies on this central module use multiprocessing-aware logging. That's annoying within the framework, let alone for all clients of the framework. Are there alternatives I'm not thinking of?\\n\",\n  'completion': \"I just now wrote a log handler of my own that just feeds everything to the parent process via a pipe.  I've only been testing it for ten minutes but it seems to work pretty well. \\n\\n(Note: This is hardcoded to RotatingFileHandler, which is my own use case.)\\n\\n\\n\\nUpdate: Implementation!\\n\\nThis now uses a queue for correct handling of concurrency, and also recovers from errors correctly.  I've now been using this in production for several months, and the current version below works without issue.\\n\\nfrom logging.handlers import RotatingFileHandler\\nimport multiprocessing, threading, logging, sys, traceback\\n\\nclass MultiProcessingLog(logging.Handler):\\n    def __init__(self, name, mode, maxsize, rotate):\\n        logging.Handler.__init__(self)\\n\\n        self._handler = RotatingFileHandler(name, mode, maxsize, rotate)\\n        self.queue = multiprocessing.Queue(-1)\\n\\n        t = threading.Thread(target=self.receive)\\n        t.daemon = True\\n        t.start()\\n\\n    def setFormatter(self, fmt):\\n        logging.Handler.setFormatter(self, fmt)\\n        self._handler.setFormatter(fmt)\\n\\n    def receive(self):\\n        while True:\\n            try:\\n                record = self.queue.get()\\n                self._handler.emit(record)\\n            except (KeyboardInterrupt, SystemExit):\\n                raise\\n            except EOFError:\\n                break\\n            except:\\n                traceback.print_exc(file=sys.stderr)\\n\\n    def send(self, s):\\n        self.queue.put_nowait(s)\\n\\n    def _format_record(self, record):\\n        # ensure that exc_info and args\\n        # have been stringified.  Removes any chance of\\n        # unpickleable things inside and possibly reduces\\n        # message size sent over the pipe\\n        if record.args:\\n            record.msg = record.msg % record.args\\n            record.args = None\\n        if record.exc_info:\\n            dummy = self.format(record)\\n            record.exc_info = None\\n\\n        return record\\n\\n    def emit(self, record):\\n        try:\\n            s = self._format_record(record)\\n            self.send(s)\\n        except (KeyboardInterrupt, SystemExit):\\n            raise\\n        except:\\n            self.handleError(record)\\n\\n    def close(self):\\n        self._handler.close()\\n        logging.Handler.close(self)\\n\\n\"},\n {'prompt': \"I am planning to write an simple 3d(isometric view) game in Java using jMonkeyEngine - nothing to fancy, I just want to learn something about OpenGL and writing efficient algorithms (random map generating ones). \\n\\nWhen I was planning what to do, I started wondering about switching to Python. I know that Python didn't come into existence to be a tool to write 3d games, but is it possible to write good looking games with this language? \\n\\nI have in mind 3d graphics, nice effects and free CPU time to power to rest of game engine? I had seen good looking java games - and too be honest, I was rather shocked when I saw level of detail achieved in Runescape HD. \\n\\nOn the other hand, pygame.org has only 2d games, with some starting 3d projects. Are there any efficient 3d game engines for python? Is pyopengl the only alternative? Good looking games in python aren't popular or possible to achieve? \\n\\nI would be grateful for any information / feedback.\\n\",\n  'completion': \"If you are worried about 3D performance: Most of the performance-critical parts will be handled by OpenGL (in a C library or even in hardware), so the language you use to drive it should not matter too much.\\n\\nTo really find out if performance is a problem, you'd have to try it. But there is no reason why it cannot work in principle.\\n\\nAt any rate, you could still optimize the critical parts, either in Python or by dropping to C. You still gain Python's benefit for most of the game engine which is less performance-critical.\\n\"},\n {'prompt': \"Empirically, it seems that Python's default list sorter, when passed a list of tuples, will sort by the first element in each tuple. Is that correct? If not, what's the right way to sort a list of tuples by their first elements?\\n\",\n  'completion': 'It automatically sorts a list of tuples by the first elements in the tuples, then by the second elements and so on tuple([1,2,3]) will go before tuple([1,2,4]). If you want to override this behaviour pass a callable as the second argument to the sort method. This callable should return 1, -1, 0.\\n'},\n {'prompt': 'I know about unittest Python module.\\n\\nI know about assertRaises() method of TestCase class.\\n\\nI would like to write a test that succeeds when an exception is not raised.\\n\\nAny hints please?\\n',\n  'completion': 'def runTest(self):\\n    try:\\n        doStuff()\\n    except:\\n        self.fail(\"Encountered an unexpected exception.\")\\n\\n\\nUPDATE: As liw.fi mentions, the default result is a success, so the example above is something of an antipattern. You should probably only use it if you want to do something special before failing. You should also catch the most specific exceptions possible.\\n'},\n {'prompt': \"I have a list of integers.  I want to know whether the number 13 appears in it and, if so, where.  Do I have to search the list twice, as in the code below?\\n\\nif 13 in intList:\\n   i = intList.index(13)\\n\\n\\nIn the case of dictionaries, there's a get function which will ascertain membership and perform look-up with the same search.  Is there something similar for lists?\\n\",\n  'completion': 'You answered it yourself, with the index() method. That will throw an exception if the index is not found, so just catch that:\\n\\ndef getIndexOrMinusOne(a, x):\\n  try:\\n    return a.index(x)\\n  except ValueError:\\n    return -1\\n\\n'},\n {'prompt': \"This really looks like something I should be able to find on Google, but for some reason I can't make heads or tails of it. There's the EDITOR environment variable, the ipy_user_conf.py file, the ipythonrc file, some weird thing about running gvim in server mode and a bunch of other stuff I can't wrap my head around (probably because of lack of sleep).\\n\\nIs there a guide somewhere I can follow, or maybe someone can just outline the steps I need to take?\\n\",\n  'completion': \"Setting the EDITOR environment variable to 'gvim -f' seems to work.\\n\\nset EDITOR=gvim -f\\n\\n\"},\n {'prompt': 'I want to get the full command line as it was typed. \\n\\nThis: \\n\\n\" \".join(sys.argv[:]) \\n\\ndoesn\\'t work here (deletes double quotes). Also I prefer not to rejoin something that was parsed and splited.\\n\\nAny ideas? \\n\\nThank you in advance.\\n',\n  'completion': \"You're too late. By the time that the typed command gets to Python your shell has already worked its magic. For example, quotes get consumed (as you've noticed), variables get interpolated, etc.\\n\"},\n {'prompt': 'I want my python application to be able to tell when the socket on the other side has been dropped. Is there a method for this?\\n',\n  'completion': 'It depends on what you mean by \"dropped\".  For TCP sockets, if the other end closes the connection either through \\nclose() or  the process terminating, you\\'ll find out by reading an end of file, or getting a read error, usually the errno being set to whatever \\'connection reset by peer\\' is by your operating system.   For python, you\\'ll read a zero length string, or a socket.error will be thrown when you try to read or write from the socket.\\n'},\n {'prompt': 'Several months ago, I wrote a blog post detailing how to achieve tab-completion in the standard Python interactive interpreter--a feature I once thought only available in IPython. I\\'ve found it tremendously handy given that I sometimes have to switch to the standard interpreter due to IPython unicode issues.\\n\\nRecently I\\'ve done some work in OS X. To my discontent, the script doesn\\'t seem to work for OS X\\'s Terminal application. I\\'m hoping some of you with experience in OS X might be able to help me trouble-shoot it so it can work in Terminal, as well.\\n\\nI am reproducing the code below\\n\\nimport atexit\\nimport os.path\\n\\ntry:\\n    import readline\\nexcept ImportError:\\n    pass\\nelse:\\n    import rlcompleter\\n\\n    class IrlCompleter(rlcompleter.Completer):\\n        \"\"\"\\n        This class enables a \"tab\" insertion if there\\'s no text for\\n        completion.\\n\\n        The default \"tab\" is four spaces. You can initialize with \\'\\\\t\\' as\\n        the tab if you wish to use a genuine tab.\\n\\n        \"\"\"\\n\\n        def __init__(self, tab=\\'    \\'):\\n            self.tab = tab\\n            rlcompleter.Completer.__init__(self)\\n\\n\\n        def complete(self, text, state):\\n            if text == \\'\\':\\n                readline.insert_text(self.tab)\\n                return None\\n            else:\\n                return rlcompleter.Completer.complete(self,text,state)\\n\\n\\n    #you could change this line to bind another key instead tab.\\n    readline.parse_and_bind(\\'tab: complete\\')\\n    readline.set_completer(IrlCompleter(\\'\\\\t\\').complete)\\n\\n\\n# Restore our command-line history, and save it when Python exits.\\nhistory_path = os.path.expanduser(\\'~/.pyhistory\\')\\nif os.path.isfile(history_path):\\n    readline.read_history_file(history_path)\\natexit.register(lambda x=history_path: readline.write_history_file(x))\\n\\n\\nNote that I have slightly edited it from the version on my blog post so that the IrlCompleter is initialized with a true tab, which seems to be what is output by the Tab key in Terminal.\\n',\n  'completion': 'This should work under Leopard\\'s python:\\n\\nimport rlcompleter\\nimport readline\\nreadline.parse_and_bind (\"bind ^I rl_complete\")\\n\\n\\nWhereas this one does not:\\n\\nimport readline, rlcompleter\\nreadline.parse_and_bind(\"tab: complete\")\\n\\n\\nSave it in ~/.pythonrc.py and execute in .bash_profile\\n\\nexport PYTHONSTARTUP=$HOME/.pythonrc.py\\n\\n'},\n {'prompt': \"I'm currently trying to optimize my website, which run on the google's appengine. It's not an easy task, because I'm not using any powerful tool.\\n\\nDoes anyone have experience in optimizing python code for this purpose?\\nHave you find a good python profiler?\\n\",\n  'completion': 'I have found Gprof2Dot extremely useful. The output of the profiling modules I\\'ve tried as pretty unintuitive to interpret.\\n\\nGprof2Dot turns the cProfile output into a pretty looking graph, with the slowest chain(?) highlighted, and a bit of information on each function (function name, percentage of time spend on this function, and number of calls).\\n\\nAn example graph (1429x1896px)\\n\\nI\\'ve not done much with the App Engine, but when profiling non-webapp scripts, I tend to profile the script that runs all the unittests, which may not be very accurate to real-world situations\\n\\nOne (better?) method would be to have a script that does a fake WSGI request, then profile that.\\n\\nWSGI is really simple protocol, it\\'s basically a function that takes two arguments, one with request info and the second with a callback function (which is used for setting headers, among other things). Perhaps something like the following (which is possible-working pseudo code)...\\n\\nclass IndexHandler(webapp.RequestHandler):\\n    \"\"\"Your site\"\"\"\\n    def get(self):\\n        self.response.out.write(\"hi\")\\n\\nif __name__ == \\'__main__\\':\\n    application = webapp.WSGIApplication([\\n        (\\'.*\\', IndexHandler),\\n    ], debug=True)\\n\\n    # Start fake-request/profiling bit\\n    urls = [\\n        \"/\",\\n        \"/blog/view/hello\",\\n        \"/admin/post/edit/hello\",\\n        \"/makeanerror404\",\\n        \"/makeanerror500\"\\n    ]\\n\\n    def fake_wsgi_callback(response, headers):\\n        \"\"\"Prints heads to stdout\"\"\"\\n        print(\"\\\\n\".join([\"%s: %s\" % (n, v) for n, v in headers]))\\n        print(\"\\\\n\")\\n\\n    for request_url in urls:\\n        html = application({\\n        \\'REQUEST_METHOD\\': \\'GET\\',\\n        \\'PATH_INFO\\': request_url},\\n        fake_wsgi_callback\\n        )\\n        print html\\n\\n\\nActually, the App Engine documentation explains a better way of profiling your application:\\n\\nFrom http://code.google.com/appengine/kb/commontasks.html#profiling:\\n\\n\\n  To profile your application\\'s performance, first rename your application\\'s main() function to real_main(). Then, add a new main function to your application, named profile_main() such as the one below:\\n\\ndef profile_main():\\n    # This is the main function for profiling \\n    # We\\'ve renamed our original main() above to real_main()\\n    import cProfile, pstats\\n    prof = cProfile.Profile()\\n    prof = prof.runctx(\"real_main()\", globals(), locals())\\n    print \"<pre>\"\\n    stats = pstats.Stats(prof)\\n    stats.sort_stats(\"time\")  # Or cumulative\\n    stats.print_stats(80)  # 80 = how many to print\\n    # The rest is optional.\\n    # stats.print_callees()\\n    # stats.print_callers()\\n    print \"</pre>\"\\n\\n  \\n  [...]\\n  \\n  To enable the profiling with your application, set main = profile_main. To run your application as normal, simply set main = real_main.\\n\\n'},\n {'prompt': \"I just got my first Jython (and Python) project, and I was wondering what documentation, IDEs, etc. are best suited to a Java buff like me. \\n\\nI know there are a lot of questions about starting out with Python, so I'm asking for things that might be specific to Jython. Where should I start? If it helps, I'm running Linux and Solaris only.\\n\",\n  'completion': \"For starters, I'd read python is not java.  It'll give you a good idea of some habits you may have to break to program in Python effectively.  As has been mentioned, pydev is a pretty good development environment.  Although I would say that you would eventually want to learn emacs (but you may just want to learn one thing at a time).\\n\"},\n {'prompt': \"How to make sure that code is still working after refactoring ( i.e, after variable name change)?\\n\\nIn static language, if a class is renamed but other referring class is not, then I will get a compilation error.  \\n\\nBut in dynamic language there is no such safety net, and your code can break during refactoring if you are not careful enough. You can use unit test,  but when you are using mocks it's pretty hard to know the name changes and as a consequence, it may not help.\\n\\nHow to solve this problem?\\n\",\n  'completion': \"Before you start refactoring you should create tests that will be able to test what you're going to change - if you say unit tests will not be enought, or they will be hard to create, then by all means create higher level tests possibly even excersising the whole of your product. \\n\\nIf you have code coverage tools for your language use them to measure the quality of the tests that you've created - after it's reached a reasonably high value and if the tests are kept up to date and extended you'll be able to do anything with your code very efficiently and be rather sure things are not going in the wrong direction.\\n\"},\n {'prompt': \"Ex.\\n\\nIf I have something like this:\\n\\nclass C(object):\\n    @classmethod\\n    def f(cls, x):\\n       return x + x\\n\\n\\nThis will work:\\n\\nc = C()\\n\\nc.f(2)\\n4\\n\\n\\nBut is that bad form?\\nShould I only call\\n\\nC.f()\\n\\n\\nor \\n\\nc.__class__.f()\\n\\n\\nObviously, this would only make sense in cases where f doesn't interact with self/cls expecting it to be class.\\n\\n?\\n\",\n  'completion': 'If you are tempted to call a class method from an instance you probably don\\'t need a class method.\\n\\nIn the example you gave a static method would be more appropriate precisely because of your last remark (no self/cls interaction).\\n\\nclass C(object):\\n    @staticmethod\\n    def f(x):\\n       return x + x\\n\\n\\nthis way it\\'s \"good form\" to do both\\n\\nc = C()\\nc.f(2)\\n\\n\\nand\\n\\nC.f(2)\\n\\n'},\n {'prompt': \"So you've got some legacy code lying around in a fairly hefty project. How can you find and delete dead functions?\\n\\nI've seen these two references: Find unused code and Tool to find unused functions in php project, but they seem specific to C# and PHP, respectively.\\n\\nIs there a Python tool that'll help you find functions that aren't referenced anywhere else in the source code (notwithstanding reflection/etc.)?\\n\",\n  'completion': \"In python you can find unused code by using dynamic or static code analyzers. Two examples for dynamic analyzers are coverage and figleaf. They have the drawback that you have to run all possible branches of your code in order to find unused parts, but they also have the advantage that you get very reliable results.\\n\\nAlternatively, you can use static code analyzers, that just look at your code, but don't actually run it. This has the advantage that they run much faster, but due to python's dynamic nature the results are not 100% percent accurate and you might want to double-check them.\\nTwo tools that come to mind here are pyflakes and vulture. They are complementary: Pyflakes finds unused imports and unused local variables while vulture finds unused functions, methods, classes, variables and attributes.\\n\\nThe tools are all available at the Python Package Index http://pypi.python.org/pypi.\\n\"},\n {'prompt': 'Google is sponsoring an Open Source project to increase the speed of Python by 5x.\\n\\nUnladen-Swallow seems to have a good project plan\\n\\nWhy is concurrency such a hard problem? \\nIs LLVM going to solve the concurrency problem? \\nAre there solutions other than Multi-core for Hardware advancement?\\n',\n  'completion': \"LLVM is several things together - kind of a virtual machine/optimizing compiler, combined with different frontends that take the input in a particular language and output the result in an intermediate language. This intermediate output can be run with the virtual machine, or can be used to generate a standalone executable. \\n\\nThe problem with concurrency is that, although it was used for a long time in scientific computing, it has just recently has become common in consumer apps. So while it's widely known how to program a scientific calculation program to achieve great performance, it is completely different thing to write a mail user agent/word processor that can be good at concurrency. Also, most of the current OS's were being designed with a single processor in mind, and they may not be fully prepared for multicore processors.\\n\\nThe benefit of LLVM with respect to concurrency is that you have an intermediate output, and if in the future there are advances in concurrency, then by updating your interpreter you instantly gain those benefits in all LLVM-compiled programs.  This is not so easy if you had compiled to a standalone executable. So LLVM doesn't solve the concurrency problem per se but it leaves an open door for future enhancements.\\n\\nSure there are more possible advances for the hardware like quantum computers, genetics computers, etc. But we have to wait for them to become a reality.\\n\"},\n {'prompt': 'Given a class C in Python, how can I determine which file the class was defined in? I need something that can work from either the class C, or from an instance off C.\\n\\nThe reason I am doing this, is because I am generally a fan off putting files that belong together in the same folder. I want to create a class that uses a Django template to render itself as HTML. The base implementation should infer the filename for the template based on the filename that the class is defined in.\\n\\nSay I put a class LocationArtifact in the file \"base/artifacts.py\", then I want the default behaviour to be that the template name is \"base/LocationArtifact.html\".\\n',\n  'completion': 'You can use the inspect module, like this:\\n\\nimport inspect\\ninspect.getfile(C.__class__)\\n\\n'},\n {'prompt': 'I want a program to do one thing if executed like this:\\n\\ncat something | my_program.py\\n\\n\\nand do another thing if run like this\\n\\nmy_program.py\\n\\n\\nBut if I read from stdin, then it will wait for user input, so I want to see if there is anything to read before trying to read from stdin.\\n',\n  'completion': \"If you want to detect if someone is piping data into your program, or running it interactively you can use isatty to see if stdin is a terminal:\\n\\n$ python -c 'import sys; print sys.stdin.isatty()'\\nTrue\\n$ echo | python -c 'import sys; print sys.stdin.isatty()'\\nFalse\\n\\n\"},\n {'prompt': \"I know I can use AWK but I am on a Windows box.  I am making a function for others that may not have AWK.  I also know I can write a C program but I would love not have to create maintain and compile something for a little Vim utility I am making.  \\n\\nThe original file might be\\n\\nTHE DAY WAS LONG \\nTHE WAY WAS FAST\\n\\n\\nand it would become\\n\\nTT\\nHH\\nEE\\n\\nDW\\nAA\\nYY\\n\\nWW\\nAA\\nSS\\n\\nLF\\nOA\\nNS\\nGT\\n\\n\\nUPDATE:  Golf rules apply to selecting correct answer.\\n\\nUPDATE:  Python fans should check out Mr. Duffy's answer below.\\n\",\n  'completion': 'Here is a command in Vim language. So you don\\'t have to compile Vim with +python support.\\n\\nfunction! s:transpose()\\n    let maxcol = 0\\n    let lines = getline(1, line(\\'$\\'))\\n\\n    for line in lines\\n        let len = len(line)\\n        if len > maxcol \\n            let maxcol = len\\n        endif\\n    endfor\\n\\n    let newlines = []\\n    for col in range(0, maxcol - 1)\\n        let newline = \\'\\'\\n        for line in lines\\n            let line_with_extra_spaces = printf(\\'%-\\'.maxcol.\\'s\\', line)\\n            let newline .= line_with_extra_spaces[col]\\n        endfor\\n        call add(newlines, newline)\\n    endfor\\n\\n    1,$\"_d\\n    call setline(1, newlines)\\nendfunction\\n\\ncommand! TransposeBuffer call s:transpose()\\n\\n\\nPut this in newly created .vim file inside vim/plugin dir or put this to your [._]vimrc.\\nExecute :TransposeBuffer to transpose current buffer \\n'},\n {'prompt': \"If I have the following python code:\\n\\nclass Foo(object):\\n    bar = 1\\n    def bah(self):\\n\\n        print bar\\n\\nf = Foo()\\nf.bah()\\n\\n\\nIt complains \\n\\nNameError: global name 'bar' is not defined\\n\\n\\nHow can I access class/static variable 'bar' within method 'bah'?\\n\",\n  'completion': 'Instead of bar use self.bar or Foo.bar. Assigning to Foo.bar will create a static variable, and assigning to self.bar will create an instance variable.\\n'},\n {'prompt': 'I\\'m trying out pylint to check my source code for conventions. Somehow some variable names are matched with the regex for constants (const-rgx) instead of the variable name regex (variable-rgx). How to match the variable name with variable-rgx? Or should I extend const-rgx with my variable-rgx stuff?\\n\\ne.g.\\nC0103: 31: Invalid name \"settings\" (should match (([A-Z_][A-Z1-9_]*)|(__.*__))$)\\n',\n  'completion': \"\\n  Somehow some variable names are matched with the regex for constants (const-rgx) instead of the variable name regex (variable-rgx).\\n\\n\\nAre those variables declared on module level? Maybe that's why they are treated as constants (at least that's how they should be declared, according to PEP-8).\\n\"},\n {'prompt': 'I use nosetests to run my unittests and it works well. I want to get a list of all the tests nostests finds without actually running them. Is there a way to do that?\\n',\n  'completion': 'Version 0.11.1 is currently available.  You can get a list of tests without running them as follows:\\n\\nnosetests -v --collect-only\\n\\n'},\n {'prompt': 'Are there better alternatives to PIL (Python Imaging Library) for basic image file I/O and processing in Python?\\n',\n  'completion': \"Try Pillow: http://pypi.python.org/pypi/Pillow\\n\\nIt's a fork of PIL but maintained by Plone community. Which is great as it is being maintained (in comparison to it's predecessor) and it is backward compatible with PIL. Existing code will work out of the box with Pillow. \\n\\nThey mostly focus on packaging issues and AFAIK this was the biggest pain with PIL.\\n\\nGood luck!\\n\"},\n {'prompt': 'In python I have a dictionary that maps tuples to a list of tuples. e.g. \\n\\n{(1,2): [(2,3),(1,7)]}\\n\\nI want to be able to encode this data use it with javascript, so I looked into json but it appears keys must be strings so my tuple does not work as a key.\\n\\nIs the best way to handle this is encode it as \"1,2\" and then parse it into something I want on the javascript? Or is there a more clever way to handle this.\\n',\n  'completion': 'You might consider saying\\n\\n{\"[1,2]\": [(2,3),(1,7)]}\\n\\n\\nand then when you need to get the value out, you can just parse the keys themselves as JSON objects, which all modern browsers can do with the built-in JSON.parse method (I\\'m using jQuery.each to iterate here but you could use anything):\\n\\nvar myjson = JSON.parse(\\'{\"[1,2]\": [[2,3],[1,7]]}\\');\\n$.each(myjson, function(keystr,val){\\n    var key = JSON.parse(keystr);\\n    // do something with key and val\\n});\\n\\n\\nOn the other hand, you might want to just structure your object differently, e.g.\\n\\n{1: {2: [(2,3),(1,7)]}}\\n\\n\\nso that instead of saying\\n\\nmyjson[1,2] // doesn\\'t work\\n\\n\\nwhich is invalid Javascript syntax, you could say\\n\\nmyjson[1][2] // returns [[2,3],[1,7]]\\n\\n'},\n {'prompt': 'http://pypi.python.org/pypi/simplejson\\n\\nI am just diving into the Python world and want to make a simple twitter application which requires the installation of simplejson but not sure how I can set it up and get it working..\\n\\nI am on a Windows System\\n',\n  'completion': \"I would recommend EasyInstall, a package management application for Python.\\n\\nOnce you've installed EasyInstall, you should be able to go to a command window and type:\\n\\neasy_install simplejson\\n\\n\\nThis may require putting easy_install.exe on your PATH first, I don't remember if the EasyInstall setup does this for  you (something like C:\\\\Python25\\\\Scripts).\\n\"},\n {'prompt': \"I'm using site wide caching with memcached as the backend. I would like to invalidate pages in the cache when the underlying database object changes. \\n\\nIf the page name changes then I would invalidate the whole cache (as it affects navigation on every page. Clumsy but sufficient for my needs.\\n\\nIf just the page content changes then I'd like to invalidate the cache of just that page.\\n\\nIs there an easy way to do this?  \\n\",\n  'completion': \"I haven't done a lot of caching with Django, but I think what you want here are signals.\\n\\nYou can set up a post_save signal on the underlying object, and have the callback function invalidate that page in the cache.\\n\\nfrom django.core.signals import post_save\\nfrom django.core.cache import cache\\n\\ndef invalidate_cache(sender, **kwargs):\\n    # invalidate cache\\n    cache.delete(sender.get_absolute_url()) # or any other pertinent keys\\n\\npost_save.connect(invalidate_cache, sender=UnderlyingModel)\\n\\n\\nThis should properly remove the item from the cache when it is updated.\\n\"},\n {'prompt': \"Often when I am coding I just like to print little things (mostly the current value of variables) out to console. I don't see anything like this for Google App Engine, although I note that the Google App Engine Launcher does have a Log terminal. Is there any way to write to said Terminal, or to some other terminal, using Google App Engine? \\n\",\n  'completion': 'You\\'ll want to use the Python\\'s standard logging module.\\n\\nimport logging\\n\\nlogging.info(\"hello\")\\nlogging.debug(\"hi\") # this won\\'t show up by default\\n\\n\\nTo see calls to logging.debug() in the GoogleAppEngineLauncher Logs console, you have to first add the flag --dev_appserver_log_level=debug to your app. However, beware that you\\'re going to see a lot of debug noise from the App Engine SDK itself. The full set of levels are:\\n\\n\\ndebug\\ninfo\\nwarning\\nerror\\ncritical\\n\\n\\nYou can add the flag by double clicking the app and then dropping it into the Extra Flags field.\\n\\n\\n'},\n {'prompt': \"I have a django application using mod_python, fairly typical configuration except that media files are being served by a (I know, not recommended) 'media' directory in the document root.  I would like to test and maybe deploy with mod_wsgi but I cannot figure out how to create something simple to serve static files.  mod_python allows the use of Apache directives like:\\n\\n<Location '/'>\\n    SetHandler MyApplication.xyz.....\\n</Location>\\n\\n<Location '/media'>\\n    SetHandler None\\n</Location>\\n\\n\\nThe django docs seem to point to the second block above as the correct way to make a similar exception for mod_wsgi, but in my tests everything below root is still being sent to the wsgi app.  Is there a good way set a static media directory with mod_wsgi, or is what I am trying to do intentionally unsupported for compelling technical reasons?  Answers that point to entirely different approaches are welcome.\\n\",\n  'completion': 'I run a a dozen or so Django sites on the same server and here\\'s how I configure the media URL\\'s.\\n\\nEach VirtualHost has the following configuration:\\n\\nAlias /media /path/to/media/\\n<Directory /path/to/media>\\n    Include /etc/apache2/vhosts.d/media.include\\n</Directory>\\n\\n\\nThis way I can make any changes to the media handling in one file.\\n\\nThen, my media.include file looks like this:\\n\\nOrder allow,deny\\nAllow from all\\nSetHandler None\\nFileETag none\\nOptions FollowSymLinks\\n\\n<IfModule mod_expires.c>\\n    ExpiresActive On\\n    ExpiresByType image/gif \"access plus 30 days\"\\n    ExpiresByType image/jpg \"access plus 30 days\"\\n    ExpiresByType image/png \"access plus 30 days\"\\n    ExpiresByType image/jpeg \"access plus 30 days\"\\n    ExpiresByType text/css \"access plus 30 days\"\\n    ExpiresByType application/x-javascript \"modification plus 2 years\"\\n</IfModule>\\n\\n<IfModule mod_headers.c>\\n    Header append Vary Accept-Encoding\\n</IfModule>\\n\\nAddOutputFilterByType DEFLATE text/html text/css text/plain\\n\\n\\nThis has worked very well for me, and gets an A grade from YSlow (also see Jeff Atwood on YSlow).\\n\\nAlso note, for the root dir I use the following configuration:\\n\\nWSGIScriptAlias / /path/to/app.wsgi\\n<Directory /path/to>\\n    Options +ExecCGI\\n    Allow from all\\n</Directory>\\n\\n\\n... which should be after the Alias /media in your configuration file (because Apache looks at the aliases in order)\\n'},\n {'prompt': 'I\\'m using Django 1.0.2.  I\\'ve written a ModelForm backed by a Model.  This model has a ForeignKey where blank=False.  When Django generates HTML for this form it creates a select box with one option for each row in the table referenced by the ForeignKey.  It also creates an option at the top of the list that has no value and displays as a series of dashes:\\n\\n<option value=\"\">---------</option>\\n\\n\\nWhat I\\'d like to know is:\\n\\n\\nWhat is the cleanest way to remove this auto-generated option from the select box?  \\nWhat is the cleanest way to customize it so that it shows as:\\n\\n<option value=\"\">Select Item</option>\\n\\n\\n\\nIn searching for a solution I came across Django ticket 4653 which gave me the impression that others had the same question and that the default behavior of Django may have been modified.  This ticket is over a year old so I was hoping there might be a cleaner way to accomplish these things.\\n\\nThanks for any help,\\n\\nJeff\\n\\nEdit: I\\'ve configured the ForeignKey field as such: \\n\\nverb = models.ForeignKey(Verb, blank=False, default=get_default_verb)\\n\\n\\nThis does set the default so that it\\'s no longer the empty/dashes option but unfortunately it doesn\\'t seem to resolve either of my questions.  That is, the empty/dashes option still appears in the list.\\n',\n  'completion': \"Haven't tested this, but based on reading Django's code here and here I believe it should work:\\n\\nclass ThingForm(models.ModelForm):\\n  class Meta:\\n    model = Thing\\n\\n  def __init__(self, *args, **kwargs):\\n    super(ThingForm, self).__init__(*args, **kwargs)\\n    self.fields['verb'].empty_label = None\\n\\n\\nEDIT: This is documented, though you wouldn't necessarily know to look for ModelChoiceField if you're working with an auto-generated ModelForm.\\n\\nEDIT: As jlpp notes in his answer, this isn't complete - you have to re-assign the choices to the widgets after changing the empty_label attribute.  Since that's a bit hacky, the other option that might be easier to understand is just overriding the entire ModelChoiceField:\\n\\nclass ThingForm(models.ModelForm):\\n  verb = ModelChoiceField(Verb.objects.all(), empty_label=None)\\n\\n  class Meta:\\n    model = Thing\\n\\n\"},\n {'prompt': 'Does anyone have any good information aside from the Google App Engine docs provided by Google that gives a good overview for people with MS SQL background to porting their knowledge and using Google App Engine Data Store API effectively.\\n\\nFor Example, if you have a self created Users Table and a Message Table\\n\\nWhere there is a relationship between Users and Message (connected by the UserID), how would this structure be represented in Google App Engine?\\n\\nSELECT * FROM Users INNER JOIN Message ON Users.ID = Message.UserID\\n\\n',\n  'completion': 'Here is a good link: One to Many Join using Google App Engine.\\n\\nhttp://blog.arbingersys.com/2008/04/google-app-engine-one-to-many-join.html\\n\\nHere is another good link: Many to Many Join using Google App Engine:\\n\\nhttp://blog.arbingersys.com/2008/04/google-app-engine-many-to-many-join.html\\n\\nHere is a good discussion regarding the above two links:\\n\\nhttp://groups.google.com/group/google-appengine/browse_thread/thread/e9464ceb131c726f/6aeae1e390038592?pli=1\\n\\nPersonally I find this comment in the discussion very informative about the Google App Engine Data Store:\\n\\nhttp://groups.google.com/group/google-appengine/msg/ee3bd373bd31e2c7\\n\\n\\n  At scale you wind up doing a bunch of\\n  things that seem wrong, but that are\\n  required by the numbers we are\\n  running. Go watch the EBay talks. Or\\n  read the posts about how many database\\n  instances FaceBook is running.\\n  \\n  The simple truth is, what we learned\\n  about in uni was great for the\\n  business automation apps of small to\\n  medium enterprise applications, where\\n  the load was predictable, and there\\n  was money enough to buy the server\\n  required to handle the load of 50\\n  people doing data entry into an\\n  accounts or business planning and\\n  control app....\\n\\n\\nSearched around a bit more and came across this Google Doc Article:\\n\\nhttp://code.google.com/appengine/articles/modeling.html\\n\\n\\n  App Engine allows the creation of easy\\n  to use relationships between datastore\\n  entities which can represent\\n  real-world things and ideas. Use\\n  ReferenceProperty when you need to\\n  associate an arbitrary number of\\n  repeated types of information with a\\n  single entity. Use key-lists when you\\n  need to allow lots of different\\n  objects to share other instances\\n  between each other. You will find that\\n  these two approaches will provide you\\n  with most of what you need to create\\n  the model behind great applications.\\n\\n'},\n {'prompt': \"I'm trying to use SQLAlchemy to implement a basic users-groups model where users can have multiple groups and groups can have multiple users.\\n\\nWhen a group becomes empty, I want the group to be deleted, (along with other things associated with the group.  Fortunately, SQLAlchemy's cascade works fine with these more simple situations).\\n\\nThe problem is that cascade='all, delete-orphan' doesn't do exactly what I want; instead of deleting the group when the group becomes empty, it deletes the group when any member leaves the group.\\n\\nAdding triggers to the database works fine for deleting a group when it becomes empty, except that triggers seem to bypass SQLAlchemy's cascade processing so things associated with the group don't get deleted.\\n\\nWhat is the best way to delete a group when all of its members leave and have this deletion cascade to related entities.\\n\\nI understand that I could do this manually by finding every place in my code where a user can leave a group and then doing the same thing as the trigger however, I'm afraid that I would miss places in the code (and I'm lazy).\\n\",\n  'completion': \"The way I've generally handled this is to have a function on your user or group called leave_group.  When you want a user to leave a group, you call that function, and you can add any side effects you want into there.  In the long term, this makes it easier to add more and more side effects.  (For example when you want to check that someone is allowed to leave a group).\\n\"},\n {'prompt': 'Is there a way to write a string directly to a tarfile? From http://docs.python.org/library/tarfile.html it looks like only files already written to the file system can be added.\\n',\n  'completion': 'I would say it\\'s possible, by playing with TarInfo e TarFile.addfile passing a StringIO as a fileobject. \\n\\nVery rough, but works\\n\\nimport tarfile\\nimport StringIO\\n\\ntar = tarfile.TarFile(\"test.tar\",\"w\")\\n\\nstring = StringIO.StringIO()\\nstring.write(\"hello\")\\nstring.seek(0)\\ninfo = tarfile.TarInfo(name=\"foo\")\\ninfo.size=len(string.buf)\\ntar.addfile(tarinfo=info, fileobj=string)\\n\\ntar.close()\\n\\n'},\n {'prompt': 'I  was creating a simple command line utility and using a dictionary as a sort of case statement with key words linking to their apropriate function.  The functions all have different amount of arguments required so currently to check if the user entered the correct amount of arguments needed for each function I placed the required amount inside the dictionary case statement in the form {Keyword:(FunctionName, AmountofArguments)}.\\n\\nThis current setup works perfectly fine however I was just wondering in the interest of self improval if there was a way to determine the required number of arguments in a function and my google attempts have returned so far nothing of value but I see how args and kwargs could screw such a command up because of the limitless amount of arguments they allow.\\n\\nThanks for any help.\\n',\n  'completion': 'inspect.getargspec():\\n\\n\\n  Get the names and default values of a functionâ\\x80\\x99s arguments. A tuple of four things is returned: (args, varargs, varkw, defaults). args is a list of the argument names (it may contain nested lists). varargs and varkw are the names of the * and ** arguments or None. defaults is a tuple of default argument values or None if there are no default arguments; if this tuple has n elements, they correspond to the last n elements listed in args.\\n\\n'},\n {'prompt': 'I\\'m interested in testing the performance of my django apps as I go, what is the best way to get line by line performance data?\\n\\nnote: Googling this returns lots of people benchmarking django itself. I\\'m not looking for a benchmarks of django, I\\'m trying to test the performance of the django apps that I\\'m writing :)\\n\\nThanks!\\n\\nedit: By \"line by line\" I just mean timing individual functions, db calls, etc to find out where the bottlenecks are on a very granular level\\n',\n  'completion': 'There\\'s two layers to this.  We have most of #1 in place for our testing.  We\\'re about to start on #2.\\n\\n\\nDjango in isolation.  The ordinary Django unit tests works well here.  Create some tests that cycle through a few (less than 6) \"typical\" use cases.  Get this, post that, etc.  Collect timing data.  This isn\\'t real web performance, but it\\'s an easy-to-work with test scenario that you can use for tuning.\\nYour whole web stack.  In this case, you need a regular server running Squid, Apache, Django, MySQL, whatever.  You need a second computer(s) to act a client exercise your web site through urllib2, doing a few (less than 6) \"typical\" use cases.  Get this, post that, etc.  Collect timing data.  This still isn\\'t \"real\" web performance, because it isn\\'t through the internet, but it\\'s as close as you\\'re going to get without a really elaborate setup.\\n\\n\\nNote that the #2 (end-to-end) includes a great deal of caching for performance.   If your client scripts are doing similar work, caching will be really beneficial.  if your client scripts do unique things each time, caching will be less beneficial.\\n\\nThe hardest part is determining what the \"typical\" workload is.  This isn\\'t functional testing, so the workload doesn\\'t have to include everything.  Also, the more concurrent sessions your client is running, the slower it becomes.  Don\\'t struggle trying to optimize your server when your test client is the slowest part of the processing.\\n\\n\\n\\nEdit\\n\\nIf \"line-by-line\" means \"profiling\", well, you\\'ve got to get a Python profiler running.\\n\\nhttps://docs.python.org/library/profile.html\\n\\nNote that there\\'s plenty of caching in the Django ORM layer.  So running a view function a  half-dozen times to get a meaningful set of measurements isn\\'t sensible.  You have to run a \"typical\" set of operations and then find hot-spots in the profile.  \\n\\nGenerally, your application is easy to optimize -- you shouldn\\'t be doing much.  Your view functions should be short and have no processing to speak of.  Your form and model method functions, similarly, should be very short.\\n'},\n {'prompt': 'In Python, the assignment operator can unpack list or tuple into variables, like this:\\n\\nl = (1, 2)\\na, b = l # Here goes auto unpack\\n\\n\\nBut I need to specify exactly the same amount of names to the left as an items count in the list to the right. But sometimes I don\\'t know a size of the list to the right, for example if I use split(). Example:\\n\\na, b = \"length=25\".split(\"=\") # This will result in a=\"length\" and b=25\\n\\n\\nBut the following code will lead to an error:\\n\\na, b = \"DEFAULT_LENGTH\".split(\"=\") # Error, list has only one item\\n\\n\\nIs it possible to somehow unpack list in the example above so I get a = \"DEFAULT_LENGTH\" and b equals to \\'None\\' or not set? A straightforward way looks kind of long:\\n\\na = b = None\\nif \"=\" in string :\\n  a, b = string.split(\"=\")\\nelse :\\n  a = string\\n\\n',\n  'completion': 'This may be of no use to you unless you\\'re using Python 3. However, for completeness, it\\'s worth noting that the extended tuple unpacking introduced there allows you to do things like:\\n\\n>>> a, *b = \"length=25\".split(\"=\")\\n>>> a,b\\n(\"length\", [\\'25\\'])\\n>>> a, *b = \"DEFAULT_LENGTH\".split(\"=\")\\n>>> a,b\\n(\"DEFAULT_LENGTH\", [])\\n\\n\\nI.e. tuple unpacking now works similarly to how it does in argument unpacking, so you can denote \"the rest of the items\" with *, and get them as a (possibly empty) list.\\n\\nPartition is probably the best solution for what you\\'re doing however.\\n'},\n {'prompt': \"I have a series of images that I want to create a video from.  Ideally I could specify a frame duration for each frame but a fixed frame rate would be fine too.  I'm doing this in wxPython, so I can render to a wxDC or I can save the images to files, like PNG.  Is there a Python library that will allow me to create either a video (AVI, MPG, etc) or an animated GIF from these frames?\\n\\nEdit: I've already tried PIL and it doesn't seem to work.  Can someone correct me with this conclusion or suggest another toolkit?  This link seems to backup my conclusion regarding PIL: http://www.somethinkodd.com/oddthinking/2005/12/06/python-imaging-library-pil-and-animated-gifs/\\n\",\n  'completion': 'As of June 2009 the originally cited blog post has a method to create animated GIFs in the comments.  Download the script images2gif.py (formerly images2gif.py, update courtesy of @geographika).\\n\\nThen, to reverse the frames in a gif, for instance:\\n\\n#!/usr/bin/env python\\n\\nfrom PIL import Image, ImageSequence\\nimport sys, os\\nfilename = sys.argv[1]\\nim = Image.open(filename)\\noriginal_duration = im.info[\\'duration\\']\\nframes = [frame.copy() for frame in ImageSequence.Iterator(im)]    \\nframes.reverse()\\n\\nfrom images2gif import writeGif\\nwriteGif(\"reverse_\" + os.path.basename(filename), frames, duration=original_duration/1000.0, dither=0)\\n\\n'},\n {'prompt': 'I was reading \\'Dive Into Python\\' and in the chapter on classes it gives this example:\\n\\nclass FileInfo(UserDict):\\n    \"store file metadata\"\\n    def __init__(self, filename=None):\\n        UserDict.__init__(self)\\n        self[\"name\"] = filename\\n\\n\\nThe author then says that if you want to override the __init__ method, you must explicitly call the parent __init__ with the correct parameters.  \\n\\n\\nWhat if that FileInfo class had more than one ancestor class?\\n\\nDo I have to explicitly call all of the ancestor classes\\' __init__ methods?  \\n\\nAlso, do I have to do this to any other method I want to override?\\n\\n',\n  'completion': 'The book is a bit dated with respect to subclass-superclass calling.  It\\'s also a little dated with respect to subclass built-in classes.\\n\\nIt looks like this nowadays.\\n\\nclass FileInfo(dict):\\n    \"\"\"store file metadata\"\"\"\\n    def __init__(self, filename=None):\\n        super( FileInfo, self ).__init__()\\n        self[\"name\"] = filename\\n\\n\\nNote the following.\\n\\n\\nWe can directly subclass built-in classes, like dict, list, tuple, etc.\\nThe super function handles tracking down this class\\'s superclasses and calling functions in them appropriately.\\n\\n'},\n {'prompt': \"I'm unclear on why the sub-interpreter API exists and why it's used in modules such as the mod_wsgi apache module.  Is it mainly used for creating a security sandbox for different applications running within the same process, or is it a way to allow concurrency with multiple threads?  Maybe both? Are there other purposes?\\n\",\n  'completion': 'I imagine the purpose is to create separate python execution environments. For instance, mod_wsgi (Apache Python module) hosts a single python interpreter and then hosts multiple applications within sub-interpreters (in the default configuration).\\n\\nSome key points from the documentation:\\n\\n\\nThis is an (almost) totally separate environment for the execution of Python code. In particular, the new interpreter has separate, independent versions of all imported modules, including the fundamental modules __builtin__, __main__ and sys.\\nThe table of loaded modules (sys.modules) and the module search path (sys.path) are also separate.\\nBecause sub-interpreters (and the main interpreter) are part of the same process, the insulation between them isnâ\\x80\\x99t perfect â\\x80\\x94 for example, using low-level file operations like os.close() they can (accidentally or maliciously) affect each otherâ\\x80\\x99s open files. \\nBecause of the way extensions are shared between (sub-)interpreters, some extensions may not work properly; this is especially likely when the extension makes use of (static) global variables, or when the extension manipulates its moduleâ\\x80\\x99s dictionary after its initialization.\\n\\n'},\n {'prompt': 'For a block like this:\\n\\ntry:\\n    #some stuff\\nexcept Exception:\\n    pass\\n\\n\\npylint raises warning W0703 \\'Catch \"Exception\"\\'. Why?\\n',\n  'completion': 'It\\'s considered good practice to not normally catch the root Exception object, but instead to catch more specific ones - for example IOException.\\n\\nConsider if an out of memory exception occurred - simply using \"pass\" isn\\'t going to leave your programme in a good state.\\n\\nPretty much the only time you should catch Exception is at the top level of your programme, where you can (try to) log it, display an error, and exit as gracefully as you can.\\n'},\n {'prompt': \"What is the nicest way of splitting this:\\n\\ntuple = ('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')\\n\\n\\ninto this:\\n\\ntuples = [('a', 'b'), ('c', 'd'), ('e', 'f'), ('g', 'h')]\\n\\n\\nAssuming that the input always has an even number of values.\\n\",\n  'completion': \"zip() is your friend:\\n\\nt = ('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h')\\nzip(t[::2], t[1::2])\\n\\n\"},\n {'prompt': \"I'm keeping track of a user status on a model. For the model 'Lesson' I have the status 'Finished', 'Learning', 'Viewed'. In a view for a list of models I want to add the user status. What is the best way to do this?\\n\\nOne idea: Adding the request to a models method would do the trick. Is that possible?\\n\\nEdit: I meant in templatecode: {{ lesson.get_status }}, with get_status(self, request). Is it possible? It does not work (yet).\\n\",\n  'completion': 'If your status is a value that changes, you have to break this into two separate parts.\\n\\n\\nUpdating the status.  This must be called in a view function.  The real work, however, belongs in the model.  The view function calls the model method and does the save.\\nDisplaying the status.  This is just some string representation of the status.\\n\\n\\nModel\\n\\nclass MyStatefulModel( models.Model ):\\n    theState = models.CharField( max_length=64 )\\n    def changeState( self ):\\n        if theState is None:\\n            theState= \"viewed\"\\n        elif theState is \"viewed\":\\n            theState= \"learning\"\\n        etc.\\n\\n\\nView Function\\n\\n def show( request, object_id ):\\n     object= MyStatefulModel.objects.get( id=object_id )\\n     object.changeState()\\n     object.save()\\n     render_to_response( ... )\\n\\n\\nTemplate\\n\\n <p>Your status is {{object.theState}}.</p>\\n\\n'},\n {'prompt': \"I started to use the csv.reader in Python 2.6 but you can't use len on it, or slice it, etc. What's the reason behind this? It certainly feels very limiting.\\n\\nOr is this just an abandoned module in later versions?\\n\",\n  'completion': \"I'm pretty sure you can't use len or slice because it is an iterator. Try this instead.\\n\\nimport csv\\nr = csv.reader(...)\\nlines = [line for line in r]\\nprint len(lines) #number of lines\\nfor odd in lines[1::2]: print odd # print odd lines\\n\\n\"},\n {'prompt': \"Is there a far shorter way to write the following code?\\n\\nmy_string = my_string.replace('A', '1')\\nmy_string = my_string.replace('B', '2')\\nmy_string = my_string.replace('C', '3')\\nmy_string = my_string.replace('D', '4')\\nmy_string = my_string.replace('E', '5')\\n\\n\\nNote that I don't need those exact values replaced; I'm simply looking for a way to turn 5+ lines into fewer than 5\\n\",\n  'completion': \"Looks like a good opportunity to use a loop:\\n\\nmapping = { 'A':'1', 'B':'2', 'C':'3', 'D':'4', 'E':'5'}\\nfor k, v in mapping.iteritems():\\n    my_string = my_string.replace(k, v)\\n\\n\\nA faster approach if you don't mind the parentheses would be:\\n\\nmapping = [ ('A', '1'), ('B', '2'), ('C', '3'), ('D', '4'), ('E', '5') ]\\nfor k, v in mapping:\\n    my_string = my_string.replace(k, v)\\n\\n\"},\n {'prompt': 'Why is :memory: in sqlite so slow?\\n\\nI\\'ve been trying to see if there are any performance improvements gained by using in-memory sqlite vs. disk based sqlite. Basically I\\'d like to trade startup time and memory to get extremely rapid queries which do not hit disk during the course of the application. \\n\\nHowever, the following benchmark gives me only a factor of 1.5X in improved speed. Here, I\\'m generating 1M rows of random data and loading it into both a disk and memory based version of the same table. I then run random queries on both dbs, returning sets of size approx 300k. I expected the memory based version to be considerably faster, but as mentioned I\\'m only getting 1.5X speedups. \\n\\nI experimented with several other sizes of dbs and query sets; the advantage of :memory: does seem to go up as the number of rows in the db increases. I\\'m not sure why the advantage is so small, though I had a few hypotheses: \\n\\n\\nthe table used isn\\'t big enough (in rows) to make :memory: a huge winner\\nmore joins/tables would make the :memory: advantage more apparent\\nthere is some kind of caching going on at the connection or OS level such that the previous results are accessible somehow, corrupting the benchmark\\nthere is some kind of hidden disk access going on that I\\'m not seeing (I haven\\'t tried lsof yet, but I did turn off the PRAGMAs for journaling)\\n\\n\\nAm I doing something wrong here? Any thoughts on why :memory: isn\\'t producing nearly instant lookups? Here\\'s the benchmark: \\n\\n==> sqlite_memory_vs_disk_benchmark.py <==\\n\\n#!/usr/bin/env python\\n\"\"\"Attempt to see whether :memory: offers significant performance benefits.\\n\\n\"\"\"\\nimport os\\nimport time\\nimport sqlite3\\nimport numpy as np\\n\\ndef load_mat(conn,mat):\\n    c = conn.cursor()\\n\\n    #Try to avoid hitting disk, trading safety for speed.\\n    #http://stackoverflow.com/questions/304393\\n    c.execute(\\'PRAGMA temp_store=MEMORY;\\')\\n    c.execute(\\'PRAGMA journal_mode=MEMORY;\\')\\n\\n    # Make a demo table\\n    c.execute(\\'create table if not exists demo (id1 int, id2 int, val real);\\')\\n    c.execute(\\'create index id1_index on demo (id1);\\')\\n    c.execute(\\'create index id2_index on demo (id2);\\')\\n    for row in mat:\\n        c.execute(\\'insert into demo values(?,?,?);\\', (row[0],row[1],row[2]))\\n    conn.commit()\\n\\ndef querytime(conn,query):\\n    start = time.time()\\n    foo = conn.execute(query).fetchall()\\n    diff = time.time() - start\\n    return diff\\n\\n#1) Build some fake data with 3 columns: int, int, float\\nnn   = 1000000 #numrows\\ncmax = 700    #num uniques in 1st col\\ngmax = 5000   #num uniques in 2nd col\\n\\nmat = np.zeros((nn,3),dtype=\\'object\\')\\nmat[:,0] = np.random.randint(0,cmax,nn)\\nmat[:,1] = np.random.randint(0,gmax,nn)\\nmat[:,2] = np.random.uniform(0,1,nn)\\n\\n#2) Load it into both dbs & build indices\\ntry: os.unlink(\\'foo.sqlite\\')\\nexcept OSError: pass\\n\\nconn_mem = sqlite3.connect(\":memory:\")\\nconn_disk = sqlite3.connect(\\'foo.sqlite\\')\\nload_mat(conn_mem,mat)\\nload_mat(conn_disk,mat)\\ndel mat\\n\\n#3) Execute a series of random queries and see how long it takes each of these\\nnumqs = 10\\nnumqrows = 300000 #max number of ids of each kind\\nresults = np.zeros((numqs,3))\\nfor qq in range(numqs):\\n    qsize = np.random.randint(1,numqrows,1)\\n    id1a = np.sort(np.random.permutation(np.arange(cmax))[0:qsize]) #ensure uniqueness of ids queried\\n    id2a = np.sort(np.random.permutation(np.arange(gmax))[0:qsize])\\n    id1s = \\',\\'.join([str(xx) for xx in id1a])\\n    id2s = \\',\\'.join([str(xx) for xx in id2a])\\n    query = \\'select * from demo where id1 in (%s) AND id2 in (%s);\\' % (id1s,id2s)\\n\\n    results[qq,0] = round(querytime(conn_disk,query),4)\\n    results[qq,1] = round(querytime(conn_mem,query),4)\\n    results[qq,2] = int(qsize)\\n\\n#4) Now look at the results\\nprint \"  disk | memory | qsize\"\\nprint \"-----------------------\"\\nfor row in results:\\n    print \"%.4f | %.4f | %d\" % (row[0],row[1],row[2])\\n\\n\\nHere\\'s the results. Note that disk takes about 1.5X as long as memory for a fairly wide range of query sizes. \\n\\n[ramanujan:~]$python -OO sqlite_memory_vs_disk_clean.py\\n  disk | memory | qsize\\n-----------------------\\n9.0332 | 6.8100 | 12630\\n9.0905 | 6.6953 | 5894\\n9.0078 | 6.8384 | 17798\\n9.1179 | 6.7673 | 60850\\n9.0629 | 6.8355 | 94854\\n8.9688 | 6.8093 | 17940\\n9.0785 | 6.6993 | 58003\\n9.0309 | 6.8257 | 85663\\n9.1423 | 6.7411 | 66047\\n9.1814 | 6.9794 | 11345\\n\\n\\nShouldn\\'t RAM be almost instant relative to disk? What\\'s going wrong here? \\n\\nEdit\\n\\nSome good suggestions here. \\n\\nI guess the main takehome point for me is that **there\\'s probably no way to make :memory: absolutely faster, but there is a way to make disk access relatively slower. ** \\n\\nIn other words, the benchmark is adequately measuring the realistic performance of memory, but not the realistic performance of disk (e.g. because the cache_size pragma is too big or because I\\'m not doing writes). I\\'ll mess around with those parameters and post my findings when I get a chance.  \\n\\nThat said, if there is anyone who thinks I can squeeze some more speed out of the in-memory db (other than by jacking up the cache_size and default_cache_size, which I will do), I\\'m all ears...\\n',\n  'completion': \"It has to do with the fact that SQLite has a page cache. According to the Documentation, the default page cache is 2000 1K pages or about 2Mb. Since this is about 75% to 90% of your data, it isn't surprising that the two number are very similar. My guess is that in addition to the SQLite page cache, the rest of the data is still in the OS disk cache. If you got SQLite to flush the page cache (and the disk cache) you would see some really significant differences.\\n\"},\n {'prompt': 'Can anyone suggest any good payment processing libraries for python/django?\\n',\n  'completion': 'The most developed Django solution is Satchmo with support for Authorize.Net, TrustCommerce, CyberSource, PayPal, Google Checkout, and Protx.\\n\\nThe new kid on the Django block is django-lfs which looks like only support for PayPal at the moment, and even that may not be complete.\\n\\nFor general Python the main player is getpaid\\n'},\n {'prompt': 'Surely a 0d array is scalar, but Numpy does not seem to think so... am I missing something or am I just misunderstanding the concept? \\n\\n>>> foo = numpy.array(1.11111111111, numpy.float64)\\n>>> numpy.ndim(foo)\\n0\\n>>> numpy.isscalar(foo)\\nFalse\\n>>> foo.item()\\n1.11111111111\\n\\n',\n  'completion': 'One should not think too hard about it. It\\'s ultimately better for the mental health and longevity of the individual.\\n\\nThe curious situation with Numpy scalar-types was bore out of the fact that there is no graceful and consistent way to degrade the 1x1 matrix to scalar types. Even though mathematically they are the same thing, they are handled by very different code.\\n\\nIf you\\'ve been doing any amount of scientific code, ultimately you\\'d want things like max(a) to work on matrices of all sizes, even scalars. Mathematically, this is a perfectly sensible thing to expect. However for programmers this means that whatever presents scalars in Numpy should have the .shape and .ndim attirbute, so at least the ufuncs don\\'t have to do explicit type checking on its input for the 21 possible scalar types in Numpy. \\n\\nOn the other hand, they should also work with existing Python libraries that does do explicit type-checks on scalar type. This is a dilemma, since a Numpy ndarray have to individually change its type when they\\'ve been reduced to a scalar, and there is no way of knowing whether that has occurred without it having do checks on all access. Actually going that route would probably make bit ridiculously slow to work with by scalar type standards.\\n\\nThe Numpy developer\\'s solution is to inherit from both ndarray and Python scalars for its own scalary type, so that all scalars also have .shape, .ndim, .T, etc etc. The 1x1 matrix will still be there, but its use will be discouraged if you know you\\'ll be dealing with a scalar. While this should work fine in theory, occasionally you could still see some places where they missed with the paint roller, and the ugly innards are exposed for all to see:\\n\\n>>> from numpy import *\\n>>> a = array(1)\\n>>> b = int_(1)\\n>>> a.ndim\\n0\\n>>> b.ndim\\n0\\n>>> a[...]\\narray(1)\\n>>> a[()]\\n1\\n>>> b[...]\\narray(1)\\n>>> b[()]\\n1\\n\\n\\nThere\\'s really no reason why a[...] and a[()] should return different things, but it does. There are proposals in place to change this, but looks like they forgot to finish the job for 1x1 arrays.\\n\\nA potentially bigger, and possibly non-resolvable issue, is the fact that Numpy scalars are immutable. Therefore \"spraying\" a scalar into a ndarray, mathematically the adjoint operation of collapsing an array into a scalar, is a PITA to implement. You can\\'t actually grow a Numpy scalar, it cannot by definition be cast into an ndarray, even though newaxis mysteriously works on it:\\n\\n>>> b[0,1,2,3] = 1\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nTypeError: \\'numpy.int32\\' object does not support item assignment\\n>>> b[newaxis]\\narray([1])\\n\\n\\nIn Matlab, growing the size of a scalar is a perfectly acceptable and brainless operation. In Numpy you have to stick jarring a = array(a) everywhere you think you\\'d have the possibility of starting with a scalar and ending up with an array. I understand why Numpy has to be this way to play nice with Python, but that doesn\\'t change the fact that many new switchers are deeply confused about this. Some have explicit memory of struggling with this behaviour and eventually persevering, while others who are too far gone are generally left with some deep shapeless mental scar that frequently haunts their most innocent dreams. It\\'s an ugly situation for all.\\n'},\n {'prompt': \"I'm currently writing a telnet server in Python. It's a content server. People would connect to the server via telnet, and be presented with text-only content.\\n\\nMy problem is that the server would obviously need to support more than one simultaneous connection. The current implementation I have now supports only one. \\n\\nThis is the basic, proof-of-concept server I began with (while the program has changed greatly over time, the basic telnet framework hasn't):\\n\\nimport socket, os\\n\\nclass Server:\\n    def __init__(self):\\n    \\tself.host, self.port = 'localhost', 50000\\n    \\tself.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n    \\tself.socket.bind((self.host, self.port))\\n\\n    def send(self, msg):\\n    \\tif type(msg) == str: self.conn.send(msg + end)\\n    \\telif type(msg) == list or tuple: self.conn.send('\\\\n'.join(msg) + end)\\n\\n    def recv(self):\\n    \\tself.conn.recv(4096).strip()\\n\\n    def exit(self):\\n    \\tself.send('Disconnecting you...'); self.conn.close(); self.run()\\n    \\t# closing a connection, opening a new one\\n\\n    # main runtime\\n    def run(self):\\n    \\tself.socket.listen(1)\\n    \\tself.conn, self.addr = self.socket.accept()\\n    \\t# there would be more activity here\\n    \\t# i.e.: sending things to the connection we just made\\n\\n\\nS = Server()\\nS.run()\\n\\n\\nThanks for your help. \\n\",\n  'completion': 'Implemented in twisted:\\n\\nfrom twisted.internet.protocol import Factory, Protocol\\nfrom twisted.internet import reactor\\n\\nclass SendContent(Protocol):\\n    def connectionMade(self):\\n        self.transport.write(self.factory.text)\\n        self.transport.loseConnection()\\n\\nclass SendContentFactory(Factory):\\n    protocol = SendContent\\n    def __init__(self, text=None):\\n        if text is None:\\n            text = \"\"\"Hello, how are you my friend? Feeling fine? Good!\"\"\"\\n        self.text = text\\n\\nreactor.listenTCP(50000, SendContentFactory())\\nreactor.run()\\n\\n\\nTesting:\\n\\n$ telnet localhost 50000\\nTrying 127.0.0.1...\\nConnected to localhost.\\nEscape character is \\'^]\\'.\\nHello, how are you my friend? Feeling fine? Good!\\nConnection closed by foreign host.\\n\\n\\nSeriously, when it comes to asynchronous network, twisted is the way to go. It handles multiple connections in a single-thread single-process approach.\\n'},\n {'prompt': 'What\\'s the magic \"python setup.py some_incantation_here\" command to upload a package to PyPI, in a form that can be downloaded to get the original package in its original form?\\n\\nI have a package with some source and a few image files (as package_data).  If I do \"setup.py sdist register upload\", the .tar.gz has the image files excluded.  If I do \"setup.py bdist_egg register upload\", the egg contains the images but excludes the setup.py file.  I want to be able to get a file uploaded that is just the entirety of my project -- aka \"setup.py the_whole_freaking_thing register upload\".\\n\\nPerhaps the best way to do this is to manually tar.gz my project directory and upload it using the PyPI web interface?\\n\\nCaveat: I\\'m trying to avoid having to store a simple project I just created in my SVN repo as well as on PyPI -- it seems like a waste of work to keep track of its history and files in two places.\\n',\n  'completion': 'When you perform an \"sdist\" command, then what controls the list of included files is your \"MANIFEST.in\" file sitting next to \"setup.py\", not whatever you have listed in \"package_data\".  This has something to do with the schizophrenic nature of the Python packaging solutions today; \"sdist\" is powered by the distutils in the standard library, while \"bdist_egg\" is controlled by the setuptools module.\\n\\nTo solve the problem, try creating a MANIFEST.in next to your setup.py file, and give it contents like this:\\n\\ninclude *.jpg\\n\\n\\nOf course, I\\'m imaging that your \"image files\" are actual pictures rather than disk images or ISO images or something; you might have to adjust the above line if I\\'ve guessed wrong!  But check out the Specifying which files to distribute section of the distutils docs, and see whether you can\\'t get those files appearing in your .tar.gz source distribution!  Good luck.\\n'},\n {'prompt': \"How do I write the magic function below?\\n\\n>>> num = 123\\n>>> lst = magic(num)\\n>>>\\n>>> print lst, type(lst)\\n[1, 2, 3], <type 'list'>\\n\\n\",\n  'completion': 'You mean this?\\n\\nnum = 1234\\nlst = [int(i) for i in str(num)]\\n\\n'},\n {'prompt': 'The sqlite3 module is included in Python version 2.5+. However, I am stuck with version 2.4. I uploaded the sqlite3 module files, added the directory to sys.path, but I get the following error when I try to import it:\\n\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in ?\\n  File \"sqlite3/__init__.py\", line 23, in ?\\n    from dbapi2 import *\\n  File \"sqlite3/dbapi2.py\", line 26, in ?\\n    from _sqlite3 import *\\nImportError: No module named _sqlite3\\n\\n\\nThe file \\'_sqlite3\\' is in lib-dynload, but if I include this in the sqlite3 directory, I get additional errors.\\n\\nAny suggestions? I am working in a limited environment; I don\\'t have access to GCC, among other things.\\n',\n  'completion': 'I had same problem with CentOS and python 2.4\\n\\nMy solution:\\n\\nyum install python-sqlite2\\n\\n\\nand try following python code\\n\\ntry:\\n    import sqlite3\\nexcept:\\n    from pysqlite2 import dbapi2 as sqlite3\\n\\n'},\n {'prompt': \"I'd like to produce sounds that would resemble audio from real instruments. The problem is that I have very little clue how to get that.\\n\\nWhat I know this far from real instruments is that sounds they output are rarely clean. But how to produce such unclean sounds?\\n\\nThis far I've gotten to do this, it produces quite plain sound from which I'm not sure it's even using the alsa correctly.\\n\\nimport numpy\\nfrom numpy.fft import fft, ifft\\nfrom numpy.random import random_sample\\nfrom alsaaudio import PCM, PCM_NONBLOCK, PCM_FORMAT_FLOAT_LE\\n\\npcm = PCM()#mode=PCM_NONBLOCK)\\npcm.setrate(44100)\\npcm.setformat(PCM_FORMAT_FLOAT_LE)\\npcm.setchannels(1)\\npcm.setperiodsize(4096)\\n\\ndef sine_wave(x, freq=100):\\n    sample = numpy.arange(x*4096, (x+1)*4096, dtype=numpy.float32)\\n    sample *= numpy.pi * 2 / 44100\\n    sample *= freq\\n    return numpy.sin(sample)\\n\\nfor x in xrange(1000):\\n    sample = sine_wave(x, 100)\\n    pcm.write(sample.tostring())\\n\\n\",\n  'completion': 'Sound synthesis is a complex topic which requires many years of study to master. \\n\\nIt is also not an entirely solved problem, although relatively recent developments (such as physical modelling synthesis) have made progress in imitating real-world instruments.\\n\\nThere are a number of options open to you. If you are sure that you want to explore synthesis further, then I suggest you start by learning about FM synthesis. It is relatively easy to learn and implement in software, at least in basic forms, and produces a wide range of interesting sounds. Also, check out the book \"The Computer Music Tutorial\" by Curtis Roads. It\\'s a bible for all things computer music, and although it\\'s a few years old it is the book of choice for learning the fundamentals.\\n\\nIf you want a quicker way to produce life-like sound, consider using sampling techniques: that is, record the instruments you want to reproduce (or use a pre-existing sample bank), and just play back the samples. It\\'s a much more straightforward (and often more effective) approach. \\n'},\n {'prompt': \"I am wondering if there are any django based, or even Python Based Reporting Services ala JasperReports or SQL Server Reporting Services?\\n\\nBasically, I would love to be able to create reports, send them out as emails as CSV or HTML or PDF without having to code the reports. Even if I have to code the report I wouldn't mind, but the whole framework with schedules and so on would be nice!\\n\\nPS. I know I could use Django Apps to do it, but I was hoping if there was any integrated solutions or even projects such as Pinax or Satchmo which brings together the apps needed.\\n\\nPPS: It would have to work off Postgres\\n\\nThanks and Regards\\n\\nMark\\n\",\n  'completion': '\"I would love to be able to create reports ... without having to code the reports\"  \\n\\nSo would I.  Sadly, however, each report seems to be unique and require custom code.\\n\\nFrom Django model to CSV is easy.  Start there with a few of your reports.\\n\\nimport csv\\nfrom myApp.models import This, That, TheOther\\ndef parseCommandLine():\\n    # setup optparse to get report query parameters\\ndef main():\\n    wtr= csv.DictWriter( sys.stdout, [\"Col1\", \"Col2\", \"Col3\"] )\\n    this, that = parseCommandLine()\\n    thisList= This.objects.filter( name=this, that__name=that )\\n    for object in thisList:\\n        write.writerow( object.col1, object.that.col2, object.theOther.col3 )\\nif __name__ == \"__main__\":\\n    main()\\n\\n\\nHTML is pretty easy -- Django has an HTML template language.  Rather than render_to_response, you simply render your template and write it to stdout.  And the core of the algorithm, interestingly, is very similar to writing a CSV.  Similar enough that -- without much cleverness -- you should have a design pattern that does both.\\n\\nOnce you have the CSV working, add the HTML using Django\\'s templates.\\n\\nPDF\\'s are harder, because you have to actually work out the formatting in some detail.  There are a lot of Python libraries for this.  Interestingly, however, the overall pattern for PDF writing is very similar to CSV and HTML writing.\\n\\nEmailing means using Python\\'s smtplib directly or Django\\'s email package.  This isn\\'t too hard.  All the pieces are there, you just need to email the output files produced above to some distribution list.\\n\\nScheduling takes a little thinking to make best use of crontab.  This -- perhaps -- is the hardest part of the job.\\n'},\n {'prompt': 'I have a django model like this:\\n\\nclass Player(models.Model):\\n    name = models.CharField()\\n    batting = models.IntegerField()\\n    bowling = models.IntegerField()\\n\\n\\nWhat would be the Django QuerySet equivalent of the following SQL?\\n\\nSELECT * FROM player WHERE batting > bowling;\\n\\n',\n  'completion': \"In django 1.1 you can do the following:\\n\\nplayers = Player.objects.filter(batting__gt=F('bowling'))\\n\\n\\nSee the other question for details\\n\"},\n {'prompt': \"Of course an HTML page can be parsed using any number of python parsers, but I'm surprised that there don't seem to be any public parsing scripts to extract meaningful content (excluding sidebars, navigation, etc.) from a given HTML doc. \\n\\nI'm guessing it's something like collecting DIV and P elements and then checking them for a minimum amount of text content, but I'm sure a solid implementation would include plenty of things that I haven't thought of.\\n\",\n  'completion': \"Try the Beautiful Soup library for Python. It has very simple methods to extract information from an html file.\\n\\nTrying to generically extract data from webpages would require people to write their pages in a similar way... but there's an almost infinite number of ways to convey a page that looks identical let alone all the conbinations you can have to convey the same information.\\n\\nWas there a particular type of information you were trying to extract or some other end goal?\\n\\nYou could try extracting any content in 'div' and 'p' markers and compare the relative sizes of all the information in the page. The problem then is that people probably group information into collections of 'div's and 'p's (or at least they do if they're writing well formed html!).\\n\\nMaybe if you formed a tree of how the information is related (nodes would be the 'p' or 'div or whatever and each node would contain the associated text) you could do some sort of analysis to identify the smallest 'p' or 'div' that encompases what appears to be the majority of the information.. ?\\n\\n[EDIT] Maybe if you can get it into the tree structure I suggested, you could then use a similar points system to spam assassin. Define some rules that attempt to classify the information. Some examples:\\n\\n+1 points for every 100 words\\n+1 points for every child element that has > 100 words\\n-1 points if the section name contains the word 'nav'\\n-2 points if the section name contains the word 'advert'\\n\\n\\nIf you have a lots of low scoring rules which add up when you find more relevent looking sections, I think that could evolve into a fairly powerful and robust technique.\\n\\n[EDIT2] Looking at the readability, it seems to be doing pretty much exactly what I just suggested! Maybe it could be improved to try and understand tables better?\\n\"},\n {'prompt': \"I'd like to reformat some SQL statements that are a single string with newlines in to something that's much easier to read.\\n\\nI don't personally know of a good coding style for indenting SQL - how should nested queries / where clauses / left joins / etc by represented to maximise readability?\\n\\nHas anyone seen a pretty-printing algorithm that does this already? In Python would be even better.\\n\",\n  'completion': \"You can try sqlparse. It's a Python module that provides simple SQL formatting. A online demo is available here.\\n\"},\n {'prompt': \"I am looking for RAD like environment for PHP and/or Python free or not does not matter.\\n\\nIt should have a visual environment where one can use a point and click interface so that it is possible to select objects with mouse and move them around.\\n\\nI have looked at Delphi4PHP. The RAD part is fantastic, but I don't like the framework on which it is based VCL4PHP (vcl4php.sourceforge.net) is crappy. Just to deploy a simple Hello world application we will have to deploy 40MB of that framework. That is just stupid.....\\n\\nI looked at Eclipse but it is only a code IDE. Does not have a visual way of designing a page/window. Did I miss any plugin that supports this feature?\\n\\nI was suggested to give NetBeans IDE a close look so I also looked that up, but did not find what I wanted.\\n\\nI have also looked up following but none of these are true RAD:\\n\\n\\nNuSphere PHPEd\\nVS PHP for Visual Studio \\nPHP Designer (not a designer by any means just a plain old IDE)\\n\\n\\nI have not been able to find any descent Python RAD tool also.\\n\\nI have looked up Yes Software's Code Charge Studio (www.yessoftware.com) but it cannot be used to develop complicated applications like say for example an Accounting System or an Inventory Management App, etc.. It is useful but for very simple apps. Making changes to Visual part (referred as components by this people) is a nightmare. Finally it does not support Python.\\n\",\n  'completion': 'Python and PHP both have a binding for GTK :\\n\\n\\nPyGTK for Python;\\nPHP GTK for PHP;\\n\\n\\nYou can use Glade as a RADD to draw a GTK app.\\n\\nGTK runs on Windows, Linux and Mac OS.\\n\\nIf you are looking for something embedding everything, I can think of SPE for Python, but you really can run Glade as stand alone. \\n\\nSince any picture is worth 1000 words :\\n\\n\\n\\nI let the PHP lovers choosing their language equivalent.\\n'},\n {'prompt': 'I\\'m a newbie to programming. I had 1 semester of computer science (we used java).  I got an A in the course and was able to do everything assigned, however I\\'m not sure I really understood it. I ignored the text and learned by looking at sample programs and then trial and error. I was ahead of the class except for two guys who came in knowing java or another OOP language.\\n\\nI\\'d like to learn Python. I\\'m also going to build a second PC from extra parts I have and use linux. Basically, I want to enhance my knowledge of computers. Thats my motivation.\\n\\nNow on learning python are there any good programming theory books that would be useful? Or should I read up on more on how computers operate on the lowest levels? I don\\'t think I know enough to ask the question I want. \\n\\nI guess to make it simple, I am asking what should I know to make the most of learning python. This is not for a career. This is from a desire to know. I am no longer a computer science major (it also would not have any direct applications to my anticipated career.)\\n\\nI\\'m not looking to learn in \"30 days\" or \"1 week\" or whatever. So, starting from a very basic level is fine with me. \\n\\nThanks in advance. I did a search and didn\\'t quite find what I was looking for. \\n\\nUPDATE: Thanks for all the great advice. I found this site at work and couldn\\'t find it on my home computer, so I am just getting to read now. \\n',\n  'completion': \"My recommendation is always to start at the high level of abstraction.  You don't need to know how logic gates work and how you can use them to build a CPU -- it's cool stuff, but it's cool stuff that makes a lot more sense once you've messed around at the higher levels.  Python is therefore an excellent choice as a learning aid.\\n\\nHow to Think Like A Computer Scientist:  Learning With Python is available on the Internet and is an excellent introduction to the high-level concepts that make computers go.  And it's even Python-specific.\\n\\nIf you're looking to have your brain turned inside-out, SICP will do a good job of it.  I don't recommend it as a first text, though; it's heavy going.\\n\\nBoth of these books are high-level.  They won't teach you anything about the low-level details like memory structures or what a CPU actually does, but that's something I would reserve for later anyway.\\n\\nD'A\\n\"},\n {'prompt': \"I was wondering if it was possible (and, if so, how) to chain together multiple managers to produce a query set that is affected by both of the individual managers.  I'll explain the specific example that I'm working on:\\n\\nI have multiple abstract model classes that I use to provide small, specific functionality to other models.  Two of these models are a DeleteMixin and a GlobalMixin.\\n\\nThe DeleteMixin is defined as such:\\n\\nclass DeleteMixin(models.Model):\\n    deleted = models.BooleanField(default=False)\\n    objects = DeleteManager()\\n\\n    class Meta:\\n        abstract = True\\n\\n    def delete(self):\\n        self.deleted = True\\n        self.save()\\n\\n\\nBasically it provides a pseudo-delete (the deleted flag) instead of actually deleting the object.\\n\\nThe GlobalMixin is defined as such:\\n\\nclass GlobalMixin(models.Model):\\n    is_global = models.BooleanField(default=True)\\n\\n    objects = GlobalManager()\\n\\n    class Meta:\\n        abstract = True\\n\\n\\nIt allows any object to be defined as either a global object or a private object (such as a public/private blog post).\\n\\nBoth of these have their own managers that affect the queryset that is returned.  My DeleteManager filters the queryset to only return results that have the deleted flag set to False, while the GlobalManager filters the queryset to only return results that are marked as global.  Here is the declaration for both:\\n\\nclass DeleteManager(models.Manager):\\n    def get_query_set(self):\\n        return super(DeleteManager, self).get_query_set().filter(deleted=False)\\n\\nclass GlobalManager(models.Manager):\\n    def globals(self):\\n        return self.get_query_set().filter(is_global=1)\\n\\n\\nThe desired functionality would be to have a model extend both of these abstract models and grant the ability to only return the results that are both non-deleted and global.  I ran a test case on a model with 4 instances: one was global and non-deleted, one was global and deleted, one was non-global and non-deleted, and one was non-global and deleted.  If I try to get result sets as such: SomeModel.objects.all(), I get instance 1 and 3 (the two non-deleted ones - great!).  If I try SomeModel.objects.globals(), I get an error that DeleteManager doesn't have a globals (this is assuming my model declaration is as such: SomeModel(DeleteMixin, GlobalMixin).  If I reverse the order, I don't get the error, but it doesn't filter out the deleted ones).  If I change GlobalMixin to attach GlobalManager to globals instead of objects (so the new command would be SomeModel.globals.globals()), I get instances 1 and 2 (the two globals), while my intended result would be to only get instance 1 (the global, non-deleted one).\\n\\nI wasn't sure if anyone had run into any situation similar to this and had come to a result.  Either a way to make it work in my current thinking or a re-work that provides the functionality I'm after would be very much appreciated.  I know this post has been a little long-winded.  If any more explanation is needed, I would be glad to provide it.\\n\\nEdit:\\n\\nI have posted the eventual solution I used to this specific problem below.  It is based on the link to Simon's custom QuerySetManager.\\n\",\n  'completion': 'See this snippet on Djangosnippets: http://djangosnippets.org/snippets/734/\\n\\nInstead of putting your custom methods in a manager, you subclass the queryset itself. It\\'s very easy and works perfectly. The only issue I\\'ve had is with model inheritance, you always have to define the manager in model subclasses (just: \"objects = QuerySetManager()\" in the subclass), even though they will inherit the queryset. This will make more sense once you are using QuerySetManager.\\n'},\n {'prompt': \"Consider the following:\\n\\n@property\\ndef name(self):\\n\\n    if not hasattr(self, '_name'):\\n\\n    \\t# expensive calculation\\n    \\tself._name = 1 + 1\\n\\n    return self._name\\n\\n\\nI'm new, but I think the caching could be factored out into a decorator. Only I didn't find one like it ;)\\n\\nPS the real calculation doesn't depend on mutable values\\n\",\n  'completion': \"Starting from Python 3.2 there is a built-in decorator:\\n\\n@functools.lru_cache(maxsize=100, typed=False)\\n\\n\\nDecorator to wrap a function with a memoizing callable that saves up to the maxsize most recent calls. It can save time when an expensive or I/O bound function is periodically called with the same arguments.\\n\\n\\nExample of an LRU cache for computing Fibonacci numbers:\\n\\n@lru_cache(maxsize=None)\\ndef fib(n):\\n    if n < 2:\\n        return n\\n    return fib(n-1) + fib(n-2)\\n\\n>>> print([fib(n) for n in range(16)])\\n[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610]\\n\\n>>> print(fib.cache_info())\\nCacheInfo(hits=28, misses=16, maxsize=None, currsize=16)\\n\\n\\n\\n\\nIf you are stuck with Python 2.x, here's a list of other compatible memoization libraries:\\n\\n\\nfunctools32 | PyPI | Source code\\nrepoze.lru | PyPI | Source code\\npylru | PyPI | Source code\\nbackports.functools_lru_cache | PyPI | Source code\\n\\n\"},\n {'prompt': \"What's the pythonic way to designate unreachable code in python as in:\\n\\ngender = readFromDB(...) # either 'm' or 'f'\\nif gender == 'm':\\n    greeting = 'Mr.'\\nelif gender == 'f':\\n    greeting = 'Ms.'\\nelse:\\n    # What should this line say?\\n\\n\",\n  'completion': \"raise ValueError('invalid gender %r' % gender)\\n\\n\"},\n {'prompt': 'I have a mapping of catalog numbers to product names:\\n\\n35  cozy comforter\\n35  warm blanket\\n67  pillow\\n\\n\\nand need a search that would find misspelled, mixed names like \"warm cmfrter\".\\n\\nWe have code using edit-distance (difflib), but it probably won\\'t scale to the 18000 names.\\n\\nI achieved something similar with Lucene, but as PyLucene only wraps Java that would complicate deployment to end-users.\\n\\nSQLite doesn\\'t usually have full-text or scoring compiled in.\\n\\nThe Xapian bindings are like C++ and have some learning curve.\\n\\nWhoosh is not yet well-documented but includes an abusable spell-checker.\\n\\nWhat else is there?\\n',\n  'completion': 'Apparently the only way to make fuzzy comparisons fast is to do less of them ;)\\n\\nInstead of writing another n-gram search or improving the one in Whoosh we now keep a word index, retrieve all entries that have at least one (correctly spelled) word in common with the query, and use difflib to rank those. Works well enough in this case.\\n'},\n {'prompt': \"I'm trying to write an __init__ function for one of my models so that I can create an object by doing\\n\\np = User('name','email')\\n\\n\\nWhen I write the model, I have \\n\\n    def __init__(self, name, email, house_id, password):\\n            models.Model.__init__(self)\\n            self.name = name\\n            self.email = email\\n\\n\\nThis works, and I can save the object to the database, but when I do 'User.objects.all()', it doesn't pull anything up unless I take out my __init__ function.  Any ideas?\\n\",\n  'completion': 'Relying on Django\\'s built-in functionality and passing named parameters would be the simplest way to go.\\n\\np = User(name=\"Fred\", email=\"fred@example.com\")\\n\\n\\nBut if you\\'re set on saving some keystrokes, I\\'d suggest adding a static convenience method to the class instead of messing with the initializer.\\n\\n# In User class declaration\\n@classmethod\\ndef create(cls, name, email):\\n  return cls(name=name, email=email)\\n\\n# Use it\\np = User.create(\"Fred\", \"fred@example.com\")\\n\\n'},\n {'prompt': \"I would like to emulate the pass-by-value behaviour in python. In other words, I would like to make absolutely sure that the function I write do not modify user supplied data. \\n\\nOne possible way is to use deep copy:\\n\\nfrom copy import deepcopy\\ndef f(data):\\n    data = deepcopy(data)\\n    #do stuff\\n\\n\\nis there more efficient or more pythonic way to achieve this goal, making as few assumptions as possible about the object being passed (such as .clone() method)\\n\\nEdit \\n\\nI'm aware that technically everything in python is passed by value. I was interested in emulating the behaviour, i.e. making sure I don't mess with the data that was passed to the function. I guess the most general way is to clone the object in question either with its own clone mechanism or with deepcopy.\\n\",\n  'completion': \"You can make a decorator and put the cloning behaviour in that. \\n\\n>>> def passbyval(func):\\ndef new(*args):\\n\\tcargs = [deepcopy(arg) for arg in args]\\n\\treturn func(*cargs)\\nreturn new\\n\\n>>> @passbyval\\ndef myfunc(a):\\n    print a\\n\\n>>> myfunc(20)\\n20\\n\\n\\nThis is not the most robust way, and doesn't handle key-value arguments or class methods (lack of self argument), but you get the picture.\\n\\nNote that the following statements are equal:\\n\\n@somedecorator\\ndef func1(): pass\\n# ... same as ...\\ndef func2(): pass\\nfunc2 = somedecorator(func2)\\n\\n\\nYou could even have the decorator take some kind of function that does the cloning and thus allowing the user of the decorator to decide the cloning strategy. In that case the decorator is probably best implemented as a class with __call__ overridden.\\n\"},\n {'prompt': 'I want my Python script to be able to read Unicode command line arguments in Windows. But it appears that sys.argv is a string encoded in some local encoding, rather than Unicode. How can I read the command line in full Unicode?\\n\\nExample code: argv.py\\n\\nimport sys\\n\\nfirst_arg = sys.argv[1]\\nprint first_arg\\nprint type(first_arg)\\nprint first_arg.encode(\"hex\")\\nprint open(first_arg)\\n\\n\\nOn my PC set up for Japanese code page, I get:\\n\\nC:\\\\temp>argv.py \"PCã\\x83»ã\\x82½ã\\x83\\x95ã\\x83\\x88ç\\x94³è«\\x8bæ\\x9b¸08.09.24.doc\"\\nPCã\\x83»ã\\x82½ã\\x83\\x95ã\\x83\\x88ç\\x94³è«\\x8bæ\\x9b¸08.09.24.doc\\n<type \\'str\\'>\\n50438145835c83748367905c90bf8f9130382e30392e32342e646f63\\n<open file \\'PCã\\x83»ã\\x82½ã\\x83\\x95ã\\x83\\x88ç\\x94³è«\\x8bæ\\x9b¸08.09.24.doc\\', mode \\'r\\' at 0x00917D90>\\n\\n\\nThat\\'s Shift-JIS encoded I believe, and it \"works\" for that filename. But it breaks for filenames with characters that aren\\'t in the Shift-JIS character setâ\\x80\\x94the final \"open\" call fails:\\n\\nC:\\\\temp>argv.py JÃ¶rgen.txt\\nJorgen.txt\\n<type \\'str\\'>\\n4a6f7267656e2e747874\\nTraceback (most recent call last):\\n  File \"C:\\\\temp\\\\argv.py\", line 7,\\nin <module>\\n    print open(first_arg)\\nIOError: [Errno 2] No such file or directory: \\'Jorgen.txt\\'\\n\\n\\nNoteâ\\x80\\x94I\\'m talking about Python 2.x, not Python 3.0. I\\'ve found that Python 3.0 gives sys.argv as proper Unicode. But it\\'s a bit early yet to transition to Python 3.0 (due to lack of 3rd party library support).\\n\\nUpdate:\\n\\nA few answers have said I should decode according to whatever the sys.argv is encoded in. The problem with that is that it\\'s not full Unicode, so some characters are not representable.\\n\\nHere\\'s the use case that gives me grief: I have enabled drag-and-drop of files onto .py files in Windows Explorer. I have file names with all sorts of characters, including some not in the system default code page. My Python script doesn\\'t get the right Unicode filenames passed to it via sys.argv in all cases, when the characters aren\\'t representable in the current code page encoding.\\n\\nThere is certainly some Windows API to read the command line with full Unicode (and Python 3.0 does it). I assume the Python 2.x interpreter is not using it.\\n',\n  'completion': 'Here is a solution that is just what I\\'m looking for, making a call to the Windows GetCommandLineArgvW  function:\\nGet sys.argv with Unicode characters under Windows (from ActiveState)\\n\\nBut I\\'ve made several changes, to simplify its usage and better handle certain uses. Here is what I use:\\n\\nwin32_unicode_argv.py\\n\\n\"\"\"\\nwin32_unicode_argv.py\\n\\nImporting this will replace sys.argv with a full Unicode form.\\nWindows only.\\n\\nFrom this site, with adaptations:\\n      http://code.activestate.com/recipes/572200/\\n\\nUsage: simply import this module into a script. sys.argv is changed to\\nbe a list of Unicode strings.\\n\"\"\"\\n\\n\\nimport sys\\n\\ndef win32_unicode_argv():\\n    \"\"\"Uses shell32.GetCommandLineArgvW to get sys.argv as a list of Unicode\\n    strings.\\n\\n    Versions 2.x of Python don\\'t support Unicode in sys.argv on\\n    Windows, with the underlying Windows API instead replacing multi-byte\\n    characters with \\'?\\'.\\n    \"\"\"\\n\\n    from ctypes import POINTER, byref, cdll, c_int, windll\\n    from ctypes.wintypes import LPCWSTR, LPWSTR\\n\\n    GetCommandLineW = cdll.kernel32.GetCommandLineW\\n    GetCommandLineW.argtypes = []\\n    GetCommandLineW.restype = LPCWSTR\\n\\n    CommandLineToArgvW = windll.shell32.CommandLineToArgvW\\n    CommandLineToArgvW.argtypes = [LPCWSTR, POINTER(c_int)]\\n    CommandLineToArgvW.restype = POINTER(LPWSTR)\\n\\n    cmd = GetCommandLineW()\\n    argc = c_int(0)\\n    argv = CommandLineToArgvW(cmd, byref(argc))\\n    if argc.value > 0:\\n        # Remove Python executable and commands if present\\n        start = argc.value - len(sys.argv)\\n        return [argv[i] for i in\\n                xrange(start, argc.value)]\\n\\nsys.argv = win32_unicode_argv()\\n\\n\\nNow, the way I use it is simply to do:\\n\\nimport sys\\nimport win32_unicode_argv\\n\\n\\nand from then on, sys.argv is a list of Unicode strings. The Python optparse module seems happy to parse it, which is great.\\n'},\n {'prompt': 'Many python libraries, even recently written ones, use httplib2 or the socket interface to perform networking tasks.\\n\\nThose are obviously easier to code on than Twisted due to their blocking nature, but I think this is a drawback when integrating them with other code, especially GUI one. If you want scalability, concurrency or GUI integration while avoiding multithreading, Twisted is then a natural choice.\\n\\nSo I would be interested in opinions in those matters:\\n\\n\\nShould new networking code (with the exception of small command line tools) be written with Twisted?\\nWould you mix Twisted, http2lib or socket code in the same project?\\nIs Twisted pythonic for most libraries (it is more complex than alternatives, introduce a dependency to a non-standard package...)?\\n\\n\\nEdit: please let me phrase this in another way. Do you feel writing new library code with Twisted may add a barrier to its adoption? Twisted has obvious benefits (especially portability and scalability as stated by gimel), but the fact that it is not a core python library may be considered by some as a drawback.\\n',\n  'completion': 'See asychronous-programming-in-python-twisted, you\\'ll have to decide if depending on a non-standard (external) library fits your needs. Note the answer by @Glyph, he is the founder of the Twisted project, and can authoritatively answer any Twisted related question.\\n\\n\\n  At the core of libraries like Twisted, the function in the main loop is not sleep, but an operating system call like select() or poll(), as exposed by a module like the Python select module. I say \"like\" select, because this is an API that varies a lot between platforms, and almost every GUI toolkit has its own version. Twisted currently provides an abstract interface to 14 different variations on this theme. The common thing that such an API provides is provide a way to say \"Here are a list of events that I\\'m waiting for. Go to sleep until one of them happens, then wake up and tell me which one of them it was.\"\\n\\n'},\n {'prompt': 'Is there a cross-platform way of getting the path to the temp directory in Python 2.6?  \\n\\nFor example, under Linux that would be /tmp, while under XP C:\\\\Documents and settings\\\\[user]\\\\Application settings\\\\Temp.\\n\\nThanks!\\n',\n  'completion': \"That would be the tempfile module.\\n\\nIt has functions to get the temporary directory, and also has some shortcuts to create temporary files and directories in it, either named or unnamed.\\n\\nExample:\\n\\nimport tempfile\\n\\nprint tempfile.gettempdir() # prints the current temporary directory\\n\\nf = tempfile.TemporaryFile()\\nf.write('something on temporaryfile')\\nf.seek(0) # return to beginning of file\\nprint f.read() # reads data back from the file\\nf.close() # temporary file is automatically deleted here\\n\\n\\nFor completeness, here's how it searches for the temporary directory, according to the documentation:\\n\\n\\nThe directory named by the TMPDIR environment variable.\\nThe directory named by the TEMP environment variable.\\nThe directory named by the TMP environment variable.\\nA platform-specific location:\\n\\nOn RiscOS, the directory named by the Wimp$ScrapDir environment variable.\\nOn Windows, the directories C:\\\\TEMP, C:\\\\TMP, \\\\TEMP, and \\\\TMP, in that order.\\nOn all other platforms, the directories /tmp, /var/tmp, and /usr/tmp, in that order.\\n\\nAs a last resort, the current working directory.\\n\\n\"},\n {'prompt': \"To squeeze into the limited amount of filesystem storage available in an embedded system I'm currently playing with, I would like to eliminate any files that could reasonably be removed without significantly impacting functionality or performance.  The *.py, *.pyo, and *.pyc files in the Python library account for a sizable amount of space, I'm wondering which of these options would be most reasonable for a Python 2.6 installation in a small embedded system:\\n\\n\\nKeep *.py, eliminate *.pyc and *.pyo (Maintain ability to debug, performance suffers?)\\nKeep *.py and *.pyc, eliminate *.pyo (Does optimization really buy anything?)\\nKeep *.pyc, eliminate *.pyo and *.py (Will this work?)\\nKeep *.py, *.pyc, and *.pyo (All are needed?)\\n\\n\",\n  'completion': \"http://www.network-theory.co.uk/docs/pytut/CompiledPythonfiles.html\\n\\n\\n  When the Python interpreter is invoked with the -O flag, optimized code is generated and stored in â\\x80\\x98.pyoâ\\x80\\x99 files. The optimizer currently doesn't help much; it only removes assert statements.\\n  \\n  Passing two -O flags to the Python interpreter (-OO) will cause the bytecode compiler to perform optimizations that could in some rare cases result in malfunctioning programs. Currently only doc strings are removed from the bytecode, resulting in more compact â\\x80\\x98.pyoâ\\x80\\x99 files.\\n\\n\\nMy suggestion to you? \\n\\nUse -OO to compile only .pyo files if you don't need assert statements and __doc__ strings.\\n\\nOtherwise, go with .pyc only.\\n\\nEdit\\n\\nI noticed that you only mentioned the Python library. Much of the python library can be removed if you only need part of the functionality. \\n\\nI also suggest that you take a look at tinypy which is large subset of Python in about 64kb.\\n\"},\n {'prompt': \"How can I open __init__.pyc here?\\n\\n    >>> import stompservice\\n    <module 'stompservice' from 'C:\\\\Python25\\\\lib\\\\site-packages\\\\stompservice-0.1.0-py2.5.egg\\\\stompservice\\\\__init__.pyc'>\\n\\n\\nAll I see in C:\\\\Python25\\\\lib\\\\site-packages\\\\ is the .egg file, but where are the internal files of the package?\\n\",\n  'completion': 'http://peak.telecommunity.com/DevCenter/PythonEggs\\n\\n.egg files are simply renamed zip files.\\n\\nOpen the egg with your zip program, or just rename the extension to .zip, and extract.\\n'},\n {'prompt': 'I have a similar model\\n\\nClass Student(models.Model):\\n\"\"\"A simple class which holds the basic info\\nof a student.\"\"\"\\n\\nname = models.CharField(max_length=50)\\nage = models.PositiveIntegerField()\\nphoto = models.ImageField(upload_to=\\'foobar\\', blank=True, null=True)\\n\\n\\nAs we can see photo field is optional. I wanted all the students who have their images saved in the college DB. For that i did this\\n\\n>>> Student.objects.exclude(photo__name=None)\\n\\n\\nBut i am getting this error :\\n\\nFieldError: Join on field \\'photo\\' not permitted.\\n\\n\\nSo, How can i extract all those students having their photos?\\n\\nAny sort of help regarding this would be appreciated.\\nThanks in advance.\\n',\n  'completion': \"It doesn't work because field lookups only work on other models. Here, name is an attribute on the return value of your photo field.\\n\\nTry this instead:\\n\\nStudent.objects.exclude(photo__isnull=True)\\n\\n\\nIt is preferred to use isnull instead of comparing equality to None.\\n\\nEDIT:\\n\\nJeff Ober's suggestion:\\n\\nStudent.objects.exclude(photo='')\\n\\n\\nHe says filtering is performed on the actual values stored in DB. In a file field's case the path to the file.\\n\"},\n {'prompt': \"How can I access Microsoft Access databases in Python? With SQL?\\n\\nI'd prefere a solution that works with Linux, but I could also settle for Windows.\\n\\nI only require read access.\\n\",\n  'completion': 'On Linux, MDBTools is your only chance as of now. [disputed]\\n\\nOn Windows, you can deal with mdb files with pypyodbc.\\n\\nTo create an Access mdb file:\\n\\nimport pypyodbc\\npypyodbc.win_create_mdb( \"D:\\\\\\\\Your_MDB_file_path.mdb\" )\\n\\n\\nHere is an Hello World script that fully demostate pypyodbc\\'s Access support functions.\\n\\nDisclaimer: I\\'m the developer of pypyodbc.\\n'},\n {'prompt': 'What is the best way to find out the user that a python process is running under?\\n\\nI could do this:\\n\\nname = os.popen(\\'whoami\\').read() \\n\\n\\nBut that has to start a whole new process.\\n\\nos.environ[\"USER\"]\\n\\n\\nworks sometimes, but sometimes that environment variable isn\\'t set.\\n',\n  'completion': 'import getpass\\nprint getpass.getuser()\\n\\n\\nSee the documentation of the getpass module.\\n\\n\\n  getpass.getuser()\\n  \\n  Return the â\\x80\\x9clogin nameâ\\x80\\x9d of the user. Availability: Unix, Windows.\\n  \\n  This function checks the environment variables LOGNAME, USER,\\n  LNAME and USERNAME, in order, and\\n  returns the value of the first one\\n  which is set to a non-empty string. If\\n  none are set, the login name from the\\n  password database is returned on\\n  systems which support the pwd module,\\n  otherwise, an exception is raised.\\n\\n'},\n {'prompt': \"I've got a python list of dictionaries:\\n\\nmylist = [\\n{'id':0, 'weight':10, 'factor':1, 'meta':'ABC'},\\n{'id':1, 'weight':5, 'factor':1, 'meta':'ABC'},\\n{'id':2, 'weight':5, 'factor':2, 'meta':'ABC'},\\n{'id':3, 'weight':1, 'factor':1, 'meta':'ABC'}\\n]\\n\\n\\nWhats the most efficient/cleanest way to order that list by weight then factor (numericaly). The resulting list should look like:\\n\\nmylist = [\\n{'id':3, 'weight':1, 'factor':1, 'meta':'ABC'},\\n{'id':1, 'weight':5, 'factor':1, 'meta':'ABC'},\\n{'id':2, 'weight':5, 'factor':2, 'meta':'ABC'},\\n{'id':0, 'weight':10, 'factor':1, 'meta':'ABC'},\\n]\\n\\n\",\n  'completion': \"mylist.sort(key=lambda d: (d['weight'], d['factor']))\\n\\n\\nor\\n\\nimport operator\\nmylist.sort(key=operator.itemgetter('weight', 'factor'))\\n\\n\"},\n {'prompt': \"I'm trying to get the elements in an HTML doc that contain the following pattern of text: #\\\\S{11}\\n\\n<h2> this is cool #12345678901 </h2>\\n\\n\\nSo, the previous would match by using:\\n\\nsoup('h2',text=re.compile(r' #\\\\S{11}'))\\n\\n\\nAnd the results would be something like:\\n\\n[u'blahblah #223409823523', u'thisisinteresting #293845023984']\\n\\n\\nI'm able to get all the text that matches (see line above). But I want the parent element of the text to match, so I can use that as a starting point for traversing the document tree. In this case, I'd want all the h2 elements to return, not the text matches.\\n\\nIdeas?\\n\",\n  'completion': 'from BeautifulSoup import BeautifulSoup\\nimport re\\n\\nhtml_text = \"\"\"\\n<h2>this is cool #12345678901</h2>\\n<h2>this is nothing</h2>\\n<h1>foo #126666678901</h1>\\n<h2>this is interesting #126666678901</h2>\\n<h2>this is blah #124445678901</h2>\\n\"\"\"\\n\\nsoup = BeautifulSoup(html_text)\\n\\n\\nfor elem in soup(text=re.compile(r\\' #\\\\S{11}\\')):\\n    print elem.parent\\n\\n\\nPrints:\\n\\n<h2>this is cool #12345678901</h2>\\n<h2>this is interesting #126666678901</h2>\\n<h2>this is blah #124445678901</h2>\\n\\n'},\n {'prompt': \"I'm writing a web app using Python and the web.py framework, and I need to use memcached throughout.\\n\\nI've been searching the internet trying to find some good documentation on the python-memcached module, but all I could find was this example on the MySQL website, and the documentation on its methods isn't great.\\n\",\n  'completion': 'It\\'s fairly simple. You write values using keys and expiry times. You get values using keys. You can expire keys from the system.\\n\\nMost clients follow the same rules. You can read the generic instructions and best practices on the memcached homepage.\\n\\nIf you really want to dig into it, I\\'d look at the source. Here\\'s the header comment:\\n\\n\"\"\"\\nclient module for memcached (memory cache daemon)\\n\\nOverview\\n========\\n\\nSee U{the MemCached homepage<http://www.danga.com/memcached>} for more about memcached.\\n\\nUsage summary\\n=============\\n\\nThis should give you a feel for how this module operates::\\n\\n    import memcache\\n    mc = memcache.Client([\\'127.0.0.1:11211\\'], debug=0)\\n\\n    mc.set(\"some_key\", \"Some value\")\\n    value = mc.get(\"some_key\")\\n\\n    mc.set(\"another_key\", 3)\\n    mc.delete(\"another_key\")\\n\\n    mc.set(\"key\", \"1\")   # note that the key used for incr/decr must be a string.\\n    mc.incr(\"key\")\\n    mc.decr(\"key\")\\n\\nThe standard way to use memcache with a database is like this::\\n\\n    key = derive_key(obj)\\n    obj = mc.get(key)\\n    if not obj:\\n        obj = backend_api.get(...)\\n        mc.set(key, obj)\\n\\n    # we now have obj, and future passes through this code\\n    # will use the object from the cache.\\n\\nDetailed Documentation\\n======================\\n\\nMore detailed documentation is available in the L{Client} class.\\n\"\"\"\\n\\n'},\n {'prompt': 'Imagine a string, like \\'Agh#$%#%2341-   -!zdrkfd\\' and I only wish to perform some operating on it such that only the lowercase letters are returned (as an example), which in this case would bring \\'ghzdrkfd\\'.\\n\\nHow do you do this in Python?  The obvious way would be to create a list, of characters, \\'a\\' through \\'z\\', then iterate over the characters in my string and build a new string, character by character, of those in my list only.  This seems primitive.\\n\\nI was wondering if regular expressions are appropriate.  Replacing unwanted characters seems problematic and I tend to prefer whitelisting over blacklisting.  The .match function does not seem appropriate.  I have looked over the appropriate page on the Python site, but have not found a method which seems to fit.\\n\\nIf regular expressions are not appropriate and the correct approach is looping, is there a simple function which \"explodes\" a string into a list?  Or am I just hitting another for loop there?\\n',\n  'completion': 'If you are looking for efficiency. Using the translate function is the fastest you can get.\\n\\nIt can be used to quickly replace characters and/or delete them.\\n\\nimport string\\ndelete_table  = string.maketrans(\\n    string.ascii_lowercase, \\' \\' * len(string.ascii_lowercase)\\n)\\ntable = string.maketrans(\\'\\', \\'\\')\\n\\n\"Agh#$%#%2341- -!zdrkfd\".translate(table, delete_table)\\n\\n\\nIn python 2.6: you don\\'t need the second table anymore\\n\\nimport string\\ndelete_table  = string.maketrans(\\n    string.ascii_lowercase, \\' \\' * len(string.ascii_lowercase)\\n)\\n\"Agh#$%#%2341- -!zdrkfd\".translate(None, delete_table)\\n\\n\\nThis is method is way faster than any other. Of course you need to store the delete_table somewhere and use it. But even if you don\\'t store it and build it every time, it is still going to be faster than other suggested methods so far.\\n\\nTo confirm my claims here are the results:\\n\\nfor i in xrange(10000):\\n    \\'\\'.join(c for c in s if c.islower())\\n\\nreal    0m0.189s\\nuser    0m0.176s\\nsys 0m0.012s\\n\\n\\nWhile running the regular expression solution:\\n\\nfor i in xrange(10000):\\n    re.sub(r\\'[^a-z]\\', \\'\\', s)\\n\\nreal    0m0.172s\\nuser    0m0.164s\\nsys 0m0.004s\\n\\n\\n[Upon request] If you pre-compile the regular expression:\\n\\nr = re.compile(r\\'[^a-z]\\')\\nfor i in xrange(10000):\\n    r.sub(\\'\\', s)\\n\\nreal    0m0.166s\\nuser    0m0.144s\\nsys 0m0.008s\\n\\n\\nRunning the translate method the same number of times took:\\n\\nreal    0m0.075s\\nuser    0m0.064s\\nsys 0m0.012s\\n\\n'},\n {'prompt': 'I have a file containing roughly all the words in English (~60k words, ~500k characters). I want to test whether a certain word I receive as input is \"in English\" (i.e. if this exact word is in the list).\\n\\nWhat would be the most efficient way to do this in Python?\\n\\nThe trivial solution is to load the file into a list and check whether the word is in that list. The list can be sorted, which I believe will shrink the complexity to O(logn). However I\\'m not sure about how Python implements searching through lists, and whether there\\'s a performance penalty if such a large list is in memory. Can I \"abuse\" the fact I can put a cap on the length of words? (e.g. say the longest one is 15 characters long).\\n\\nPlease note I run the application on a machine with lots of memory, so I care less for memory consumption than for speed and CPU utilization.\\n\\nThanks\\n',\n  'completion': 'The python Set is what you should try.\\n\\n\\n  A set object is an unordered collection of distinct hashable objects. Common uses include membership testing, removing duplicates from a sequence, and computing mathematical operations such as intersection, union, difference, and symmetric difference. \\n\\n'},\n {'prompt': 'Are there regular expression equivalents for searching and modifying tree structures? Concise mini-languages (like perl regex) are what I am looking for.\\n\\nHere is an example that might clarify what I am looking for.\\n\\n<root>\\n  <node name=\"1\">\\n    subtrees ....\\n  </node>\\n  <node name=\"2\">\\n    <node name=\"2.1\">\\n     data\\n    </node>\\n    other subtrees...\\n  </node>\\n</root>\\n\\n\\nAn operation that would be possible on the above tree is \"move subtree at node 2.1 into\\nthe subtree at node 1.\" The result of the operation might look something like..\\n\\n<root>\\n  <node name=\"1\">\\n    subtrees ....\\n    <node name=\"2.1\">\\n     data\\n    </node>\\n  </node>\\n  <node name=\"2\">\\n    other subtrees...\\n  </node>\\n</root>\\n\\n\\nSearch and replace operations like find all nodes with atleast 2 children, find all nodes whose data starts with \"a\" and replace it with \"b\" if the subtrees have atleast 2 other siblings, etc. should be supported. \\n\\nFor strings, where the only dimension is across the length of the string, we can do many of above operations (or their 1D equivalents) using regular expressions. I wonder if there are equivalents for trees. (instead of a single regex, you might need to write a set of transformation rules, but that is ok).\\n\\nI would like to know if there is some simple mini language (not regex per.se, but something that is as accessible as regex via libraries, etc..). to perform these operations? Preferably, as a python library.\\n',\n  'completion': 'TSurgeon and Tregex from Stanford is capable of doing that. You can download the library from http://nlp.stanford.edu/software/tregex.shtml\\n'},\n {'prompt': 'With python properties, I can make it such that \\n\\nobj.y \\n\\n\\ncalls a function rather than just returning a value.\\n\\nIs there a way to do this with modules? I have a case where I want\\n\\nmodule.y \\n\\n\\nto call a function, rather than just returning the value stored there.\\n',\n  'completion': 'Only instances of new-style classes can have properties.  You can make Python believe such an instance is a module by stashing it in sys.modules[thename] = theinstance.  So, for example, your m.py module file could be:\\n\\nimport sys\\nclass _M(object):\\n  def __init__(self):\\n    self.c = 0\\n  def afunction(self):\\n    self.c += 1\\n    return self.c\\n  y = property(afunction)\\nsys.modules[__name__] = _M()\\n\\n\\nEdited: removed an implicit dependency on globals (had nothing to do with the point of the example but did confuse things by making the original code fail!).\\n'},\n {'prompt': 'Brand new to web design, using python.  Got Apache up and running, test python script working in cgi-bin directory.  Get valid results when I type in the URL explicitly:  \".../cgi-bin/showenv.py\"\\n\\nBut I don\\'t want the URL to look that way.  Here at stackoverflow, for example, the URLs that display in my address bar never have the messy details showing the script that was used to run them.  They\\'re clean of cgi-bin, .py, etc. extensions.  How do I do that?\\n\\nEDIT: Thanks for responses, every single one helpful, lots to learn.  I\\'m going with URL Rewriting for now; example in the docs looks extremely close to what I actually want to do.  But I\\'m committed to python, so will have to look at WSGI down the road.\\n',\n  'completion': \"The python way of writing web applications is not cgi-bin. It is by using WSGI.\\n\\nWSGI is a standard interface between web servers and Python web applications or frameworks. The PEP 0333 defines it.\\n\\nThere are no disadvantages in using it instead of CGI. And you'll gain a lot. Beautiful URLs is just one of the neat things you can do easily.\\n\\nAlso, writing a WSGI application means you can deploy on any web server that supports the WSGI interface. Apache does so by using mod_wsgi.\\n\\nYou can configure it in apache like that:\\n\\nWSGIScriptAlias /myapp /usr/local/www/wsgi-scripts/myapp.py\\n\\n\\nThen all requests on http://myserver.domain/myapp will go to myapp.py's application callable, including http://myserver.domain/myapp/something/here. \\n\\nexample myapp.py:\\n\\ndef application(environ, start_response):\\n    start_response('200 OK', [('Content-type', 'text/plain')])\\n    return ['Hello World!']\\n\\n\"},\n {'prompt': 'I am trying to run a simple multiple processes application in Python. The main thread spawns 1 to N processes and waits until they all done processing. The processes each run an infinite loop, so they can potentially run forever without some user interruption, so I put in some code to handle a KeyboardInterrupt:\\n\\n#!/usr/bin/env python\\nimport sys\\nimport time\\nfrom multiprocessing import Process\\n\\ndef main():\\n    # Set up inputs..\\n\\n    # Spawn processes\\n    Proc( 1).start()\\n    Proc( 2).start()\\n\\nclass Proc ( Process ):\\n    def __init__ ( self, procNum):\\n        self.id = procNum\\n        Process.__init__(self)\\n\\n    def run ( self ):\\n        doneWork = False\\n\\n        while True:\\n\\n            try:\\n                # Do work...\\n                time.sleep(1)\\n                sys.stdout.write(\\'.\\')\\n\\n                if doneWork:\\n                    print \"PROC#\" + str(self.id) + \" Done.\"\\n                    break\\n\\n            except KeyboardInterrupt:\\n                print \"User aborted.\"\\n                sys.exit()\\n\\n# Main Entry\\nif __name__==\"__main__\":\\n    main()\\n\\n\\nThe problem is that when using CTRL-C to exit, I get an additional error even though the processes seem to exit immediately:\\n\\n......User aborted.\\nError in atexit._run_exitfuncs:\\nTraceback (most recent call last):\\n  File \"C:\\\\Python26\\\\lib\\\\atexit.py\", line 24, in _run_exitfuncs\\n    func(*targs, **kargs)\\n  File \"C:\\\\Python26\\\\lib\\\\multiprocessing\\\\util.py\", line 281, in _exit_function\\n    p.join()\\n  File \"C:\\\\Python26\\\\lib\\\\multiprocessing\\\\process.py\", line 119, in join\\n    res = self._popen.wait(timeout)\\n  File \"C:\\\\Python26\\\\lib\\\\multiprocessing\\\\forking.py\", line 259, in wait\\n    res = _subprocess.WaitForSingleObject(int(self._handle), msecs)\\nKeyboardInterrupt\\nError in sys.exitfunc:\\nTraceback (most recent call last):\\n  File \"C:\\\\Python26\\\\lib\\\\atexit.py\", line 24, in _run_exitfuncs\\n    func(*targs, **kargs)\\n  File \"C:\\\\Python26\\\\lib\\\\multiprocessing\\\\util.py\", line 281, in _exit_function\\n    p.join()\\n  File \"C:\\\\Python26\\\\lib\\\\multiprocessing\\\\process.py\", line 119, in join\\n    res = self._popen.wait(timeout)\\n  File \"C:\\\\Python26\\\\lib\\\\multiprocessing\\\\forking.py\", line 259, in wait\\n    res = _subprocess.WaitForSingleObject(int(self._handle), msecs)\\nKeyboardInterrupt\\n\\n\\nI am running Python 2.6 on Windows. If there is a better way to handle multiprocessing in Python, please let me know.\\n',\n  'completion': \"Rather then just forcing sys.exit(), you want to send a signal to your threads to tell them to stop.  Look into using signal handlers and threads in Python.\\n\\nYou could potentially do this by changing your while True: loop to be while keep_processing:  where keep_processing is some sort of global variable that gets set on the KeyboardInterrupt exception.  I don't think this is a good practice though.\\n\"},\n {'prompt': 'I have a Python script that I want to use as a controller to another Python script. I have a server with 64 processors, so want to spawn up to 64 child processes of this second Python script. The child script is called:\\n\\n$ python create_graphs.py --name=NAME\\n\\n\\nwhere NAME is something like XYZ, ABC, NYU etc.\\n\\nIn my parent controller script I retrieve the name variable from a list:\\n\\nmy_list = [ \\'XYZ\\', \\'ABC\\', \\'NYU\\' ]\\n\\n\\nSo my question is, what is the best way to spawn off these processes as children? I want to limit the number of children to 64 at a time, so need to track the status (if the child process has finished or not) so I can efficiently keep the whole generation running.\\n\\nI looked into using the subprocess package, but rejected it because it only spawns one child at a time. I finally found the multiprocessor package, but I admit to being overwhelmed by the whole threads vs. subprocesses documentation.\\n\\nRight now, my script uses subprocess.call to only spawn one child at a time and looks like this:\\n\\n#!/path/to/python\\nimport subprocess, multiprocessing, Queue\\nfrom multiprocessing import Process\\n\\nmy_list = [ \\'XYZ\\', \\'ABC\\', \\'NYU\\' ]\\n\\nif __name__ == \\'__main__\\':\\n    processors = multiprocessing.cpu_count()\\n\\n    for i in range(len(my_list)):\\n        if( i < processors ):\\n             cmd = [\"python\", \"/path/to/create_graphs.py\", \"--name=\"+ my_list[i]]\\n             child = subprocess.call( cmd, shell=False )\\n\\n\\nI really want it to spawn up 64 children at a time. In other stackoverflow questions I saw people using Queue, but it seems like that creates a performance hit?\\n',\n  'completion': \"What you are looking for is the process pool class in multiprocessing.\\n\\nimport multiprocessing\\nimport subprocess\\n\\ndef work(cmd):\\n    return subprocess.call(cmd, shell=False)\\n\\nif __name__ == '__main__':\\n    count = multiprocessing.cpu_count()\\n    pool = multiprocessing.Pool(processes=count)\\n    print pool.map(work, ['ls'] * count)\\n\\n\\nAnd here is a calculation example to make it easier to understand. The following will divide 10000 tasks on N processes where N is the cpu count. Note that I'm passing None as the number of processes. This will cause the Pool class to use cpu_count for the number of processes (reference)\\n\\nimport multiprocessing\\nimport subprocess\\n\\ndef calculate(value):\\n    return value * 10\\n\\nif __name__ == '__main__':\\n    pool = multiprocessing.Pool(None)\\n    tasks = range(10000)\\n    results = []\\n    r = pool.map_async(calculate, tasks, callback=results.append)\\n    r.wait() # Wait on the results\\n    print results\\n\\n\"},\n {'prompt': 'Why python compile the source to bytecode before interpreting?\\n\\nWhy not interpret from the source directly?\\n',\n  'completion': \"Nearly no interpreter really interprets code directly, line by line â\\x80\\x93 it's simply too inefficient. Almost all interpreters use some intermediate representation which can be executed easily. Also, small optimizations can be performed on this intermediate code.\\n\\nPython furthermore stores this code which has a huge advantage for the next time this code gets executed: Python doesn't have to parse the code anymore; parsing is the slowest part in the compile process. Thus, a bytecode representation reduces execution overhead quite substantially.\\n\"},\n {'prompt': 'I\\'m programming in python on windows and would like to accurately measure the time it takes for a function to run.  I have written a function \"time_it\" that takes another function, runs it, and returns the time it took to run.\\n\\ndef time_it(f, *args):\\n    start = time.clock()\\n    f(*args)\\n    return (time.clock() - start)*1000\\n\\n\\ni call this 1000 times and average the result.  (the 1000 constant at the end is to give the answer in milliseconds.)\\n\\nThis function seems to work but i have this nagging feeling that I\\'m doing something wrong, and that by doing it this way I\\'m using more time than the function actually uses when its running.\\n\\nIs there a more standard or accepted way to do this?\\n\\nWhen i changed my test function to call a print so that it takes longer, my time_it function returns an average of 2.5 ms while the cProfile.run(\\'f()\\') returns and average of 7.0 ms.  I figured my function would overestimate the time if anything, what is going on here?\\n\\nOne additional note, it is the relative time of functions compared to each other that i care about, not the absolute time as this will obviously vary depending on hardware and other factors.\\n',\n  'completion': 'Use the timeit module from the Python standard library.\\n\\nBasic usage:\\n\\nfrom timeit import Timer\\n\\n# first argument is the code to be run, the second \"setup\" argument is only run once,\\n# and it not included in the execution time.\\nt = Timer(\"\"\"x.index(123)\"\"\", setup=\"\"\"x = range(1000)\"\"\")\\n\\nprint t.timeit() # prints float, for example 5.8254\\n# ..or..\\nprint t.timeit(1000) # repeat 1000 times instead of the default 1million\\n\\n'},\n {'prompt': 'I\\'m working on code to parse a configuration file written in XML, where the XML tags are mixed case and the case is significant.  Beautiful Soup appears to convert XML tags to lowercase by default, and I would like to change this behavior.\\n\\nI\\'m not the first to ask a question on this subject [see here].  However, I did not understand the answer given to that question and in BeautifulSoup-3.1.0.1 BeautifulSoup.py does not appear to contain any instances of \"encodedName\" or \"Tag.__str__\"\\n',\n  'completion': 'import html5lib\\nfrom html5lib import treebuilders\\n\\nf = open(\"mydocument.html\")\\nparser = html5lib.XMLParser(tree=treebuilders.getTreeBuilder(\"beautifulsoup\"))\\ndocument = parser.parse(f)\\n\\n\\n\\'document\\' is now a BeautifulSoup-like tree, but retains the cases of tags. See html5lib for documentation and installation.\\n'},\n {'prompt': \"I have been doing some work in python, but that was all for stand alone applications. I'm curious to know whether any offshoot of python supports web development?\\n\\nWould some one also suggest a good tutorial or a website from where I can pick up some of the basics of web development using python?\\n\",\n  'completion': \"Now that everyone has said Django, I can add my two cents: I would argue that you might learn more by looking at the different components first, before using Django. For web development with Python, you often want 3 components:\\n\\n\\nSomething that takes care\\nof the HTTP stuff (e.g.\\nCherryPy)\\nA templating language\\nto create your web pages.\\nMako\\nis very pythonic and works with Cherrpy.\\nIf you get your data from a\\ndatabase, an ORM comes in handy.\\nSQLAlchemy\\nwould be an example.\\n\\n\\nAll the links above have good tutorials. For many real-world use-cases, Django will be a better solution than such a stack as it seamlessly integrates this functionality (and more). And if you need a CMS, Django is your best bet short of Zope. Nevertheless, to get a good grasp of what's going on, a stack of loosely coupled programs might be better. Django hides a lot of the details.\\n\"},\n {'prompt': 'I\\'ve tried all manner of Python modules and they either escape too much or in the wrong way.\\nWhat\\'s the best way you\\'ve found to escape quotes (\", \\') in Python?\\n',\n  'completion': \"If it's part of a Database query you should be able to use a Parameterized SQL Statement.\\n\\nAs well as escaping your quotes, this will deal with all special characters and will protect you from SQL injection attacks.\\n\"},\n {'prompt': 'Does python provide an elegant way to check for \"equality\" of sequences of different types? The following work, but they seem rather ugly and verbose for python code:\\n\\ndef comp1(a, b):\\n    if len(a) != len(b):\\n        return False\\n    for i, v in enumerate(a):\\n        if v != b[i]:\\n            return False\\n    return True\\n\\n\\nThe following is a bit shorter, but also less efficient since a third sequence is created:\\n\\ndef comp2(a, b):\\n    for l, r in map(None, a, b):\\n        if l != r:\\n            return False\\n    return True\\n\\n\\nShoehorning one of those examples into a list comprehension isn\\'t really what I\\'m looking for either.\\n\\nEdit: Ideally I am looking for a solution that doesn\\'t create another sequence during the comparison.\\n',\n  'completion': 'Convert both sequences to lists, and use builtin list comparison. It should be sufficient, unless your sequences are really large.\\n\\nlist(a) == list(b)\\n\\n\\nEdit:\\n\\nTesting done by schickb shows that using tuples is slightly faster:\\n\\ntuple(a) == tuple(b)\\n\\n'},\n {'prompt': 'I have 20+ tables similar to table 1. Where all letters represent actual values.\\n\\nTable 1:\\n$ / cars |<1 | 2 | 3 | 4+\\n<10,000  | a | b | c | d\\n20,000   | e | f | g | h\\n30,000   | i | j | k | l\\n40,000+  | m | n | o | p\\n\\n\\nA user input could be for example, (2.4, 24594) which is a value between f, g, j, and k.\\nMy Python function definition and pseudo-code to calculate this bilinear interpolation is as follows.\\n\\ndef bilinear_interpolation( x_in, y_in, x_high, x_low, y_low, y_high ):\\n   # interpolate with respect to x\\n   # interpolate with respect to y\\n   # return result\\n\\n\\nHow should I store the data from table 1 (a file, a dict, tuple of tuples, or dict of lists), so I can perform the bilinear interpolation most efficiently and correctly? \\n',\n  'completion': \"If you want the most computationally efficient solution I can think of and are not restricted to the standard library, then I would recommend scipy/numpy.  First, store the a..p array as a 2D numpy array and then both the $4k-10k and 1-4 arrays as 1D numpy arrays.  Use scipy's interpolate.interp1d if both 1D arrays are monotonically increasing, or interpolate.bsplrep (bivariate spline representation) if not and your example arrays are as small as your example.  Or simply write your own and not bother with scipy.  Here are some examples:\\n\\n# this follows your pseudocode most closely, but it is *not*\\n# the most efficient since it creates the interpolation \\n# functions on each call to bilinterp\\nfrom scipy import interpolate\\nimport numpy\\ndata = numpy.arange(0., 16.).reshape((4,4))  #2D array\\nprices = numpy.arange(10000., 50000., 10000.)\\ncars = numpy.arange(1., 5.)\\ndef bilinterp(price,car):\\n    return interpolate.interp1d(cars, interpolate.interp1d(prices, a)(price))(car)\\nprint bilinterp(22000,2)\\n\\n\\nThe last time I checked (a version of scipy from 2007-ish) it only worked for monotonically increasing arrays of x and y)\\n\\nfor small arrays like this 4x4 array, I think you want to use this:\\nhttp://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.bisplrep.html#scipy.interpolate.bisplrep\\nwhich will handle more interestingly shaped surfaces and the function only needs to be created once.  For larger arrays, I think you want this (not sure if this has the same restrictions as interp1d):\\nhttp://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp2d.html#scipy.interpolate.interp2d\\nbut they both require a different and more verbose data structure than the three arrays in the example above.\\n\"},\n {'prompt': \"if hasattr(obj, 'attribute'):\\n    # do somthing\\n\\n\\nvs\\n\\ntry:\\n    # access obj.attribute\\nexcept AttributeError, e:\\n    # deal with AttributeError\\n\\n\\nWhich should be preferred and why?\\n\",\n  'completion': 'Any benches that illustrate difference in performance?\\n\\ntimeit it\\'s your friend\\n\\n$ python -mtimeit -s \\'class C(object): a = 4\\nc = C()\\' \\'hasattr(c, \"nonexistent\")\\'\\n1000000 loops, best of 3: 1.87 usec per loop\\n$ python -mtimeit -s \\'class C(object): a = 4\\nc = C()\\' \\'hasattr(c, \"a\")\\'\\n1000000 loops, best of 3: 0.446 usec per loop\\n$ python -mtimeit -s \\'class C(object): a = 4\\nc = C()\\' \\'try:\\n c.a\\nexcept:\\n pass\\'\\n1000000 loops, best of 3: 0.247 usec per loop\\n$ python -mtimeit -s \\'class C(object): a = 4\\nc = C()\\' \\'try:\\n c.nonexistent\\nexcept:\\n pass\\'\\n100000 loops, best of 3: 3.13 usec per loop\\n$\\n\\n       |positive|negative\\nhasattr|  0.446 |  1.87 \\ntry    |  0.247 |  3.13\\n\\n'},\n {'prompt': \"I updated my python interpreter, but I think the old one is still called. When I check for the version I get:\\n\\n$ python -V\\nPython 3.0.1\\n\\n\\nBut I believe the old interpreter is still being called. When I run the command:\\n\\npython myProg.py\\n\\n\\nThe script runs properly. But when I invoke it with the command\\n\\n./myProg.py\\n\\n\\nI get the error message:\\n\\nAttributeError: 'str' object has no attribute 'format'\\n\\n\\nWhich apparently is due to the old interpreter being called. How can I fix this? I run Mac OS X 10.5. Has it something to do with the first line:\\n\\n#!/usr/bin/python\\n\\n\\nI just started out with python and am not very familiar with interpreted languages, so I am not too sure what is going on.\\n\\nEdit: Wow, that was quick. Thanks a lot!\\n\",\n  'completion': 'According to the first line of the script, #!/usr/bin/python, you are calling the Python interpreter at /usr/bin/python (which is most likely the one that ships with Mac OS X). You have to change that path to the path where you installed your Python 3 interpreter (likely /usr/local/bin/python or /opt/local/bin/python); or you can just change that line to read #!/usr/bin/env python, which will call the python listed first in your PATH variable (which seems to be the newer version you installed).\\n'},\n {'prompt': \"I'm trying to learn a little about python scripting in GVim, but I'm having trouble with starting. Elementary things, really.\\n\\nAre there any resources / tutorials concerting python scripting in Vim out there ? Simple examples which show the basic principles, would be welcomed also.\\n\",\n  'completion': 'Here is all I know of in terms of such docs:\\n\\n\\nA nice presentation by Sean Reifschneider\\nThe \"official\" VIM Python Interface reference\\nsome shorter notes\\nExtending Vim With Python\\n\\n'},\n {'prompt': \"I don't think this has been asked before-I have a folder that has lots of different .py files.  The script I've made only uses some-but some call others & I don't know all the ones being used.  Is there a program that will get everything needed to make that script run into one folder?\\n\\nCheers!\\n\",\n  'completion': \"# zipmod.py - make a zip archive consisting of Python modules and their dependencies as reported by modulefinder\\n# To use: cd to the directory containing your Python module tree and type\\n# $ python zipmod.py archive.zip mod1.py mod2.py ...\\n# Only modules in the current working directory and its subdirectories will be included.\\n# Written and tested on Mac OS X, but it should work on other platforms with minimal modifications.\\n\\nimport modulefinder\\nimport os\\nimport sys\\nimport zipfile\\n\\ndef main(output, *mnames):\\n    mf = modulefinder.ModuleFinder()\\n    for mname in mnames:\\n        mf.run_script(mname)\\n    cwd = os.getcwd()\\n    zf = zipfile.ZipFile(output, 'w')\\n    for mod in mf.modules.itervalues():\\n        if not mod.__file__:\\n            continue\\n        modfile = os.path.abspath(mod.__file__)\\n        if os.path.commonprefix([cwd, modfile]) == cwd:\\n            zf.write(modfile, os.path.relpath(modfile))\\n    zf.close()\\n\\nif __name__ == '__main__':\\n    main(*sys.argv[1:])\\n\\n\"},\n {'prompt': \"Modifying Abstract Syntax Trees\\n\\nI would like to be able to build and modify an ast and then optionally write it out as python byte code for execution later without overhead.\\n\\nI have been hacking around with the ast docs for python3.0 and python2.6, but I can't seem to find any good sources on best practices for this type of code.\\n\\nQuestion\\n\\nWhat are some best practices and guidelines for modifying abstract syntax trees in python?\\n\\n[edit]\\n\\nUnknown states that byteplay is a good example of such a library.\\n\\nAlso, benford cites GeniuSQL which uses abstract syntax trees to transform python code to SQL.\\n\",\n  'completion': \"Other than the manual and the source code, you are on your own. This subject and python bytecode are very undocumented.\\n\\nAlternatively you could try using this python bytecode library which I have heard good thing about but haven't tried it yet:\\n\\nhttp://code.google.com/p/byteplay/\\n\"},\n {'prompt': 'Is there a simple way to run a Python script on Windows/Linux/OS X?\\n\\nOn the latter two, subprocess.Popen(\"/the/script.py\") works, but on Windows I get the following error:\\n\\nTraceback (most recent call last):\\n  File \"test_functional.py\", line 91, in test_functional\\n    log = tvnamerifiy(tmp)\\n  File \"test_functional.py\", line 49, in tvnamerifiy\\n    stdout = PIPE\\n  File \"C:\\\\Python26\\\\lib\\\\subprocess.py\", line 595, in __init__\\n    errread, errwrite)\\n  File \"C:\\\\Python26\\\\lib\\\\subprocess.py\", line 804, in _execute_child\\n    startupinfo)\\nWindowsError: [Error 193] %1 is not a valid Win32 application\\n\\n\\n\\n\\n\\n  monkut\\'s comment: The use case isn\\'t clear. Why use subprocess to run a python script? Is there something preventing you from importing the script and calling the necessary function?\\n\\n\\nI was writing a quick script to test the overall functionality of a Python-command-line tool (to test it on various platforms). Basically it had to create a bunch of files in a temp folder, run the script on this and check the files were renamed correctly.\\n\\nI could have imported the script and called the function, but since it relies on sys.argv and uses sys.exit(), I would have needed to do something like..\\n\\nimport sys\\nimport tvnamer\\nsys.argv.append(\"-b\", \"/the/folder\")\\ntry:\\n    tvnamer.main()\\nexcept BaseException, errormsg:\\n    print type(errormsg)\\n\\n\\nAlso, I wanted to capture the stdout and stderr for debugging incase something went wrong.\\n\\nOf course a better way would be to write the script in more unit-testable way, but the script is basically \"done\" and I\\'m doing a final batch of testing before doing a \"1.0\" release (after which I\\'m going to do a rewrite/restructure, which will be far tidier and more testable)\\n\\nBasically, it was much easier to simply run the script as a process, after finding the sys.executable variable. I would have written it as a shell-script, but that wouldn\\'t have been cross-platform. The final script can be found here\\n',\n  'completion': 'Just found sys.executable - the full path to the current Python executable, which can be used to run the script (instead of relying on the shbang, which obviously doesn\\'t work on Windows)\\n\\nimport sys\\nimport subprocess\\n\\ntheproc = subprocess.Popen([sys.executable, \"myscript.py\"])\\ntheproc.communicate()\\n\\n'},\n {'prompt': \"I'm learning Django by building a simple recipes app. I have a 1 table model using the 'choices' field option for recipe categories rather than using a 2nd 'categories' table and a foreign key relationship. So i created db table via syncdb and then loaded table with test data. When i go to admin and click on the 'Recipes' link in an attempt to view recipes i get the following error:\\n\\nTemplate error\\n\\nIn template /var/lib/python-support/python2.6/django/contrib/admin/templates/admin/change_list.html, error at line 34\\nCaught an exception while rendering: too many values to unpack\\n\\n\\nIf anyone can shed light on this cryptic error that would be great. Db is Sqlite. Django version is 1.0. The model is listed below:\\n\\nfrom django.db import models\\n\\nclass Recipe(models.Model):\\n    CATEGORY_CHOICES = (\\n        (1, u'Appetizer'),\\n        (2, u'Bread'),\\n        (3, u'Dessert'),\\n        (4, u'Drinks'),\\n        (5, u'Main Course'),\\n        (6, u'Salad'),\\n        (7, u'Side Dish'),\\n        (8, u'Soup'),\\n        (9, u'Sauce/Marinade'),\\n        (10, u'Other'),        \\n    )\\n    name = models.CharField(max_length=255)\\n    submitter = models.CharField(max_length=40)\\n    date = models.DateTimeField()\\n    category = models.SmallIntegerField(choices=CATEGORY_CHOICES)\\n    ingredients = models.TextField()\\n    directions = models.TextField()\\n    comments = models.TextField(null=True, blank=True)\\n\\n\",\n  'completion': \"Edit: Updated in light of kibibu's correction.\\n\\nI have encountered what I believe is this same error, producing the message:\\n\\nCaught ValueError while rendering: too many values to unpack\\n\\n\\nMy form class was as follows:\\n\\nclass CalcForm(forms.Form):\\n    item = forms.ChoiceField(choices=(('17815', '17816')))\\n\\n\\nNote that my choices type here a tuple. Django official documentation reads as follows for the choices arg:\\n\\n\\n  An iterable (e.g., a list or tuple) of 2-tuples to use as choices for\\n  this field. This argument accepts the same formats as the choices\\n  argument to a model field.\\n\\n\\nsrc: https://docs.djangoproject.com/en/1.3/ref/forms/fields/#django.forms.ChoiceField.choices\\n\\nThis problem was solved by my observing the documentation and using a list of tuples:\\n\\nclass CalcForm(forms.Form):\\n    item = forms.ChoiceField(choices=[('17815', '17816')])\\n\\n\\nDo note that while the docs state any iterable of the correct form can be used, a tuple of 2-tuples did not work:\\n\\nitem = forms.ChoiceField(choices=(('17815', '17816'), ('123', '456')))\\n\\n\\nThis produced the same error as before.\\n\\nLesson: bugs happen.\\n\"},\n {'prompt': 'I have an issue with the django.contrib.auth User model where the email max_length is 75.\\n\\nI am receiving email addresses that are longer than 75 characters from the facebook api, and I need to (would really like to) store them in the user for continuity among users that are from facebook connect and others.\\n\\nI am able to solve the problem of \"Data truncated for column \\'email\\' at row 1\" by manually going editing the field in our mySql database, but is there a better way to solve this? preferably one that does not involve me manually editing the database every time I reset it for a schema change?\\n\\nI am ok with editing the database as long as I can add it to the reset script, or the initial_data.json file.\\n',\n  'completion': \"EmailField 75 chars length is hardcoded in django. You can fix this like that:\\n\\nfrom django.db.models.fields import EmailField\\ndef email_field_init(self, *args, **kwargs):\\n  kwargs['max_length'] = kwargs.get('max_length', 200)\\n  CharField.__init__(self, *args, **kwargs)\\nEmailField.__init__ = email_field_init\\n\\n\\nbut this will change ALL EmailField fields lengths, so you could also try:\\n\\nfrom django.contrib.auth.models import User\\nfrom django.utils.translation import ugettext as _\\nfrom django.db import models\\nUser.email = models.EmailField(_('e-mail address'), blank=True, max_length=200)\\n\\n\\nboth ways it'd be best to put this code in init of any module BEFORE django.contrib.auth in your INSTALLED_APPS\\n\"},\n {'prompt': \"What alternatives are there to pylab for plotting in Python? In particular, I'm looking for something that doesn't use the stateful model that pylab does.\\n\",\n  'completion': 'Plotly lets you make graphs using a Python API, matplotlib, and pandas. Their IPython gallery has some example scientific graphs with the Python scripts that generated them. \\n\\nHere\\'s a sample: \\n\\n\\n\\nSome recent exciting open source offerings:\\n\\n\\nggplot is based on R\\'s ggplot2, with aesthetically pleasing defaults and a really concise api. wants to be a matplotlib killer\\n\\n\\n\\n\\n\\nbokeh makes interactive (html canvas) plots. emphasis on interativity + handling big data\\n\\n\\n\\n\\n\\nvega translates JSON \"plot descriptions\" into SVG or Canvas-based interactive plots, and vincent is a declarative interface for generating the JSON specifications.\\n\\n\\n\\n'},\n {'prompt': 'In a similar way to using varargs in C or C++:\\n\\nfn(a, b)\\nfn(a, b, c, d, ...)\\n\\n',\n  'completion': 'Yes.\\n\\nThis is simple and works if you disregard keyword arguments:\\n\\ndef manyArgs(*arg):\\n  print \"I was called with\", len(arg), \"arguments:\", arg\\n\\n>>> manyArgs(1)\\nI was called with 1 arguments: (1,)\\n>>> manyArgs(1, 2,3)\\nI was called with 3 arguments: (1, 2, 3)\\n\\n\\nAs you can see, Python will give you a single tuple with all the arguments.\\n\\nFor keyword arguments you need to accept those as a separate actual argument, as shown in Skurmedel\\'s answer.\\n'},\n {'prompt': 'I\\'ve been playing around with the email module in python but I want to be able to know how to embed images which are included in the html.\\n\\nSo for example if the body is something like\\n\\n<img src=\"../path/image.png\"></img>\\n\\n\\nI would like to embed image.png into the email, and the src attribute should be replaced with content-id. Does anybody know how to do this?\\n',\n  'completion': 'Here is an example I found.\\n\\n\\n  Recipe 473810: Send an HTML email with embedded image and plain text alternate:  \\n  \\n  HTML is the method of choice for those\\n  wishing to send emails with rich text,\\n  layout and graphics. Often it is\\n  desirable to embed the graphics within\\n  the message so recipients can display\\n  the message directly, without further\\n  downloads.\\n  \\n  Some mail agents don\\'t support HTML or\\n  their users prefer to receive plain\\n  text messages. Senders of HTML\\n  messages should include a plain text\\n  message as an alternate for these\\n  users.\\n  \\n  This recipe sends a short HTML message\\n  with a single embedded image and an\\n  alternate plain text message.\\n\\n\\n# Send an HTML email with an embedded image and a plain text message for\\n# email clients that don\\'t want to display the HTML.\\n\\nfrom email.MIMEMultipart import MIMEMultipart\\nfrom email.MIMEText import MIMEText\\nfrom email.MIMEImage import MIMEImage\\n\\n# Define these once; use them twice!\\nstrFrom = \\'from@example.com\\'\\nstrTo = \\'to@example.com\\'\\n\\n# Create the root message and fill in the from, to, and subject headers\\nmsgRoot = MIMEMultipart(\\'related\\')\\nmsgRoot[\\'Subject\\'] = \\'test message\\'\\nmsgRoot[\\'From\\'] = strFrom\\nmsgRoot[\\'To\\'] = strTo\\nmsgRoot.preamble = \\'This is a multi-part message in MIME format.\\'\\n\\n# Encapsulate the plain and HTML versions of the message body in an\\n# \\'alternative\\' part, so message agents can decide which they want to display.\\nmsgAlternative = MIMEMultipart(\\'alternative\\')\\nmsgRoot.attach(msgAlternative)\\n\\nmsgText = MIMEText(\\'This is the alternative plain text message.\\')\\nmsgAlternative.attach(msgText)\\n\\n# We reference the image in the IMG SRC attribute by the ID we give it below\\nmsgText = MIMEText(\\'<b>Some <i>HTML</i> text</b> and an image.<br><img src=\"cid:image1\"><br>Nifty!\\', \\'html\\')\\nmsgAlternative.attach(msgText)\\n\\n# This example assumes the image is in the current directory\\nfp = open(\\'test.jpg\\', \\'rb\\')\\nmsgImage = MIMEImage(fp.read())\\nfp.close()\\n\\n# Define the image\\'s ID as referenced above\\nmsgImage.add_header(\\'Content-ID\\', \\'<image1>\\')\\nmsgRoot.attach(msgImage)\\n\\n# Send the email (this example assumes SMTP authentication is required)\\nimport smtplib\\nsmtp = smtplib.SMTP()\\nsmtp.connect(\\'smtp.example.com\\')\\nsmtp.login(\\'exampleuser\\', \\'examplepass\\')\\nsmtp.sendmail(strFrom, strTo, msgRoot.as_string())\\nsmtp.quit()\\n\\n'},\n {'prompt': \"I've seen decorators that let you mark a function a deprecated so that a warning is given whenever that function is used. I'd like to do the same thing but for a global variable, but I can't think of a way to detect global variable accesses. I know about the globals() function, and I could check its contents, but that would just tell me if the global is defined (which it still will be if the function is deprecated and not all out removed) not if it's actually being used. The best alternative I can think of is something like this:\\n\\n# myglobal = 3\\nmyglobal = DEPRECATED(3)\\n\\n\\nBut besides the problem of how to get DEPRECATED to act exactly like a '3', I'm not sure what DEPRECATED could do that would let you detect every time it's accessed. I think the best it could do is iterate through all of the global's methods (since everything in Python is an object, so even '3' has methods, for converting to string and the like) and 'decorate' them to all be deprecated. But that's not ideal.\\n\\nAny ideas? Has anyone else tackled this problem?\\n\",\n  'completion': 'You can\\'t do this directly, since theres no way of intercepting the module access.  However, you can replace that module with an object of your choosing that acts as a proxy, looking for accesses to certain properties:\\n\\nimport sys, warnings\\n\\ndef WrapMod(mod, deprecated):\\n    \"\"\"Return a wrapped object that warns about deprecated accesses\"\"\"\\n    deprecated = set(deprecated)\\n    class Wrapper(object):\\n        def __getattr__(self, attr):\\n            if attr in deprecated:\\n                warnings.warn(\"Property %s is deprecated\" % attr)\\n\\n            return getattr(mod, attr)\\n\\n        def __setattr__(self, attr, value):\\n            if attr in deprecated:\\n                warnings.warn(\"Property %s is deprecated\" % attr)\\n            return setattr(mod, attr, value)\\n    return Wrapper()\\n\\noldVal = 6*9\\nnewVal = 42\\n\\nsys.modules[__name__] = WrapMod(sys.modules[__name__], \\n                         deprecated = [\\'oldVal\\'])\\n\\n\\nNow, you can use it as:\\n\\n>>> import mod1\\n>>> mod1.newVal\\n42\\n>>> mod1.oldVal\\nmod1.py:11: UserWarning: Property oldVal is deprecated\\n  warnings.warn(\"Property %s is deprecated\" % attr)\\n54\\n\\n\\nThe downside is that you are now performing two lookups when you access the module, so there is a slight performance hit.\\n'},\n {'prompt': 'Referring on this question, I have a similar -but not the same- problem..\\n\\nOn my way, I\\'ll have some text file, structured like:\\n\\nvar_a: \\'home\\'\\nvar_b: \\'car\\'\\nvar_c: 15.5\\n\\n\\nAnd I need that python read the file and then create a variable named var_a with value \\'home\\', and so on.\\n\\nExample:\\n\\n#python stuff over here\\ngetVarFromFile(filename) #this is the function that im looking for\\nprint var_b\\n#output: car, as string\\nprint var_c\\n#output 15.5, as number.\\n\\n\\nIs this possible, I mean, even keep the var type?\\n\\nNotice that I have the full freedom to the text file structure, I can use the format I like if the one I proposed isn\\'t the best.\\n\\nEDIT: the ConfigParser can be a solution, but I don\\'t like it so much, because in my script I\\'ll have then to refer to the variables in the file with\\n\\nconfig.get(\"set\", \"var_name\")\\n\\n\\nBut what I\\'ll love is to refer to the variable directly, as I declared it in the python script...\\n\\nThere is a way to import the file as a python dictionary?\\n\\nOh, last thing, keep in mind that I don\\'t know exactly how many variables would I have in the text file.\\n\\nEdit 2: I\\'m very interested at stephan\\'s JSON solution, because in that way the text file could be read simply with others languages (PHP, then via AJAX JavaScript, for example), but I fail in something while acting that solution:\\n\\n#for the example, i dont load the file but create a var with the supposed file content\\nfile_content = \"\\'var_a\\': 4, \\'var_b\\': \\'a string\\'\"\\nmydict = dict(file_content)\\n#Error: ValueError: dictionary update sequence element #0 has length 1; 2 is required\\nfile_content_2 = \"{\\'var_a\\': 4, \\'var_b\\': \\'a string\\'}\"\\nmydict_2 = dict(json.dump(file_content_2, True))\\n#Error:\\n#Traceback (most recent call last):\\n#File \"<pyshell#5>\", line 1, in <module>\\n#mydict_2 = dict(json.dump(file_content_2, True))\\n#File \"C:\\\\Python26\\\\lib\\\\json\\\\__init__.py\", line 181, in dump\\n#fp.write(chunk)\\n#AttributeError: \\'bool\\' object has no attribute \\'write\\'\\n\\n\\nIn what kind of issues can I fall with the JSON format?\\nAnd, how can I read a JSON array in a text file, and transform it in a python dict?\\n\\nP.S: I don\\'t like the solution using .py files; I\\'ll prefer .txt, .inc, .whatever is not restrictive to one language.\\n',\n  'completion': '\\n  But what i\\'ll love is to refer to the variable direclty, as i declared it in the python script..\\n\\n\\nAssuming you\\'re happy to change your syntax slightly, just use python and import the \"config\" module.\\n\\n# myconfig.py:\\n\\nvar_a = \\'home\\'\\nvar_b = \\'car\\'\\nvar_c = 15.5\\n\\n\\nThen do \\n\\nfrom myconfig import *\\n\\n\\nAnd you can reference them by name in your current context.\\n'},\n {'prompt': 'This sample code works (I can write something in the file):\\n\\nfrom multiprocessing import Process, Queue\\n\\nqueue = Queue()\\ndef _printer(self, queue):\\n    queue.put(\"hello world!!\")\\n\\ndef _cmdDisp(self, queue):\\n    f = file(\"Cmd.log\", \"w\")\\n    print >> f, queue.get()\\n    f.close()\\n\\n\\ninstead this other sample not: (errormsg: \\'module\\' object is not callable)\\n\\nimport Queue\\n\\nqueue = Queue()\\ndef _printer(self, queue):\\n    queue.put(\"hello world!!\")\\n\\ndef _cmdDisp(self, queue):\\n    f = file(\"Cmd.log\", \"w\")\\n    print >> f, queue.get()\\n    f.close()\\n\\n\\nthis other sample not (I cannot write something in the file):\\n\\nimport Queue\\n\\nqueue = Queue.Queue()\\ndef _printer(self, queue):\\n    queue.put(\"hello world!!\")\\n\\ndef _cmdDisp(self, queue):\\n    f = file(\"Cmd.log\", \"w\")\\n    print >> f, queue.get()\\n    f.close()\\n\\n\\nCan someone explain the differences? and the right to do?\\n',\n  'completion': \"For your second example, you already gave the explanation yourself---Queue is a module, which cannot be called.\\n\\nFor the third example: I assume that you use Queue.Queue together with multiprocessing.  A Queue.Queue will not be shared between processes.  If the Queue.Queue is declared before the processes then each process will receive a copy of it which is then independent of every other process.  Items placed in the Queue.Queue by the parent before starting the children will be available to each child.  Items placed in the Queue.Queue by the parent after starting the child will only be available to the parent. Queue.Queue is made for data interchange between different threads inside the same process (using the threading module). The multiprocessing queues are for data interchange between different Python processes. While the API looks similar (it's designed to be that way), the underlying mechanisms are fundamentally different.\\n\\n\\nmultiprocessing queues exchange data by pickling (serializing) objects and sending them through pipes. \\nQueue.Queue uses a data structure that is shared between threads and locks/mutexes for correct behaviour.\\n\\n\"},\n {'prompt': 'What\\'s the best way to parse messages received from an IRC server with Python according to the RFC? I simply want some kind of list/whatever, for example:\\n\\n:test!~test@test.com PRIVMSG #channel :Hi!\\n\\n\\nbecomes this:\\n\\n{ \"sender\" : \"test!~test@test.com\", \"target\" : \"#channel\", \"message\" : \"Hi!\" }\\n\\n\\nAnd so on?\\n\\n(Edit: I want to parse IRC messages in general, not just PRIVMSG\\'s)\\n',\n  'completion': 'Look at Twisted\\'s implementation http://twistedmatrix.com/\\n\\nUnfortunately I\\'m out of time, maybe someone else can paste it here for you.\\n\\nEdit\\n\\nWell I\\'m back, and strangely no one has pasted it yet so here it is:\\n\\nhttp://twistedmatrix.com/trac/browser/trunk/twisted/words/protocols/irc.py#54\\n\\ndef parsemsg(s):\\n    \"\"\"Breaks a message from an IRC server into its prefix, command, and arguments.\\n    \"\"\"\\n    prefix = \\'\\'\\n    trailing = []\\n    if not s:\\n       raise IRCBadMessage(\"Empty line.\")\\n    if s[0] == \\':\\':\\n        prefix, s = s[1:].split(\\' \\', 1)\\n    if s.find(\\' :\\') != -1:\\n        s, trailing = s.split(\\' :\\', 1)\\n        args = s.split()\\n        args.append(trailing)\\n    else:\\n        args = s.split()\\n    command = args.pop(0)\\n    return prefix, command, args\\n\\nparsemsg(\":test!~test@test.com PRIVMSG #channel :Hi!\")\\n# (\\'test!~test@test.com\\', \\'PRIVMSG\\', [\\'#channel\\', \\'Hi!\\'])\\n\\n\\nThis function closely follows the EBNF described in the IRC RFC.\\n'},\n {'prompt': 'I\\'m really confused with the codecs.open function. When I do:\\n\\nfile = codecs.open(\"temp\", \"w\", \"utf-8\")\\nfile.write(codecs.BOM_UTF8)\\nfile.close()\\n\\n\\nIt gives me the error\\n\\n\\n  UnicodeDecodeError: \\'ascii\\' codec can\\'t decode byte 0xef in position\\n  0: ordinal not in range(128)\\n\\n\\nIf I do:\\n\\nfile = open(\"temp\", \"w\")\\nfile.write(codecs.BOM_UTF8)\\nfile.close()\\n\\n\\nIt works fine.\\n\\nQuestion is why does the first method fail? And how do I insert the bom?\\n\\nIf the second method is the correct way of doing it, what the point of using codecs.open(filename, \"w\", \"utf-8\")?\\n',\n  'completion': 'Disclaimer: I\\'m not a Python programmer.\\n\\nI believe the problem is that codecs.BOM_UTF8 is a byte string, not a Unicode string. I suspect the file handler is trying to guess what you really mean based on \"I\\'m meant to be writing Unicode as UTF-8-encoded text, but you\\'ve given me a byte string!\"\\n\\nTry writing the Unicode string for the byte order mark (i.e. Unicode U+FEFF) directly, so that the file just encodes that as UTF-8:\\n\\nimport codecs\\n\\nfile = codecs.open(\"lol\", \"w\", \"utf-8\")\\nfile.write(u\\'\\\\ufeff\\')\\nfile.close()\\n\\n\\n(That seems to give the right answer - a file with bytes EF BB BF.)\\n\\nEDIT: S. Lott\\'s suggestion of using \"utf-8-sig\" as the encoding is a better one than explicitly writing the BOM yourself, but I\\'ll leave this answer here as it explains what was going wrong before.\\n'},\n {'prompt': \"So right now i need to create and implement an extension of the Python logging module that will be used to log to our database. Basically we have several python applications(that all run in the background) that currently log to a random mishmash of text files. Which makes it almost impossible to find out if a certain application failed or not. \\n\\nThe problem given to me is to move said logging to text files to an oracle DB. The tables have already been defined, and where things need to be logged to but right now, im looking at adding another logging handler that will log to the DB. \\n\\nI am using python 2.5.4 and cx_Oracle and the applications in general can be ether run as a service/daemon or a straight application.\\n\\nI'm just mainly curious about what would be the best possible way to go about this. Few questions:\\n\\n\\nIf any errors occur with cx_Oracle, where should these errors be logged to? If its down would it be best to just go and have the logger retreat to the default text file?\\nAwhile back we started enforcing that people use sys.stderr/stdout.write instead of print, so worst case scenario we wouldn't run into any issues with print becoming deprecated. Is there a way to seamlessly make all of the thousands of sys.std calls be piped directly into the logger, and have the logger pickup the slack?\\nAfter every logged message, should the script automatically do a commit? (there's going to be several dozen a second.)\\nWhat is the best way to implement a new handler for the logging system? Inheriting from the basic Handler class seems to be easiest. \\n\\n\\nAny ideas / suggestions would be great. \\n\",\n  'completion': '\\nIf errors occur with cx_Oracle, it\\'s probably best to log these to a text file.\\nYou could try redirecting sys.stdout and sys.stderr to file-like objects which log whatever\\'s written to them to a logger.\\nI would guess you do want to commit after each event, unless you have strong reasons for not doing this. Alternatively, you can buffer several events and write them all in a single transaction every so often.\\nBelow is an example which uses mx.ODBC, you can probably adapt this to cx_Oracle without too much trouble. It\\'s meant to be Python DB-API 2.0 compliant, I think.\\n\\n\\nThe standalone Python logging distribution (before logging was added to Python) is at http://www.red-dove.com/python_logging.html and although the logging package in Python is much more up to date, the standalone distribution contains a test directory which has a lot of useful examples of derived handler classes.\\n\\n#!/usr/bin/env python\\n#\\n# Copyright 2001-2009 by Vinay Sajip. All Rights Reserved.\\n#\\n# Permission to use, copy, modify, and distribute this software and its\\n# documentation for any purpose and without fee is hereby granted,\\n# provided that the above copyright notice appear in all copies and that\\n# both that copyright notice and this permission notice appear in\\n# supporting documentation, and that the name of Vinay Sajip\\n# not be used in advertising or publicity pertaining to distribution\\n# of the software without specific, written prior permission.\\n# VINAY SAJIP DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING\\n# ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL\\n# VINAY SAJIP BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR\\n# ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER\\n# IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT\\n# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\\n#\\n# This file is part of the standalone Python logging distribution. See\\n# http://www.red-dove.com/python_logging.html\\n#\\n\"\"\"\\nA test harness for the logging module. An example handler - DBHandler -\\nwhich writes to an Python DB API 2.0 data source. You\\'ll need to set this\\nsource up before you run the test.\\n\\nCopyright (C) 2001-2009 Vinay Sajip. All Rights Reserved.\\n\"\"\"\\nimport sys, string, time, logging\\n\\nclass DBHandler(logging.Handler):\\n    def __init__(self, dsn, uid=\\'\\', pwd=\\'\\'):\\n        logging.Handler.__init__(self)\\n        import mx.ODBC.Windows\\n        self.dsn = dsn\\n        self.uid = uid\\n        self.pwd = pwd\\n        self.conn = mx.ODBC.Windows.connect(self.dsn, self.uid, self.pwd)\\n        self.SQL = \"\"\"INSERT INTO Events (\\n                        Created,\\n                        RelativeCreated,\\n                        Name,\\n                        LogLevel,\\n                        LevelText,\\n                        Message,\\n                        Filename,\\n                        Pathname,\\n                        Lineno,\\n                        Milliseconds,\\n                        Exception,\\n                        Thread\\n                   )\\n                   VALUES (\\n                        %(dbtime)s,\\n                        %(relativeCreated)d,\\n                        \\'%(name)s\\',\\n                        %(levelno)d,\\n                        \\'%(levelname)s\\',\\n                        \\'%(message)s\\',\\n                        \\'%(filename)s\\',\\n                        \\'%(pathname)s\\',\\n                        %(lineno)d,\\n                        %(msecs)d,\\n                        \\'%(exc_text)s\\',\\n                        \\'%(thread)s\\'\\n                   );\\n                   \"\"\"\\n        self.cursor = self.conn.cursor()\\n\\n    def formatDBTime(self, record):\\n        record.dbtime = time.strftime(\"#%m/%d/%Y#\", time.localtime(record.created))\\n\\n    def emit(self, record):\\n        try:\\n            #use default formatting\\n            self.format(record)\\n            #now set the database time up\\n            self.formatDBTime(record)\\n            if record.exc_info:\\n                record.exc_text = logging._defaultFormatter.formatException(record.exc_info)\\n            else:\\n                record.exc_text = \"\"\\n            sql = self.SQL % record.__dict__\\n            self.cursor.execute(sql)\\n            self.conn.commit()\\n        except:\\n            import traceback\\n            ei = sys.exc_info()\\n            traceback.print_exception(ei[0], ei[1], ei[2], None, sys.stderr)\\n            del ei\\n\\n    def close(self):\\n        self.cursor.close()\\n        self.conn.close()\\n        logging.Handler.close(self)\\n\\ndh = DBHandler(\\'Logging\\')\\nlogger = logging.getLogger(\"\")\\nlogger.setLevel(logging.DEBUG)\\nlogger.addHandler(dh)\\nlogger.info(\"Jackdaws love my big %s of %s\", \"sphinx\", \"quartz\")\\nlogger.debug(\"Pack my %s with five dozen %s\", \"box\", \"liquor jugs\")\\ntry:\\n    import math\\n    math.exp(1000)\\nexcept:\\n    logger.exception(\"Problem with %s\", \"math.exp\")\\n\\n'},\n {'prompt': 'I\\'m fairly new to Python and recursive functions as a whole, so pardon my ignorance.\\n\\nI am trying to implement a binary search tree in Python and have the following insert method (taken out of a class):\\n\\ndef insert(self, key, root=None):\\n    \\'\\'\\'Inserts a node in the tree\\'\\'\\'\\n    if root == None:\\n        root = self.root\\n    if root.key == None:\\n        self._update(root, key)\\n        return 0\\n    else:\\n        tmp = root\\n        if key > tmp.key: # we work with the right subtree\\n            self.insert(key, root=tmp.right)\\n        elif key < tmp.key: # we work with the left subtree\\n            self.insert(key, root=tmp.left)\\n        else: # key already exists\\n            return 0\\n\\n\\nI\\'m not sure if this is legible, but it traverses the tree until it gets to a None value and updates the node with the key to insert.\\n\\nNow, the method works nicely and correctly creates a BST from scratch. But there\\'s a problem with the return statements, as it only returns 0 if there is no recursion performed.\\n\\n>>> bst.insert(10)\\n0\\n>>> bst.insert(15)\\n>>> bst.root.right.key\\n15\\n>>>\\n\\n\\n\"Inserting\" the root key again returns 0 (from line 15) the way it should.\\n\\n>>> bst.insert(10)\\n0\\n\\n\\nI can\\'t figure out why this happens. If I put a print statement in line 6, it executes correctly, yet it just won\\'t return anything past the first insertion. Why is this? (I\\'m pretty sure I\\'m missing some basic information regarding Python and recursion)\\n\\nThanks for your help,\\n\\nIvan\\n\\nP.S.: I\\'ve read that recursion is not the best way to implement a BST, so I\\'ll look into other solutions, but I\\'d like to know the answer to this before moving on.\\n',\n  'completion': 'On your recursive lines, you do not return anything.  If you want it to return 0, you should replace them with lines like:\\n\\nreturn self.insert(key, root=tmp.left)\\n\\n\\ninstead of just\\n\\nself.insert(key, root=tmp.left)\\n\\n'},\n {'prompt': \"I'm guessing this is going to involve regexp or something, but I'll give it  a shot. At the minute, a user can break a website by typing something similar to Â£$(*Â£$(Â£@$&Â£($ in the title field, which is converted into a slug using Django slugify.\\n\\nBecause none of these characters can be converted, Django returns an error. My question is, what should I put in the form validation method to raise a forms.ValidationError when the user uses a title like this?\\n\\nThanks.\\n\",\n  'completion': \"SLUG_REGEX = re.compile('^[-\\\\w]+$')\\n\"},\n {'prompt': 'The Development version of Django has aggregate functions like Avg, Count, Max, Min, StdDev, Sum, and Variance (link text). Is there a reason Median is missing from the list? \\n\\nImplementing one seems like it would be easy. Am I missing something? How much are the aggregate functions doing behind the scenes?\\n',\n  'completion': \"Because median isn't a SQL aggregate. See, for example, the list of PostgreSQL aggregate functions and the list of MySQL aggregate functions.\\n\"},\n {'prompt': \"float('nan') results in a thingy simply called nan. But how do I check for it? Should be very easy, but i cannot find it.\\n\",\n  'completion': \"math.isnan()\\n\\n\\n  Checks if the float x is a NaN (not a number). NaNs are part of the IEEE 754 standards. Operation like but not limited to inf * 0, inf / inf or any operation involving a NaN, e.g. nan * 1, return a NaN.\\n  \\n  New in version 2.6.\\n\\n\\n>>> import math\\n>>> x=float('nan')\\n>>> math.isnan(x)\\nTrue\\n>>>\\n\\n\"},\n {'prompt': \"I managed to get a set of images loaded using Python. \\n\\nI'd like my script to take this series of images (in whatever format I need them), and create a video from them. The big limit in all this is that I am looking for something easy and simple to install. Ideally, using the standard OS X installation procedure: \\n\\n\\ndownload .dmg\\nclick\\nmove into the application folder\\n\\n\\nI do not want to expend a lot of effort to install the video editing program. Just something simple that works.\\n\\n\\n\\nQuestions\\n\\n\\nWhat format should I aim for? I need my video to be playable on Linux, Mac, and Windows systems. The images are graphs, so we are speaking of discreet images, not photographs. It should be pretty easy to compress it. There will be about 1000 images, so this will be a short movie.\\nWhat tools should I use to produce the actual video? I need to either do it directly from Python using a library designed for this purpose, or by scripting command-line tools called from Python. \\n\\n\",\n  'completion': \"If you're not averse to using the command-line, there's the convert command from the ImageMagick package. It's available for Mac, Linux, Windows. See http://www.imagemagick.org/script/index.php.\\n\\nIt supports a huge number of image formats and you can output your movie as an mpeg file:\\n\\nconvert -quality 100 *.png outvideo.mpeg\\n\\n\\nor as animated gifs for uploading to webpages:\\n\\nconvert -set delay 3 -loop 0 -scale 50% *.png animation.gif\\n\\n\\nMore options for the convert command available here: ImageMagick v6 Examples -\\nAnimation Basics\\n\"},\n {'prompt': \"Are there any equivalent Javascript functions for Python's urllib.quote() and urllib.unquote()?\\n\\nThe closest I've come across are escape(), encodeURI(), and encodeURIComponent() (and their corresponding un-encoding functions), but they don't encode/decode the same set of special characters as far as I can tell.\\n\\nThanks,\\nCameron\\n\",\n  'completion': \"For the record:\\n\\nJavaScript               |  Python\\n----------------------------------- \\nencodeURI(str)           |  urllib.quote(str, safe='~@#$&()*!+=:;,.?/\\\\'');\\n-----------------------------------\\nencodeURIComponent(str)  |  urllib.quote(str, safe='~()*!.\\\\'')\\n\\n\"},\n {'prompt': 'Python\\'s list type has an index() method that takes one parameter and returns the index of the first item in the list matching the parameter.  For instance:\\n\\n>>> some_list = [\"apple\", \"pear\", \"banana\", \"grape\"]\\n>>> some_list.index(\"pear\")\\n1\\n>>> some_list.index(\"grape\")\\n3\\n\\n\\nIs there a graceful (idiomatic) way to extend this to lists of complex objects, like tuples?  Ideally, I\\'d like to be able to do something like this:\\n\\n>>> tuple_list = [(\"pineapple\", 5), (\"cherry\", 7), (\"kumquat\", 3), (\"plum\", 11)]\\n>>> some_list.getIndexOfTuple(1, 7)\\n1\\n>>> some_list.getIndexOfTuple(0, \"kumquat\")\\n2\\n\\n\\ngetIndexOfTuple() is just a hypothetical method that accepts a sub-index and a value, and then returns the index of the list item with the given value at that sub-index.  I hope\\n\\nIs there some way to achieve that general result, using list comprehensions or lambas or something \"in-line\" like that?  I think I could write my own class and method, but I don\\'t want to reinvent the wheel if Python already has a way to do it.\\n',\n  'completion': 'How about this?\\n\\n>>> tuple_list = [(\"pineapple\", 5), (\"cherry\", 7), (\"kumquat\", 3), (\"plum\", 11)]\\n>>> [x for x, y in enumerate(tuple_list) if y[1] == 7]\\n[1]\\n>>> [x for x, y in enumerate(tuple_list) if y[0] == \\'kumquat\\']\\n[2]\\n\\n\\nAs pointed out in the comments, this would get all matches. To just get the first one, you can do:\\n\\n>>> [y[0] for y in tuple_list].index(\\'kumquat\\')\\n2\\n\\n\\nThere is a good discussion in the comments as to the speed difference between all the solutions posted. I may be a little biased but I would personally stick to a one-liner as the speed we\\'re talking about is pretty insignificant versus creating functions and importing modules for this problem, but if you are planning on doing this to a very large amount of elements you might want to look at the other answers provided, as they are faster than what I provided.\\n'},\n {'prompt': \"I find myself frequently using Python's interpreter to work with databases, files, etc -- basically a lot of manual formatting of semi-structured data.  I don't properly save and clean up the useful bits as often as I would like.  Is there a way to save my input into the shell (db connections, variable assignments, little for loops and bits of logic) -- some history of the interactive session?  If I use something like script I get too much stdout noise.  I don't really need to pickle all the objects -- though if there is a solution that does that, it would be OK.  Ideally I would just be left with a script that ran as the one I created interactively, and I could just delete the bits I didn't need.  Is there a package that does this, or a DIY approach?\\n\\nUPDATE:  I am really amazed at the quality and usefulness of these packages.  For those with a similar itch:\\n\\n\\nIPython -- should have been using this for ages, kind of what I had in mind\\nreinteract -- very impressive, I want to learn more about visualization and this seems like it will shine there.  Sort of a gtk/gnome desktop app that renders graphs inline.  Imagine a hybrid shell + graphing calculator + mini eclipse.  Source distribution here: http://www.reinteract.org/trac/wiki/GettingIt . Built fine on Ubuntu, integrates into gnome desktop, Windows and Mac installers too.\\nbpython -- extremely cool, lots of nice features, autocomplete(!), rewind, one keystroke save to file, indentation, well done.  Python source distribution, pulled a couple of dependencies from sourceforge.\\n\\n\\nI am converted, these really fill a need between interpreter and editor.\\n\",\n  'completion': 'IPython is extremely useful if you like using interactive sessions. For example for your usecase there is the %save magic command, you just input %save my_useful_session 10-20 23 to save input lines 10 to 20 and 23 to my_useful_session.py. (to help with this, every line is prefixed by its number)\\n\\nLook at the videos on the documentation page to get a quick overview of the features.\\n'},\n {'prompt': \"In python it's possible to use '.' in order to access object's dictionary items. For example:\\n\\nclass test( object ) :\\n  def __init__( self ) :\\n    self.b = 1\\n  def foo( self ) :\\n    pass\\nobj = test()\\na = obj.foo\\n\\n\\nFrom above example, having 'a' object, is it possible to get from it reference to 'obj' that is a parent namespace for 'foo' method assigned? For example, to change obj.b into 2?\\n\",\n  'completion': \"On bound methods, you can use three special read-only parameters:\\n\\n\\nim_func which returns the (unbound) function object\\nim_self which returns the object the function is bound to (class instance)\\nim_class which returns the class of im_self\\n\\n\\nTesting around:\\n\\nclass Test(object):\\n    def foo(self):\\n        pass\\n\\ninstance = Test()\\ninstance.foo          # <bound method Test.foo of <__main__.Test object at 0x1>>\\ninstance.foo.im_func  # <function foo at 0x2>\\ninstance.foo.im_self  # <__main__.Test object at 0x1>\\ninstance.foo.im_class # <__main__.Test class at 0x3>\\n\\n# A few remarks\\ninstance.foo.im_self.__class__ == instance.foo.im_class # True\\ninstance.foo.__name__ == instance.foo.im_func.__name__  # True\\ninstance.foo.__doc__ == instance.foo.im_func.__doc__    # True\\n\\n# Now, note this:\\nTest.foo.im_func != Test.foo # unbound method vs function\\nTest.foo.im_self is None\\n\\n# Let's play with classmethods\\nclass Extend(Test):\\n    @classmethod\\n    def bar(cls): \\n        pass\\n\\nextended = Extend()\\n\\n# Be careful! Because it's a class method, the class is returned, not the instance\\nextended.bar.im_self # <__main__.Extend class at ...>\\n\\n\\nThere is an interesting thing to note here, that gives you a hint on how the methods are being called:\\n\\nclass Hint(object):\\n    def foo(self, *args, **kwargs):\\n        pass\\n\\n    @classmethod\\n    def bar(cls, *args, **kwargs):\\n        pass\\n\\ninstance = Hint()\\n\\n# this will work with both class methods and instance methods:\\nfor name in ['foo', 'bar']:\\n    method = instance.__getattribute__(name)\\n    # call the method\\n    method.im_func(method.im_self, 1, 2, 3, fruit='banana')\\n\\n\\nBasically, im_self attribute of a bound method changes, to allow using it as the first parameter when calling im_func\\n\"},\n {'prompt': 'Is there anyway I can zip dynamically generated content, such as a freshly rendered html template, into a zip file using zipfile?\\n\\nThere seem to be some examples around for zipping static content, but none for zipping dynamic ones. Or, is it not possible at all?\\n\\nOne more question: Is it possible to create a zip file with a bunch of sub-folders inside it?\\n\\nThanks.\\n',\n  'completion': 'The working code: (for app engine:)\\n\\noutput = StringIO.StringIO()\\nz = zipfile.ZipFile(output,\\'w\\')\\nmy_data = \"<html><body><p>Hello, world!</p></body></html>\"\\nz.writestr(\"hello.html\", my_data)\\nz.close()\\n\\nself.response.headers[\"Content-Type\"] = \"multipart/x-zip\"\\nself.response.headers[\\'Content-Disposition\\'] = \"attachment; filename=test.zip\"\\nself.response.out.write(output.getvalue())\\n\\n\\nThanks again to Schnouki and Ryan.\\n'},\n {'prompt': \"I'm trying to read lines from a pipe and process them, but I'm doing something silly and I can't figure out what. The producer is going to keep producing lines indefinitely, like this:\\n\\nproducer.py\\n\\nimport time\\n\\nwhile True:\\n    print 'Data'\\n    time.sleep(1)\\n\\n\\nThe consumer just needs to check for lines periodically:\\n\\nconsumer.py\\n\\nimport sys, time\\nwhile True:\\n    line = sys.stdin.readline()\\n    if line:\\n        print 'Got data:', line\\n    else:\\n        time.sleep(1)\\n\\n\\nWhen I run this in the Windows shell as python producer.py | python consumer.py, it just sleeps forever (never seems to get data?) It seems that maybe the problem is that the producer never terminates, since if I send a finite amount of data then it works fine.\\n\\nHow can I get the data to be received and show up for the consumer? In the real application, the producer is a C++ program I have no control over.\\n\",\n  'completion': \"Some old versions of Windows simulated pipes through files (so they were prone to such problems), but that hasn't been a problem in 10+ years.  Try adding a\\n\\n  sys.stdout.flush()\\n\\n\\nto the producer after the print, and also try to make the producer's stdout unbuffered (by using python -u).\\n\\nOf course this doesn't help if you have no control over the producer -- if it buffers too much of its output you're still going to wait a long time.\\n\\nUnfortunately - while there are many approaches to solve that problem on Unix-like operating systems, such as pyexpect, pexpect, exscript, and paramiko, I doubt any of them works on Windows; if that's indeed the case, I'd try Cygwin, which puts enough of a Linux-like veneer on Windows as to often enable the use of Linux-like approaches on a Windows box.\\n\"},\n {'prompt': \"I have been in love with zsh for a long time, and more recently I have been discovering the advantages of the ipython interactive interpreter over python itself. Being able to cd, to ls, to run or to ! is indeed very handy. But now it feels weird to have such a clumsy shell when in ipython, and I wonder how I could integrate my zsh and my ipython better.\\n\\nOf course, I could rewrite my .zshrc and all my scripts in python, and emulate most of my shell world from ipython, but it doesn't feel right. And I am obviously not ready to use ipython as a main shell anyway.\\n\\nSo, here comes my question: how do you work efficiently between your shell and your python command-loop ? Am I missing some obvious integration strategy ? Should I do all that in emacs ? \\n\",\n  'completion': 'I asked this question on the zsh list and this answer worked for me. YMMV.\\n\\nIn genutils.py after the line \\n\\n\\n  if not debug:\\n\\n\\nRemove the line:\\n\\n\\n  stat = os.system(cmd)\\n\\n\\nReplace it with:\\n\\n\\n  stat =\\n  subprocess.call(cmd,shell=True,executable=\\'/bin/zsh\\')\\n\\n\\nyou see, the problem is that that \"!\" call uses os.system to run it, which defaults to manky old /bin/sh .\\n\\nLike I said, it worked for me, although I\\'m not sure what got borked behind the scenes.\\n'},\n {'prompt': 'I\\'m trying to figure out how to redirect output from some FORTRAN code for which I\\'ve generated a Python interface by using F2PY. I\\'ve tried:\\n\\nfrom fortran_code import fortran_function\\nstdout_holder = sys.stdout\\nstderr_holder = sys.stderr\\nsys.stdout = file(\"/dev/null\",\"w\")\\nfortran_function()\\nsys.stdout.close()\\nsys.stderr.close()\\nsys.stdout = stdout_holder\\nsys.stderr = stderr_holder\\n\\n\\nThis is the de facto method of redirecting output in Python, but it doesn\\'t seem to work in this case (i.e., the output is displayed anyway).\\n\\nI did find a mailing list post from 2002 saying that \"It is possible to read messages from pts devices, e.g. ttysnoop does this\". Information on ttysnoop seems to be pretty difficult to find online (I don\\'t think it\\'s been updated in quite a few years; for example, the first result on Google for \"ttysnoop\" has only dead links to tarballs, RPMs, and .deb\\'s), and this request for a port to OS X received the response \"No luck, it requires some linux specific utmp functions which I can\\'t create.\"\\n\\nI\\'m open to any suggestions on how to redirect the output (it doesn\\'t have to use ttysnoop).\\n\\nThanks!\\n',\n  'completion': 'The stdin and stdout fds are being inherited by the C shared library.\\n\\nfrom fortran_code import fortran_function\\nimport os\\n\\nprint \"will run fortran function!\"\\n\\n# open 2 fds\\nnull_fds = [os.open(os.devnull, os.O_RDWR) for x in xrange(2)]\\n# save the current file descriptors to a tuple\\nsave = os.dup(1), os.dup(2)\\n# put /dev/null fds on 1 and 2\\nos.dup2(null_fds[0], 1)\\nos.dup2(null_fds[1], 2)\\n\\n# *** run the function ***\\nfortran_function()\\n\\n# restore file descriptors so I can print the results\\nos.dup2(save[0], 1)\\nos.dup2(save[1], 2)\\n# close the temporary fds\\nos.close(null_fds[0])\\nos.close(null_fds[1])\\n\\nprint \"done!\"\\n\\n'},\n {'prompt': 'Can Windows drivers be written in Python?\\n',\n  'completion': 'Yes. You cannot create the \"classic\" kernel-mode drivers. However, starting with XP, Windows offers a User-Mode Driver Framework. They can\\'t do everything, obviously - any driver used in booting the OS obviously has to be kernel-mode. But with UMDF, you only need to implement COM components. \\n\\nBesides boot-time drivers, you also can\\'t write UMDF drivers that:\\n\\n\\nHandle interrupts\\nDirectly access hardware, such as direct memory access (DMA)\\nhave strict timing loops\\nUse nonpaged pool or other resources that are reserved for kernel mode\\n\\n'},\n {'prompt': \"I have a password string that must be passed to a method. Everything works fine but I don't feel comfortable storing the password in clear text. Is there a way to obfuscate the string or to truly encrypt it? I'm aware that obfuscation can be reverse engineered, but I think I should at least try to cover up the password a bit. At the very least it wont be visible to a indexing program, or a stray eye giving a quick look at my code.\\n\\nI am aware of pyobfuscate but I don't want the whole program obfuscated, just one string and possibly the whole line itself where the variable is defined.\\n\\nTarget platform is GNU Linux Generic (If that makes a difference)\\n\",\n  'completion': \"If you just want to prevent casually glancing at a password, you may want to consider encoding/decoding the password to/from base64. It's not secure in the least, but the password won't be casually human/robot readable.\\n\\nimport base64\\n# Encode password\\nencoded_pw = base64.b64encode(raw_pw)\\n\\n# Decode password\\ndecoded_pw = base64.b64decode(encoded_pw)\\n\\n\"},\n {'prompt': \"I want to count the number of times each character is repeated in a string. Is there any particular way to do it apart from comparing each character of the string from A-Z\\nand incrementing a counter?\\n\\nUpdate (in reference to Anthony's answer): Whatever you have suggested till now I have to write 26 times. Is there an easier way?\\n\",\n  'completion': \"import collections\\n\\nd = collections.defaultdict(int)\\nfor c in thestring:\\n    d[c] += 1\\n\\n\\nA collections.defaultdict is like a dict (subclasses it, actually), but when an entry is sought and not found, instead of reporting it doesn't have it, it makes it and inserts it by calling the supplied 0-argument callable. Most popular are defaultdict(int), for counting (or, equivalently, to make a multiset AKA bag data structure), and defaultdict(list), which does away forever with the need to use .setdefault(akey, []).append(avalue) and similar awkward idioms.\\n\\nSo once you've done this d is a dict-like container mapping every character to the number of times it appears, and you can emit it any way you like, of course. For example, most-popular character first:\\n\\nfor c in sorted(d, key=d.get, reverse=True):\\n  print '%s %6d' % (c, d[c])\\n\\n\"},\n {'prompt': 'This is hopefully a quick/easy one. I know a way to work around this via a custom template tag, but I was curious if there were other methods I was over looking. I\\'ve created a gallery function of sorts for my blog, and I have a gallery list page that paginates all my galleries. Now, I don\\'t want to show all the photos of each gallery in that list, since if each gallery even has 20 images, then that\\'s 100 images on a page if I paginate at 5 posts. That\\'d be wasteful, and the wrong way to go about things.\\n\\nThe question I have is, is there a way to just display 3 photos from the photo set? What I\\'d like to do, but I don\\'t think is possible is something like (pseudocode):\\n\\n{% for photos in gallery.photo_set %}\\n   {% if forloop.counter lt 3 %}\\n     <img src=\"{{ photos.url }}\">\\n   {% endif %}\\n{% endfor %}\\n\\n\\nJudging from the documentation, unless I\\'m completely missing it, that\\'s not possible via the templating system. Hence, I can just write my own template tag of sorts to work around it. I could probably do something from the view aspect, but I haven\\'t looked to far into that idea. The other option I have is giving the model a preview field, and allow the user to select the photos they want in the preview field. \\n\\nAnyways, a few different options, so I thought I\\'d poll the audience to see how you\\'d do it. Any opinion is appreciated. Personally, enjoying that there\\'s numerous ways to skin this cat.\\n',\n  'completion': 'Use:\\n\\n{% for photos in gallery.photo_set|slice:\":3\" %}\\n\\n'},\n {'prompt': 'On this data:\\n\\n<row Id=\"37501\" PostId=\"135577\" Text=\"...uses though.&#x10;\"/>\\n\\n\\nI\\'m getting an error with the Python sax parser:\\n\\nxml.sax._exceptions.SAXParseException:\\ncomments.xml:29776:332: reference to invalid character number\\n\\n\\nI trimmed the example; 332 points to \"&#x10;\".\\n\\nIs the parser correct in rejecting this character?\\n',\n  'completion': \"As others have stated, you probably meant &#10;. The reason why &#x10; (0x10 = 10h = 16) is invalid is that it's explicitly excluded by the XML 1.0 standard: (http://www.w3.org/TR/xml/#NT-Char)\\n\\nChar ::= #x9 | #xA | #xD | [#x20-#xD7FF] | [#xE000-#xFFFD] | [#x10000-#x10FFFF]\\n\\n\"},\n {'prompt': 'I have just started with Python. When I execute a python script file on Windows, the output window appears but instantaneously goes away. I need it to stay there so I can analyze my output. How can I keep it open?\\n',\n  'completion': 'You have a few options:\\n\\n\\nRun the program from an already-open terminal. Open a command prompt and type:\\n\\npython myscript.py\\n\\n\\nFor that to work you need the python executable in your path. Just check on how to edit environment variables on Windows, and add C:\\\\PYTHON26 (or whatever directory you installed python to).\\n\\nWhen the program ends, it\\'ll drop you back to the cmd prompt instead of closing the window.\\nAdd code to wait at the end of your script. Adding ...\\n\\nraw_input()\\n\\n\\n... at the end of the script makes it wait for the Enter key. That method is annoying because you have to modify the script, and have to remember removing it when you\\'re done. Specially annoying when testing other people\\'s scripts.\\nUse an editor that pauses for you. Some editors prepared for python will automatically pause for you after execution. Other editors allow you to configure the command line it uses to run your program. I find it particularly useful to configure it as \"python -i myscript.py\" when running. That drops you to a python shell after the end of the program, with the program environment loaded, so you may further play with the variables and call functions and methods.\\n\\n'},\n {'prompt': 'I was writing a python function that looked something like this\\n\\ndef foo(some_list):\\n   for i in range(0, len(some_list)):\\n       bar(some_list[i], i)\\n\\n\\nso that it was called with\\n\\nx = [0, 1, 2, 3, ... ]\\nfoo(x)\\n\\n\\nI had assumed that index access of lists was O(1), but was surprised to find that for large lists this was significantly slower than I expected.\\n\\nMy question, then, is how are python lists are implemented, and what is the runtime complexity of the following\\n\\n\\nIndexing: list[x]\\nPopping from the end: list.pop()\\nPopping from the beginning: list.pop(0)\\nExtending the list: list.append(x)\\n\\n\\nFor extra credit, splicing or arbitrary pops.\\n',\n  'completion': 'there is a very detailed table on python wiki which answers your question.\\n\\nHowever, in  your particular example you should use enumerate to get an index of an iterable within a loop. like so:\\n\\nfor i, item in enumerate(some_seq):\\n    bar(item, i)\\n\\n'},\n {'prompt': 'I am originally a C programmer. I have seen numerous tricks and \"hacks\" to read many different arguments. \\n\\nWhat are some of the ways Python programmers can do this?\\n\\nRelated\\n\\n\\nWhatâ\\x80\\x99s the best way to grab/parse command line arguments passed to a Python script?\\nImplementing a â\\x80\\x9c[command] [action] [parameter]â\\x80\\x9d style command-line interfaces?\\nHow can I process command line arguments in Python?\\nHow do I format positional argument help using Pythonâ\\x80\\x99s optparse?\\n\\n',\n  'completion': 'import sys\\n\\nprint \"\\\\n\".join(sys.argv)\\n\\n\\nsys.argv is a list that contains all the arguments passed to the script on the command line.\\n\\nBasically,\\n\\nimport sys\\nprint sys.argv[1:]\\n\\n'},\n {'prompt': 'I am trying to write a \"login_required\" decorator for the views in a WSGI+Werkzeug application.\\n\\nIn order to do this, I need to get at the user\\'s session, which is accessible via the Request object that is passed into the view methods.\\n\\nI can\\'t figure out how to get at that instance of Request in the decorator, though. I looked at PEP318, specifically the fourth example, but I\\'m not quite getting it.\\n\\nHere\\'s what I\\'m trying:\\n\\ndef login_required(*args, **kw):\\n    def goto_login(**kw):\\n        return redirect(url_for(\\'login\\'))\\n\\n    def decorate(f):\\n        # args[0] should be request\\n        args[0].client_session[\\'test\\'] = True\\n        logged_in = 0\\n        if logged_in:\\n            return f\\n        else:\\n            return goto_login\\n    return decorate\\n\\n\\n@login_required()\\n@expose(\\'/hello/<string:name>\\')\\ndef hello(request, name):\\n    return render_template(\\'say_hello.html\\', name=name)\\n\\n\\nbut I get an index out of bounds error trying to call args[0].\\n\\nIs there any way I can get access to the request argument passed into the \"hello\" function in the \"login_required\" decorator?\\n',\n  'completion': 'The decorator login_required is passed the function (hello in this case).\\n\\nSo what you want to do is:\\n\\ndef login_required(f):\\n\\n  # This function is what we \"replace\" hello with\\n  def wrapper(*args, **kw):\\n    args[0].client_session[\\'test\\'] = True\\n    logged_in = 0\\n    if logged_in:\\n      return f(*args, **kw)  # Call hello\\n    else:\\n      return redirect(url_for(\\'login\\'))\\n\\n  return wrapper\\n\\n'},\n {'prompt': 'I have a text file which a lot of random occurrences of the string @STRING_A, and I would be interested in writing a short script which removes only some of them. Particularly one that scans the file and once it finds a line which starts with this string like\\n\\n@STRING_A\\n\\n\\nthen checks if 3 lines backwards there is another occurrence of a line starting with the same string, like\\n\\n@STRING_A\\n\\n\\n@STRING_A\\n\\n\\nand if it happens, to delete the occurrence 3 lines backward. I was thinking about bash, but I do not know how to \"go backwards\" with it. So I am sure that this is not possible with bash. I also thought about python, but then I should store all information in memory in order to go backwards and then, for long files it would be unfeasible. \\n\\nWhat do you think? Is it possible to do it in bash or python?\\n\\nThanks\\n',\n  'completion': 'Funny that after all these hours nobody\\'s yet given a solution to the problem as actually phrased (as @John Machin points out in a comment) -- remove just the leading marker (if followed by another such marker 3 lines down), not the whole line containing it. It\\'s not hard, of course -- here\\'s a tiny mod as needed of @truppo\\'s fun solution, for example:\\n\\nfrom itertools import izip, chain\\nf = \"foo.txt\"\\nfor third, line in izip(chain(\"   \", open(f)), open(f)):\\n    if third.startswith(\"@STRING_A\") and line.startswith(\"@STRING_A\"):\\n        line = line[len(\"@STRING_A\"):]\\n    print line,\\n\\n\\nOf course, in real life, one would use an iterator.tee instead of reading the file twice, have this code in a function, not repeat the marker constant endlessly, &c;-).\\n'},\n {'prompt': \"I'm curious as to why it's so much faster to multiply than to take powers in python (though from what I've read this may well be true in many other languages too). For example it's much faster to do\\n\\nx*x\\n\\n\\nthan\\n\\nx**2\\n\\n\\nI suppose the ** operator is more general and can also deal with fractional powers. But if that's why it's so much slower, why doesn't it perform a check for an int exponent and then just do the multiplication?\\n\\n\\nEdit: Here's some example code I tried...\\n\\ndef pow1(r, n):\\n  for i in range(r):\\n    p = i**n\\n\\ndef pow2(r, n):\\n  for i in range(r):\\n    p = 1\\n    for j in range(n):\\n      p *= i\\n\\n\\nNow, pow2 is just a quick example and is clearly not optimised!\\nBut even so I find that using n = 2 and r = 1,000,000, then pow1 takes ~ 2500ms and pow2 takes ~ 1700ms.\\n I admit that for large values of n, then pow1 does get much quicker than pow2. But that's not too surprising.\\n\",\n  'completion': \"Basically naive multiplication is O(n) with a very low constant factor. Taking the power is O(log n) with a higher constant factor (There are special cases that need to be tested... fractional exponents, negative exponents, etc) . Edit: just to be clear, that's O(n) where n is the exponent.\\n\\nOf course the naive approach will be faster for small n, you're only really implementing a small subset of exponential math so your constant factor is negligible. \\n\"},\n {'prompt': \"I'm making a program in Python to be distributed to windows users via an installer.\\n\\nThe program needs to be able to download a file every day encrypted with the user's public key and then decrypt it.\\n\\nSo I need to find a Python library that will let me generate public and private PGP keys, and also decrypt files encrypted with the public key.\\n\\nIs this something pyCrypto will do (documentation is nebulous)?  Are there other pure Python libraries?  How about a standalone command line tool in any language?\\n\\nAll I saw so far was GNUPG but installing that on Windows does stuff to the registry and throws dll's everywhere, and then I have to worry about whether the user already has this installed, how to backup their existing keyrings, etc.  I'd rather just have a python library or command line tool and mange the keys myself.\\n\\nUpdate: pyME might work but it doesn't seem to be compatible with Python 2.4 which I have to use.\\n\",\n  'completion': \"You don't need PyCrypto or PyMe, fine though those packages may be - you will have all kinds of problems building under Windows. Instead, why not avoid the rabbit-holes and do what I did? Use gnupg 1.4.9. You don't need to do a full installation on end-user machines - just gpg.exe and iconv.dll from the distribution are sufficient, and you just need to have them somewhere in the path or accessed from your Python code using a full pathname. No changes to the registry are needed, and everything (executables and data files) can be confined to a single folder if you want.\\n\\nThere's a module GPG.py which was originally written by Andrew Kuchling, improved by Richard Jones and improved further by Steve Traugott. It's available here, but as-is it's not suitable for Windows because it uses os.fork(). Although originally part of PyCrypto, it is completely independent of the other parts of PyCrypto and needs only gpg.exe/iconv.dll in order to work.\\n\\nI have a version (gnupg.py) derived from Traugott's GPG.py, which uses the subprocess module. It works fine under Windows, at least for my purposes - I use it to do the following:\\n\\n\\nKey management - generation, listing, export etc.\\nImport keys from an external source (e.g. public keys received from a partner company)\\nEncrypt and decrypt data\\nSign and verify signatures\\n\\n\\nThe module I've got is not ideal to show right now, because it includes some other stuff which shouldn't be there - which means I can't release it as-is at the moment. At some point, perhaps in the next couple of weeks, I hope to be able to tidy it up, add some more unit tests (I don't have any unit tests for sign/verify, for example) and release it (either under the original PyCrypto licence or a similar commercial-friendly license). If you can't wait, go with Traugott's module and modify it yourself - it wasn't too much work to make it work with the subprocess module.\\n\\nThis approach was a lot less painful than the others (e.g. SWIG-based solutions, or solutions which require building with MinGW/MSYS), which I considered and experimented with. I've used the same (gpg.exe/iconv.dll) approach with systems written in other languages, e.g. C#, with equally painless results.\\n\\nP.S. It works with Python 2.4 as well as Python 2.5 and later. Not tested with other versions, though I don't foresee any problems.\\n\"},\n {'prompt': \"I need to write a Python script that can run another command line program and interact with it's stdin and stdout streams. Essentially, the Python script will read from the target command line program, intelligently respond by writing to its stdin, and then read the results from the program again. (It would do this repeatedly.)\\n\\nI've looked through the subprocess module, and I can't seem to get it to do this read/write/read/write thing that I'm looking for. Is there something else I should be trying?\\n\",\n  'completion': 'To perform such detailed interaction (when, outside of your control, the other program may be buffering its output unless it thinks it\\'s talking to a terminal) needs something like pexpect -- which in turns requires pty, a Python standard library module that (on operating systems that allow it, such as Linux and Mac OS x) implements \"pseudo-terminals\".\\n\\nLife is harder on Windows, but maybe this zipfile can help -- it\\'s supposed to be a port of pexpect to Windows (sorry, I have no Windows machine to check it on). The project in question, called wexpect, lives here.\\n'},\n {'prompt': \"I'm trying to build my first facebook app, and it seems that the python facebook (pyfacebook) wrapper is really out of date, and the most relevant functions, like stream functions, are not implemented.\\n\\nAre there any mature python frontends for facebook? If not, what's the best language for facebook development?\\n\",\n  'completion': \"The updated location of pyfacebook is on github. Plus, as arstechnica well explains:\\n\\n\\n  PyFacebook is also very easy to extend\\n  when new Facebook API methods are\\n  introduced. Each Facebook API method\\n  is described in the PyFacebook library\\n  using a simple data structure that\\n  specifies the method's name and\\n  parameter types.\\n\\n\\nso, even should you be using a pyfacebook version that doesn't yet implement some brand-new thing you need, it's easy to add said thing, as Ryan Paul shows here regarding some of the stream functions (back in April right after they were launched).\\n\"},\n {'prompt': 'Here is a simple example of a django view with a potential race condition:\\n\\n# myapp/views.py\\nfrom django.contrib.auth.models import User\\nfrom my_libs import calculate_points\\n\\ndef add_points(request):\\n    user = request.user\\n    user.points += calculate_points(user)\\n    user.save()\\n\\n\\nThe race condition should be fairly obvious: A user can make this request twice, and the application could potentially execute user = request.user simultaneously, causing one of the requests to override the other.\\n\\nSuppose the function calculate_points is relatively complicated, and makes calculations based on all kinds of weird stuff that cannot be placed in a single update and would be difficult to put in a stored procedure.\\n\\nSo here is my question: What kind of locking mechanisms are available to django, to deal with situations similar to this?\\n',\n  'completion': 'Django 1.4+ supports select_for_update, in earlier versions you may execute raw SQL queries e.g. select ... for update which depending on underlying DB will lock the row from any updates, you can do whatever you want with that row until the end of transaction. e.g.\\n\\nfrom django.db import transaction\\n\\n@transaction.commit_manually()\\ndef add_points(request):\\n    user = User.objects.select_for_update().get(id=request.user.id)\\n    # you can go back at this point if something is not right \\n    if user.points > 1000:\\n        # too many points\\n        return\\n    user.points += calculate_points(user)\\n    user.save()\\n    transaction.commit()\\n\\n'},\n {'prompt': 'In Python, how do I read in a binary file and loop over each byte of that file?\\n',\n  'completion': 'f = open(\"myfile\", \"rb\")\\ntry:\\n    byte = f.read(1)\\n    while byte != \"\":\\n        # Do stuff with byte.\\n        byte = f.read(1)\\nfinally:\\n    f.close()\\n\\n\\nBy suggestion of chrispy:\\n\\nwith open(\"myfile\", \"rb\") as f:\\n    byte = f.read(1)\\n    while byte != \"\":\\n        # Do stuff with byte.\\n        byte = f.read(1)\\n\\n\\nNote that the with statement is not available in versions of Python below 2.5. To use it in v 2.5 you\\'ll need to import it:\\n\\nfrom __future__ import with_statement\\n\\n\\nIn 2.6 this is not needed.\\n\\nIn Python 3, it\\'s a bit different. We will no longer get raw characters from the stream in byte mode but byte objects, thus we need to alter the condition:\\n\\nwith open(\"myfile\", \"rb\") as f:\\n    byte = f.read(1)\\n    while byte != b\"\":\\n        # Do stuff with byte.\\n        byte = f.read(1)\\n\\n\\nOr as benhoyt says, skip the not equal and take advantage of the fact that b\"\" evaluates to false. This makes the code compatible between 2.6 and 3.x without any changes. It would also save you from changing the condition if you go from byte mode to text or the reverse.\\n\\nwith open(\"myfile\", \"rb\") as f:\\n    byte = f.read(1)\\n    while byte:\\n        # Do stuff with byte.\\n        byte = f.read(1)\\n\\n'},\n {'prompt': 'My scenario is as follows: I have a table of data (handful of fields, less than a hundred rows) that I use extensively in my program. I also need this data to be persistent, so I save it as a CSV and load it on start-up. I choose not to use a database because every option (even SQLite) is an overkill for my humble requirement (also - I would like to be able to edit the values offline in a simple way, and nothing is simpler than notepad).\\n\\nAssume my data looks as follows (in the file it\\'s comma separated without titles, this is just an illustration):\\n\\n Row  | Name     | Year   | Priority\\n------------------------------------\\n 1    | Cat      | 1998   | 1\\n 2    | Fish     | 1998   | 2\\n 3    | Dog      | 1999   | 1 \\n 4    | Aardvark | 2000   | 1\\n 5    | Wallaby  | 2000   | 1\\n 6    | Zebra    | 2001   | 3\\n\\n\\nNotes:\\n\\n\\nRow may be a \"real\" value written to the file or just an auto-generated value that represents the row number. Either way it exists in memory.\\nNames are unique.\\n\\n\\nThings I do with the data:\\n\\n\\nLook-up a row based on either ID (iteration) or name (direct access).\\nDisplay the table in different orders based on multiple field: I need to sort it e.g. by Priority and then Year, or Year and then Priority, etc.\\nI need to count instances based on sets of parameters, e.g. how many rows have their year between 1997 and 2002, or how many rows are in 1998 and priority > 2, etc.\\n\\n\\nI know this \"cries\" for SQL...\\n\\nI\\'m trying to figure out what\\'s the best choice for data structure. Following are several choices I see:\\n\\nList of row lists:\\n\\na = []\\na.append( [1, \"Cat\", 1998, 1] )\\na.append( [2, \"Fish\", 1998, 2] )\\na.append( [3, \"Dog\", 1999, 1] )\\n...\\n\\n\\nList of column lists (there will obviously be an API for add_row etc):\\n\\na = []\\na.append( [1, 2, 3, 4, 5, 6] )\\na.append( [\"Cat\", \"Fish\", \"Dog\", \"Aardvark\", \"Wallaby\", \"Zebra\"] )\\na.append( [1998, 1998, 1999, 2000, 2000, 2001] )\\na.append( [1, 2, 1, 1, 1, 3] )\\n\\n\\nDictionary of columns lists (constants can be created to replace the string keys):\\n\\na = {}\\na[\\'ID\\'] = [1, 2, 3, 4, 5, 6]\\na[\\'Name\\'] = [\"Cat\", \"Fish\", \"Dog\", \"Aardvark\", \"Wallaby\", \"Zebra\"] \\na[\\'Year\\'] = [1998, 1998, 1999, 2000, 2000, 2001] \\na[\\'Priority\\'] = [1, 2, 1, 1, 1, 3]\\n\\n\\nDictionary with keys being tuples of (Row, Field):\\n\\nCreate constants to avoid string searching\\nNAME=1\\nYEAR=2\\nPRIORITY=3\\n\\na={}\\na[(1, NAME)] = \"Cat\"\\na[(1, YEAR)] = 1998\\na[(1, PRIORITY)] = 1\\na[(2, NAME)] = \"Fish\"\\na[(2, YEAR)] = 1998\\na[(2, PRIORITY)] = 2\\n...\\n\\n\\nAnd I\\'m sure there are other ways... However each way has disadvantages when it comes to my requirements (complex ordering and counting). \\n\\nWhat\\'s the recommended approach?\\n\\nEDIT:\\n\\nTo clarify, performance is not a major issue for me. Because the table is so small, I believe almost every operation will be in the range of milliseconds, which is not a concern for my application.\\n',\n  'completion': 'Having a \"table\" in memory that needs lookups, sorting, and arbitrary aggregation really does call out for SQL.  You said you tried SQLite, but did you realize that SQLite can use an in-memory-only database?\\n\\nconnection = sqlite3.connect(\\':memory:\\')\\n\\n\\nThen you can create/drop/query/update tables in memory with all the functionality of SQLite and no files left over when you\\'re done.  And as of Python 2.5, sqlite3 is in the standard library, so it\\'s not really \"overkill\" IMO.\\n\\nHere is a sample of how one might create and populate the database:\\n\\nimport csv\\nimport sqlite3\\n\\ndb = sqlite3.connect(\\':memory:\\')\\n\\ndef init_db(cur):\\n    cur.execute(\\'\\'\\'CREATE TABLE foo (\\n        Row INTEGER,\\n        Name TEXT,\\n        Year INTEGER,\\n        Priority INTEGER)\\'\\'\\')\\n\\ndef populate_db(cur, csv_fp):\\n    rdr = csv.reader(csv_fp)\\n    cur.executemany(\\'\\'\\'\\n        INSERT INTO foo (Row, Name, Year, Priority)\\n        VALUES (?,?,?,?)\\'\\'\\', rdr)\\n\\ncur = db.cursor()\\ninit_db(cur)\\npopulate_db(cur, open(\\'my_csv_input_file.csv\\'))\\ndb.commit()\\n\\n\\nIf you\\'d really prefer not to use SQL, you should probably use a list of dictionaries:\\n\\nlod = [ ] # \"list of dicts\"\\n\\ndef populate_lod(lod, csv_fp):\\n    rdr = csv.DictReader(csv_fp, [\\'Row\\', \\'Name\\', \\'Year\\', \\'Priority\\'])\\n    lod.extend(rdr)\\n\\ndef query_lod(lod, filter=None, sort_keys=None):\\n    if filter is not None:\\n        lod = (r for r in lod if filter(r))\\n    if sort_keys is not None:\\n        lod = sorted(lod, key=lambda r:[r[k] for k in sort_keys])\\n    else:\\n        lod = list(lod)\\n    return lod\\n\\ndef lookup_lod(lod, **kw):\\n    for row in lod:\\n        for k,v in kw.iteritems():\\n            if row[k] != str(v): break\\n        else:\\n            return row\\n    return None\\n\\n\\nTesting then yields:\\n\\n>>> lod = []\\n>>> populate_lod(lod, csv_fp)\\n>>> \\n>>> pprint(lookup_lod(lod, Row=1))\\n{\\'Name\\': \\'Cat\\', \\'Priority\\': \\'1\\', \\'Row\\': \\'1\\', \\'Year\\': \\'1998\\'}\\n>>> pprint(lookup_lod(lod, Name=\\'Aardvark\\'))\\n{\\'Name\\': \\'Aardvark\\', \\'Priority\\': \\'1\\', \\'Row\\': \\'4\\', \\'Year\\': \\'2000\\'}\\n>>> pprint(query_lod(lod, sort_keys=(\\'Priority\\', \\'Year\\')))\\n[{\\'Name\\': \\'Cat\\', \\'Priority\\': \\'1\\', \\'Row\\': \\'1\\', \\'Year\\': \\'1998\\'},\\n {\\'Name\\': \\'Dog\\', \\'Priority\\': \\'1\\', \\'Row\\': \\'3\\', \\'Year\\': \\'1999\\'},\\n {\\'Name\\': \\'Aardvark\\', \\'Priority\\': \\'1\\', \\'Row\\': \\'4\\', \\'Year\\': \\'2000\\'},\\n {\\'Name\\': \\'Wallaby\\', \\'Priority\\': \\'1\\', \\'Row\\': \\'5\\', \\'Year\\': \\'2000\\'},\\n {\\'Name\\': \\'Fish\\', \\'Priority\\': \\'2\\', \\'Row\\': \\'2\\', \\'Year\\': \\'1998\\'},\\n {\\'Name\\': \\'Zebra\\', \\'Priority\\': \\'3\\', \\'Row\\': \\'6\\', \\'Year\\': \\'2001\\'}]\\n>>> pprint(query_lod(lod, sort_keys=(\\'Year\\', \\'Priority\\')))\\n[{\\'Name\\': \\'Cat\\', \\'Priority\\': \\'1\\', \\'Row\\': \\'1\\', \\'Year\\': \\'1998\\'},\\n {\\'Name\\': \\'Fish\\', \\'Priority\\': \\'2\\', \\'Row\\': \\'2\\', \\'Year\\': \\'1998\\'},\\n {\\'Name\\': \\'Dog\\', \\'Priority\\': \\'1\\', \\'Row\\': \\'3\\', \\'Year\\': \\'1999\\'},\\n {\\'Name\\': \\'Aardvark\\', \\'Priority\\': \\'1\\', \\'Row\\': \\'4\\', \\'Year\\': \\'2000\\'},\\n {\\'Name\\': \\'Wallaby\\', \\'Priority\\': \\'1\\', \\'Row\\': \\'5\\', \\'Year\\': \\'2000\\'},\\n {\\'Name\\': \\'Zebra\\', \\'Priority\\': \\'3\\', \\'Row\\': \\'6\\', \\'Year\\': \\'2001\\'}]\\n>>> print len(query_lod(lod, lambda r:1997 <= int(r[\\'Year\\']) <= 2002))\\n6\\n>>> print len(query_lod(lod, lambda r:int(r[\\'Year\\'])==1998 and int(r[\\'Priority\\']) > 2))\\n0\\n\\n\\nPersonally I like the SQLite version better since it preserves your types better (without extra conversion code in Python) and easily grows to accommodate future requirements.  But then again, I\\'m quite comfortable with SQL, so YMMV.\\n'},\n {'prompt': 'I have some some data that I would like to visualize. Each byte of the source data roughly corresponds to a pixel value of the image.\\n\\nWhat is the easiest way to generate an image file (bitmap?) using Python?\\n',\n  'completion': \"You can create images with a list of pixel values using Pillow:\\n\\nfrom PIL import Image\\n\\nimg = Image.new('RGB', (width, height))\\nimg.putdata(my_list)\\nimg.save('image.png')\\n\\n\"},\n {'prompt': \"Suppose I have the following Event model:\\n\\nfrom django.db import models\\nimport datetime\\n\\nclass Event(models.Model):\\n    date_start = models.DateField()\\n    date_end = models.DateField()\\n\\n    def is_over(self):\\n        return datetime.date.today() > self.date_end\\n\\n\\nI want to test Event.is_over() by creating an Event that ends in the future (today + 1 or something), and stubbing the date and time so the system thinks we've reached that future date.\\n\\nI'd like to be able to stub ALL system time objects as far as python is concerned. This includes datetime.date.today(), datetime.datetime.now(), and any other standard date/time objects.\\n\\nWhat's the standard way to do this?\\n\",\n  'completion': \"EDIT: Since my answer is the accepted answer here I'm updating it to let everyone know a better way has been created in the meantime, the freezegun library: https://pypi.python.org/pypi/freezegun. I use this in all my projects when I want to influence time in tests. Have a look at it.\\n\\nOriginal answer:\\n\\nReplacing internal stuff like this is always dangerous because it can have nasty side effects. So what you indeed want, is to have the monkey patching be as local as possible.\\n\\nWe use Michael Foord's excellent mock library: http://www.voidspace.org.uk/python/mock/ that has a @patch decorator which patches certain functionality, but the monkey patch only lives in the scope of the testing function, and everything is automatically restored after the function runs out of its scope.\\n\\nThe only problem is that the internal datetime module is implemented in C, so by default you won't be able to monkey patch it. We fixed this by making our own simple implementation which can be mocked.\\n\\nThe total solution is something like this (the example is a validator function used within a Django project to validate that a date is in the future). Mind you I took this from a project but took out the non-important stuff, so things may not actually work when copy-pasting this, but you get the idea, I hope :)\\n\\nFirst we define our own very simple implementation of datetime.date.today in a file called utils/date.py:\\n\\nimport datetime\\n\\ndef today():\\n    return datetime.date.today()\\n\\n\\nThen we create the unittest for this validator in tests.py:\\n\\nimport datetime\\nimport mock\\nfrom unittest2 import TestCase\\n\\nfrom django.core.exceptions import ValidationError\\n\\nfrom .. import validators\\n\\nclass ValidationTests(TestCase):\\n    @mock.patch('utils.date.today')\\n    def test_validate_future_date(self, today_mock):\\n        # Pin python's today to returning the same date\\n        # always so we can actually keep on unit testing in the future :)\\n        today_mock.return_value = datetime.date(2010, 1, 1)\\n\\n        # A future date should work\\n        validators.validate_future_date(datetime.date(2010, 1, 2))\\n\\n        # The mocked today's date should fail\\n        with self.assertRaises(ValidationError) as e:\\n            validators.validate_future_date(datetime.date(2010, 1, 1))\\n        self.assertEquals([u'Date should be in the future.'], e.exception.messages)\\n\\n        # Date in the past should also fail\\n        with self.assertRaises(ValidationError) as e:\\n            validators.validate_future_date(datetime.date(2009, 12, 31))\\n        self.assertEquals([u'Date should be in the future.'], e.exception.messages)\\n\\n\\nThe final implementation looks like this:\\n\\nfrom django.utils.translation import ugettext_lazy as _\\nfrom django.core.exceptions import ValidationError\\n\\nfrom utils import date\\n\\ndef validate_future_date(value):\\n    if value <= date.today():\\n        raise ValidationError(_('Date should be in the future.'))\\n\\n\\nHope this helps\\n\"},\n {'prompt': 'Is there a library for using MS Access database in python? The win32 module is not as easy as the MySQL library. Is there a simpler way to use MS Access with Python?\\n',\n  'completion': \"Depending on what you want to do, pyodbc might be what you are looking for.\\n\\n\\nimport pyodbc\\ndb_file = r'''C:\\\\x.mdb'''\\nuser = 'admin'\\npassword = ''\\n\\nodbc_conn_str = 'DRIVER={Microsoft Access Driver (*.mdb)};DBQ=%s;UID=%s;PWD=%s' %\\\\\\n                (db_file, user, password)\\n# Or, for newer versions of the Access drivers:\\nodbc_conn_str = 'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=%s;UID=%s;PWD=%s' %\\\\\\n                (db_file, user, password)\\n\\nconn = pyodbc.connect(odbc_conn_str)\\n\\n\"},\n {'prompt': 'I have a function that take an argument which can be either a single item or a double item:\\n\\ndef iterable(arg)\\n    if #arg is an iterable:\\n        print \"yes\"\\n    else:\\n        print \"no\"\\n\\n\\nso that:\\n\\n\\n>>> iterable( (\"f\",\"f\") )\\nyes\\n\\n>>> iterable( [\"f\",\"f\"] )\\nyes\\n\\n>>> iterable(\"ff\")\\nno\\n\\n\\nThe problem is that string is technically iterable, so I can\\'t just catch the ValueError when trying arg[1]. I don\\'t want to use isinstance(), because that\\'s not good practice (or so I\\'m told).\\n',\n  'completion': 'Use isinstance (I don\\'t see why it\\'s bad practice)\\n\\nimport types\\nif not isinstance(arg, types.StringTypes):\\n\\n\\nNote the use of StringTypes.  It ensures that we don\\'t forget about some obscure type of string.\\n\\nOn the upside, this also works for derived string classes.\\n\\nclass MyString(str):\\n    pass\\n\\nisinstance(MyString(\"  \"), types.StringTypes) # true\\n\\n\\nAlso, you might want to have a look at this previous question.\\n\\nCheers.\\n'},\n {'prompt': 'I was just wondering if anyone knew of a way to change variable names based off of a for loop for something like this:\\n\\nfor i in range(3)\\n     group+i=self.getGroup(selected, header+i)\\n\\n\\nso that the names of the variables change to accomodate the data.  Thanks!\\n\\n~Sam\\n',\n  'completion': 'You probably want a dict instead of separate variables.  For example\\n\\nd = {}\\nfor i in range(3):\\n    d[\"group\" + str(i)] = self.getGroup(selected, header+i)\\n\\n\\nIf you insist on actually modifying local variables, you could use the locals function:\\n\\nfor i in range(3):\\n    locals()[\"group\"+str(i)] = self.getGroup(selected, header+i)\\n\\n\\nOn the other hand, if what you actually want is to modify instance variables of the class you\\'re in, then you can use the setattr function\\n\\nfor i in group(3):\\n    setattr(self, \"group\"+str(i), self.getGroup(selected, header+i)\\n\\n\\nAnd of course, I\\'m assuming with all of these examples that you don\\'t just want a list:\\n\\ngroups = [self.getGroup(i,header+i) for i in range(3)]\\n\\n'},\n {'prompt': 'I found this Perl script while migrating my SQLite database to mysql\\n\\nI was wondering (since I don\\'t know Perl) how could one rewrite this in Python?\\n\\nBonus points for the shortest (code) answer :)\\n\\nedit: sorry I meant shortest code, not strictly shortest answer\\n\\n#! /usr/bin/perl\\n\\nwhile ($line = <>){\\n    if (($line !~  /BEGIN TRANSACTION/) && ($line !~ /COMMIT/) && ($line !~ /sqlite_sequence/) && ($line !~ /CREATE UNIQUE INDEX/)){\\n\\n        if ($line =~ /CREATE TABLE \\\\\"([a-z_]*)\\\\\"(.*)/){\\n                $name = $1;\\n                $sub = $2;\\n                $sub =~ s/\\\\\"//g; #\"\\n                $line = \"DROP TABLE IF EXISTS $name;\\\\nCREATE TABLE IF NOT EXISTS $name$sub\\\\n\";\\n        }\\n        elsif ($line =~ /INSERT INTO \\\\\"([a-z_]*)\\\\\"(.*)/){\\n                $line = \"INSERT INTO $1$2\\\\n\";\\n                $line =~ s/\\\\\"/\\\\\\\\\\\\\"/g; #\"\\n                $line =~ s/\\\\\"/\\\\\\'/g; #\"\\n        }else{\\n                $line =~ s/\\\\\\'\\\\\\'/\\\\\\\\\\\\\\'/g; #\\'\\n        }\\n        $line =~ s/([^\\\\\\\\\\'])\\\\\\'t\\\\\\'(.)/$1THIS_IS_TRUE$2/g; #\\'\\n        $line =~ s/THIS_IS_TRUE/1/g;\\n        $line =~ s/([^\\\\\\\\\\'])\\\\\\'f\\\\\\'(.)/$1THIS_IS_FALSE$2/g; #\\'\\n        $line =~ s/THIS_IS_FALSE/0/g;\\n        $line =~ s/AUTOINCREMENT/AUTO_INCREMENT/g;\\n        print $line;\\n    }\\n}\\n\\n\\nSome additional code was necessary to successfully migrate the sqlite database (handles one line Create table statements, foreign keys, fixes a bug in the original program that converted empty fields \\'\\' to \\\\\\'. \\n\\nI posted the code on the migrating my SQLite database to mysql Question\\n',\n  'completion': 'Here\\'s a pretty literal translation with just the minimum of obvious style changes (putting all code into a function, using string rather than re operations where possible).\\n\\nimport re, fileinput\\n\\ndef main():\\n  for line in fileinput.input():\\n    process = False\\n    for nope in (\\'BEGIN TRANSACTION\\',\\'COMMIT\\',\\n                 \\'sqlite_sequence\\',\\'CREATE UNIQUE INDEX\\'):\\n      if nope in line: break\\n    else:\\n      process = True\\n    if not process: continue\\n    m = re.search(\\'CREATE TABLE \"([a-z_]*)\"(.*)\\', line)\\n    if m:\\n      name, sub = m.groups()\\n      line = \\'\\'\\'DROP TABLE IF EXISTS %(name)s;\\nCREATE TABLE IF NOT EXISTS %(name)s%(sub)s\\n\\'\\'\\'\\n      line = line % dict(name=name, sub=sub)\\n    else:\\n      m = re.search(\\'INSERT INTO \"([a-z_]*)\"(.*)\\', line)\\n      if m:\\n        line = \\'INSERT INTO %s%s\\\\n\\' % m.groups()\\n        line = line.replace(\\'\"\\', r\\'\\\\\"\\')\\n        line = line.replace(\\'\"\\', \"\\'\")\\n    line = re.sub(r\"([^\\'])\\'t\\'(.)\", r\"\\\\1THIS_IS_TRUE\\\\2\", line)\\n    line = line.replace(\\'THIS_IS_TRUE\\', \\'1\\')\\n    line = re.sub(r\"([^\\'])\\'f\\'(.)\", r\"\\\\1THIS_IS_FALSE\\\\2\", line)\\n    line = line.replace(\\'THIS_IS_FALSE\\', \\'0\\')\\n    line = line.replace(\\'AUTOINCREMENT\\', \\'AUTO_INCREMENT\\')\\n    print line,\\n\\nmain()\\n\\n'},\n {'prompt': 'The source code behind EveryBlock.com, a major Django-powered website founded by Adrian Holovaty, one of the co-Benevolent Dictators For Life of the Django framework, was recently open-sourced. The source is available as tarballs and on github.\\n\\nThis large body of code from an originator of Django should have some interesting features, patterns, tricks, or techniques. What is your favorite?\\n',\n  'completion': \"Some of the things that I noticed:\\n\\n\\nThe publishing system ebpub uses custom django Authentication and user system, hence cannot use django-admin.\\nAltho' it uses Relational Database PostgreSQL, the data items for various data entries are stored in a single table, with types of fields defined in another table, for scalability. (An alternative to key-value pair storing systems, CouchDB)\\nThe system uses custom database backend, so that such a modified form database can accessed with convenience in views.\\nThe blog application is very small and sweet; Just 1 Entry model and no views, Only generic views.\\nSome of the bots present could be used for multiple purposes, with little tweaking.\\n\\n\"},\n {'prompt': \"I have been doing active development in C# for several years now.  I primarily build enterprise application and in house frameworks on the .NET stack.\\n\\nI've never had the need to use any other mainstream high level languages besides C# for my tasks, since .NET is the standard platform we use.\\n\\nThere are some legacy Python applications that I have been asked to support going forward, I have no exposure to python and dynamic languages in general(although I've done a fair bit of JavaScript).\\n\\nI was hoping to get some guidance/advise to aid in how to go about learning a language like python for the statically typed mind.\\n\\nEDIT: Using IronPython is not an option!\\n\",\n  'completion': \"Foord and Muirhead's IronPython in Action is an amazingly good book, perfectly suitable for teaching Python to .NET folks as well as teaching .NET to Python folks. I may be biased, as I was a tech reviewer and Foord is a friend, but I've had other cases in the past where a friend wrote a book and I tech reviewed it -- and ended up deciding the book was just wrong and publicly saying so (way to lose friends, but, I just can't tell a lie, not where Python is concerned at least!-)\\n\\nEdit: If you're forbidden from moving to IronPython (which would probably support your legacy apps just fine, btw), there are better answers: Mark Pilgrim's Dive into Python is often considered the best Python intro for the experienced developer, and my own Python in a Nutshell has been praised as the fastest way onboard for superstar developers. I am of course biased in favor of these -- Mark is a colleague, and my wife was a key tech editor for his book (and my own as well), and obviously I'm biased in favor of my own book too;-). But then, I do tend to be biased towards a lot of the best Python books, as I've either had a hand in their editing, or am friends with their authors, or both;-).\\n\"},\n {'prompt': 'Which are the user friendly frameworks for building personal sites? Specially if that comes with little programming knowledge. And integrated jquery will be great. python or php based framework will do better.\\n\\nI tried wordpress and joomla! But those are far more complex for a simple personal site with personal blogging, live commenting, twitting, keeping personal projects and resume etc.\\n\\nPlease suggest me. Thanks in advance.\\n',\n  'completion': '\"a simple personal site with personal blogging, live commenting, twitting, keeping personal projects and resume etc.\"\\n\\nIn my opinion, a personal site means a single author.  You don\\'t have a lot of really \"dynamic\" content.  How many times a day will  you update a person site?  Once?  Twice?\\n\\nA blog, comment, twitter things change relatively slowly -- once or twice a day.\\n\\nPersonal projects, resume, etc. change even more slowly.\\n\\nNone of this requires dynamic content creation.  A database is often more trouble than help.  Most of it is simply unstructured text.  Consequently, consider using a toolset to build static HTML and simply FTP that to a server.  \\n\\nConsider using Sphinx to build static content.  You can generate a mountain of content, maintain it, and upload it periodically.  You don\\'t need to know HTML because you write in RST.  It\\'s easy to generate hundreds of pages of content and adjust the look and feel.\\n\\nBest of all, it\\'s very, very lightweight.  You can easily get by with zero code.  Or, if you want to add directives or interpreted text roles, you can do a little coding.\\n'},\n {'prompt': 'The following snippet of code doesn\\'t seem to affect the system clipboard at all:\\n\\nclipboard = QtGui.QApplication.clipboard()\\nclipboard.setText(text)\\n\\n\\nAccording to the Qt documentation, this is how you copy text to clipboard, \\n\\nWhy isn\\'t it working?\\n\\nGoogling turned this up.\\n\\nIt suggests adding this after the above code:\\n\\nevent = QtCore.QEvent(QtCore.QEvent.Clipboard)\\napp.sendEvent(clipboard, event)\\n\\n\\nBut this one behaves odd: it only copies the text to the clipboard after the program exits. Plus, some people in that link reported that this doesn\\'t work with linux.\\n\\nUPDATE:\\n\\nNevermind, I was doing something wrong else where, instead of binding the copy slot to the copy button, I connected it to the \"quit\" button.\\n',\n  'completion': \"I know you are not using Windows, but maybe this will give you some ideas... I used this in a PyQt program to copy URLs to the clipboard:\\n\\nimport win32clipboard\\n\\ns = 'copy this to the clipboard'\\ntry:\\n    win32clipboard.OpenClipboard()\\n    win32clipboard.EmptyClipboard()\\n    win32clipboard.SetClipboardText(s)\\n    win32clipboard.CloseClipboard()\\nexcept:\\n    print 'Could not copy clipboard data.'\\n\\n\"},\n {'prompt': 'How do I serve a dynamically generated image in Django? \\n\\nI have an html tag\\n\\n<html>\\n...\\n    <img src=\"images/dynamic_chart.png\" />\\n...\\n</html>\\n\\n\\nlinked up to this request handler, which creates an in-memory image\\n\\ndef chart(request):\\n    img = Image.new(\"RGB\", (300,300), \"#FFFFFF\")\\n    data = [(i,randint(100,200)) for i in range(0,300,10)]\\n    draw = ImageDraw.Draw(img)\\n    draw.polygon(data, fill=\"#000000\")\\n    # now what?\\n    return HttpResponse(output)\\n\\n\\nI also plan to change the requests to AJAX, and add some sort of caching mechanism, but my understanding is that wouldn\\'t affect this part of the solution.\\n',\n  'completion': 'I assume you\\'re using PIL (Python Imaging Library). You need to replace your last line with (for example, if you want to serve a PNG image):\\n\\nresponse = HttpResponse(mimetype=\"image/png\")\\nimg.save(response, \"PNG\")\\nreturn response\\n\\n\\nSee here for more information.\\n'},\n {'prompt': 'Is there any programming language (or type system) in which you could express the following Python-functions in a statically typed and type-safe way (without having to use casts, runtime-checks etc)?\\n\\n#1:\\n\\n# My function - What would its type be? \\ndef Apply(x):\\n    return x(x)\\n\\n# Example usage\\nprint Apply(lambda _: 42)\\n\\n\\n#2:\\n\\nwhite = None\\nblack = None\\n\\ndef White():\\n    for x in xrange(1, 10):\\n        print (\"White move #%s\" % x)\\n        yield black\\n\\ndef Black():\\n    for x in xrange(1, 10):\\n        print (\"Black move #%s\" % x)\\n        yield white\\n\\nwhite = White()\\nblack = Black()\\n\\n# What would the type of the iterator objects be?\\nfor it in white:\\n    it = it.next()\\n\\n',\n  'completion': '1#\\nThis is not typeable with a finite type. This means that very few (if any) programming languages will be able to type this.\\n\\nHowever, as you have demonstrated, there is a specific type for x that allows the function to be typed:\\n\\nx :: t -> B\\n\\n\\nWhere B is some concrete type. This results in apply being typed as:\\n\\napply :: (t -> B) -> B\\n\\n\\nNote that Hindley-Milner will not derive this type.\\n\\n2#\\nThis is easy to represent in Haskell (left as an exercise to the reader...)\\n'},\n {'prompt': \"I want to do something after I have rendered the view using \\n\\nreturn render_to_response()\\n\\n\\nAre signals the only way to do this? Do I need to write a custom signal or does request_finished give me enough information? Basically I need to know what page was rendered, and then do an action in response to that.\\n\\nThanks.\\n\\nUPDATE FROM COMMENTS: I don't want to hold up the rendering of the page, so I want to render the page first and then do the action.\\n\",\n  'completion': \"You spawn a separate thread and have it do the action.\\n\\nt = threading.Thread(target=do_my_action, args=[my_argument])\\n# We want the program to wait on this thread before shutting down.\\nt.setDaemon(False)\\nt.start()\\n\\n\\nThis will cause 'do_my_action(my_argument)' to be executed in a second thread which will keep working even after you send your Django response and terminate the initial thread. For example it could send an email without delaying the response.\\n\"},\n {'prompt': 'Best practices aside, is there a compelling reason not to do this?\\n\\nI\\'m writing a post-commit hook for use with a Google Code project, which provides commit data via a JSON object.  GC provides an HMAC authentication token along with the request (outside the JSON data), so by validating that token I gain high confidence that the JSON data is both benign (as there\\'s little point in distrusting Google) and valid.\\n\\nMy own (brief) investigations suggest that JSON happens to be completely valid Python, with the exception of the \"\\\\/\" escape sequence â\\x80\\x94 which GC doesn\\'t appear to generate.\\n\\nSo, as I\\'m working with Python 2.4 (i.e. no json module), eval() is looking really tempting.\\n\\nEdit: For the record, I am very much not asking if this is a good idea.  I\\'m quite aware that it isn\\'t, and I very much doubt I\\'ll ever use this technique for any future projects even if I end up using it for this one.  I just wanted to make sure that I know what kind of trouble I\\'ll run into if I do.  :-)\\n',\n  'completion': 'If you\\'re comfortable with your script working fine for a while, and then randomly failing on some obscure edge case, I would go with eval.\\n\\nIf it\\'s important that your code be robust, I would take the time to add simplejson. You don\\'t need the C portion for speedups, so it really shouldn\\'t be hard to dump a few .py files into a directory somewhere.\\n\\nAs an example of something that might bite you, JSON uses Unicode and simplejson returns Unicode, whereas eval returns str:\\n\\n>>> simplejson.loads(\\'{\"a\":1, \"b\":2}\\')\\n{u\\'a\\': 1, u\\'b\\': 2}\\n>>> eval(\\'{\"a\":1, \"b\":2}\\')\\n{\\'a\\': 1, \\'b\\': 2}\\n\\n\\nEdit: a better example of where eval() behaves differently:\\n\\n>>> simplejson.loads(\\'{\"X\": \"\\\\uabcd\"}\\')\\n{u\\'X\\': u\\'\\\\uabcd\\'}\\n>>> eval(\\'{\"X\": \"\\\\uabcd\"}\\')\\n{\\'X\\': \\'\\\\\\\\uabcd\\'}\\n>>> simplejson.loads(\\'{\"X\": \"\\\\uabcd\"}\\') == eval(\\'{\"X\": \"\\\\uabcd\"}\\')\\nFalse\\n\\n\\nEdit 2: saw yet another problem today pointed out by SilentGhost: eval doesn\\'t handle true -> True, false -> False, null -> None correctly.\\n\\n>>> simplejson.loads(\\'[false, true, null]\\')\\n[False, True, None]\\n>>> eval(\\'[false, true, null]\\')\\nTraceback (most recent call last):\\n  File \"<interactive input>\", line 1, in <module>\\n  File \"<string>\", line 1, in <module>\\nNameError: name \\'false\\' is not defined\\n>>>\\n\\n'},\n {'prompt': \"What are all the special (magic) methods in Python? The __xxx__ methods, that is.\\n\\nI'm often looking for a way to override something which I know is possible to do through one of these methods, but I'm having a hard time to find how since as far as I can tell there is no definitive list of these methods, PLUS their names are not really Google friendly. So I think having a list of those here on SO would be a good idea.\\n\",\n  'completion': 'At the python level, most of them are documented in the language reference. At the C level, you can find it under the object protocol section (strictly speaking, you only have a subset here, though).\\n'},\n {'prompt': 'Is there a FFT-based 2D cross-correlation or convolution function built into scipy (or another popular library)?\\n\\nThere are functions like these:\\n\\n\\nscipy.signal.correlate2d - \"the direct method implemented by convolveND will be\\nslow for large data\"\\nscipy.ndimage.correlate - \"The array is correlated with the given kernel using\\nexact calculation (i.e. not FFT).\"\\nscipy.fftpack.convolve.convolve, which I don\\'t really understand, but seems wrong\\n\\n\\nnumarray had a correlate2d() function with an fft=True switch, but I guess numarray was folded\\ninto numpy, and I can\\'t find if this function was included.\\n',\n  'completion': \"I found scipy.signal.fftconvolve, as also pointed out by magnus, but didn't realize at the time that it's n-dimensional.  Since it's built-in and produces the right values, it seems like the ideal solution.\\n\\nFrom Example of 2D Convolution:\\n\\nIn [1]: a = asarray([[ 1, 2, 3],\\n   ...:              [ 4, 5, 6],\\n   ...:              [ 7, 8, 9]])\\n\\nIn [2]: b = asarray([[-1,-2,-1],\\n   ...:              [ 0, 0, 0],\\n   ...:              [ 1, 2, 1]])\\n\\nIn [3]: scipy.signal.fftconvolve(a, b, mode = 'same')\\nOut[3]: \\narray([[-13., -20., -17.],\\n       [-18., -24., -18.],\\n       [ 13.,  20.,  17.]])\\n\\n\\nCorrect!  The STSCI version, on the other hand, requires some extra work to make the boundaries correct?\\n\\nIn [4]: stsci.convolve2d(a, b, fft = True)\\nOut[4]: \\narray([[-12., -12., -12.],\\n       [-24., -24., -24.],\\n       [-12., -12., -12.]])\\n\\n\\n(The STSCI method also requires compiling, which I was unsuccessful with (I just commented out the non-python parts), has some bugs like this and modifying the inputs ([1, 2] becomes [[1, 2]]), etc.  So I changed my accepted answer to the built-in fftconvolve() function.)\\n\\nCorrelation, of course, is the same thing as convolution, but with one input reversed:\\n\\nIn [5]: a\\nOut[5]: \\narray([[3, 0, 0],\\n       [2, 0, 0],\\n       [1, 0, 0]])\\n\\nIn [6]: b\\nOut[6]: \\narray([[3, 2, 1],\\n       [0, 0, 0],\\n       [0, 0, 0]])\\n\\nIn [7]: scipy.signal.fftconvolve(a, b[::-1, ::-1])\\nOut[7]: \\narray([[ 0., -0.,  0.,  0.,  0.],\\n       [ 0., -0.,  0.,  0.,  0.],\\n       [ 3.,  6.,  9.,  0.,  0.],\\n       [ 2.,  4.,  6.,  0.,  0.],\\n       [ 1.,  2.,  3.,  0.,  0.]])\\n\\nIn [8]: scipy.signal.correlate2d(a, b)\\nOut[8]: \\narray([[0, 0, 0, 0, 0],\\n       [0, 0, 0, 0, 0],\\n       [3, 6, 9, 0, 0],\\n       [2, 4, 6, 0, 0],\\n       [1, 2, 3, 0, 0]])\\n\\n\\nand the latest revision has been sped up by using power-of-two sizes internally (and then I sped it up more by using real FFT for real input and using 5-smooth lengths instead of powers of 2  :D ).\\n\"},\n {'prompt': \"I want to build a bot that basically does the following:\\n\\n\\nListens to the room and interacts with users and encourages them to PM the bot.\\nOnce a user has PMed the bot engage with the client using various AI techniques. \\n\\n\\nShould I just use the IRC library or Sockets in python or do I need more of a bot framework.\\n\\nWhat would you do?\\n\\nThanks!\\n\\nHere is the code I'm currently using, however, I haven't gotten it to work.\\n\\n#!/usr/bin/python \\nimport socket\\nnetwork = 'holmes.freenet.net'\\nport = 6667\\nirc = socket.socket ( socket.AF_INET, socket.SOCK_STREAM )\\nirc.connect ( ( network, port ) )\\nirc.send ( 'NICK PyIRC\\\\r\\\\n' )\\nirc.send ( 'USER PyIRC PyIRC PyIRC :Python IRC\\\\r\\\\n' )\\nirc.send ( 'JOIN #pyirc\\\\r\\\\n' )\\nirc.send ( 'PRIVMSG #pyirc :Can you hear me?\\\\r\\\\n' )\\nirc.send ( 'PART #pyirc\\\\r\\\\n' )\\nirc.send ( 'QUIT\\\\r\\\\n' )\\nirc.close()\\n\\n\",\n  'completion': 'Use Twisted or Asynchat if you want to have a sane design. It is possible to just do it with sockets but why bother doing it from scratch?\\n'},\n {'prompt': 'I have seen a couple of other posts on similar error message but couldn\\'t find a solution which would fix it in my case.\\n\\nI dabbled a bit with TkInter and created a very simple UI. The code follows-\\n\\nfrom string import *\\nfrom Tkinter import *\\nimport tkMessageBox\\n\\nroot=Tk()\\nvid = IntVar()\\n\\ndef grabText(event):\\n    if entryBox.get().strip()==\"\":\\n        tkMessageBox.showerror(\"Error\", \"Please enter text\")\\n    else:\\n        print entryBox.get().strip()    \\n\\nroot.title(\"My Sample\")\\nroot.maxsize(width=550, height=200)\\nroot.minsize(width=550, height=200)\\nroot.resizable(width=NO, height=NO)    \\n\\nlabel=Label(root, text = \"Enter text:\").grid(row=2,column=0,sticky=W)\\nentryBox=Entry(root,width=60).grid(row=2, column=1,sticky=W)\\ngrabBtn=Button(root, text=\"Grab\")\\ngrabBtn.grid(row=8, column=1)\\ngrabBtn.bind(\\'<Button-1>\\', grabText)\\n\\nroot.mainloop()\\n\\n\\nI get the UI up and running. When I click on the Grab button, I get the following error on the console:\\n\\nC:\\\\Python25>python.exe myFiles\\\\testBed.py\\nException in Tkinter callback\\nTraceback (most recent call last):\\n  File \"C:\\\\Python25\\\\lib\\\\lib-tk\\\\Tkinter.py\", line 1403, in __call__\\n    return self.func(*args)\\n  File \"myFiles\\\\testBed.py\", line 10, in grabText\\n    if entryBox.get().strip()==\"\":\\nAttributeError: \\'NoneType\\' object has no attribute \\'get\\'\\n\\n\\nThe error traces back to Tkinter.py.\\n\\nI\\'m sure some one might have dealt with this before. Any help is appreciated.\\n',\n  'completion': \"The grid (and pack, and place) function of the Entry object (and of all other widgets) returns None. In python when you do a().b(), the result of the expression is whatever b() returns, therefore Entry(...).grid(...) will return None. \\n\\nYou should split that onto two lines, like this:\\n\\nentryBox = Entry(root, width=60)\\nentryBox.grid(row=2, column=1, sticky=W)\\n\\n\\nThat way, you get your Entry reference stored in entryBox, and it's laid out like you expect. This has a bonus side effect of making your layout easier to understand and maintain, if you collect all of your grid and/or pack statements in blocks. \\n\"},\n {'prompt': 'Ok I know you can use the dir() method to list everything in a module, but is there any way to see only the functions that are defined in that module?  For example, assume my module looks like this:\\n\\nfrom datetime import date, datetime\\n\\ndef test():\\n    return \"This is a real method\"\\n\\n\\nEven if i use inspect() to filter out the builtins, I\\'m still left with anything that was imported.  E.g I\\'ll see:\\n\\n[\\'date\\', \\'datetime\\', \\'test\\']\\n\\nIs there any way to exclude imports?  Or another way to find out what\\'s defined in a module?\\n',\n  'completion': \"Are you looking for something like this?\\n\\nimport sys, inspect\\n\\ndef is_mod_function(mod, func):\\n    return inspect.isfunction(func) and inspect.getmodule(func) == mod\\n\\ndef list_functions(mod):\\n    return [func.__name__ for func in mod.__dict__.itervalues() \\n            if is_mod_function(mod, func)]\\n\\n\\nprint 'functions in current module:\\\\n', list_functions(sys.modules[__name__])\\nprint 'functions in inspect module:\\\\n', list_functions(inspect)\\n\\n\\nEDIT: Changed variable names from 'meth' to 'func' to avoid confusion (we're dealing with functions, not methods, here).\\n\"},\n {'prompt': \"What's going on here?  I'm trying to create a list of functions:\\n\\ndef f(a,b):\\n    return a*b\\n\\nfuncs = []\\n\\nfor i in range(0,10):\\n    funcs.append(lambda x:f(i,x))\\n\\n\\nThis isn't doing what I expect.  I would expect the list to act like this:\\n\\nfuncs[3](3) = 9\\nfuncs[0](5) = 0\\n\\n\\nBut all the functions in the list seem to be identical, and be setting the fixed value to be 9:\\n\\nfuncs[3](3) = 27\\nfuncs[3](1) = 9\\n\\nfuncs[2](6) = 54\\n\\n\\nAny ideas?\\n\",\n  'completion': \"lambdas in python are closures.... the arguments you give it aren't going to be evaluated until the lambda is evaluated.  At that time, i=9 regardless, because your iteration is finished.\\n\\nThe behavior you're looking for can be achieved with functools.partial\\n\\nimport functools\\n\\ndef f(a,b):\\n    return a*b\\n\\nfuncs = []\\n\\nfor i in range(0,10):\\n    funcs.append(functools.partial(f,i))\\n\\n\"},\n {'prompt': 'I\\'m wondering if Python has anything like the C# anonymous classes feature. To clarify, here\\'s a sample C# snippet:\\n\\nvar foo = new { x = 1, y = 2 };\\nvar bar = new { y = 2, x = 1 };\\nfoo.Equals(bar); // \"true\"\\n\\n\\nIn Python, I would imagine something like this:\\n\\nfoo = record(x = 1, y = 2)\\nbar = record(y = 2, x = 1)\\nfoo == bar  # true\\n\\n\\nThe specific requirement is being able to create an object with specified fields in expression context (e.g. usable in lambdas and other places where statements aren\\'t allowed), with no additional external declarations, and ability to access individual components by name via the normal member access syntax foo.bar. The created object should also implement structural comparison by component names  (not by position, as tuples do).\\n\\nIn particular: tuples isn\\'t it because their components are not named; classes isn\\'t it because they require a declaration; dicts isn\\'t it because they have undesired foo[\"bar\"] syntax to access components.\\n\\nnamedtuple isn\\'t it, because it still requires a name even if you define the type inline, and the comparison is position-based, not name-based. In particular:\\n\\n def foo(): return namedtuple(\"Foo\", \"x y\")(x = 1, y = 2)\\n def bar(): return namedtuple(\"Foo\", \"y x\")(x = 1, y = 2)\\n foo() == bar()   # False because fields are compared in order, and not by name\\n                  # True would be desired instead\\n\\n\\nI know how to write such a thing in Python if needed. But I would like to know if there\\'s anything like that in the Python standard library, or any popular third-party libraries.\\n\\n[EDIT]\\n\\nJust for the sake of it, here\\'s a single-expression solution that combines two very informative answers by Ken and alanlcode, yielding structural equality without any extra outside declarations:\\n\\ntype(\"\", (), { \\\\\\n    \"__init__\": (lambda self, **kwargs: self.__dict__.update(kwargs)), \\\\\\n    \"__eq__\": (lambda self, other: self.__dict__ == other.__dict__) } \\\\\\n)(x = 1, y = 2)\\n\\n\\nTechnically, it satisfies all the requirements of the question, but I sincerely hope that no-one ever uses it (I definitely won\\'t).\\n',\n  'completion': \"The pythonic way would be to use a dict:\\n\\n>>> foo = dict(x=1, y=2)\\n>>> bar = dict(y=2, x=1)\\n>>> foo == bar\\nTrue\\n\\n\\nMeets all your requirements except that you still have to do foo['x'] instead of foo.x. \\n\\nIf that's a problem, you could easily define a class such as:\\n\\nclass Bunch(object):\\n    def __init__(self, **kwds):\\n        self.__dict__.update(kwds)\\n\\n    def __eq__(self, other):\\n        return self.__dict__ == other.__dict__\\n\\n\\nOr, a nice and short one\\n\\nclass Bunch(dict):\\n    __getattr__, __setattr__ = dict.get, dict.__setitem__\\n\\n\\n(but note that this second one has problems as Alex points out in his comment!)\\n\"},\n {'prompt': \"I can't find a good clean way to lock a critical section in Django.  I could use a lock or semaphore but the python implementation is for threads only, so if the production server forks then those will not be respected.  Does anyone know of a way (I am thinking posix semaphores right now) to guarantee a lock across processes, or barring that a way to stop a Django server from forking.\\n\",\n  'completion': 'If you use RDBMS, you can use its \"LOCK\" mechanism.\\nFor example, while one \"SELECT FOR UPDATE\" transaction locks a row, the other \"SELECT FOR UPDATE\" transactions with the row must wait.\\n\\n# You can use any Python DB API.\\n[SQL] BEGIN;\\n\\n[SQL] SELECT col_name FROM table_name where id = 1 FOR UPDATE;\\n\\n[Process some python code]\\n\\n[SQL] COMMIT;\\n\\n'},\n {'prompt': \"I'm looking for a documentation generator for Python. I'm familiar with javadoc, and I  tried Doxygen, but it seems quite unfit and counter-intuitive for Python.\\n\\nAny ideas?\\n\\nEDIT: Apart from the excellent answers below, you can also consult wikipedia's exhaustive Comparison of documentation generators.\\n\",\n  'completion': 'The classic tool for API doc is epydoc. It handles javadoc, docstrings, etc... But I find API docs tools to be quite poor. I much prefer tool which focus around the documentation itself, and enables to inject additional documentation extracted from the code. Sphinx is perfect for this job. It can generates html and pdf, you can include automatically extracted docstring from code, it does syntax highlighting, etc... A strong point of sphinx is that it is done by someone who knows something about web design, and does not look like a**. matplotlib website and doc is generated entirely from sphinx, with default values. It looks much nicer than anything you will get with epydoc/doxygen. And there is an integrated search engine in javascript\\n'},\n {'prompt': 'For my debugging needs, pdb is pretty good. However, it would be much cooler (and helpful) if I could go into ipython. Is this thing possible?\\n',\n  'completion': \"There is an ipdb project which embeds iPython into the standard pdb, so you can just do:\\n\\nimport ipdb; ipdb.set_trace()\\n\\n\\nIt's installable via the usual easy_install ipdb.\\n\\nipdb is pretty short, so instead of easy_installing you can also create a file ipdb.py somewhere on your Python path and paste the following into the file:\\n\\nimport sys\\nfrom IPython.Debugger import Pdb\\nfrom IPython.Shell import IPShell\\nfrom IPython import ipapi\\n\\nshell = IPShell(argv=[''])\\n\\ndef set_trace():\\n    ip = ipapi.get()\\n    def_colors = ip.options.colors\\n    Pdb(def_colors).set_trace(sys._getframe().f_back)\\n\\n\"},\n {'prompt': 'When packaging a Python package with a setup.py that uses the setuptools:\\n\\nfrom setuptools import setup\\n...\\n\\n\\nthe source distribution created by:\\n\\npython setup.py sdist\\n\\n\\nnot only includes, as usual, the files specified in MANIFEST.in, but it also, gratuitously, includes all of the files that Subversion lists as being version controlled beneath the package directory. This is vastly annoying. Not only does it make it difficult to exercise any sort of explicit control over what files get distributed with my package, but it means that when I build my package following an \"svn export\" instead of an \"svn checkout\", the contents of my package might be quite different, since without the .svn metadata setuptools will make different choices about what to include.\\n\\nMy question: how can I turn off this terrible behavior, so that \"setuptools\" treats my project the same way whether I\\'m using Subversion, or version control it\\'s never heard of, or a bare tree created with \"svn export\" that I\\'ve created at the end of my project to make sure it builds cleanly somewhere besides my working directory?\\n\\nThe best I have managed so far is an ugly monkey-patch:\\n\\nfrom setuptools.command import sdist\\ndel sdist.finders[:]\\n\\n\\nBut this is Python, not the jungle, so of course I want a better solution that involves no monkeys at all. How can I tame setuptools, turn off its magic, and have it behave sensibly by looking at the visible, predictable rules in my MANIFEST.py instead?\\n',\n  'completion': 'I know you know much of this, Brandon, but I\\'ll try to give as a complete answer as I can (although I\\'m no setuptools gury) for the benefit of others.\\n\\nThe problem here is that setuptools itself involves quite a lot of black magick, including using an entry point called setuptools.file_finders where you can add plugins to find files to include. I am, however, at a complete loss as to how REMOVE plugins from it...\\n\\n\\nQuick workaround: svn export your package to a temporary directory and run the setup.py from there. That means you have no svn, so the svn finder finds no files to include. :)\\nLonger workaround: Do you really need setuptools? Setuptools have a lot of features, so the answer is likely yes, but mainly those features are depdenencies (so your dependencies get installed by easy_install), namespace packages (foo.bar), and entry points. Namespace packages can actually be created without setuptools as well. But if you use none of these you might actually get away with just using distutils.\\nUgly workaround: The monkeypatch you gave to sdist in your question, which simply makes the plugin not have any finders, and exit quickly.\\n\\n\\nSo as you see, this answer, although as complete as I can make it, is still embarrassingly incomplete. I can\\'t actually answer your question, though I think the answer is \"You can\\'t\". \\n'},\n {'prompt': 'I have used hashlib (which replaces md5 in Python 2.6/3.0) and it worked fine if I opened a file and put its content in hashlib.md5() function.\\n\\nThe problem is with very big files that their sizes could exceed RAM size.\\n\\nHow to get the MD5 hash of a file without loading the whole file to memory?\\n',\n  'completion': 'You need to read the file in chunks of suitable size:\\n\\ndef md5_for_file(f, block_size=2**20):\\n    md5 = hashlib.md5()\\n    while True:\\n        data = f.read(block_size)\\n        if not data:\\n            break\\n        md5.update(data)\\n    return md5.digest()\\n\\n\\nNOTE: Make sure you open your file with the \\'rb\\' to the open - otherwise you will get the wrong result.\\n\\nSo to do the whole lot in one method - use something like: \\n\\ndef generate_file_md5(rootdir, filename, blocksize=2**20):\\n    m = hashlib.md5()\\n    with open( os.path.join(rootdir, filename) , \"rb\" ) as f:\\n        while True:\\n            buf = f.read(blocksize)\\n            if not buf:\\n                break\\n            m.update( buf )\\n    return m.hexdigest()\\n\\n\\nThe update above was based on the comments provided by Frerich Raabe - and I tested this and found it to be correct on my Python 2.7.2 windows installation\\n\\nI cross-checked the results using the \\'jacksum\\' tool.\\n\\njacksum -a md5 <filename>\\n\\n\\nhttp://www.jonelo.de/java/jacksum/\\n'},\n {'prompt': 'I have a multithreaded program where I create a generator function and then pass it to new threads.  I want it to be shared/global in nature so each thread can get the next value from the generator.\\n\\nIs it safe to use a generator like this, or will I run into problems/conditions accessing the shared generator from multiple threads?  \\n\\nIf not, is there a better way to approach the problem?  I need something that will cycle through a list and produce the next value for whichever thread calls it.\\n',\n  'completion': \"It's not thread-safe; simultaneous calls may interleave, and mess with the local variables.\\n\\nThe common approach is to use the master-slave pattern (now called farmer-worker pattern in PC). Make a third thread which generates data, and add a Queue between the master and the slaves, where slaves will read from the queue, and the master will write to it. The standard queue module provides the necessary thread safety and arranges to block the master until the slaves are ready to read more data.\\n\"},\n {'prompt': 'I have a problem with serialization of Django inherited models. For example\\n\\nclass Animal(models.Model):\\n    color = models.CharField(max_length=50)\\n\\nclass Dog(Animal):\\n    name = models.CharField(max_length=50)\\n\\n...\\n# now I want to serialize Dog model with Animal inherited fields obviously included\\nprint serializers.serialize(\\'xml\\', Dog.objects.all())\\n\\n\\nand only Dog model has been serialized.\\n\\nI can do smth like \\n\\nall_objects = list(Animal.objects.all()) + list(Dog.objects.all())\\nprint serializers.serialize(\\'xml\\', all_objects)\\n\\n\\nBut it looks ugly and because my models are very big so I have to use SAX parser and with such output it\\'s difficult to parse.\\n\\nAny idea how to serialize django models with parent class?\\n\\n**EDIT: ** It use to work ok before this patch has been applied. And the explanation why the patch exist \"Model saving was too aggressive about creating new parent class instances during deserialization. Raw save on a model now skips saving of the parent class. \" I think there should be an option to be able to serialize \"local fields only\" by default and second option - \"all\" - to serialize all inherited fields.\\n',\n  'completion': \"You found your answer in the documentation of the patch.\\n\\nall_objects = list(Animal.objects.all()) + list(Dog.objects.all())\\nprint serializers.serialize('xml', all_objects)\\n\\n\\nHowever, if you change Animal to be an abstract base class it will work:\\n\\nclass Animal(models.Model):\\n    color = models.CharField(max_length=50)\\n\\n    class Meta:\\n        abstract = True\\n\\nclass Dog(Animal):\\n    name = models.CharField(max_length=50)\\n\\n\\nThis works as of Django 1.0.  See http://docs.djangoproject.com/en/dev/topics/db/models/.\\n\"},\n {'prompt': \"I am parsing some XML with the elementtree.parse() function.  It works, except for some utf-8 characters(single byte character above 128).  I see that the default parser is XMLTreeBuilder which is based on expat.\\n\\nIs there an alternative parser that I can use that may be less strict and allow utf-8 characters?\\n\\nThis is the error I'm getting with the default parser:\\n\\nExpatError: not well-formed (invalid token): line 311, column 190\\n\\n\\nThe character causing this is a single byte x92 (in hex).  I'm not certain this is even a valid utf-8 character.  But it would be nice to handle it because most text editors display this as: Ã\\xad\\n\\nEDIT: The context of the character is: canÃ\\xadt , where I assume it is supposed to be a fancy apostraphe, but in the hex editor, that same sequence is: 63 61 6E 92 74 \\n\",\n  'completion': 'I\\'ll start from the question: \"Is there an alternative parser that I can use that may be less strict and allow utf-8 characters?\"\\n\\nAll XML parsers will accept data encoded in UTF-8. In fact, UTF-8 is the default encoding.\\n\\nAn XML document may start with a declaration like this:\\n\\n`<?xml version=\"1.0\" encoding=\"UTF-8\"?>`\\n\\n\\nor like this:\\n    <?xml version=\"1.0\"?>\\nor not have a declaration at all ... in each case the parser will decode the document using UTF-8.\\n\\nHowever your data is NOT encoded in UTF-8 ... it\\'s probably Windows-1252 aka cp1252.\\n\\nIf the encoding is not UTF-8, then either the creator should include a declaration (or the recipient can prepend one) or the recipient can transcode the data to UTF-8. The following showcases what works and what doesn\\'t:\\n\\n>>> import xml.etree.ElementTree as ET\\n>>> from StringIO import StringIO as sio\\n\\n>>> raw_text = \\'<root>can\\\\x92t</root>\\' # text encoded in cp1252, no XML declaration\\n\\n>>> t = ET.parse(sio(raw_text))\\n[tracebacks omitted]\\nxml.parsers.expat.ExpatError: not well-formed (invalid token): line 1, column 9\\n# parser is expecting UTF-8\\n\\n>>> t = ET.parse(sio(\\'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\' + raw_text))\\nxml.parsers.expat.ExpatError: not well-formed (invalid token): line 1, column 47\\n# parser is expecting UTF-8 again\\n\\n>>> t = ET.parse(sio(\\'<?xml version=\"1.0\" encoding=\"cp1252\"?>\\' + raw_text))\\n>>> t.getroot().text\\nu\\'can\\\\u2019t\\'\\n# parser was told to expect cp1252; it works\\n\\n>>> import unicodedata\\n>>> unicodedata.name(u\\'\\\\u2019\\')\\n\\'RIGHT SINGLE QUOTATION MARK\\'\\n# not quite an apostrophe, but better than an exception\\n\\n>>> fixed_text = raw_text.decode(\\'cp1252\\').encode(\\'utf8\\')\\n# alternative: we transcode the data to UTF-8\\n\\n>>> t = ET.parse(sio(fixed_text))\\n>>> t.getroot().text\\nu\\'can\\\\u2019t\\'\\n# UTF-8 is the default; no declaration needed\\n\\n'},\n {'prompt': 'Is there a way to create an NTFS junction point in Python? I know I can call the junction utility, but it would be better not to rely on external tools.\\n',\n  'completion': 'you can use python win32 API modules e.g.\\n\\nimport win32file\\n\\nwin32file.CreateSymbolicLink(srcDir, targetDir, 1)\\n\\n\\nsee http://docs.activestate.com/activepython/2.5/pywin32/win32file__CreateSymbolicLink_meth.html for more details\\n\\nif you do not want to rely on that too, you can always use ctypes and directly call CreateSymbolicLinl win32 API, which is anyway a simple call\\n\\nhere is example call using ctypes\\n\\nimport ctypes\\n\\nkdll = ctypes.windll.LoadLibrary(\"kernel32.dll\")\\n\\nkdll.CreateSymbolicLinkA(\"d:\\\\testdir\", \"d:\\\\testdir_link\", 1)\\n\\n\\nMSDN says Minimum supported client Windows Vista\\n'},\n {'prompt': 'I am using Sphinx for documenting my python project. I have the autodoc extension enabled and have the following in my docs.\\n\\n.. autoclass:: ClassName\\n   :members:\\n\\n\\nThe problem is, it only documents the non-private methods in the class. How do I include the private methods too?\\n',\n  'completion': 'if you are using sphinx 1.1 or above, from the sphinx documentation site at http://sphinx.pocoo.org/ext/autodoc.html,\\n\\n:special-members:\\n:private-members:\\n\\n'},\n {'prompt': \"How do I get the DNS records for a zone in python?  I'm looking for data similar to the output of dig.\\n\",\n  'completion': 'Try the dnspython library:\\n\\n\\nhttp://www.dnspython.org/\\n\\n\\nYou can see some examples here:\\n\\n\\nhttp://www.dnspython.org/examples.html\\n\\n'},\n {'prompt': \"\\n  Possible Duplicate:\\n  Java Python Integration  \\n\\n\\nI have a large existing codebase written in 100% Java, but I would like to use Python for some new sections of it. I need to do some text and language processing, and I'd much rather use Python and a library like NLTK to do this. \\n\\nI'm aware of the Jython project, but it looks like this represents a way to use Java and its libraries from within Python, rather than the other way round - am I wrong about this?\\n\\nIf not, what would be the best method to interface between Java and Python, such that (ideally) I can call a method in Python and have the result returned to Java? \\n\\nThank you.\\n\",\n  'completion': \"\\n  I'm aware of the Jython project, but\\n  it looks like this represents a way to\\n  use Java and its libraries from within\\n  Python, rather than the other way\\n  round - am I wrong about this?\\n\\n\\nYes, you are wrong. You can either use jythonc to compile python code to java .class files or call the python interpreter directly from Java.\\n\"},\n {'prompt': 'I\\'m new to Django (and Python) and I have been trying to work out a few things myself, before jumping into using other people\\'s apps. I\\'m having trouble understanding where things \\'fit\\' in the Django (or Python\\'s) way of doing things. What I\\'m trying to work out is how to resize an image, once it\\'s been uploaded. I have my model setup nicely and plugged into the admin, and the image uploads fine to the directory:\\n\\nfrom django.db import models\\n\\n# This is to list all the countries\\n# For starters though, this will be just United Kingdom (GB)\\nclass Country(models.Model):\\n    name = models.CharField(max_length=120, help_text=\"Full name of country\")\\n    code = models.CharField(max_length=2, help_text=\"This is the ISO 3166 2-letter country code (see: http://www.theodora.com/country_digraphs.html)\")\\n    flag = models.ImageField(upload_to=\"images/uploaded/country/\", max_length=150, help_text=\"The flag image of the country.\", blank=True)\\n\\n    class Meta:\\n        verbose_name_plural = \"Countries\"\\n\\n    def __unicode__(self):\\n        return self.name\\n\\n\\nThe thing I\\'m now having trouble with is taking that file and making a new file into a thumbnail. Like I say, I\\'d like to know how to do it without using others\\' apps (for now). I have got this code from DjangoSnippets:\\n\\nfrom PIL import Image\\nimport os.path\\nimport StringIO\\n\\ndef thumbnail(filename, size=(50, 50), output_filename=None):\\n    image = Image.open(filename)\\n    if image.mode not in (\\'L\\', \\'RGB\\'):\\n        image = image.convert(\\'RGB\\')\\n    image = image.resize(size, Image.ANTIALIAS)\\n\\n    # get the thumbnail data in memory.\\n    if not output_filename:\\n        output_filename = get_default_thumbnail_filename(filename)\\n    image.save(output_filename, image.format) \\n    return output_filename\\n\\ndef thumbnail_string(buf, size=(50, 50)):\\n    f = StringIO.StringIO(buf)\\n    image = Image.open(f)\\n    if image.mode not in (\\'L\\', \\'RGB\\'):\\n        image = image.convert(\\'RGB\\')\\n    image = image.resize(size, Image.ANTIALIAS)\\n    o = StringIO.StringIO()\\n    image.save(o, \"JPEG\")\\n    return o.getvalue()\\n\\ndef get_default_thumbnail_filename(filename):\\n    path, ext = os.path.splitext(filename)\\n    return path + \\'.thumb.jpg\\'\\n\\n\\n...but this has ultimately confused me... As I don\\'t know how this \\'fits in\\' to my Django app? And really, is it the best solution for simply making a thumbnail of an image that has been successfully uploaded? Can anyone possibly show me a good, solid, decent way that a beginner like me can learn to do this properly? As in, knowing where to put that sort of code (models.py? forms.py? ...) and how it would work in context? ... I just need a bit of help understanding and working this problem out.\\n\\nThank you!\\n',\n  'completion': \"If it's OK for you, there is a Django application ready, doing exactly what you want:\\nhttps://github.com/sorl/sorl-thumbnail\\n\"},\n {'prompt': \"I can't remember which application I was using, but I do recall it having really neat date parsing/interpretation.\\n\\nFor example, you could type in 'two days ago' or 'tomorrow' and it would understand.\\n\\nAny libraries to suggest? Bonus points if usable from Python.\\n\",\n  'completion': 'Perhaps you are thinking of PHP\\'s strtotime() function, the Swiss Army Knife of date parsing:\\n\\n\\n  Man, what did I do before strtotime().  Oh, I know, I had a 482 line function to parse date formats and return timestamps.  And I still could not do really cool stuff.  Like tonight I needed to figure out when Thanksgiving was in the US.  I knew it was the 4th Thursday in November.  So, I started with some math stuff and checking what day of the week Nov. 1 would fall on.  All that was making my head hurt.  So, I just tried this for fun.\\n\\nstrtotime(\"thursday, november \".date(\"Y\").\" + 3 weeks\")\\n\\n  \\n  That gives me Thanksgiving.  Awesome.\\n\\n\\nWould you believe it even has its own dedicated web site, www.strtotime.net?\\n\\nSadly, there does not appear to be a Python equivalent. The closest thing I could find is the dateutil.parser module.\\n'},\n {'prompt': 'I have been playing around with sorl-thumbnail for Django. And trying to understand how it works better. \\n\\nI\\'ve read the guide for it, installed it in my site-packages, made sure PIL is installed correctly, put sorl.thumbnail in the INSTALLED APPS in my settings.py, put from sorl.thumbnail.fields import ImageWithThumbnailsField at the top in my models.py, added image = ImageWithThumbnailsField(upload to=\"images/\", thumbnail={\\'size\\':(80, 80)}) as one of my model fields, passed the model through my view to the template, and in the template added {% load thumbnail %} at the top and put in the variable {{ mymodel.image.thumbnail_tag }} in there too.\\n\\nBut from what I understood is that when I upload an image through the admin, it would create the thumbnail straight away, but it only actually creates in when I see my template in the browser? Is this correct? The thumbnail shows fine, it looks great in fact, but I thought that adding the model field part of it would create the thumbnail instantly once the image has uploaded? ...Why not just use the models.ImageField in my model instead?\\n\\n...or have I done this all OK and I\\'ve just got the way it works wrong?\\n',\n  'completion': \"I'm one of the sorl-thumbnail developers.\\n\\nFirstly, you don't need to {% load thumbnail %} unless you're just using the thumbnail tag rather than a thumbnail field.\\n\\nCurrently, a thumbnail is only ever created the first time it is used - even if you use the field [I'll get around to changing that one day if no-one else does first]. The advantage of the field is that you can specify the sizing rather than giving the freedom to the designer in the template level [and making it easier for an admin thumbnail].\\n\\nBoth ways work, you get to decide which works best for you.\\n\"},\n {'prompt': \"When using (pseudo) random numbers in Jython, would it be more efficient to use the Python random module or Java's random class?\\n\",\n  'completion': 'Python\\'s version is much faster in a simple test on my Mac:\\n\\njython -m timeit -s \"import random\" \"random.random()\"\\n\\n\\n1000000 loops, best of 3: 0.266 usec per loop\\n\\nvs\\n\\n jython -m timeit -s \"import java.util.Random; random=java.util.Random()\" \"random.nextDouble()\"\\n\\n\\n1000000 loops, best of 3: 1.65 usec per loop\\n\\nJython version 2.5b3 and Java version 1.5.0_19.\\n'},\n {'prompt': 'Currently, django.contrib.comments sends the user to the preview page if there is any error on the form. \\n\\nI am using comments in the context of a blog and I would much rather that the user stayed on the page they were on if something went wrong with the submission. As far as I can tell though, this is hard-coded in django.contrib.comments.views.comments.post_comment:\\n\\n# If there are errors or if we requested a preview show the comment\\nif form.errors or preview:\\n    template_list = [\\n        \"comments/%s_%s_preview.html\" % tuple(str(model._meta).split(\".\")),\\n        \"comments/%s_preview.html\" % model._meta.app_label,\\n        \"comments/preview.html\",\\n    ]\\n    return render_to_response(\\n        template_list, {\\n            \"comment\" : form.data.get(\"comment\", \"\"),\\n            \"form\" : form,\\n            \"next\": next,\\n        },\\n        RequestContext(request, {})\\n    )\\n\\n\\nIs there any way that I can change this behavior without changing the source code to django.contrib.comments?\\n\\nAny pointer would be appreciated...\\n\\nThanks!\\n',\n  'completion': \"Looks like you have two real options:\\n\\n\\nWrite your own view.  Possibly copy that view's code to get started.\\nPatch that view to take an extra parameter, such as 'preview_on_errors' which defaults to True but can be overridden.  Contribute the patch back to Django so other people can benefit from it.\\n\\n\"},\n {'prompt': \"I have a service that runs that takes a list of about 1,000,000 dictionaries and does the following\\n\\nmyHashTable = {}\\nmyLists = { 'hits':{}, 'misses':{}, 'total':{} }\\nsorted = { 'hits':[], 'misses':[], 'total':[] }\\nfor item in myList:\\n  id = item.pop('id')\\n  myHashTable[id] = item\\n  for k, v in item.iteritems():\\n    myLists[k][id] = v\\n\\n\\nSo, if I had the following list of dictionaries:\\n\\n[ {'id':'id1', 'hits':200, 'misses':300, 'total':400},\\n  {'id':'id2', 'hits':300, 'misses':100, 'total':500},\\n  {'id':'id3', 'hits':100, 'misses':400, 'total':600}\\n]\\n\\n\\nI end up with\\n\\nmyHashTable =\\n{ \\n  'id1': {'hits':200, 'misses':300, 'total':400},\\n  'id2': {'hits':300, 'misses':100, 'total':500},\\n  'id3': {'hits':100, 'misses':400, 'total':600}\\n}\\n\\n\\nand\\n\\nmyLists = \\n\\n    {\\n      'hits': {'id1':200, 'id2':300, 'id3':100},\\n      'misses': {'id1':300, 'id2':100, 'id3':400},\\n      'total': {'id1':400, 'id2':500, 'id3':600}\\n    }\\n\\n\\nI then need to sort all of the data in each of the myLists dictionaries.\\n\\nWhat I doing currently is something like the following:\\n\\ndef doSort(key):\\n  sorted[key] = sorted(myLists[key].items(), key=operator.itemgetter(1), reverse=True)\\n\\nwhich would yield, in the case of misses:\\n[('id3', 400), ('id1', 300), ('id2', 200)]\\n\\n\\nThis works great when I have up to 100,000 records or so, but with 1,000,000 it is taking at least 5 - 10 minutes to sort each with a total of 16 (my original list of dictionaries actually has 17 fields including id which is popped)\\n\\n\\n  * EDIT * This service is a ThreadingTCPServer which has a method\\n  allowing a client to connect and add\\n  new data.  The new data may include\\n  new records (meaning dictionaries with\\n  unique 'id's to what is already in\\n  memory) or modified records (meaning\\n  the same 'id' with different data for\\n  the other key value pairs\\n  \\n  So, once this is running I would pass\\n  in \\n\\n[\\n  {'id':'id1', 'hits':205, 'misses':305, 'total':480},\\n  {'id':'id4', 'hits':30, 'misses':40, 'total':60},\\n  {'id':'id5', 'hits':50, 'misses':90, 'total':20\\n]\\n\\n  \\n  I have been using dictionaries to\\n  store the data so that I don't end up\\n  with duplicates.   After the\\n  dictionaries are updated with the\\n  new/modified data I resort each of\\n  them.\\n  \\n  * END EDIT *\\n\\n\\nSo, what is the best way for me to sort these?  Is there a better method?\\n\",\n  'completion': 'You may find this related answer from Guido:  Sorting a million 32-bit integers in 2MB of RAM using Python\\n'},\n {'prompt': 'I am a .Net / SQL Server developer via my daytime job, and on the side I do some objective C development for the iPhone.  I would like to develop a web service and since dreamhost supports mySql, python, ruby on rails and PHP5, I would like to create it using one of those languages.  If you had no experience in either python, Ruby on Rails or PHP, which would you go with and why?  The service basically just takes a request and talks to a MySql database.\\n\\nNote:  Was planning on using the SOAP protocol.. though I am open to suggestions since I have a clean slate with these languages.\\n',\n  'completion': \"Ruby-on-rails, Python and PHP would all be excellent choices for developing a web service in.  All the languages are capable (with of course Ruby being the language that Ruby on Rails is written in), have strong frameworks if that is your fancy (Django being a good python example, and something like Drupal or CakePHP being good PHP examples) and can play nicely with MySql.\\n\\nI'd say that it would depend mostly on your past experience and what you'd be the most comfortable with.  Assuming that you're developing C# on .NET and have experience with Objective-C PHP may be a good choice because it is most certainly from the C family of languages.  So the syntax might be more familiar and a bit easier to deal with.\\n\\nI'm a PHP developer so I'll give you that slant and let more knowledgeable developers with the others give theirs as well.  PHP is tightly integrated with Apache, which can make some of the more mundane tasks that you'd have to handle with the others a bit more trivial (though when working with a framework those are usually removed). The PHP documentation is second to none and is a great resource for getting up and going easily.  It has decent speed and there are good caching mechanisms out there to get more performance out of it.  I know that getting up and running with PHP on Dreamhost is trivial.  I haven't done it in the other instances although it wouldn't surprise me if those were just as easy as well.\\n\\nI'd suggest digging a bit more into the documentation and frameworks for each language to find out what suits you best. \\n\"},\n {'prompt': \"Consider:\\n\\npipe_read, pipe_write = os.pipe()\\n\\n\\nNow, I would like to know two things:\\n\\n(1) I have two threads. If I guarantee that only one is reading os.read(pipe_read,n) and the other is only writing os.write(pipe_write), will I have any problem, even if the two threads do it simultaneously? Will I get all data that was written in the correct order? What happens if they do it simultaneously? Is it possible that a single write is read in pieces, like?:\\n\\nThread 1: os.write(pipe_write, '1234567')\\nThread 2: os.read(pipe_read,big_number) --> '123'\\nThread 2: os.read(pipe_read,big_number) --> '4567'\\n\\n\\nOr -- again, consider simultaneity -- will a single os.write(some_string) always return entirely by a single os.read(pipe_read, very_big_number)?\\n\\n(2) Consider more than one thread writing to the pipe_write end of the pipe using logging.handlers.FileHandler() -- I've read that the logging module is threadsafe. Does this mean that I can do this without losing data? I think I won't be able to control the order of the data in the pipe; but this is not a requirement.\\nRequirements:\\n\\n\\nall data written by some threads on the write end must come out at the read end \\na string written by a single logger.info(), logger.error(), ... has to stay in one piece.\\n\\n\\nAre these reqs fulfilled?\\n\\nThank you in advance,\\n\\nJan-Philip Gehrcke\\n\",\n  'completion': 'os.read and os.write on the two fds returned from os.pipe is threadsafe, but you appear to demand more than that. Sub (1), yes, there is no \"atomicity\" guarantee for sinle reads or writes -- the scenario you depict (a single short write ends up producing two reads) is entirely possible. (In general, os.whatever is a thin wrapper on operating system functionality, and it\\'s up to the OS to ensure, or fail to ensure, the kind of functionality you require; in this case, the Posix standard doesn\\'t require the OS to ensure this kind of \"atomicity\"). You\\'re guaranteed to get all data that was written, and in the correct order, but that\\'s it. A single write of a large piece of data might stall once it\\'s filled the OS-supplied buffer and only proceed once some other thread has read some of the initial data (beware deadlocks, of course!), etc, etc.\\n\\nSub (2), yes, the logging module is threadsafe AND \"atomic\" in that data produced by a single call to logging.info, logging.warn, logging.error, etc, \"stays in one piece\" in terms of calls to the underlying handler (however if that handler in turn uses non-atomic means such as os.write, it may still e.g. stall in the kernel until the underlying buffer gets unclogged, etc, etc, as above).\\n'},\n {'prompt': 'I would like to know how to I exit from Python without having an traceback dump on the output. \\n\\nI still want want to be able to return an error code but I do not want to display the traceback log.\\n\\nI want to be able to exit using exit(number) without trace but in case of an Exception (not an exit) I want the trace.\\n',\n  'completion': 'You are presumably encountering an exception and the program is exiting because of this (with a traceback).  The first thing to do therefore is to catch that exception, before exiting cleanly (maybe with a message, example given).\\n\\nTry something like this in your main routine:\\n\\nimport sys, traceback\\n\\ndef main():\\n    try:\\n        do main program stuff here\\n        ....\\n    except KeyboardInterrupt:\\n        print \"Shutdown requested...exiting\"\\n    except Exception:\\n        traceback.print_exc(file=sys.stdout)\\n    sys.exit(0)\\n\\nif __name__ == \"__main__\":\\n    main()\\n\\n'},\n {'prompt': 'Suppose I have a relatively long module, but need an external module or method only once.\\n\\nIs it considered OK to import that method or module in the middle of the module?\\n\\nOr should imports only be in the first part of the module.\\n\\nExample:\\n\\nimport string, pythis, pythat\\n...\\n...\\n...\\n...\\ndef func():\\n     blah\\n     blah \\n     blah\\n     from pysomething import foo\\n     foo()\\n     etc\\n     etc \\n     etc\\n...\\n...\\n...\\n\\n\\nPlease justify your answer and add links to PEPs or relevant sources\\n',\n  'completion': 'PEP 8 authoritatively states:\\n\\n\\n  Imports are always put at the top of\\n  the file, just after any module\\n        comments and docstrings, and before module globals and constants.\\n\\n\\nPEP 8 should be the basis of any \"in-house\" style guide, since it summarizes what the core Python team has found to be the most effective style, overall (and with individual dissent of course, as on any other language, but consensus and the BDFL agree on PEP 8).\\n'},\n {'prompt': 'How to make tabulation look different than whitespace in vim (highlighted for example).\\n\\nThat would be useful for code in Python.\\n',\n  'completion': \"I use something like this:\\n\\nset list listchars=tab:Â»Â·,trail:Â·,precedes:â\\x80¦,extends:â\\x80¦,nbsp:â\\x80\\x97\\n\\n\\nRequires Vim7 and I'm not sure how well this is going to show up in a browser, because it uses some funky Unicode characters.  It's good to use some oddball characters so that you can distinguish a tab from something you may have typed yourself.\\n\\nIn addition to showing tabs, showing spaces at the end of lines is useful so you know to remove them (they are annoying).\\n\"},\n {'prompt': 'Is there a standard pythonic way to treat physical units / quantities in python? I saw different module-specific solutions from different fields like physics or neuroscience. But I would rather like to use a standard method than \"island\"-solutions as others should be able to easily read my code.\\n',\n  'completion': 'The best solution is the Unum package. a de-facto standard, imho.\\n'},\n {'prompt': \"I'm trying to reduce the number of scripts included in our website and we use buildout to handle deployments. Has anybody successfully implemented a method of combining and compressing scripts with buildout?\\n\",\n  'completion': 'Here\\'s a Python script I made that I use with all my heavy JavaScript projects. I\\'m using YUICompressor, but you can change the code to use another compressor.\\n\\nimport os, os.path, shutil\\n\\nYUI_COMPRESSOR = \\'yuicompressor-2.4.2.jar\\'\\n\\ndef compress(in_files, out_file, in_type=\\'js\\', verbose=False,\\n             temp_file=\\'.temp\\'):\\n    temp = open(temp_file, \\'w\\')\\n    for f in in_files:\\n        fh = open(f)\\n        data = fh.read() + \\'\\\\n\\'\\n        fh.close()\\n\\n        temp.write(data)\\n\\n        print \\' + %s\\' % f\\n    temp.close()\\n\\n    options = [\\'-o \"%s\"\\' % out_file,\\n               \\'--type %s\\' % in_type]\\n\\n    if verbose:\\n        options.append(\\'-v\\')\\n\\n    os.system(\\'java -jar \"%s\" %s \"%s\"\\' % (YUI_COMPRESSOR,\\n                                          \\' \\'.join(options),\\n                                          temp_file))\\n\\n    org_size = os.path.getsize(temp_file)\\n    new_size = os.path.getsize(out_file)\\n\\n    print \\'=> %s\\' % out_file\\n    print \\'Original: %.2f kB\\' % (org_size / 1024.0)\\n    print \\'Compressed: %.2f kB\\' % (new_size / 1024.0)\\n    print \\'Reduction: %.1f%%\\' % (float(org_size - new_size) / org_size * 100)\\n    print \\'\\'\\n\\n    #os.remove(temp_file)\\n\\n\\nI use it like this (the below is just a code snippet, and assumes that the compress function exists in the current namespace):\\n\\nSCRIPTS = [\\n    \\'app/js/libs/EventSource.js\\',\\n    \\'app/js/libs/Hash.js\\',\\n    \\'app/js/libs/JSON.js\\',\\n    \\'app/js/libs/ServiceClient.js\\',\\n    \\'app/js/libs/jquery.hash.js\\',\\n    \\'app/js/libs/Application.js\\',\\n    \\'app/js/intro.js\\',\\n    \\'app/js/jquery-extras.js\\',\\n    \\'app/js/settings.js\\',\\n    \\'app/js/api.js\\',\\n    \\'app/js/game.js\\',\\n    \\'app/js/user.js\\',\\n    \\'app/js/pages.intro.js\\',\\n    \\'app/js/pages.home.js\\',\\n    \\'app/js/pages.log-in.js\\',\\n    \\'app/js/pages.log-out.js\\',\\n    \\'app/js/pages.new-command.js\\',\\n    \\'app/js/pages.new-frame.js\\',\\n    \\'app/js/pages.not-found.js\\',\\n    \\'app/js/pages.register.js\\',\\n    \\'app/js/pages.outro.js\\',\\n    \\'app/js/outro.js\\',\\n    ]\\nSCRIPTS_OUT_DEBUG = \\'app/js/multifarce.js\\'\\nSCRIPTS_OUT = \\'app/js/multifarce.min.js\\'\\n\\nSTYLESHEETS = [\\n    \\'app/media/style.css\\',\\n    ]\\nSTYLESHEETS_OUT = \\'app/media/style.min.css\\'\\n\\ndef main():\\n    print \\'Compressing JavaScript...\\'\\n    compress(SCRIPTS, SCRIPTS_OUT, \\'js\\', False, SCRIPTS_OUT_DEBUG)\\n\\n    print \\'Compressing CSS...\\'\\n    compress(STYLESHEETS, STYLESHEETS_OUT, \\'css\\')\\n\\nif __name__ == \\'__main__\\':\\n    main()\\n\\n'},\n {'prompt': 'What\\'s the right way to control timeouts, from the client, when running against a MySQL database, using SQLAlchemy?  The connect_timeout URL parameter seems to be insufficient.\\n\\nI\\'m more interested in what happens when the machine that the database is running on, e.g., disappears from the network unexpectedly.  I\\'m not worried about the queries themselves taking too long.  \\n\\nThe following script does what you\\'d expect (i.e., time out after approximately one second) if somehost is unavailable before the while loop is ever reached.  But if somehost goes down during the while loop (e.g., try yanking out its network cable after the loop has started), then the timeout seems to take at least 18 seconds.  Is there some additional setting or parameter I\\'m missing?\\n\\nIt\\'s not surprising that the wait_timeout session variable doesn\\'t work, as I think that\\'s a server-side variable.  But I threw it in there just to make sure.\\n\\nfrom sqlalchemy import *\\nfrom sqlalchemy.exc import *\\nimport time\\nimport sys\\n\\nengine = create_engine(\"mysql://user:password@somehost/test?connect_timeout=1\")\\ntry:\\n    engine.execute(\"set session wait_timeout = 1;\")\\n    while True:\\n        t = time.time()\\n        print t\\n        engine.execute(\"show tables;\")\\nexcept DBAPIError:\\n    pass\\nfinally:\\n    print time.time() - t, \"seconds to time out\"\\n\\n',\n  'completion': 'this isn\\'t possible due to the way TCP works. if the other computer drops off the network, it will simply stop responding to incoming packets. the \"18 seconds\" you\\'re seeing is something on your TCP stack timing out due to no response.\\n\\nthe only way you can get your desired behavior is to have the computer generate a \"i\\'m dying\" message immediately before it dies. which, if the death is unexpected, is completely impossible.\\n\\nhave you ever heard of hearbeats? these are packets that high-availability systems send to each other every second or less to let the other one know they still exist. if you want your application to know \"immediately\" that the server is gone, you first have to decide how long \"immediate\" is (1 second, 200 ms, etc.) and then designed a system (such as heartbeats) to detect when the other system is no longer there.\\n'},\n {'prompt': 'I\\'m starting to learn python and loving it. I work on a Mac mainly as well as Linux. I\\'m finding that on Linux (Ubuntu 9.04 mostly) when I install a python module using apt-get it works fine. I can import it with no trouble.\\n\\nOn the Mac, I\\'m used to using Macports to install all the Unixy stuff. However, I\\'m finding that most of the python modules I install with it are not being seen by python. I\\'ve spent some time playing around with PATH settings and using python_select . Nothing has really worked and at this point I\\'m not really understanding, instead I\\'m just poking around.\\n\\nI get the impression that Macports isn\\'t universally loved for managing python modules. I\\'d like to start fresh using a more \"accepted\" (if that\\'s the right word) approach. \\n\\nSo, I was wondering, what is the method that Mac python developers use to manage their modules?\\n\\nBonus questions: \\n\\nDo you use Apple\\'s python, or some other version?\\nDo you compile everything from source or is there a package manger that works well (Fink?).\\n\\nAny tips or suggestions here are greatly appreciated. Thanks for your time. :)\\n',\n  'completion': \"The most popular way to manage python packages (if you're not using your system package manager) is to use setuptools and easy_install. It is probably already installed on your system. Use it like this:\\n\\neasy_install django\\n\\n\\neasy_install uses the Python Package Index  which is an amazing resource for python developers. Have a look around to see what packages are available.\\n\\nA better option is pip, which is gaining traction, as it attempts to fix a lot of the problems associated with easy_install. Pip uses the same package repository as easy_install, it just works better. Really the only time use need to use easy_install is for this command:\\n\\neasy_install pip\\n\\n\\nAfter that, use:\\n\\npip install django\\n\\n\\nAt some point you will probably want to learn a bit about virtualenv. If you do a lot of python development on projects with conflicting package requirements, virtualenv is a godsend. It will allow you to have completely different versions of various packages, and switch between them easily depending your needs.\\n\\nRegarding which python to use, sticking with Apple's python will give you the least headaches, but If you need a newer version (Leopard is 2.5.1 I believe), I would go with the macports python 2.6.\\n\"},\n {'prompt': \"Can someone please explain to me what is going on with python in ubuntu 9.04?\\n\\nI'm trying to spin up virtualenv, and the --no-site-packages flag seems to do nothing with ubuntu. I installed virtualenv 1.3.3 with easy_install (which I've upgraded to setuptools 0.6c9) and everything seems to be installed to /usr/local/lib/python2.6/dist-packages\\n\\nI assume that when installing a package using apt-get, it's placed in /usr/lib/python2.6/dist-packages/ ?\\n\\nThe issue is, there is a /usr/local/lib/python2.6/site-packages as well that just sits there being empty. It would seem (by looking at the path in a virtualenv) that this is the folder virtualenv uses as backup. Thus even thought I omit --no-site-packages, I cant access my local systems packages from any of my virtualenv's.\\n\\nSo my questions are:\\n\\n\\nHow do I get virtualenv to point to one of the dist-packages?\\nWhich dist-packages should I point it to? /usr/lib/python2.6/dist-packages or /usr/local/lib/python2.6/dist-packages/\\nWhat is the point of /usr/lib/python2.6/site-packages? There's nothing in there!\\nIs it first come first serve on the path? If I have a newer version of package XYZ installed in /usr/local/lib/python2.6/dist-packages/ and and older one (from ubuntu repos/apt-get) in /usr/lib/python2.6/dist-packages, which one gets imported when I import xyz? I'm assuming this is based on the path list, yes?\\nWhy the hell is this so confusing? Is there something I'm missing here?\\nWhere is it defined that easy_install should install to /usr/local/lib/python2.6/dist-packages?\\nWill this affect pip as well?\\n\\n\\nThanks to anyone who can clear this up!\\n\",\n  'completion': 'I believe Mike Orr\\'s answer from the virtual-env mailing list seems to be the best. Note the OP published this question in both places.\\n\\nOriginal content of mail:\\n\\nYears ago Debian created /usr/local/lib/pythonVERSION/site-packages,\\nand compiled the Python binary to include it in the default search\\npath.  Ubuntu followed Debian\\'s lead as it normally does.  The Python\\ndevelopers did not like this because you\\'d get interference with a\\nlocally-installed /usr/local/bin/python using the same site-packages\\ndirectory. Ubuntu finally decided to abandon site-packages and use\\ndist-packages instead, a name which they invented so it wouldn\\'t\\ninterfere with anything.  The loing story is out there somewhere if\\nyou google it, somewhere in the Python bug tracker or distutils SIG or\\nsuch.\\n\\nThe system works, at least if you use the Ubuntu virtualenv package.\\nSome people have had problems using a locally-installed virtualenv on\\nUbuntu because the magic sys.path entries weren\\'t being added or\\nsomething.  I\\'m not sure about --no-site-packages because I never use\\nthat option: I run PIL and mysqldb from the Ubuntu packages because it\\ncan be hard to compile their C dependencies sometimes.  (Need the\\nright header files, Python is ignoring the header files, etc.)\\n\\nSo Ubuntu Python packages go into\\n/usr/lib/pythonVERSION/dist-packages.  Or that python-support\\ndirectory for some reason.  Locally-installed Python packages go into\\n/usr/local/lib/pythonVERSION/dist-packages by default.  Whenever I\\ninstall an Ubuntu 9.04 system I run:\\n\\n$ sudo apt-get install python-setuptools   (6.0c9)\\n$ sudo apt-get install python-virtualenv   (1.3.3)\\n$ sudo easy_install pip\\n$ sudo pip install virtualenvwrapper\\n\\nThe virtualenvs work fine this way, although I haven\\'t tried --no-site-packages.\\n\\n\\n  I\\'m trying to spin up virtualenv, and the --no-site-packages flag\\n  seems to do nothing with ubuntu. I installed virtualenv 1.3.3 with\\n  easy_install (which I\\'ve upgraded to setuptools 0.6c9)\\n\\n\\nThese versions are both in Ubuntu 9.04, so you\\'re making it harder on\\nyourself by installing them locally.\\n\\n\\n  and everything\\n  seems to be installed to /usr/local/lib/python2.6/dist-packages\\n\\n\\nYes\\n\\n\\n  I assume that when installing a package using apt-get, it\\'s placed in /\\n  usr/lib/python2.6/dist-packages/ ?\\n\\n\\nYes\\n\\n\\n  \\n  Is it first come first serve on the path? If I have a newer\\n  version of package XYZ installed in /usr/local/lib/python2.6/dist-\\n  packages/ and and older one (from ubuntu repos/apt-get) in /usr/lib/\\n  python2.6/dist-packages, which one gets imported when I import xyz?\\n  I\\'m assuming this is based on the path list, yes?\\n  \\n\\n\\nsys.path is scanned in order.  The only funny thing is that .pth eggs\\nget put earlier or later in the path than some people expect.  But if\\nyou\\'re using pip for everything it can do (i.e. except to install pip\\nitself, precompiled eggs, and a snapshot of a local directory that\\'s a\\ncopy rather than an egg link), you won\\'t have many .pth eggs anyway.\\n\\n\\n  \\n  Why the hell is this so confusing? Is there something I\\'m\\n  missing here?\\n  \\n\\n\\nIt\\'s not well documented.  I figured it out by scanning the web.\\n\\n\\n  \\n  Will this affect pip as well?\\n  \\n\\n\\nYes, pip will automatically install to\\n/usr/local/lib/pythonVERSION/site-packages.  Use \"pip install -E\\n$VIRTUAL_ENV packagename\" to install into a virtualenv.\\n'},\n {'prompt': 'The app runs fine using django internal server however when I use apache + mod_python I get the below error \\n\\n\\n\\n  File \"/usr/local/lib/python2.6/dist-packages/django/conf/__init__.py\", line 75, in __init__\\n    raise ImportError, \"Could not import settings \\'%s\\' (Is it on sys.path? Does it have syntax errors?): %s\" % (self.SETTINGS_MODULE, e)\\n\\nImportError: Could not import settings \\'settings\\' (Is it on sys.path? Does it have syntax errors?): No module named settings\\n\\n\\n\\n\\nHere is the needed information \\n\\n1) Project directory: /root/djangoprojects/mysite\\n\\n2) directory listing of /root/djangoprojects/mysite\\n\\nls -ltr\\ntotal 28\\n-rw-r--r-- 1 root root  546 Aug  1 08:34 manage.py\\n-rw-r--r-- 1 root root    0 Aug  1 08:34 __init__.py\\n-rw-r--r-- 1 root root  136 Aug  1 08:35 __init__.pyc\\n-rw-r--r-- 1 root root 2773 Aug  1 08:39 settings.py\\n-rw-r--r-- 1 root root 1660 Aug  1 08:53 settings.pyc\\ndrwxr-xr-x 2 root root 4096 Aug  1 09:04 polls\\n-rw-r--r-- 1 root root  581 Aug  1 10:06 urls.py\\n-rw-r--r-- 1 root root  314 Aug  1 10:07 urls.pyc\\n\\n\\n3) App directory : /root/djangoprojects/mysite/polls\\n\\n4) directory listing of /root/djangoprojects/mysite/polls \\n\\nls -ltr\\ntotal 20\\n-rw-r--r-- 1 root root 514 Aug  1 08:53 tests.py\\n-rw-r--r-- 1 root root  57 Aug  1 08:53 models.py\\n-rw-r--r-- 1 root root   0 Aug  1 08:53 __init__.py\\n-rw-r--r-- 1 root root 128 Aug  1 09:02 views.py\\n-rw-r--r-- 1 root root 375 Aug  1 09:04 views.pyc\\n-rw-r--r-- 1 root root 132 Aug  1 09:04 __init__.pyc\\n\\n\\n5) Anywhere in the filesystem running import django in python interpreter works fine\\n\\n6) content of httpd.conf\\n\\n<Location \"/mysite\">\\n    SetHandler python-program\\n    PythonHandler django.core.handlers.modpython\\n    SetEnv DJANGO_SETTINGS_MODULE settings\\n    PythonOption django.root /mysite\\n    PythonPath \"[\\'/root/djangoprojects/\\', \\'/root/djangoprojects/mysite\\',\\'/root/djangoprojects/mysite/polls\\', \\'/var/www\\'] + sys.path\"\\n    PythonDebug On\\n</Location>\\n\\n\\n7) PYTHONPATH variable is set to \\n\\necho $PYTHONPATH\\n/root/djangoprojects/mysite\\n\\n\\n8) DJANGO_SETTINGS_MODULE is set to\\n\\necho $DJANGO_SETTINGS_MODULE\\nmysite.settings\\n\\n\\n9) content of sys.path is \\n\\nimport sys\\n>>> sys.path\\n[\\'\\', \\'/root/djangoprojects/mysite\\', \\'/usr/lib/python2.6\\', \\'/usr/lib/python2.6/plat-linux2\\', \\'/usr/lib/python2.6/lib-tk\\', \\'/usr/lib/python2.6/lib-old\\', \\'/usr/lib/python2.6/lib-dynload\\', \\'/usr/lib/python2.6/dist-packages\\', \\'/usr/local/lib/python2.6/dist-packages\\']\\n\\n\\nHow do I add settings location to sys.path such that it persistent across sessions ? \\n\\nI have read umpteen no of post with people having the same issue it and I have tried a lot completely beats me as to what I need to do.\\n\\nLooking for some help.\\n\\nThanks in advance\\nAnkur Gupta\\n',\n  'completion': 'Your apache configuration should look like this:\\n\\n<Location \"/mysite\">\\n    SetHandler python-program\\n    PythonHandler django.core.handlers.modpython\\n    SetEnv DJANGO_SETTINGS_MODULE mysite.settings\\n    PythonOption django.root /mysite\\n    PythonPath \"[\\'/root/djangoprojects/\\', \\'/root/djangoprojects/mysite\\',\\'/root/djangoprojects/mysite/polls\\', \\'/var/www\\'] + sys.path\"\\n    PythonDebug On\\n</Location>\\n\\n\\nNote that the sole difference is the \"mysite.settings\". Don\\'t forget to restart apache once the config has changed (apache2ctl restart). See http://docs.djangoproject.com/en/dev/howto/deployment/modpython/ for more info.\\n'},\n {'prompt': \"Is there a simple and quick way to use sum() with non-integer values?\\n\\nSo I can use it like this:\\n\\nclass Foo(object):\\n    def __init__(self,bar)\\n        self.bar=bar\\n\\nmylist=[Foo(3),Foo(34),Foo(63),200]\\nresult=sum(mylist) # result should be 300\\n\\n\\nI tried overriding __add__ and __int__ etc, but I don't have found a solution yet\\n\\nEDIT:\\n\\nThe solution is to implement:\\n\\n def __radd__(self, other):\\n    return other + self.bar\\n\\n\\nas Will suggested in his post. But as always, all roads lead to Rome, but I think this is the best solution since I don't need __add__ in my class\\n\",\n  'completion': 'Its a bit tricky - the sum() function takes the start and adds it to the next and so on\\n\\nYou need to implement the __radd__ method:\\n\\nclass T:\\n    def __init__(self,x):\\n    \\tself.x = x\\n    def __radd__(self, other):\\n    \\treturn other + self.x\\n\\ntest = (T(1),T(2),T(3),200)\\nprint sum(test)\\n\\n'},\n {'prompt': 'I am trying to modify the controls of a Panel, have it update, then continue on with code execution.  The problem seems to be that the Panel is waiting for Idle before it will refresh itself.  I\\'ve tried refresh of course as well as GetSizer().Layout() and even sent a resize event to the frame using the SendSizeEvent() method, but to no avail.  I\\'m at a loss here, I find it difficult to believe there is no way to force a redrawing of this panel.  Here is the code that changes the controls:\\n\\ndef HideButtons(self):\\n        self.newButton.Show(False)\\n        self.openButton.Show(False)\\n        self.exitButton.Show(False)\\n        self.buttonSizer.Detach(self.newButton)\\n        self.buttonSizer.Detach(self.openButton)\\n        self.buttonSizer.Detach(self.exitButton)\\n        loadingLabel = wx.StaticText(self.splashImage, wx.ID_ANY, \"Loading...\", style=wx.ALIGN_LEFT)\\n        loadingLabel.SetBackgroundColour(wx.WHITE)\\n        self.buttonSizer.Add(loadingLabel)\\n        self.GetSizer().Layout()\\n        self.splashImage.Refresh()\\n\\n\\nHas anybody else encountered anything like this? And how did you resolve it if so?\\n',\n  'completion': 'You need to call the Update method.\\n'},\n {'prompt': 'I am looking for a syntax definition, example, sample code, wiki, etc. for \\nexecuting a LOAD DATA LOCAL INFILE command from python.\\n\\nI believe I can use mysqlimport as well if that is available, so any feedback (and code snippet) on which is the better route, is welcome.  A Google search is not turning up much in the way of current info\\n\\nThe goal in either case is the same:  Automate loading hundreds of files with a known naming convention & date structure, into a single MySQL table.\\n\\nDavid\\n',\n  'completion': 'Well, using python\\'s MySQLdb, I use this:\\n\\nconnection = MySQLdb.Connect(host=\\'**\\', user=\\'**\\', passwd=\\'**\\', db=\\'**\\')\\ncursor = connection.cursor()\\nquery = \"LOAD DATA INFILE \\'/path/to/my/file\\' INTO TABLE sometable FIELDS TERMINATED BY \\';\\' ENCLOSED BY \\'\\\\\"\\' ESCAPED BY \\'\\\\\\\\\\\\\\\\\\'\"\\ncursor.execute( query )\\nconnection.commit()\\n\\n\\nreplacing the host/user/passwd/db as appropriate for your needs.  This is based on the MySQL docs here,  The exact LOAD DATA INFILE statement would depend on your specific requirements etc (note the FIELDS TERMINATED BY, ENCLOSED BY, and ESCAPED BY statements will be specific to the type of file you are trying to read in). \\n'},\n {'prompt': \"Python rather stupidly has a pragma directive in its include files that forces a link against python26_d.lib when the DEBUG preprocessor variable is defined. This is a problem because the python installer doesn't come with python26_d.lib! So I can't build applications in msvc in debug mode. If i temporarily #undef DEBUG for just one file I get many complaints about inconsistent DLL linkage. If I change the pragma in pythons include file I get undefined references to various debug functions.\\n\\nI have tried compiling my own version of python but its somehow different enough from the python that gets distributed that I can't use my modules with apps built with the vanilla version of python\\n\\nCan anyone give me any advice on how to get round this?\\n\\nThanks\\n\",\n  'completion': 'From python list\\n\\n\\n  As a workaround to the situation, try\\n  to copy the file python26.dll to\\n  python26_d.dll.  (I\\'m not sure this\\n  will work; you say you are building a\\n  SWIG library in debug mode, and it\\'s\\n  possible that SWIG will try to use\\n  features of the Python debugging\\n  version.  If that\\'s the case, you\\'ll\\n  have no choice but to use the\\n  debugging version of Python.)\\n\\n\\nEdit: From comments:\\n\\n\\n  You should also edit pyconfig.h and\\n  comment out the line \"#define\\n  Py_DEBUG\" (line 374)\\n\\n'},\n {'prompt': 'x=True\\ndef stupid():\\n    x=False\\nstupid()\\nprint x\\n\\n',\n  'completion': 'You don\\'t need to declare a function-local variable in Python.  The \"x=False\" is referring to an x local to stupid().  If you really want to modify the global x inside stupid:\\n\\ndef stupid():\\n    global x\\n    x=False\\n\\n'},\n {'prompt': \"I'm becoming acquainted with python and am creating problems in order to help myself learn the ins and outs of the language.  My next problem comes as follows:\\n\\nI have copied and pasted a huge slew of text from the internet, but the copy and paste added several new lines to break up the huge string.  I wish to programatically remove all of these and return the string into a giant blob of characters.  This is obviously a job for regex (I think), and parsing through the file and removing all instances of the newline character sounds like it would work, but it doesn't seem to be going over all that well for me.  \\n\\nIs there an easy way to go about this?  It seems rather simple.\\n\",\n  'completion': 'The two main alternatives: read everything in as a single string and remove newlines:\\n\\nclean = open(\\'thefile.txt\\').read().replace(\\'\\\\n\\', \\'\\')\\n\\n\\nor, read line by line, removing the newline that ends each line, and join it up again:\\n\\nclean = \\'\\'.join(l[:-1] for l in open(\\'thefile.txt\\'))\\n\\n\\nThe former alternative is probably faster, but, as always, I strongly recommend you MEASURE speed (e.g., use python -mtimeit) in cases of your specific interest, rather than just assuming you know how performance will be.  REs are probably slower, but, again: don\\'t guess, MEASURE!\\n\\nSo here are some numbers for a specific text file on my laptop:\\n\\n$ python -mtimeit -s\"import re\" \"re.sub(\\'\\\\n\\',\\'\\',open(\\'AV1611Bible.txt\\').read())\"\\n10 loops, best of 3: 53.9 msec per loop\\n$ python -mtimeit \"\\'\\'.join(l[:-1] for l in open(\\'AV1611Bible.txt\\'))\"\\n10 loops, best of 3: 51.3 msec per loop\\n$ python -mtimeit \"open(\\'AV1611Bible.txt\\').read().replace(\\'\\\\n\\', \\'\\')\"\\n10 loops, best of 3: 35.1 msec per loop\\n\\n\\nThe file is a version of the KJ Bible, downloaded and unzipped from here (I do think it\\'s important to run such measurements on one easily fetched file, so others can easily reproduce them!).\\n\\nOf course, a few milliseconds more or less on a file of 4.3 MB, 34,000 lines, may not matter much to you one way or another; but as the fastest approach is also the simplest one (far from an unusual occurrence, especially in Python;-), I think that\\'s a pretty good recommendation.\\n'},\n {'prompt': 'I know it can be done, but I never remember how.\\n\\nHow can you reimport a module in python? \\nThe scenario is as follows: I import a module interactively and tinker with it, but then I face an error. I fix the error in the .py file and then I want to reimport the fixed module without quitting python. How can I do it ?\\n',\n  'completion': 'This should work:\\n\\nreload(my.module)\\n\\n\\nFrom the Python docs\\n\\n\\n  Reload a previously imported module. The argument must be a module object, so it must have been successfully imported before. This is useful if you have edited the module source file using an external editor and want to try out the new version without leaving the Python interpreter.\\n\\n'},\n {'prompt': \"Apologies, I am completely new to Django and Python.\\n\\nI have 2 questions. First, how would I go about getting the last object created (or highest pk) in a list of objects? For example, I know that I could use the following to get the first object:\\n\\nlist = List.objects.all()[0]\\n\\n\\nIs there a way to get the length of List.objects? I've tried List.objects.length but to no avail.\\n\\nSecond, is it possible to create simultaneous filters or combine lists? Here is an example:\\n\\ndef findNumber(request, number)\\n    phone_list = Numbers.objects.filter(cell=number)\\n\\n\\nI want something like the above, but more like:\\n\\ndef findNumber(request, number)\\n    phone_list = Numbers.objects.filter(cell=number or home_phone=number)\\n\\n\\nWhat is the correct syntax, if any?\\n\",\n  'completion': 'I haven\\'t tried this yet, but I\\'d look at the latest() operator on QuerySets:\\n\\n\\n  latest(field_name=None)\\n  \\n  Returns the latest object in the\\n  table, by date, using the field_name\\n  provided as the date field.\\n  \\n  This example returns the latest Entry\\n  in the table, according to the\\n  pub_date field:\\n  \\n  Entry.objects.latest(\\'pub_date\\')\\n  \\n  If your model\\'s Meta specifies\\n  get_latest_by, you can leave off the\\n  field_name argument to latest().\\n  Django will use the field specified in\\n  get_latest_by by default.\\n  \\n  Like get(), latest() raises\\n  DoesNotExist if an object doesn\\'t\\n  exist with the given parameters.\\n  \\n  Note latest() exists purely for\\n  convenience and readability.\\n\\n\\nAnd the model docs on get_latest_by:\\n\\n\\n  get_latest_by\\n  \\n  Options.get_latest_by\\n  \\n  The name of a DateField or DateTimeField in the model. This specifies the default field to use in your model Manager\\'s latest method.\\n  \\n  Example:\\n  \\n  get_latest_by = \"order_date\"\\n  \\n  See the docs for latest() for more.\\n\\n\\nEdit: Wade has a good answer on Q() operator.\\n'},\n {'prompt': 'I was wondering if there was anything similar like Mechanize or BeautifulSoup for PHP?\\n',\n  'completion': 'SimpleTest provides you with similar functionality:\\n\\nhttp://www.simpletest.org/en/browser_documentation.html\\n'},\n {'prompt': 'I am in the final stretch of a project I have been working on.  Everything is running smoothly but I have a bottleneck that I am having trouble working around.\\n\\nI have a list of tuples.  The list ranges in length from say 40,000 - 1,000,000 records.  Now I have a dictionary where each and every (value, key) is a tuple in the list.\\n\\nSo, I might have\\n\\nmyList = [(20000, 11), (16000, 4), (14000, 9)...]\\nmyDict = {11:20000, 9:14000, ...}\\n\\n\\nI want to remove each (v, k) tuple from the list.\\n\\nCurrently I am doing:\\n\\nfor k, v in myDict.iteritems():\\n    myList.remove((v, k))\\n\\n\\nRemoving 838 tuples from the list containing 20,000 tuples takes anywhere from 3 - 4 seconds.  I will most likely be removing more like 10,000 tuples from a list of 1,000,000 so I need this to be faster.\\n\\nIs there a better way to do this?\\n\\nI can provide code used to test, plus pickled data from the actual application if needed.\\n',\n  'completion': 'You\\'ll have to measure, but I can imagine this to be more performant:\\n\\nmyList = filter(lambda x: myDict.get(x[1], None) != x[0], myList)\\n\\n\\nbecause the lookup happens in the dict, which is more suited for this kind of thing. Note, though, that this will create a new list before removing the old one; so there\\'s a memory tradeoff. If that\\'s an issue, rethinking your container type as jkp suggest might be in order.\\n\\nEdit: Be careful, though, if None is actually in your list -- you\\'d have to use a different \"placeholder.\"\\n'},\n {'prompt': 'I\\'ve been playing with various ways of doing literate programming in Python.  I like noweb, but I have two main problems with it: first, it is hard to build on Windows, where I spend about half my development time; and second, it requires me to indent each chunk of code as it will be in the final program --- which I don\\'t necessarily know when I write it.  I don\\'t want to use Leo, because I\\'m very attached to Emacs.\\n\\nIs there a good literate programming tool that:\\n\\n\\nRuns on Windows\\nAllows me to set the indentation of the chunks when they\\'re used, not when they\\'re written\\nStill lets me work in Emacs\\n\\n\\nThanks!\\n\\n\\n\\nCorrection: noweb does allow me to indent later --- I misread the paper I found on it.  \\n\\n\\n  \\n    \\n      By default, notangle preserves whitespace and maintains indentation when expanding chunks.  It can therefore be used with languages like Miranda and Haskell, in which indentation is significant\\n    \\n  \\n\\n\\nThat leaves me with only the \"Runs on Windows\" problem.\\n',\n  'completion': \"I have written Pweave http://mpastell.com/pweave, that is aimed for dynamic report generation and uses noweb syntax. It is a pure python script so it also runs on Windows. It doesn't fix your indent problem, but maybe you can modify it for that, the code is really quite simple. \\n\"},\n {'prompt': 'In this Django Doc explain how to create a formset that allows you to edit books belonging to a particular author.\\n\\nWhat I want to do is: Create a formset that allows you to ADD new book belonging to a NEW author... Add the Book and their Authors in the same formset.\\n\\nCan you gime a light? thanks.\\n',\n  'completion': \"When you're instantiating the form and formset for the initial display, you don't need to provide an instance - so you will just get blank forms.\\n\\nWhen you pass in the data on POST, you can do the form first, save it, and get an instance. Then you can pass that instance into the formset, so that it correctly saves the related objects.\\n\"},\n {'prompt': 'In GTK, how can I scale an image? Right now I load images with PIL and scale them beforehand, but is there a way to do it with GTK?\\n',\n  'completion': \"Load the image from a file using gtk.gdk.Pixbuf for that:\\n\\nimport gtk\\npixbuf = gtk.gdk.pixbuf_new_from_file('/path/to/the/image.png')\\n\\n\\nthen scale it:\\n\\npixbuf = pixbuf.scale_simple(width, height, gtk.gdk.INTERP_BILINEAR)\\n\\n\\nThen, if you want use it in a gtk.Image, crate the widget and set the image from the pixbuf.\\n\\nimage = gkt.Image()\\nimage.set_from_pixbuf(pixbuf)\\n\\n\\nOr maybe in a direct way:\\n\\nimage = gtk.image_new_from_pixbuf(pixbuf)\\n\\n\"},\n {'prompt': 'Most concise way to check whether a list is empty or contains only None?\\n\\nI understand that I can test:\\n\\nif MyList:\\n    pass\\n\\n\\nand:\\n\\nif not MyList:\\n    pass\\n\\n\\nbut what if the list has an item (or multiple items), but those item/s are None:\\n\\nMyList = [None, None, None]\\nif ???:\\n    pass\\n\\n',\n  'completion': \"One way is to use all and a list comprehension:\\n\\nif all(e is None for e in myList):\\n    print('all empty or None')\\n\\n\\nThis works for empty lists as well. More generally, to test whether the list only contains things that evaluate to False, you can use any:\\n\\nif not any(myList):\\n    print('all empty or evaluating to False')\\n\\n\"},\n {'prompt': \"I'm a complete Python noob. How can I remove two characters from the beginning of each line in a file? I was trying something like this:\\n\\n#!/Python26/\\n\\nimport re\\n\\nf = open('M:/file.txt')\\nlines=f.readlines()\\n\\ni=0;\\nfor line in lines:\\n    line = line.strip()     \\n    #do something here\\n\\n\",\n  'completion': 'You were off to a good start. Try this in your loop:\\n\\nfor line in lines:\\n    line = line[2:]\\n    # do something here\\n\\n\\nThe [2:] is called \"slice\" syntax, it essentially says \"give me the part of this sequence which begins at index 2 and continues to the end (since no end point was specified after the colon).\\n'},\n {'prompt': \"I have  generator object returned by multiple yield. Preparation to call this generator is rather time-consuming operation. That is why I want to reuse generator several times.\\n\\ny = FunctionWithYield()\\nfor x in y: print(x)\\n#here must be something to reset 'y'\\nfor x in y: print(x)\\n\\n\\nOf course, I'm taking in mind copying content into simple list. \\n\",\n  'completion': \"Generators can't be rewound. You have the following options:\\n\\n\\nRun the generator function again, restarting the generation:\\n\\ny = FunctionWithYield()\\nfor x in y: print(x)\\ny = FunctionWithYield()\\nfor x in y: print(x)\\n\\nStore the generator results in a data structure on memory or disk which you can iterate over again:\\n\\ny = list(FunctionWithYield())\\nfor x in y: print(x)\\n# can iterate again:\\nfor x in y: print(x)\\n\\n\\n\\nThe downside of option 1 is that it computes the values again. If that's CPU-intensive you end up calculating twice. On the other hand, the downside of 2 is the storage. The entire list of values will be stored on memory. If there are too many values, that can be unpractical.\\n\\nSo you have the classic memory vs. processing tradeoff. I can't imagine a way of rewinding the generator without either storing the values or calculating them again.\\n\"},\n {'prompt': \"I have several buttons in various sizers and they expand in the way that I want them to. However, when I add the parent to a new wx.BoxSizer that is used to add a border around all the elements in the frame, the sizer that has been added functions correctly vertically, but not horizontally.\\n\\nThe following code demonstrates the problem:\\n\\n#! /usr/bin/env python\\n\\nimport wx\\nimport webbrowser\\n\\nclass App(wx.App):\\n\\n\\n    def OnInit(self):\\n       frame = MainFrame()\\n       frame.Show()\\n       self.SetTopWindow(frame)\\n       return True\\n\\n\\nclass MainFrame(wx.Frame):\\n\\n    title = 'Title'\\n\\n\\n    def __init__(self):\\n        wx.Frame.__init__(self, None, -1, self.title)\\n\\n        panel = wx.Panel(self)\\n\\n        #icon = wx.Icon('icon.png', wx.BITMAP_TYPE_PNG)\\n        #self.SetIcon(icon)\\n\\n        sizer = wx.FlexGridSizer(rows=2, cols=1, vgap=10, hgap=10)\\n\\n        button1 = wx.Button(panel, -1, 'BUTTON')\\n        sizer.Add(button1, 0, wx.EXPAND)\\n\\n        buttonSizer = wx.FlexGridSizer(rows=1, cols=4, vgap=10, hgap=5)\\n\\n        buttonDelete = wx.Button(panel, -1, 'Delete')\\n        buttonSizer.Add(buttonDelete, 0, 0)\\n\\n        buttonEdit = wx.Button(panel, -1, 'Edit')\\n        buttonSizer.Add(buttonEdit, 0, 0)\\n\\n        buttonNew = wx.Button(panel, -1, 'New')\\n        buttonSizer.Add(buttonNew, 0, 0)\\n\\n        buttonSizer.AddGrowableCol(0, 0)\\n\\n        sizer.Add(buttonSizer, 0, wx.EXPAND|wx.HORIZONTAL)\\n\\n        sizer.AddGrowableCol(0, 0)\\n        sizer.AddGrowableRow(0, 0)\\n\\n        mainSizer = wx.BoxSizer(wx.EXPAND)\\n        mainSizer.Add(sizer, 0, wx.EXPAND|wx.ALL, 10)\\n\\n        #panel.SetSizerAndFit(sizer)\\n        #sizer.SetSizeHints(self)\\n        panel.SetSizerAndFit(mainSizer)\\n        mainSizer.SetSizeHints(self)\\n\\n\\nif __name__ == '__main__':\\n    app = App(False)\\n    app.MainLoop()\\n\\n\\nCommenting out lines 57 and 58 and uncommenting lines 55 and 56 removes the extra BoxSizer and shows how I expect everything to function (without the whitespace of course).\\n\\nI am completely stuck with this problem and still have no clue as to how to fix it.\\n\",\n  'completion': \"First of all, you're passing some flags incorrectly.  BoxSizer takes wx.HORIZONTAL or wx.VERTICAL, not wx.EXPAND.  sizer.Add does not take wx.HORIZONTAL.\\n\\nIf you have a VERTICAL BoxSizer, wx.EXPAND will make the control fill horizontally, while a proportion of 1 or more (second argument to Add) will make the control fill vertically.  It's the opposite for HORIZONTAL BoxSizers.\\n\\nsizer = wx.BoxSizer(wx.VERTICAL)\\nsizer.Add(widget1, 0, wx.EXPAND)\\nsizer.Add(widget2, 1)\\n\\n\\nwidget1 will expand horizontally.  widget2 will expand vertically.\\n\\nIf you put a sizer in another sizer, you need to be sure to have its proportion and EXPAND flags set so that its insides will grow how you want them to.\\n\\nI'll leave the rest to you.\\n\"},\n {'prompt': \"Does anyone know if there's an existing module/function inside Ruby to traverse file system directories and files?  I'm looking for something similar to Python's os.walk. The closest module I've found is Find but requires some extra work to do the traversal.\\n\\nThe Python code looks like the following:\\n\\nfor root, dirs, files in os.walk('.'):\\n    for name in files:\\n        print name\\n    for name in dirs:\\n        print name\\n\\n\",\n  'completion': \"The following will print all files recursively. Then you can use File.directory? to see if the it is a directory or a file.\\n\\nDir['**/*'].each { |f| print f }\\n\\n\"},\n {'prompt': 'How can I implement Comet / Server push in Google App Engine in Python?\\n',\n  'completion': \"We just announced the Channel API to do comet push with App Engine apps: http://googleappengine.blogspot.com/2010/05/app-engine-at-google-io-2010.html\\n\\nIf you're at Google IO, I'll be talking about this at 1pm tomorrow (on the APIs track): http://code.google.com/events/io/2010/sessions/building-real-time-apps-app-engine-feed-api.html\\n\\nHere's the YouTube video of the session: http://www.youtube.com/watch?v=oMXe-xK0BWA\\n\\nHopefully last update! This is now released: code.google.com/appengine/docs/python/channel\\n\"},\n {'prompt': \"Is there a recommended package for machine learning in Python?\\n\\nI have previous experience in implementing a variety of machine learning and statistical algorithms in C++ and MATLAB, but having done some work in Python I'm curious about the available packages for Python.\\n\",\n  'completion': 'There is also scikit-learn (BSD, with only dependencies on numpy & scipy). It includes various supervised learning algorithms such as:\\n\\n\\nSVM based on libsvm and linear with scipy.sparse bindings for wide features datasets\\nbayesian methods\\nHMMs\\nL1 and L1+L2 regularized regression methods aka Lasso and Elastic Net models implemented with algorithms such as LARS and coordinate descent\\n\\n\\nIt also features unsupervised clustering algorithms such as:\\n\\n\\nkmeans++\\nmeanshift\\naffinity propagation\\nspectral clustering\\n\\n\\nAnd also other tools such as:\\n\\n\\nfeature extractors for text content (token and char ngrams + hashing vectorizer)\\nunivariate feature selections\\na simple pipe line tool\\nnumerous implementations of cross validation strategies\\nperformance metrics evaluation and ploting (ROC curve, AUC, confusion matrix, ...)\\na grid search utility to perform hyper-parameters tuning using parallel cross validation\\nintegration with joblib for caching partial results when working in interactive environment (e.g. using ipython)\\n\\n\\nEach algorithm implementation comes with sample programs demonstrating its usage either on toy data or real life datasets.\\n\\nAlso, the official source repository is hosted on github so please feel free to contribute bugfixes and improvement using the regular pull request feature for interactive code review.\\n'},\n {'prompt': 'I tried IronPython some time ago and it seemed that it implements only python language, and uses .NET for libraries. Is this still the case? Can one use python modules from IronPython?\\n',\n  'completion': 'The IronPython installer includes the Python standard library. Otherwise, you can use the standard library from a compatible Python install (IPy 2.0 -> CPy 2.5, IPy 2.6 -> CPy 2.6). Either copy the Python Lib directory to the IronPython folder, or set IRONPYTHONPATH.\\n\\nDo note that only the pure Pyton modules will be available; Python modules that require C extensions have to be re-implemented (and most of them have been).\\n'},\n {'prompt': 'I have a postscript file and want it to be printed on a IPP capable device (or CUPS server). What is the minimal code and dependencies I could get away with to do that.\\n\\nUsing LPR or libcups gives me lot of cross-plattform dependencies. So my first approach was to implement a minimal subset of IPP (the protocol used by cups and many modern printers) since \"it\\'s only extended HTTP\". But unfortuntely a IPP client is a lot more code than a few lines and so far I found no IPP client implementation meant for just printing and not managing a printserver.\\n\\nI would prefer a solution in Python, but would also be happy with something in an oter dynamic language.\\n',\n  'completion': 'you need to add remote printer to CUPS:\\n\\nlpadmin -p printername -E -v //IPADDRESS/spool -m driver.ppd\\n\\n\\nwhere driver.ppd is the driver to print with\\n\\nps: this could also work for programatic access, if printer is set before.\\n'},\n {'prompt': \"I'm about to begin my next web development project and wanted to hear about the merits of Lua within the web-development space.\\n\\nHow does Lua compare to PHP/Python/JSP/etc.. for web development?\\n\\nAny reason why Lua would be a poor choice for a web application language vs the others?\\n\",\n  'completion': 'In brief:\\n\\n\\nLua gives you a smaller, simpler system that you can understand in its entirety, but it is in a much smaller ecosystem; Kepler is all you get, and you will probably have to build some of your own stuff.  I find this easy and fun (I make heavy use of the Lua bindings to the Expat parser and the Lua Object Model, which are part of Kepler), but others may prefer to use what everyone else is using.\\nPHP started out as more of a macro processor than a language, and although it has improved over the years, when people say \"X has really gotten a lot better\", I tend to be wary of\\xa0X.  I\\xa0find PHP offputting, but there is a huge ecosystem for web development.\\nPython is a nice language but much bigger than Lua, and in the throes of a major revision (transition from 2.5 to 3.x).  Again you get a big ecosystem; the problem I have with Python is that the language and system are too big for any one person to understand all of.  I\\xa0don\\'t like to be in this situation if I don\\'t have to.\\nRuby is a bit of a cleaner language design, and the large Rails ecosystem is a winner.  Ruby is less complex than Python but more complex than Lua.  Rails is a bit of a beast.\\n\\n\\nIt comes down to this question:\\n\\n\\nWould you rather understand all the software in your system, even if you have to build a lot of things yourself?\\nOr would you rather have a lot of things already built for you, even if you wind up not understanding exactly how every piece works?\\n\\n\\nIf you want to understand everything, Lua is your game.  If you want a lot of stuff already built for you, I\\xa0can\\'t advise you how to pick among PHP/Python/JSP/Rails and so on.\\n\\nMore on Lua and Python at Which language is better to use, Lua or Python?\\n'},\n {'prompt': 'Amazon Product API now requires a signature with every request which I\\'m trying to generate ushing Python.\\n\\nThe step I get hung up on is this one:\\n\\n\"Calculate an RFC 2104-compliant HMAC with the SHA256 hash algorithm using the string above with our \"dummy\" Secret Access Key: 1234567890. For more information about this step, see documentation and code samples for your programming language.\" \\n\\nGiven a string and a secret key (in this case 1234567890) how do I calculate this hash using Python?\\n\\n----------- UPDATE -------------\\n\\nThe first solution using HMAC.new looks correct however I\\'m getting a different result than they are.\\n\\nhttp://docs.amazonwebservices.com/AWSECommerceService/latest/DG/index.html?rest-signature.html\\n\\nAccording to Amazon\\'s example when you hash the secret key 1234567890 and the following string\\n\\nGET\\nwebservices.amazon.com\\n/onca/xml\\nAWSAccessKeyId=00000000000000000000&ItemId=0679722769&Operation=I\\ntemLookup&ResponseGroup=ItemAttributes%2COffers%2CImages%2CReview\\ns&Service=AWSECommerceService&Timestamp=2009-01-01T12%3A00%3A00Z&\\nVersion=2009-01-06\\n\\n\\nYou should get the following signature: \\'Nace+U3Az4OhN7tISqgs1vdLBHBEijWcBeCqL5xN9xg=\\'\\n\\nI am getting this:  \\'411a59403c9f58b4a434c9c6a14ef6e363acc1d1bb2c6faf9adc30e20898c83b\\'\\n',\n  'completion': \"import hmac\\nimport hashlib\\nimport base64\\ndig = hmac.new(b'1234567890', msg=your_bytes_string, digestmod=hashlib.sha256).digest()\\nbase64.b64encode(dig).decode()      # py3k-mode\\n'Nace+U3Az4OhN7tISqgs1vdLBHBEijWcBeCqL5xN9xg='\\n\\n\"},\n {'prompt': \"I have the following code which I use to map a nested list in Python to produce a list with the same structure. \\n\\n>>> nested_list = [['Hello', 'World'], ['Goodbye', 'World']]\\n>>> [map(str.upper, x) for x in nested_list]\\n[['HELLO', 'WORLD'], ['GOODBYE', 'WORLD']]\\n\\n\\nCan this be done with list comprehension alone (without using the map function)?\\n\",\n  'completion': \"For nested lists you can use nested list comprehensions:\\n\\nnested_list = [[s.upper() for s in xs] for xs in nested_list]\\n\\n\\nPersonally I find map to be cleaner in this situation, even though I almost always prefer list comprehensions.  So it's really your call, since either will work.\\n\"},\n {'prompt': \"I have two PNGs that I am trying to combine into a PDF using ReportLab 2.3 on Python 2.5.  When I use canvas.drawImage(ImageReader) to write either PNG onto the canvas and save, the transparency comes out black.  If I use PIL (1.1.6) to generate a new Image, then paste() either PNG onto the PIL Image, it composits just fine.  I've double checked in Gimp and both images have working alpha channels and are being saved correctly.  I'm not receiving an error and there doesn't seem to be anything my google-fu can turn up.  \\n\\nHas anybody out there composited a transparent PNG onto a ReportLab canvas, with the transparency working properly?  Thanks!\\n\",\n  'completion': \"Passing the mask parameter with a value of 'auto' to drawImage fixes this for me.\\n\\ndrawImage(......., mask='auto')\\n\\n\\nMore information on the drawImage-function\\n\"},\n {'prompt': 'I have written a function comp(time1, time2) which will return true when time1 is lesser than time2. I have a scenario where time1 should always be lesser than time2. I need time1 to have the least possible value(date). How to find this time and how to form the corresponding object.\\n',\n  'completion': 'If using the datetime module, date, time, and datetime objects all have a min and max attribute.\\n\\n>>> from datetime import date, time, datetime\\n>>> date.min\\ndatetime.date(1, 1, 1)\\n>>> date.max\\ndatetime.date(9999, 12, 31)\\n>>> time.min\\ndatetime.time(0, 0)\\n>>> time.max\\ndatetime.time(23, 59, 59, 999999)\\n>>> datetime.min\\ndatetime.datetime(1, 1, 1, 0, 0)\\n>>> datetime.max\\ndatetime.datetime(9999, 12, 31, 23, 59, 59, 999999)\\n\\n'},\n {'prompt': \"I am trying to find corresponding keys in two different dictionaries.  Each has about 600k entries.\\n\\nSay for example:\\n\\n    myRDP = { 'Actinobacter': 'GATCGA...TCA', 'subtilus sp.': 'ATCGATT...ACT' }\\n    myNames = { 'Actinobacter': '8924342' }\\n\\n\\nI want to print out the value for Actinobacter (8924342) since it matches a value in myRDP.\\n\\nThe following code works, but is very slow:\\n\\n    for key in myRDP:\\n        for jey in myNames:\\n            if key == jey:\\n                print key, myNames[key]\\n\\n\\nI've tried the following but it always results in a KeyError:\\n\\n    for key in myRDP:\\n        print myNames[key]\\n\\n\\nIs there perhaps a function implemented in C for doing this?  I've googled around but nothing seems to work.\\n\\nThanks.\\n\",\n  'completion': 'You could do this:\\n\\nfor key in myRDP:\\n    if key in myNames:\\n        print key, myNames[key]\\n\\n\\nYour first attempt was slow because you were comparing every key in myRDP with every key in myNames.  In algorithmic jargon, if myRDP has n elements and myNames has m elements, then that algorithm would take O(nÃ\\x97m) operations.  For 600k elements each, this is 360,000,000,000 comparisons!\\n\\nBut testing whether a particular element is a key of a dictionary is fast -- in fact, this is one of the defining characteristics of dictionaries.  In algorithmic terms, the key in dict test is O(1), or constant-time.  So my algorithm will take O(n) time, which is one 600,000th of the time.\\n'},\n {'prompt': \"I need to run a simple script after the modules and programs have been installed.\\nI'm having a little trouble finding straight-forward documentation on how to do this. It looks like I need to inherit from distutils.command.install, override some methods and add this object to the setup script. The specifics are a bit hazy though and it seems like a lot of effort for such a simple hook. Does anyone know an easy way to do this? \\n\",\n  'completion': \"I dug through distutils source for a day to learn enough about it to make a bunch of custom commands. It's not pretty, but it does work.\\n\\nimport distutils.core\\nfrom distutils.command.install import install\\n...\\nclass my_install(install):\\n    def run(self):\\n        install.run(self)\\n        # Custom stuff here\\n        # distutils.command.install actually has some nice helper methods\\n        # and interfaces. I strongly suggest reading the docstrings.\\n...\\ndistutils.core.setup(..., cmdclass=dict(install=my_install), ...)\\n\\n\"},\n {'prompt': 'Folks,\\n\\nis there a collection of gotchas where Numpy differs from python,\\npoints that have puzzled and cost time ?\\n\\n\\n  \"The horror of that moment I shall\\n  never never forget !\"\\n  \"You will, though,\" the Queen said, \"if you don\\'t\\n  make a memorandum of it.\"\\n\\n\\nFor example, NaNs are always trouble, anywhere.\\nIf you can explain this without running it, give yourself a point --\\n\\nfrom numpy import array, NaN, isnan\\n\\npynan = float(\"nan\")\\nprint pynan is pynan, pynan is NaN, NaN is NaN\\na = (0, pynan)\\nprint a, a[1] is pynan, any([aa is pynan for aa in a])\\n\\na = array(( 0, NaN ))\\nprint a, a[1] is NaN, isnan( a[1] )\\n\\n\\n(I\\'m not knocking numpy, lots of good work there, just think a FAQ or Wiki of gotchas would be useful.)\\n\\nEdit: I was hoping to collect half a dozen gotchas (surprises for people learning Numpy).\\nThen, if there are common gotchas or, better, common explanations,\\nwe could talk about adding them to a community Wiki (where ?)\\nIt doesn\\'t look like we have enough so far.\\n',\n  'completion': 'Because __eq__ does not return a bool, using numpy arrays in any kind of containers prevents equality testing without a container-specific work around.\\n\\nExample:\\n\\n>>> import numpy\\n>>> a = numpy.array(range(3))\\n>>> b = numpy.array(range(3))\\n>>> a == b\\narray([ True,  True,  True], dtype=bool)\\n>>> x = (a, \\'banana\\')\\n>>> y = (b, \\'banana\\')\\n>>> x == y\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\\n\\n\\nThis is a horrible problem.  For example, you cannot write unittests for containers which use TestCase.assertEqual() and must instead write custom comparison functions.  Suppose we write a work-around function special_eq_for_numpy_and_tuples.  Now we can do this in a unittest:\\n\\nx = (array1, \\'deserialized\\')\\ny = (array2, \\'deserialized\\')\\nself.failUnless( special_eq_for_numpy_and_tuples(x, y) )\\n\\n\\nNow we must do this for every container type we might use to store numpy arrays.  Furthermore, __eq__ might return a bool rather than an array of bools:\\n\\n>>> a = numpy.array(range(3))\\n>>> b = numpy.array(range(5))\\n>>> a == b\\nFalse\\n\\n\\nNow each of our container-specific equality comparison functions must also handle that special case.\\n\\nMaybe we can patch over this wart with a subclass?\\n\\n>>> class SaneEqualityArray (numpy.ndarray):\\n...   def __eq__(self, other):\\n...     return isinstance(other, SaneEqualityArray) and self.shape == other.shape and (numpy.ndarray.__eq__(self, other)).all()\\n... \\n>>> a = SaneEqualityArray( (2, 3) )\\n>>> a.fill(7)\\n>>> b = SaneEqualityArray( (2, 3) )\\n>>> b.fill(7)\\n>>> a == b\\nTrue\\n>>> x = (a, \\'banana\\')\\n>>> y = (b, \\'banana\\')\\n>>> x == y\\nTrue\\n>>> c = SaneEqualityArray( (7, 7) )\\n>>> c.fill(7)\\n>>> a == c\\nFalse\\n\\n\\nThat seems to do the right thing.  The class should also explicitly export elementwise comparison, since that is often useful.\\n'},\n {'prompt': \"I wonder what is better to do:\\n\\nd = {'a': 1, 'b': 2}\\n'a' in d\\nTrue\\n\\n\\nor:\\n\\nd = {'a': 1, 'b': 2}\\nd.has_key('a')\\nTrue\\n\\n\",\n  'completion': 'in is definitely more pythonic.\\n\\nIn fact has_key() was removed in Python 3.x.\\n'},\n {'prompt': 'I have the following simple python test script that uses Suds to call a SOAP web service (the service is written in ASP.net):\\n\\nfrom suds.client import Client\\n\\nurl = \\'http://someURL.asmx?WSDL\\'\\n\\nclient = Client( url )\\n\\nresult = client.service.GetPackageDetails( \"MyPackage\"  )\\n\\nprint result\\n\\n\\nWhen I run this test script I am getting the following error (used code markup as it doesn\\'t wrap):\\n\\nNo handlers could be found for logger \"suds.bindings.unmarshaller\"\\nTraceback (most recent call last):\\n  File \"sudsTest.py\", line 9, in <module>\\n    result = client.service.GetPackageDetails( \"t3db\"  )\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/client.py\", line 240, in __call__\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/client.py\", line 379, in call\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/client.py\", line 240, in __call__\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/client.py\", line 422, in call\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/client.py\", line 480, in invoke\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/client.py\", line 505, in send\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/client.py\", line 537, in succeeded\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/bindings/binding.py\", line 149, in get_reply\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/bindings/unmarshaller.py\", line 303, in process\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/bindings/unmarshaller.py\", line 88, in process\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/bindings/unmarshaller.py\", line 104, in append\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/bindings/unmarshaller.py\", line 181, in append_children\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/bindings/unmarshaller.py\", line 104, in append\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/bindings/unmarshaller.py\", line 181, in append_children\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/bindings/unmarshaller.py\", line 104, in append\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/bindings/unmarshaller.py\", line 181, in append_children\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/bindings/unmarshaller.py\", line 102, in append\\n  File \"build/bdist.cygwin-1.5.25-i686/egg/suds/bindings/unmarshaller.py\", line 324, in start\\nsuds.TypeNotFound: Type not found: \\'xs:complexType\\'\\n\\n\\nLooking at the source for the WSDL file\\'s header (reformatted to fit):\\n\\n<?xml version=\"1.0\" encoding=\"utf-8\" ?> \\n<wsdl:definitions xmlns:http=\"http://schemas.xmlsoap.org/wsdl/http/\" \\nxmlns:soap=\"http://schemas.xmlsoap.org/wsdl/soap/\" \\nxmlns:s=\"http://www.w3.org/2001/XMLSchema\" \\nxmlns:soapenc=\"http://schemas.xmlsoap.org/soap/encoding/\" \\nxmlns:tns=\"http://http://someInternalURL/webservices.asmx\" \\nxmlns:tm=\"http://microsoft.com/wsdl/mime/textMatching/\" \\nxmlns:mime=\"http://schemas.xmlsoap.org/wsdl/mime/\" \\ntargetNamespace=\"http://someURL.asmx\" \\nxmlns:wsdl=\"http://schemas.xmlsoap.org/wsdl/\">\\n\\n\\nI am guessing based on the last line of output:\\n\\nsuds.TypeNotFound: Type not found: \\'xs:complexType\\'\\n\\n\\nThat I need to use Sud\\'s doctor class to fix the schema but being a SOAP newbie I don\\'t know what exactly needs fixed in my case.  Does anyone here have any experience using Suds to fix/correct schema?\\n',\n  'completion': 'Ewall\\'s resource is a good one. If you try to search in suds trac tickets, you could see that other people have problems similar to yours, but with different object types. It can be a good way to learn from it\\'s examples and how they import their namespaces.\\n\\n\\n  The problem is that your wsdl contains\\n  a schema definition that references\\n  the (...) but fails to import\\n  the\\n  \"http://schemas.xmlsoap.org/soap/encoding/\"\\n  namespace (and associated schema)\\n  properly. The schema can be patched at\\n  runtime using the schema ImportDoctor\\n  as discussed here:\\n  https://fedorahosted.org/suds/wiki/Documentation#FIXINGBROKENSCHEMAs.\\n  \\n  This is a fairly common problem.\\n  \\n  A commonly referenced schema (that is\\n  not imported) is the SOAP section 5\\n  encoding schema. This can now be fixed\\n  as follows:\\n\\n\\n(all emphasis were mine).\\n\\nYou could try the lines that these documentations provide adding the namespaces presented in your WSDL. This can be a try-and-error aproach.\\n\\nimp = Import(\\'http://schemas.xmlsoap.org/soap/encoding/\\')\\n# Below is your targetNamespace presented in WSDL. Remember\\n# that you can add more namespaces by appending more imp.filter.add\\nimp.filter.add(\\'http://someURL.asmx\\') \\ndoctor = ImportDoctor(imp) \\nclient = Client(url, doctor=doctor)\\n\\n\\nYou didn\\'t provide the WSDL you\\'re working with,  I suppose you have reasons to not showing to us... so I think you have to try these possibilities by yourself. Good luck!\\n'},\n {'prompt': \"Newbie to Python, so this may seem silly.\\n\\nI have two dicts:\\n\\ndefault = {'a': 'alpha', 'b': 'beta', 'g': 'Gamma'}\\nuser = {'a': 'NewAlpha', 'b': None}\\n\\n\\nI need to update my defaults with the values that exist in user.  But only for those that have a value not equal to None.  So I need to get back a new dict:\\n\\nresult = {'a': 'NewAlpha', 'b': 'beta', 'g': 'Gamma'}\\n\\n\",\n  'completion': 'result = default.copy()\\nresult.update((k, v) for k, v in user.iteritems() if v is not None)\\n\\n'},\n {'prompt': \"I have a string that looks like so:\\n\\n6Ã\\x82Â\\xa0918Ã\\x82Â\\xa0417Ã\\x82Â\\xa0712\\n\\n\\nThe clear cut way to trim this string (as I understand Python) is simply to say the string is in a variable called s, we get:\\n\\ns.replace('Ã\\x82 ', '')\\n\\n\\nThat should do the trick. But of course it complains that the non-ASCII character '\\\\xc2' in file blabla.py is not encoded.\\n\\nI never quite could understand how to switch between different encodings.\\n\\nHere's the code, it really is just the same as above, but now it's in context. The file is saved as UTF-8 in notepad and has the following header:\\n\\n#!/usr/bin/python2.4\\n# -*- coding: utf-8 -*-\\n\\n\\nThe code:\\n\\nf = urllib.urlopen(url)\\n\\nsoup = BeautifulSoup(f)\\n\\ns = soup.find('div', {'id':'main_count'})\\n\\n#making a print 's' here goes well. it shows 6Ã\\x82 918Ã\\x82 417Ã\\x82 712\\n\\ns.replace('Ã\\x82 ','')\\n\\nsave_main_count(s)\\n\\n\\nIt gets no further than s.replace...\\n\",\n  'completion': 'def removeNonAscii(s): return \"\".join(filter(lambda x: ord(x)<128, s))\\n\\n\\nedit: my first impulse is always to use a filter, but the generator expression is more memory efficient (and shorter)...\\n\\ndef removeNonAscii(s): return \"\".join(i for i in s if ord(i)<128)\\n\\n\\nKeep in mind that this is guaranteed to work with UTF-8 encoding (because all bytes in multi-byte characters have the highest bit set to 1).\\n'},\n {'prompt': \"How can I flip the origin of a matplotlib plot to be in the upper-left corner - as opposed to the default lower-left?  I'm using matplotlib.pylab.plot to produce the plot (though if there is another plotting routine that is more flexible, please let me know).\\n\\nI'm looking for the equivalent of the matlab command:  axis ij;\\n\\nAlso, I've spent a couple hours surfing matplotlib help and google but haven't come up with an answer.  Some info on where I could have looked up the answer would be helpful as well.\\n\",\n  'completion': \"axis ij just makes the y-axis increase downward instead of upward, right?  If so, then matplotlib.axes.invert_yaxis() might be all you need -- but I can't test that right now.\\n\\nIf that doesn't work, I found a mailing post suggesting that\\n\\nsetp(gca(), 'ylim', reversed(getp(gca(), 'ylim')))\\n\\n\\nmight do what you want to resemble axis ij.\\n\"},\n {'prompt': \"I'm having trouble debugging a multi-process application (specifically using a process pool in python's multiprocessing module). I have an apparent deadlock and I do not know what is causing it. The stack trace is not sufficient to describe the issue, as it only displays code in the multiprocessing module.\\n\\nAre there any python tools, or otherwise general techniques used to debug deadlocks?\\n\",\n  'completion': 'Yah, debugging deadlocks is fun.  You can set the logging level to be higher -- see the Python documentation for a description of it, but really quickly:\\n\\nimport multiprocessing, logging\\nlogger = multiprocessing.log_to_stderr()\\nlogger.setLevel(multiprocessing.SUBDEBUG)\\n\\n\\nAlso, add logging for anything in your code that deals with a resource or whatnot that might be in contention.  Finally, shot in the dark:  spawning off child processes during an import might cause a problem.\\n'},\n {'prompt': 'Can someone help me to find a solution on how to calculate a cubic root of the negative number using python?\\n\\n>>> math.pow(-3, float(1)/3)\\nnan\\n\\n\\nit does not work. Cubic root of the negative number is negative number. Any solutions?\\n',\n  'completion': \"A simple use of De Moivre's formula, is sufficient  to show that the cube root of a value, regardless of sign, is a multi-valued function. That means, for any input value, there will be three solutions. Most of the solutions presented to far only return the principle root. A solution that returns all valid roots, and explicitly tests for non-complex special cases, is shown below.\\n\\nimport numpy\\nimport math\\ndef cuberoot( z ):\\n    z = complex(z)\\n    x = z.real\\n    y = z.imag\\n    mag = abs(z)\\n    arg = math.atan2(y,x)\\n    return [ mag**(1./3) * numpy.exp( 1j*(arg+2*n*math.pi)/3 ) for n in range(1,4) ]\\n\\n\\nEdit: As requested, in cases where it is inappropriate to have dependency on numpy, the following code does the same thing.\\n\\ndef cuberoot( z ):\\n    z = complex(z) \\n    x = z.real\\n    y = z.imag\\n    mag = abs(z)\\n    arg = math.atan2(y,x)\\n    resMag = mag**(1./3)\\n    resArg = [ (arg+2*math.pi*n)/3. for n in range(1,4) ]\\n    return [  resMag*(math.cos(a) + math.sin(a)*1j) for a in resArg ]\\n\\n\"},\n {'prompt': 'I have a group of objects which I am creating a class for that I want to store each object as its own text file. I would really like to store it as a Python class definition which subclasses the main class I am creating. So, I did some poking around and found a Python Code Generator on effbot.org. I did some experimenting with it and here\\'s what I came up with:\\n\\n#\\n# a Python code generator backend\\n#\\n# fredrik lundh, march 1998\\n#\\n# fredrik@pythonware.com\\n# http://www.pythonware.com\\n#\\n# Code taken from http://effbot.org/zone/python-code-generator.htm\\n\\nimport sys, string\\n\\nclass CodeGeneratorBackend:\\n\\n    def begin(self, tab=\"\\\\t\"):\\n        self.code = []\\n        self.tab = tab\\n        self.level = 0\\n\\n    def end(self):\\n        return string.join(self.code, \"\")\\n\\n    def write(self, string):\\n        self.code.append(self.tab * self.level + string)\\n\\n    def indent(self):\\n        self.level = self.level + 1\\n\\n    def dedent(self):\\n        if self.level == 0:\\n            raise SyntaxError, \"internal error in code generator\"\\n        self.level = self.level - 1\\n\\nclass Point():\\n    \"\"\"Defines a Point. Has x and y.\"\"\"\\n    def __init__(self, x, y):\\n        self.x = x\\n        self.y = y\\n\\n    def dump_self(self, filename):\\n        self.c = CodeGeneratorBackend()\\n        self.c.begin(tab=\"    \")\\n        self.c.write(\"class {0}{1}Point()\\\\n\".format(self.x,self.y))\\n        self.c.indent()\\n        self.c.write(\\'\"\"\"Defines a Point. Has x and y\"\"\"\\\\n\\')\\n        self.c.write(\\'def __init__(self, x={0}, y={1}):\\\\n\\'.format(self.x, self.y))\\n        self.c.indent()\\n        self.c.write(\\'self.x = {0}\\\\n\\'.format(self.x))\\n        self.c.write(\\'self.y = {0}\\\\n\\'.format(self.y))\\n        self.c.dedent()\\n        self.c.dedent()\\n        f = open(filename,\\'w\\')\\n        f.write(self.c.end())\\n        f.close()\\n\\nif __name__ == \"__main__\":\\n    p = Point(3,4)\\n    p.dump_self(\\'demo.py\\')\\n\\n\\nThat feels really ugly, is there a cleaner/better/more pythonic way to do this? Please note, this is not the class I actually intend to do this with, this is a small class I can easily mock up in not too many lines. Also, the subclasses don\\'t need to have the generating function in them, if I need that again, I can just call the code generator from the superclass.\\n',\n  'completion': \"We use Jinja2 to fill in a template.  It's much simpler.\\n\\nThe template looks a lot like Python code with a few {{something}} replacements in it.\\n\"},\n {'prompt': 'I am sending an AJAX request to a Django view that can potentially take a lot of time. It goes through some well-defined steps, however, so I would like to print status indicators to the user letting it know when it is finished doing a certain thing and has moved on to the next.\\n\\nIf I was using PHP it might look like this, using the flush function:\\n\\ndo_something();\\nprint \\'Done doing something!\\';\\nflush();\\n\\ndo_something_else();\\nprint \\'Done doing something else!\\';\\nflush();\\n\\n\\nHow would I go about doing the same with Django? Looking at the documentation I see that HttpResponse objects have a flush method, but all it has to say is that \"This method makes an HttpResponse instance a file-like object.\" - I\\'m not sure that\\'s what I want. I\\'m having a hard time wrapping my head around how this could be done in Django since I have to return the response and don\\'t really have a control of when the content goes to the browser.\\n',\n  'completion': 'Most webservers (eg. FCGI/SCGI) do their own buffering, HTTP clients do their own, and so on.  It\\'s very difficult to actually get data flushed out in this way and for the client to actually receive it, because it\\'s not a typical operation.\\n\\nThe closest to what you\\'re trying to do would be to pass an iterator to HttpResponse, and to do the work in a generator; something like this:\\n\\ndef index(request):\\n    def do_work():\\n        step_1()\\n        yield \"step 1 complete\"\\n        step_2()\\n        yield \"step 2 complete\"\\n        step_3()\\n        yield \"step 3 complete\"\\n    return HttpResponse(do_work())\\n\\n\\n... but this won\\'t necessarily flush.  (Not tested code, but you get the idea; see http://docs.djangoproject.com/en/dev/ref/request-response/#passing-iterators.)\\n\\nMost of the infrastructure is simply not expecting a piecemeal response.  Even if Django isn\\'t buffering, your front-end server might be, and the client probably is, too.  That\\'s why most things use pull updates for this: a separate interface to query the status of a long-running request.\\n\\n(I\\'d like to be able to do reliable push updates for this sort of thing, too...)\\n'},\n {'prompt': 'To read contents of a file:\\n\\ndata = open(filename, \"r\").read()\\n\\n\\nThe open file immediately stops being referenced anywhere, so the file object will eventually close... and it shouldn\\'t affect other programs using it, since the file is only open for reading, not writing.\\n\\nEDIT: This has actually bitten me in a project I wrote - it prompted me to ask this question. File objects are cleaned up only when you run out of memory, not when you run out of file handles. So if you do this too often, you could end up running out of file descriptors and causing your IO attempts at opening files to throw exceptions.\\n',\n  'completion': 'Just for the record:\\nThis is only slightly longer, and closes the file immediately:\\n\\nfrom __future__ import with_statement\\n\\nwith open(filename, \"r\") as f:\\n    data = f.read()\\n\\n'},\n {'prompt': 'Like if I have a string like str1 = \"IWantToMasterPython\"\\n\\nIf I want to extract \"Py\" from the above string. I write:\\n\\nextractedString = foo(\"Master\",\"thon\")\\n\\n\\nI want to do all this because i am trying to extract lyrics from an html page. The lyrics are written like <div class = \"lyricbox\"> ....lyrics goes here....</div>.\\n\\nAny suggestions on how can I implement.\\n',\n  'completion': \"The solution is to use a regexp:\\n\\nimport re\\nr = re.compile('Master(.*?)thon')\\nm = r.search(str1)\\nif m:\\n    lyrics = m.group(1)\\n\\n\"},\n {'prompt': 'One of the things I deal with most in data cleaning is missing values. R deals with this well using its \"NA\" missing data label. In python, it appears that I\\'ll have to deal with masked arrays which seem to be a major pain to set up and don\\'t seem to be well documented. Any suggestions on making this process easier in Python? This is becoming a deal-breaker in moving into Python for data analysis. Thanks\\n\\nUpdate It\\'s obviously been a while since I\\'ve looked at the methods in the numpy.ma module. It appears that at least the basic analysis functions are available for masked arrays, and the examples provided helped me understand how to create masked arrays (thanks to the authors). I would like to see if some of the newer statistical methods in Python (being developed in this year\\'s GSoC) incorporates this aspect, and at least does the complete case analysis.\\n',\n  'completion': \"If you are willing to consider a library, pandas (http://pandas.pydata.org/) is a library built on top of numpy which amongst many other things provides:\\n\\n\\n  Intelligent data alignment and integrated handling of missing data: gain automatic label-based alignment in computations and easily manipulate messy data into an orderly form\\n\\n\\nI've been using it for almost one year in the financial industry where missing and badly aligned data is the norm and it really made my life easier.\\n\"},\n {'prompt': \"I'm having some weird issues with pytz's .localize() function. Sometimes it wouldn't make adjustments to the localized datetime:\\n\\n.localize behaviour:\\n\\n>>> tz\\n<DstTzInfo 'Africa/Abidjan' LMT-1 day, 23:44:00 STD> \\n>>> d\\ndatetime.datetime(2009, 9, 2, 14, 45, 42, 91421)\\n\\n>>> tz.localize(d)\\ndatetime.datetime(2009, 9, 2, 14, 45, 42, 91421, \\n                  tzinfo=<DstTzInfo 'Africa/Abidjan' GMT0:00:00 STD>)\\n>>> tz.normalize(tz.localize(d))\\ndatetime.datetime(2009, 9, 2, 14, 45, 42, 91421,\\n                  tzinfo=<DstTzInfo 'Africa/Abidjan' GMT0:00:00 STD>)\\n\\n\\nAs you can see, time has not been changed as a result of localize/normalize operations.\\nHowever, if .replace is used:\\n\\n>>> d.replace(tzinfo=tz)\\ndatetime.datetime(2009, 9, 2, 14, 45, 42, 91421, \\n                  tzinfo=<DstTzInfo 'Africa/Abidjan' LMT-1 day, 23:44:00 STD>)\\n>>> tz.normalize(d.replace(tzinfo=tz))\\ndatetime.datetime(2009, 9, 2, 15, 1, 42, 91421,\\n                  tzinfo=<DstTzInfo 'Africa/Abidjan' GMT0:00:00 STD>)\\n\\n\\nWhich seems to make adjustments into datetime. \\n\\nQuestion is - which is correct and why other's wrong?\\n\\nThanks!\\n\",\n  'completion': 'localize just assumes that the naive datetime you pass it is \"right\" (except for not knowing about the timezone!) and so just sets the timezone, no other adjustments.\\n\\nYou can (and it\\'s advisable...) internally work in UTC (rather than with naive datetimes) and use replace when you need to perform I/O of datetimes in a localized way (normalize will handle DST and the like).\\n'},\n {'prompt': \"I am learning Python and creating a database connection.\\nWhile trying to add to the DB, I am thinking of creating tuples out of information and then add them to the DB. \\n\\nWhat I am Doing:\\nI am taking information from the user and store it in variables. \\nCan I add these variables into a tuple?  Can you please help me with the syntax?\\n\\nAlso if there is an efficient way of doing this, please share...\\n\\nEDIT\\nLet me edit this question a bit...I only need the tuple to enter info into the DB.  Once the information is added to the DB, should I delete the tuple?  I mean I don't need the tuple anymore.\\n\",\n  'completion': 'Tuples are immutable; you can\\'t change which variables they contain after construction. However, you can concatenate or slice them to form new tuples:\\n\\na = (1, 2, 3)\\nb = a + (4, 5, 6)\\nc = b[1:]\\n\\n\\nAnd, of course, build them from existing values:\\n\\n   name = \"Joe\"\\n   age = 40\\n   location = \"New York\"\\n   joe = (name, age, location)\\n\\n'},\n {'prompt': 'I\\'m getting about the same bad looking resizing from all the 4 algorithms of PIL\\n\\n>>> data = utils.fetch(\"http://wavestock.com/images/beta-icon.gif\")\\n>>> image = Image.open(StringIO.StringIO(data)); image.save(\"/home/ptarjan/www/tmp/metaward/original.png\")\\n>>>\\n>>> image = Image.open(StringIO.StringIO(data)); image.resize((36,36), Image.ANTIALIAS).save(\"/home/ptarjan/www/tmp/metaward/antialias.png\")\\n>>> image = Image.open(StringIO.StringIO(data)); image.resize((36,36), Image.BILINEAR).save(\"/home/ptarjan/www/tmp/metaward/bilinear.png\")\\n>>> image = Image.open(StringIO.StringIO(data)); image.resize((36,36), Image.BICUBIC).save(\"/home/ptarjan/www/tmp/metaward/bicubic.png\")\\n>>> image = Image.open(StringIO.StringIO(data)); image.resize((36,36), Image.NEAREST).save(\"/home/ptarjan/www/tmp/metaward/nearest.png\")\\n>>>\\n>>> image = Image.open(StringIO.StringIO(data)); image.thumbnail((36,36), Image.ANTIALIAS); image.save(\"/home/ptarjan/www/tmp/metaward/antialias-thumb.png\")\\n>>> image = Image.open(StringIO.StringIO(data)); image.thumbnail((36,36), Image.BILINEAR); image.save(\"/home/ptarjan/www/tmp/metaward/bilinear-thumb.png\")\\n>>> image = Image.open(StringIO.StringIO(data)); image.thumbnail((36,36), Image.BICUBIC); image.save(\"/home/ptarjan/www/tmp/metaward/bicubic-thumb.png\")\\n>>> image = Image.open(StringIO.StringIO(data)); image.thumbnail((36,36), Image.NEAREST); image.save(\"/home/ptarjan/www/tmp/metaward/nearest-thumb.png\")\\n>>>\\n>>> image = Image.open(StringIO.StringIO(data)); image.convert(\"RGB\").resize((36,36), Image.ANTIALIAS).save(\"/home/ptarjan/www/tmp/metaward/antialias-rgb.png\")\\n>>> image = Image.open(StringIO.StringIO(data)); image.convert(\"RGB\").resize((36,36), Image.BILINEAR).save(\"/home/ptarjan/www/tmp/metaward/bilinear-rgb.png\")\\n>>> image = Image.open(StringIO.StringIO(data)); image.convert(\"RGB\").resize((36,36), Image.BICUBIC).save(\"/home/ptarjan/www/tmp/metaward/bicubic-rgb.png\")\\n>>> image = Image.open(StringIO.StringIO(data)); image.convert(\"RGB\").resize((36,36), Image.NEAREST).save(\"/home/ptarjan/www/tmp/metaward/nearest-rgb.png\")\\n\\n\\nBut the results look much worse that just resizing in firefox.\\n\\nhttp://paulisageek.com/tmp/metaward/images.html\\n\\nHow can I get a similar effect to the firefox result using PIL (or another python image library)?\\n\\nEDIT : Hover your mouse to see what each image is\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIt looks like the RGB and then ANTIALIS looks the best. Any other recommendations?\\n\\nFor reference, this is the one that looked the best :\\n\\n>>> image = Image.open(StringIO.StringIO(data)); \\n>>> image.convert(\"RGB\").resize((36,36), Image.ANTIALIAS)\\n\\n',\n  'completion': 'I resized the \"original\" with Python and found the same results as you did. I also resized the \"original\" with GIMP and I got the same (if not inferior) quality. This made me suspect that Firefox cheats. Possibly it converts to RGB (\"original\" mode is indexed color). Thus the following code:\\n\\nimport Image\\nim=Image.open(\"beta-icon.gif\")\\nim = im.convert(\"RGB\")\\nim=im.resize((36,36), Image.ANTIALIAS)\\nim.save(\"q5.png\")\\n\\n\\nThe result is almost as good as that of Firefox.\\n'},\n {'prompt': \"I have a python class that looks like this:\\n\\nclass Process:\\n    def __init__(self, PID, PPID, cmd, FDs, reachable, user):\\n\\n\\nfollowed by:\\n\\n        self.PID=PID\\n        self.PPID=PPID\\n        self.cmd=cmd\\n        ...\\n\\n\\nIs there any way to autoinitialize these instance variables, like C++'s initialization list? It would spare lots of redundant code.\\n\",\n  'completion': 'Edit: extended the solution to honor default arguments also\\n\\nHere is the complete solution:\\n\\nfrom functools import wraps\\nimport inspect\\n\\n\\ndef initializer(func):\\n    \"\"\"\\n    Automatically assigns the parameters.\\n\\n    >>> class process:\\n    ...     @initializer\\n    ...     def __init__(self, cmd, reachable=False, user=\\'root\\'):\\n    ...         pass\\n    >>> p = process(\\'halt\\', True)\\n    >>> p.cmd, p.reachable, p.user\\n    (\\'halt\\', True, \\'root\\')\\n    \"\"\"\\n    names, varargs, keywords, defaults = inspect.getargspec(func)\\n\\n    @wraps(func)\\n    def wrapper(self, *args, **kargs):\\n        for name, arg in list(zip(names[1:], args)) + list(kargs.items()):\\n            setattr(self, name, arg)\\n\\n        for name, default in zip(reversed(names), reversed(defaults)):\\n            if not hasattr(self, name):\\n                setattr(self, name, default)\\n\\n        func(self, *args, **kargs)\\n\\n    return wrapper\\n\\n\\n\\n\\nEdit: Adam asked me to extend the solution to support keyword arguments\\n\\nfrom functools import wraps\\nimport inspect\\n\\ndef initializer(fun):\\n   names, varargs, keywords, defaults = inspect.getargspec(fun)\\n   @wraps(fun)\\n   def wrapper(self, *args, **kargs):\\n       for name, arg in zip(names[1:], args) + kargs.items():\\n           setattr(self, name, arg)\\n       fun(self, *args, **kargs)\\n   return wrapper\\n\\n\\n\\n\\nYou can use a decorator:\\n\\nfrom functools import wraps\\nimport inspect\\n\\ndef initializer(fun):\\n    names, varargs, keywords, defaults = inspect.getargspec(fun)\\n    @wraps(fun)\\n    def wrapper(self, *args):\\n        for name, arg in zip(names[1:], args):\\n            setattr(self, name, arg)\\n        fun(self, *args)\\n    return wrapper\\n\\nclass process:\\n    @initializer\\n    def __init__(self, PID, PPID, cmd, FDs, reachable, user):\\n        pass\\n\\n\\nOutput:\\n\\n>>> c = process(1, 2, 3, 4, 5, 6)\\n>>> c.PID\\n1\\n>>> dir(c)\\n[\\'FDs\\', \\'PID\\', \\'PPID\\', \\'__doc__\\', \\'__init__\\', \\'__module__\\', \\'cmd\\', \\'reachable\\', \\'user\\'\\n\\n'},\n {'prompt': 'I\\'m trying to download file with Python using IE:\\n\\nfrom win32com.client import DispatchWithEvents\\n\\nclass EventHandler(object):\\n    def OnDownloadBegin(self):\\n        pass\\n\\nie = DispatchWithEvents(\"InternetExplorer.Application\", EventHandler)\\n\\nie.Visible = 0\\n\\nie.Navigate(\\'http://website/file.xml\\')\\n\\n\\nAfter this, I\\'m getting a window asking the user where to save the file. How can I save this file automatically from python?\\n\\nI need to use some browser, not urllib or mechanize, because before downloading file I need to interact with some ajax functionality.\\n',\n  'completion': 'This works for me as long as the IE dialogs are in the foreground and the downloaded file does not already exist in the \"Save As\" directory:\\n\\nimport time\\nimport threading\\nimport win32ui, win32gui, win32com, pythoncom, win32con\\nfrom win32com.client import Dispatch\\n\\nclass IeThread(threading.Thread):\\n    def run(self):\\n        pythoncom.CoInitialize()\\n        ie = Dispatch(\"InternetExplorer.Application\")\\n        ie.Visible = 0\\n        ie.Navigate(\\'http://website/file.xml\\')\\n\\ndef PushButton(handle, label):\\n    if win32gui.GetWindowText(handle) == label:\\n        win32gui.SendMessage(handle, win32con.BM_CLICK, None, None)\\n        return True\\n\\nIeThread().start()\\ntime.sleep(3)  # wait until IE is started\\nwnd = win32ui.GetForegroundWindow()\\nif wnd.GetWindowText() == \"File Download - Security Warning\":\\n    win32gui.EnumChildWindows(wnd.GetSafeHwnd(), PushButton, \"&Save\");\\n    time.sleep(1)\\n    wnd = win32ui.GetForegroundWindow()\\nif wnd.GetWindowText() == \"Save As\":\\n    win32gui.EnumChildWindows(wnd.GetSafeHwnd(), PushButton, \"&Save\");\\n\\n'},\n {'prompt': 'I\\'ve got a bit of Django form code that looks like this:\\n\\nclass GalleryAdminForm(forms.ModelForm):\\n    auto_id=False\\n    order = forms.CharField(widget=forms.HiddenInput())\\n\\n\\nAnd that makes the form field go away, but it leaves the label \"Order\" in the Django admin page. If I use:\\n\\norder = forms.CharField(widget=forms.HiddenInput(), label=\\'\\')\\n\\n\\nI\\'m still left with the \":\" between where the field and label used to be.\\n\\nHow do I hide the whole thing?!\\n',\n  'completion': \"I can't believe several people have suggested using jQuery for this...\\n\\nIs it a case of: when the only tool you know is a hammer everything looks like a nail?\\n\\nCome on, if you're going to do it from the client-side (instead of fixing the source of the problem in the back-end code) surely the right place to do it would be in CSS?\\n\\nIf you're in the admin site then it's a bit harder but if it's a regular page then it's easy to just omit the whole label from the form template, for example\\n\\nIf you're in the admin site then you could still override the as_table, as_ul, as_p methods of BaseForm (see django/forms/forms.py) in your GalleryAdminForm class to omit the label of any field where the label is blank (or == ':' as the value may be at this stage of rendering)\\n\\n(...looking at lines 160-170 of forms.py it seems like Django 1.2 should properly omit the ':' if the label is blank so I guess you're on an older version?)\\n\"},\n {'prompt': 'What difference it makes when I set python thread as a Deamon, using thread.setDaemon(True) ?\\n',\n  'completion': \"A daemon thread will not prevent the application from exiting.  The program ends when all non-daemon threads (main thread included) are complete.\\n\\nSo generally, if you're doing something in the background, you might want to set the thread as daemon so you don't have to explicitly have that thread's function return before the app can exit.\\n\\nFor example, if you are writing a GUI application and the user closes the main window, the program should quit.  But if you have non-daemon threads hanging around, it won't.\\n\\nFrom the docs: http://docs.python.org/library/threading.html#threading.Thread.daemon\\n\\n\\n  Its initial value is inherited from\\n  the creating thread; the main thread\\n  is not a daemon thread and therefore\\n  all threads created in the main thread\\n  default to daemon = False.\\n  \\n  The entire Python program exits when\\n  no alive non-daemon threads are left.\\n\\n\"},\n {'prompt': \"What is the easiest way to show a .jpg or .gif image from Python console?\\n\\nI've got a Python console program that is checking a data set which contains links to images stored locally. How should I write the script so that it would display images pop-up graphical windows?\\n\",\n  'completion': \"Using the awesome Pillow library:\\n\\n>>> from PIL import Image                                                                                \\n>>> img = Image.open('test.png')\\n>>> img.show() \\n\\n\\nThis will open the image in your default image viewer.\\n\"},\n {'prompt': 'According to the documentation, if DEBUG is set to False and something is provided under the ADMINS setting, Django will send an email whenever the code raises a 500 status code. I have the email settings filled out properly (as I can use send_mail fine) but whenever I intentionally put up erroneous code I get my 500.html template but no error email is sent. What could cause Django to not do this?\\n',\n  'completion': \"In my case the cause was missing SERVER_EMAIL setting.\\n\\nThe default for SERVER_EMAIL is root@localhost. But many of email servers including \\nmy email provider do not accept emails from such suspicious addresses. They silently drop the emails.\\n\\nChanging the sender email address to django@my-domain.com solved the problem. In settings.py:\\n\\nSERVER_EMAIL = 'django@my-domain.com'\\n\\n\"},\n {'prompt': 'I just installed it with apt-get on debian linux with\\n\\napt-get install libqt4-opengl\\n\\n\\nthe rest of PyQt4 is available, but I cant get to this new module.\\n\\nfrom PyQt4 import QtOpenGL\\n\\n\\nraises ImportError. any idea what to do? \\n',\n  'completion': 'Did you forget to install the Python bindings?\\n\\napt-get install python-qt4-gl\\n\\n'},\n {'prompt': \"I'm starting work on some simulations using MPI and want to do the programming in Python/scipy. The scipy site lists a number of mpi libraries, but I was hoping to get feedback on quality, ease of use, etc from anyone who has used one.\\n\",\n  'completion': \"I have heard good things about mpi4py (but I have never used it myself). That's what a colleague recommended who looked at all the alternatives. He mentioned the completeness as one advantage.\\n\"},\n {'prompt': \"I'm reading the not so complete pytz documentation and I'm stuck on understand one part of it.\\n\\n\\n  Converting between timezones also needs special attention. This also needs to use the normalize method to ensure the conversion is correct.\\n\\n\\n>>> utc_dt = utc.localize(datetime.utcfromtimestamp(1143408899))\\n>>> utc_dt.strftime(fmt)\\n'2006-03-26 21:34:59 UTC+0000'\\n>>> au_tz = timezone('Australia/Sydney')\\n>>> au_dt = au_tz.normalize(utc_dt.astimezone(au_tz))\\n>>> au_dt.strftime(fmt)\\n'2006-03-27 08:34:59 EST+1100'\\n>>> utc_dt2 = utc.normalize(au_dt.astimezone(utc))\\n>>> utc_dt2.strftime(fmt)\\n'2006-03-26 21:34:59 UTC+0000'\\n\\n\\nI tried this very example without using normalize and it turned out just the same. In my opinion this example doesn't really explain why we have to use normalize when converting between datetime objects in different timezones.\\n\\nWould someone please give me an example (like the one above) where the result differs when not using normalize.\\n\\nThanks\\n\",\n  'completion': 'From the pytz documentation:\\n\\n\\n  In addition, if you perform date arithmetic on local times that cross DST boundaries, the results may be in an incorrect timezone (ie. subtract 1 minute from 2002-10-27 1:00 EST and you get 2002-10-27 0:59 EST instead of the correct 2002-10-27 1:59 EDT). A normalize() method is provided to correct this. Unfortunately these issues cannot be resolved without modifying the Python datetime implementation.\\n\\n'},\n {'prompt': 'I know there\\'s a similar topic about python console, but I do not know if they are the same. I tried system(\"clear\") and it didn\\'t work here.\\n\\nHow do I clear python\\'s IDLE window?\\n',\n  'completion': 'The \"cls\" and \"clear\" are commands which will clear a terminal (ie a DOS prompt, or terminal window).  From your screenshot, you are using the shell within IDLE, which won\\'t be affected by such things.  Unfortunately, I don\\'t think there is a way to clear the screen in IDLE.  The best you could do is to scroll the screen down lots of lines, eg:\\n\\nprint \"\\\\n\" * 100\\n\\n\\nThough you could put this in a function:\\n\\ndef cls(): print \"\\\\n\" * 100\\n\\n\\nAnd then call it when needed as cls()\\n'},\n {'prompt': \"I'm working on a library for Python that implements some persistent data structures (mainly as a learning exercise).  However, I'm beginning to learn that explaining persistent data structures to people unfamiliar with them can be difficult.  Can someone help me think of an easy (or at least the least complicated) way to describe persistent data structures to them?\\n\\nI've had a couple of people tell me that the documentation that I have is somewhat confusing.\\n\\n(And before anyone asks, no I don't mean persistent data structures as in persisted to the file system.  Google persistent data structures if you're unclear on this.)\\n\",\n  'completion': 'Try this:\\n\\nPersistent data structures are data structures which, unlike arrays or lists, always preserve their original structure and contents.\\n\\nThey are effectively immutable - instead of changing such a structure, any computation will yield a new copy leaving the original structure unchanged. Whereas conventional data structures follow an imperative (change-based) philosophy, persistent ones are commonly used in functional programming where, in extreme cases, no change is allowed at all. The advantage of this paradigm is that persistent data are much safer, often easier to handle and even preventing bugs connected to unintended change and multithreading issues. Many problems can be formulated functionally in a much more concise way.\\n\\nExample for a non-persistent data structure: The list (vector-list)\\n\\nlist = [1, 2, 3]\\n# List is [1, 2, 3]\\n\\nlist += [4]\\n# Added an element at the end\\n\\nlist[0] = 42\\n# We changed the first element to 42\\n# List is [42, 2, 3, 4]\\n\\n\\nPersistence example: Linked lists (Haskell)\\n\\nlist = [1, 2, 3]\\n# List is [1, 2, 3]\\n\\nlist2 = 0 : list\\n# List2 combines [0] and [1, 2, 3] to [0, 1, 2, 3]\\n# List is still [1, 2, 3]\\n\\nlist3 = updateAt 0 42 list\\n# List3 contains the elements of list2 with the first one set to 42\\n# List and List2 still hold their original values\\n\\n'},\n {'prompt': \"I have a fresh install (started with a wiped drive) of Snow Leopard with the developer tools installed during the Snow Leopard installation.\\n\\nI then installed Python 2.6.2, replacing the Snow Leopard default python 2.6.1. I've tried to install PIL by:\\n\\n\\neasy_install\\npip\\ndownloading source and running python setup.py build manually.\\n\\n\\nAll yield the same error (link to pip log: http://drop.io/gi2bgw6). I've seen others have had success installing PIL using the Snow Leopard default python 2.6.1, so I'm not sure why I'm having so much trouble getting it to work with 2.6.2.\\n\",\n  'completion': 'The problem I ran into was that PIL was being compiled against PowerPC architecture (-arch ppc).\\n\\nDo this before setup/build/compile:\\n\\nexport ARCHFLAGS=\"-arch i386\"\\n\\n\\n(Assuming you\\'re on i386)\\n'},\n {'prompt': \"I'm writing a Python script that may or may not (depending on a bunch of things) run for a long time, and I'd like to make sure that multiple instances (started via cron) don't step on each others toes. The logical way to do this seems to be a PID-based lockfileâ\\x80¦ But I don't want to re-invent the wheel if there is already code to do this.\\n\\nSo, is there a Python module out there which will manage the details of a PID-based lockfile?\\n\",\n  'completion': 'This might be of help to you:  lockfile\\n'},\n {'prompt': 'I\\'m trying to do this:\\n\\nmax_title_width = max([len(text) for text in columns])\\n\\nfor column in columns:\\n    print \"%10s, blah\" % column\\n\\n\\nBut I want to replace the 10 with the value of max_title_width.  How do I do this in the most pythonic way possible?\\n',\n  'completion': 'This is a carryover from the C formatting markup:\\n\\nprint \"%*s, blah\" % (max_title_width,column)\\n\\n\\nIf you want left-justified text (for entries shorter than max_title_width), put a \\'-\\' before the \\'*\\'.\\n\\n>>> text = \"abcdef\"\\n>>> print \"<%*s>\" % (len(text)+2,text)\\n<  abcdef>\\n>>> print \"<%-*s>\" % (len(text)+2,text)\\n<abcdef  >\\n>>>\\n\\n\\nIf the len field is shorter than the text string, the string just overflows:\\n\\n>>> print \"<%*s>\" % (len(text)-2,text)\\n<abcdef>\\n\\n\\nIf you want to clip at a maximum length, use the \\'.\\' precision field of the format placeholder:\\n\\n>>> print \"<%.*s>\" % (len(text)-2,text)\\n<abcd>\\n\\n\\nPut them all together this way:\\n\\n%\\n- if left justified\\n* or integer - min width (if \\'*\\', insert variable length in data tuple)\\n.* or .integer - max width (if \\'*\\', insert variable length in data tuple)\\n\\n'},\n {'prompt': 'I am trying to install MySQLdb package. I found the source code here.\\n\\nI did the following:\\n\\ngunzip MySQL-python-1.2.3c1.tar.gz\\ntar xvf MySQL-python-1.2.3c1.tar\\ncd MySQL-python-1.2.3c1\\npython setup.py build\\n\\n\\nAs the result I got the following:\\n\\nTraceback (most recent call last):\\n  File \"setup.py\", line 5, in ?\\n    from setuptools import setup, Extension\\nImportError: No module named setuptools\\n\\n\\nDoes anybody knows how to solve this problem?\\nBy the way, if I am able to do the described step, I will need to do the following:\\n\\nsudo python setup.py install\\n\\n\\nAnd I have no system-administrator-rights. Do I still have a chance to install MySQLdb?\\n\\nThank you.\\n',\n  'completion': 'After trying many suggestions, simply using sudo apt-get install python-mysqldb worked for me.\\n\\nMore info: \\nGetting \"Error loading MySQLdb module: No module named MySQLdb\" - have tried previously posted solutions\\n'},\n {'prompt': \"I'm new to Python and I'm trying to create a simple GUI using Tkinter. \\n\\nSo often in many user interfaces, hitting the tab button will change the focus from one Text widget to another. Whenever I'm in a Text widget, tab only indents the text cursor.\\n\\nDoes anyone know if this is configurable? If not, can PyQt or any other Python UI framework offer this functionality?\\n\",\n  'completion': 'This is very easy to do with Tkinter.\\n\\nThere are a couple of things that have to happen to make this work. First, you need to make sure that the standard behavior doesn\\'t happen. That is, you don\\'t want tab to both insert a tab and move focus to the next widget. By default events are processed by a specific widget prior to where the standard behavior occurs (typically in class bindings). Tk has a simple built-in mechanism to stop events from further processing. \\n\\nSecond, you need to make sure you send focus to the appropriate widget. There is built-in support for determining what the next widget is.\\n\\nFor example:\\n\\ndef focus_next_window(event):\\n    event.widget.tk_focusNext().focus()\\n    return(\"break\")\\n\\ntext_widget=Text(...)\\ntext_widget.bind(\"<Tab>\", focus_next_window)\\n\\n\\nImportant points about this code:\\n\\n\\nThe method tk_focusNext() returns the next widget in the keyboard traversal hierarchy.\\nthe method focus() sets the focus to that widget\\nreturning \"break\" is critical in that it prevents the class binding from firing. It is this class binding that inserts the tab character, which you don\\'t want.\\n\\n\\nIf you want this behavior for all text widgets in an application you can use the bind_class() method instead of bind() to make this binding affect all text widgets. \\n\\nYou can also have the binding send focus to a very specific widget but I recommend sticking with the default traversal order, then make sure the traversal order is correct.\\n'},\n {'prompt': 'class gpagelet:\\n    \"\"\"\\n    Holds   1) the pagelet xpath, which is a string\\n            2) the list of pagelet shingles, list\\n    \"\"\"\\n    def __init__(self, parent):\\n        if not isinstance( parent, gwebpage):\\n            raise Exception(\"Parent must be an instance of gwebpage\")\\n        self.parent = parent    # This must be a gwebpage instance\\n        self.xpath = None       # String\\n        self.visibleShingles = [] # list of tuples\\n        self.invisibleShingles = [] # list of tuples\\n        self.urls = [] # list of string\\n\\nclass gwebpage:\\n    \"\"\"\\n    Holds all the datastructure after the results have been parsed\\n    holds:  1) lists of gpagelets\\n            2) loc, string, location of the file that represents it\\n    \"\"\"\\n    def __init__(self, url):\\n        self.url = url              # Str\\n        self.netloc = False         # Str\\n        self.gpagelets = []         # gpagelets instance\\n        self.page_key = \"\"          # str\\n\\n\\nIs there a way for me to make my class json serializable? The thing that I am worried is the recursive reference.\\n',\n  'completion': 'Write your own encoder and decoder, which can be very simple like return __dict__\\n\\ne.g. here is a encoder to dump totally recursive tree structure, you can enhance it or use as it is for your own purpose\\n\\nimport json\\n\\nclass Tree(object):\\n    def __init__(self, name, childTrees=None):\\n        self.name = name\\n        if childTrees is None:\\n            childTrees = []\\n        self.childTrees = childTrees\\n\\nclass MyEncoder(json.JSONEncoder):\\n    def default(self, obj):\\n        if not isinstance(obj, Tree):\\n            return super(MyEncoder, self).default(obj)\\n\\n        return obj.__dict__\\n\\nc1 = Tree(\"c1\")\\nc2 = Tree(\"c2\") \\nt = Tree(\"t\",[c1,c2])\\n\\nprint json.dumps(t, cls=MyEncoder)\\n\\n\\nit prints \\n\\n{\"childTrees\": [{\"childTrees\": [], \"name\": \"c1\"}, {\"childTrees\": [], \"name\": \"c2\"}], \"name\": \"t\"}\\n\\n\\nyou can similarly write a decoder but there you will somehow need to identify is it is your object or not, so may be you can put a type too if needed.\\n'},\n {'prompt': \"I just read about zip bombs, i.e. zip files that contain very large amount of highly compressible data (00000000000000000...).\\n\\nWhen opened they fill the server's disk.\\n\\nHow can I detect a zip file is a zip bomb before unzipping it?\\n\\nUPDATE Can you tell me how is this done in Python or Java?\\n\",\n  'completion': \"Try this in Python:\\n\\nimport zipfile\\nz = zipfile.ZipFile('c:/a_zip_file')\\nprint 'total files size=', sum(e.file_size for e in z.infolist())\\nz.close()\\n\\n\"},\n {'prompt': 'I\\'ve followed the basic CherryPy tutorial (http://www.cherrypy.org/wiki/CherryPyTutorial).  One thing not discussed is deployment.\\n\\nHow can I launch a CherryPy app as a daemon and \"forget about it\"?  What happens if the server reboots?\\n\\nIs there a standard recipe?  Maybe something that will create a service script (/etc/init.d/cherrypy...)\\n\\nThanks!\\n',\n  'completion': 'There is a Daemonizer plugin for CherryPy included by default which is useful for getting it to start but by far the easiest way for simple cases is to use the cherryd script:\\n\\n> cherryd -h\\nUsage: cherryd [options]\\n\\nOptions:\\n  -h, --help            show this help message and exit\\n  -c CONFIG, --config=CONFIG\\n                        specify config file(s)\\n  -d                    run the server as a daemon\\n  -e ENVIRONMENT, --environment=ENVIRONMENT\\n                        apply the given config environment\\n  -f                    start a fastcgi server instead of the default HTTP\\n                        server\\n  -s                    start a scgi server instead of the default HTTP server\\n  -i IMPORTS, --import=IMPORTS\\n                        specify modules to import\\n  -p PIDFILE, --pidfile=PIDFILE\\n                        store the process id in the given file\\n\\n\\nAs far as an init.d script goes I think there are examples that can be Googled.\\n\\nAnd the cherryd is found in your:\\n\\n\\n  virtualenv/lib/python2.7/site-packages/cherrypy/cherryd\\n\\n\\nor in: https://bitbucket.org/cherrypy/cherrypy/src/default/cherrypy/cherryd\\n'},\n {'prompt': 'How do you do jinja2 aware syntax highlighting for vim?\\n',\n  'completion': 'There appears to be a syntax highlighting file here.\\n'},\n {'prompt': 'In the python built-in open function, what is the exact difference between the modes w, a, w+, a+, and r+?\\n\\nIn particular, the documentation implies that all of these will allow writing to the file, and says that it opens the files for \"appending\", \"writing\", and \"updating\" specifically, but does not define what these terms mean.\\n',\n  'completion': \"The opening modes are exactly the same that C fopen() std library function.\\n\\nThe BSD fopen manpage defines them as follows:\\n\\n The argument mode points to a string beginning with one of the following\\n sequences (Additional characters may follow these sequences.):\\n\\n ``r''   Open text file for reading.  The stream is positioned at the\\n         beginning of the file.\\n\\n ``r+''  Open for reading and writing.  The stream is positioned at the\\n         beginning of the file.\\n\\n ``w''   Truncate file to zero length or create text file for writing.\\n         The stream is positioned at the beginning of the file.\\n\\n ``w+''  Open for reading and writing.  The file is created if it does not\\n         exist, otherwise it is truncated.  The stream is positioned at\\n         the beginning of the file.\\n\\n ``a''   Open for writing.  The file is created if it does not exist.  The\\n         stream is positioned at the end of the file.  Subsequent writes\\n         to the file will always end up at the then current end of file,\\n         irrespective of any intervening fseek(3) or similar.\\n\\n ``a+''  Open for reading and writing.  The file is created if it does not\\n         exist.  The stream is positioned at the end of the file.  Subse-\\n         quent writes to the file will always end up at the then current\\n         end of file, irrespective of any intervening fseek(3) or similar.\\n\\n\"},\n {'prompt': 'I\\'ve started using Eclipe+PyDev as an environment for developing my first app for Google App Engine. Eclipse is configured according to this tutorial.\\n\\nEverything was working until I start to use memcache. PyDev reports the errors and I don\\'t know how to fix it:\\n\\n\\n\\nError: Undefined variable from import: get\\n\\nHow to fix this?\\nSure, it is only PyDev checker problem. Code is correct and run on GAE.\\n\\nUPDATE:\\n\\n\\nI\\'m using PyDev 1.5.0 but experienced the same with 1.4.8.\\nMy PYTHONPATH includes (set in Project Properties/PyDev - PYTHONPATH):\\n\\nC:\\\\Program Files\\\\Google\\\\google_appengine\\nC:\\\\Program Files\\\\Google\\\\google_appengine\\\\lib\\\\django\\nC:\\\\Program Files\\\\Google\\\\google_appengine\\\\lib\\\\webob\\nC:\\\\Program Files\\\\Google\\\\google_appengine\\\\lib\\\\yaml\\\\lib\\n\\n\\n\\nUPDATE 2:\\n\\nI took a look at C:\\\\Program Files\\\\Google\\\\google_appengine\\\\google\\\\appengine\\\\api\\\\memcache\\\\__init__.py and found get() is not declared as memcache module function. They use the following trick to do that (I didn\\'t hear about such possibility):\\n\\n_CLIENT = None\\n\\n\\ndef setup_client(client_obj):\\n  \"\"\"Sets the Client object instance to use for all module-level methods.\\n\\n  Use this method if you want to have customer persistent_id() or\\n  persistent_load() functions associated with your client.\\n\\n  Args:\\n    client_obj: Instance of the memcache.Client object.\\n  \"\"\"\\n  global _CLIENT\\n  var_dict = globals()\\n\\n  _CLIENT = client_obj\\n  var_dict[\\'set_servers\\'] = _CLIENT.set_servers\\n  var_dict[\\'disconnect_all\\'] = _CLIENT.disconnect_all\\n  var_dict[\\'forget_dead_hosts\\'] = _CLIENT.forget_dead_hosts\\n  var_dict[\\'debuglog\\'] = _CLIENT.debuglog\\n  var_dict[\\'get\\'] = _CLIENT.get\\n  var_dict[\\'get_multi\\'] = _CLIENT.get_multi\\n  var_dict[\\'set\\'] = _CLIENT.set\\n  var_dict[\\'set_multi\\'] = _CLIENT.set_multi\\n  var_dict[\\'add\\'] = _CLIENT.add\\n  var_dict[\\'add_multi\\'] = _CLIENT.add_multi\\n  var_dict[\\'replace\\'] = _CLIENT.replace\\n  var_dict[\\'replace_multi\\'] = _CLIENT.replace_multi\\n  var_dict[\\'delete\\'] = _CLIENT.delete\\n  var_dict[\\'delete_multi\\'] = _CLIENT.delete_multi\\n  var_dict[\\'incr\\'] = _CLIENT.incr\\n  var_dict[\\'decr\\'] = _CLIENT.decr\\n  var_dict[\\'flush_all\\'] = _CLIENT.flush_all\\n  var_dict[\\'get_stats\\'] = _CLIENT.get_stats\\n\\n\\nsetup_client(Client())\\n\\n\\nHmm... Any idea how to force PyDev to recognize that?\\n',\n  'completion': 'There is a cleaner solution: Try adding GAE\\'s memcache to your forced builtins.\\n\\nIn your PyDev->Interpreter-Python->ForcedBuiltins window, add the \"google.appengine.api.memcache\" entry and apply.\\n\\nDouble-click on the memcache errors to check them back, they disappear!\\n\\nPlease make sure that system pythonpath includes google APE install directory.\\n'},\n {'prompt': 'So, I\\'ve got an application that uses Twisted + Stomper as a STOMP client which farms out work to a multiprocessing.Pool of workers.\\n\\nThis appears to work ok when I just use a python script to fire this up, which (simplified) looks something like this:\\n\\n# stompclient.py\\n\\nlogging.config.fileConfig(config_path)\\nlogger = logging.getLogger(__name__)\\n\\n# Add observer to make Twisted log via python\\ntwisted.python.log.PythonLoggingObserver().start() \\n\\n# initialize the process pool.  (child processes get forked off immediately)\\npool = multiprocessing.Pool(processes=processes)\\n\\nStompClientFactory.username = username\\nStompClientFactory.password = password\\nStompClientFactory.destination = destination\\nreactor.connectTCP(host, port, StompClientFactory())\\nreactor.run()\\n\\n\\nAs this gets packaged for deployment, I thought I would take advantage of the twistd script and run this from a tac file.\\n\\nHere\\'s my very-similar-looking tac file:\\n\\n# stompclient.tac\\n\\nlogging.config.fileConfig(config_path)\\nlogger = logging.getLogger(__name__)\\n\\n# Add observer to make Twisted log via python\\ntwisted.python.log.PythonLoggingObserver().start() \\n\\n# initialize the process pool.  (child processes get forked off immediately)\\npool = multiprocessing.Pool(processes=processes)\\n\\nStompClientFactory.username = username\\nStompClientFactory.password = password\\nStompClientFactory.destination = destination\\n\\napplication = service.Application(\\'myapp\\')\\n\\nservice = internet.TCPClient(host, port, StompClientFactory())\\nservice.setServiceParent(application)\\n\\n\\nFor the sake of illustration, I have collapsed or changed a few details; hopefully they were not the essence of the problem.  For example, my app has a plugin system, the pool is initialized by a separate method, and then work is delegated to the pool using pool.apply_async() passing one of my plugin\\'s process() methods.\\n\\nSo, if I run the script (stompclient.py), everything works as expected.\\n\\nIt also appears to work OK if I run twist in non-daemon mode (-n):\\n\\ntwistd -noy stompclient.tac\\n\\n\\nhowever, it does not work when I run in daemon mode:\\n\\ntwistd -oy stompclient.tac\\n\\n\\nThe application appears to start up OK, but when it attempts to fork off work, it just hangs.  By \"hangs\", I mean that it appears that the child process is never asked to do anything and the parent (that called pool.apply_async()) just sits there waiting for the response to return.\\n\\nI\\'m sure that I\\'m doing something stupid with Twisted + multiprocessing, but I\\'m really hoping that someone can explain to my the flaw in my approach.\\n\\nThanks in advance!\\n',\n  'completion': 'Since the difference between your working invocation and your non-working invocation is only the \"-n\" option, it seems most likely that the problem is caused by the daemonization process (which \"-n\" prevents from happening).\\n\\nOn POSIX, one of the steps involved in daemonization is forking and having the parent exit.  Among of things, this has the consequence of having your code run in a different process than the one in which the .tac file was evaluated.  This also re-arranges the child/parent relationship of processes which were started in the .tac file - as your pool of multiprocessing processes were.\\n\\nThe multiprocessing pool\\'s processes start off with a parent of the twistd process you start.  However, when that process exits as part of daemonization, their parent becomes the system init process.  This may cause some problems, although probably not the hanging problem you described.  There are probably other similarly low-level implementation details which normally allow the multiprocessing module to work but which are disrupted by the daemonization process.\\n\\nFortunately, avoiding this strange interaction should be straightforward.  Twisted\\'s service APIs allow you to run code after daemonization has completed.  If you use these APIs, then you can delay the initialization of the multiprocessing module\\'s process pool until after daemonization and hopefully avoid the problem.  Here\\'s an example of what that might look like:\\n\\nfrom twisted.application.service import Service\\n\\nclass MultiprocessingService(Service):\\n    def startService(self):\\n        self.pool = multiprocessing.Pool(processes=processes)\\n\\nMultiprocessingService().setServiceParent(application)\\n\\n\\nNow, separately, you may also run into problems relating to clean up of the multiprocessing module\\'s child processes, or possibly issues with processes created with Twisted\\'s process creation API, reactor.spawnProcess.  This is because part of dealing with child processes correctly generally involves handling the SIGCHLD signal.  Twisted and multiprocessing aren\\'t going to be cooperating in this regard, though, so one of them is going to get notified of all children exiting and the other will never be notified.  If you don\\'t use Twisted\\'s API for creating child processes at all, then this may be okay for you - but you might want to check to make sure any signal handler the multiprocessing module tries to install actually \"wins\" and doesn\\'t get replaced by Twisted\\'s own handler.\\n'},\n {'prompt': 'I need to emulate \"tail -f\" in python, but I don\\'t want to use time.sleep in the reading loop. I want something more elegant like some kind of blocking read, or select.select with timeout, but python 2.6 \"select\" documentation specifically says: \"it cannot be used on regular files to determine whether a file has grown since it was last read.\"\\nAny other way?\\nIn a few days if no solution is given I will read tail\\'s C source code to try to figure it out. I hope they don\\'t use sleep, hehe\\nThanks.\\n\\nMarioR\\n',\n  'completion': '(update)\\nEither use FS monitors tools \\n\\n\\nFor linux\\nFor Windows\\nFor Mac\\n\\n\\nOr a single sleep usage (which I would you consider as much more elegant).\\n\\nimport time\\ndef follow(thefile):\\n    thefile.seek(0,2)      # Go to the end of the file\\n    while True:\\n         line = thefile.readline()\\n         if not line:\\n             time.sleep(0.1)    # Sleep briefly\\n             continue\\n         yield line\\n\\nlogfile = open(\"access-log\")\\nloglines = follow(logfile)\\nfor line in loglines:\\n    print line\\n\\n'},\n {'prompt': 'I\\'m creating a chat daemon in python and twisted framework.  And I\\'m wondering if I have to delete every variable create in my functions to save memory in the long run when multiple users are connected, or are those variable automatically clear?.  Here\\'s a strip down version of my code to illustrate my point:\\n\\nclass Chat(LineOnlyReceiver):\\n\\n    LineOnlyReceiver.MAX_LENGTH = 500\\n\\n    def lineReceived(self, data):\\n\\n            self.sendMessage(data)\\n\\n    def sendMessage(self, data):\\n\\n            try:\\n                message = data.split(None,1)[1]\\n            except IndexError:\\n                return\\n\\n            self.factory.sendAll(message)\\n\\n            #QUESTION : do i have to delete message and date??????????????????\\n\\n            del message\\n            del data\\n\\n\\nclass ChatFactory(Factory):\\n    protocol = Chat\\n\\n    def __init__(self):\\n        self.clients = []\\n\\n    def addClient(self, newclient):\\n        self.clients.append(newclient)\\n\\n    def delClient(self, client):\\n        self.clients.remove(client)\\n\\n    def sendAll(self, message):\\n        for client in self.clients:\\n            client.transport.write(message + \"\\\\n\")\\n\\n',\n  'completion': 'C Python (the reference implementation) uses reference counting and garbage collection. When count of references to object decrease to 0, it is automatically reclaimed. The garbage collection normally reclaims only those objects that refer to each other (or other objects from them) and thus cannot be reclaimed by reference counting. \\n\\nThus, in most cases, local variables are reclaimed at the end of the function, because at the exit from the function, the objects cease being referenced from anywhere. So your \"del\" statements are completely unnecessary, because Python does that anyway.\\n'},\n {'prompt': 'I am working on embedding python in to c++. In some peculiar case I require two separate instances of the interpreter in same thread.\\n\\nCan I wrap Python interpreter in to a c++ class and get services from two or more class instances?\\n',\n  'completion': 'I have used Py_NewInterpreter for different interpreters in different threads, but this should also work for several interpreters within one thread:\\n\\nIn the main thread:\\n\\nPy_Initialize();\\nPyEval_InitThreads();\\nmainThreadState = PyEval_SaveThread();\\n\\n\\nFor each interpreter instance (in any thread):\\n\\n// initialize interpreter\\nPyEval_AcquireLock();                // get the GIL\\nmyThreadState = Py_NewInterpreter();\\n... // call python code\\nPyEval_ReleaseThread(myThreadState); // swap out thread state + release the GIL\\n\\n... // any other code\\n\\n// continue with interpreter\\nPyEval_AcquireThread(myThreadState); // get GIL + swap in thread state\\n... // call python code\\nPyEval_ReleaseThread(myThreadState);\\n\\n... // any other code\\n\\n// finish with interpreter\\nPyEval_AcquireThread(myThreadState);\\n... // call python code\\nPy_EndInterpreter(myThreadState);\\nPyEval_ReleaseLock();                // release the GIL\\n\\n\\nNote that you need a variable myThreadState for each interpreter instance!\\n\\nFinally the finish in the main thread:\\n\\nPyEval_RestoreThread(mainThreadState);\\nPy_Finalize();\\n\\n\\nThere are some restrictions with using several interpreter instances (they seem not to be totally independent), but in most cases this does not seem to cause problems.\\n'},\n {'prompt': 'xrange function doesn\\'t work for large integers:\\n\\n>>> N = 10**100\\n>>> xrange(N)\\nTraceback (most recent call last):\\n...\\nOverflowError: long int too large to convert to int\\n>>> xrange(N, N+10)\\nTraceback (most recent call last):\\n...\\nOverflowError: long int too large to convert to int\\n\\n\\nPython 3.x:\\n\\n>>> N = 10**100\\n>>> r = range(N)\\n>>> r = range(N, N+10)\\n>>> len(r)\\n10\\n\\n\\nIs there a backport of py3k builtin range() function for Python 2.x?\\n\\nEdit\\n\\nI\\'m looking for a complete implementation of \"lazy\" range(), not just a partial implementation of some of its functionality. \\n',\n  'completion': \"I believe there is no backport (Py 3's completely removed the int/long distinction, after all, but in 2.* it's here to stay;-) but it's not hard to hack your own, e.g....:\\n\\nimport operator\\n\\ndef wowrange(start, stop, step=1):\\n  if step == 0:\\n    raise ValueError('step must be != 0')\\n  elif step < 0:\\n    proceed = operator.gt\\n  else:\\n    proceed = operator.lt\\n  while proceed(start, stop):\\n    yield start\\n    start += step\\n\\n\\nEdit it appears the OP doesn't just want looping (the normal purpose of xrange, and \\nrange in Py3), but also len and the in operator (the latter does work on the above generator, but slowly -- optimizations are possible). For such richness a class \\nis better...:\\n\\nimport operator\\n\\nclass wowrange(object):\\n  def __init__(self, start, stop=None, step=1):\\n    if step == 0: raise ValueError('step must be != 0')\\n    if stop is None: start, stop = 0, start\\n    if step < 0:\\n      self.proceed = operator.gt\\n      self.l = (stop-start+step+1)//step\\n    else:\\n      self.proceed = operator.lt\\n      self.l = (stop-start+step-1)//step\\n    self.lo = min(start, stop)\\n    self.start, self.stop, self.step = start, stop, step\\n  def __iter__(self):\\n    start = self.start\\n    while self.proceed(start, self.stop):\\n      yield start\\n      start += self.step\\n  def __len__(self):\\n    return self.l\\n  def __contains__(self, x):\\n    if x == self.stop:\\n      return False\\n    if self.proceed(x, self.start):\\n      return False\\n    if self.proceed(self.stop, x):\\n      return False\\n    return (x-self.lo) % self.step == 0\\n\\n\\nI wouldn't be surprised if there's an off-by-one or similar glitch lurking here, but, I hope this helps!\\n\\nEdit again: I see indexing is ALSO required. Is it just too hard to write your own __getitem__?  I guess it is, so here it, too, is, served on a silver plate...:\\n\\n def __getitem__(self, i):\\n   if i < 0:\\n     i += self.l\\n     if i < 0: raise IndexError\\n   elif if i >= self.l:\\n     raise IndexError\\n   return self.start + i * self.step\\n\\n\\nI don't know if 3.0 range supports slicing (xrange in recent 2.* releases doesn't -- it used to, but that was removed because the complication was ridiculous and prone to bugs), but I guess I do have to draw a line in the sand somewhere, so I'm not going to add it;-).\\n\"},\n {'prompt': 'I have been programming Python for a while and I have a very good understanding of its features, but I would like to improve my coding style. I think reading the source code of the Python Modules would be a good idea. Can anyone recommend any ones in particular?\\n\\nRelated Threads:\\n\\n\\nBeginner looking for beautiful and instructional Python code: This thread actually inspired this question\\n\\n',\n  'completion': \"Queue.py shows you how to make a class thread-safe, and the proper use of the Template Method design pattern.\\n\\nsched.py is a great example of the Dependency Injection pattern.\\n\\nheapq.py is a really well-crafted implementation of the Heap data structure.\\n\\nIf I had to pick my three favorite modules in the Python standard library, this triplet would probably be my choice. (It doesn't hurt that they're all so very useful... but I'm picking in terms of quality of code, comments and design, first and foremost).\\n\"},\n {'prompt': \"Let's say you are building a Python-based web app that requires some workflow management such as that in jBPM or Windows Workflow Foundation. Is there a library that offers this in the Python world?\\n\",\n  'completion': \"Oh yes, tons. But most of them depend on a specific framework. DCWorkflow is integrated with Zopes CMF, for example. hurry.workflow is for Zope 3, etc. SpiffWorkflow presumes sql-alchemy, etc. This is because you need to have something to apply the workflow to, and that means you need to make some basic assumptions on the objects you use.\\n\\nHurry.workflow is probably one of the more independent ones, but it still assumes both that you use the Persistence library (and therefore in practice ZODB), and zope3's security model.\\n\\nSo you probably need to expand a bit on your requirements here...\\n\"},\n {'prompt': 'I have a very large collection of (p, q) tuples that I would like to convert into a dictionary of lists where the first item in each tuple is a key that indexes a list that contains q.\\n\\nExample:  \\n\\nOriginal List: (1, 2), (1, 3), (2, 3)  \\nResultant Dictionary: {1:[2, 3], 2:[3]}\\n\\n\\nFurthermore, I would like to efficiently combine these dictionaries.\\n\\nExample:  \\n\\nOriginal Dictionaries: {1:[2, 3], 2:[3]}, {1:[4], 3:[1]}  \\nResultant Dictionary: {1:[2, 3, 4], 2:[3], 3:[1]}\\n\\n\\nThese operations reside within an inner loop, so I would prefer that they be as fast as possible.\\n\\nThanks in advance\\n',\n  'completion': 'If the list of tuples is sorted, itertools.groupby, as suggested by @gnibbler, is not a bad alternative to defaultdict, but it needs to be used differently than he suggested:\\n\\nimport itertools\\nimport operator\\n\\ndef lot_to_dict(lot):\\n  key = operator.itemgetter(0)\\n  # if lot\\'s not sorted, you also need...:\\n  # lot = sorted(lot, key=key)\\n  # NOT in-place lot.sort to avoid changing it!\\n  grob = itertools.groupby(lot, key)\\n  return dict((k, [v[1] for v in itr]) for k, itr in grob)\\n\\n\\nFor \"merging\" dicts of lists into a new d.o.l...:\\n\\ndef merge_dols(dol1, dol2):\\n  keys = set(dol1).union(dol2)\\n  no = []\\n  return dict((k, dol1.get(k, no) + dol2.get(k, no)) for k in keys)\\n\\n\\nI\\'m giving [] a nickname no to avoid uselessly constructing a lot of empty lists, given that performance is important. If the sets of the dols\\' keys overlap only modestly, faster would be:\\n\\ndef merge_dols(dol1, dol2):\\n  result = dict(dol1, **dol2)\\n  result.update((k, dol1[k] + dol2[k])\\n                for k in set(dol1).intersection(dol2))\\n  return result\\n\\n\\nsince this uses list-catenation only for overlapping keys -- so, if those are few, it will be faster.\\n'},\n {'prompt': 'I am attempting to use BeautifulSoup to parse through a DOM tree and extract the names of authors. Below is a snippet of HTML to show the structure of the code I\\'m going to scrape. \\n\\n<html>\\n<body>\\n<div class=\"list-authors\">\\n<span class=\"descriptor\">Authors:</span> \\n<a href=\"/find/astro-ph/1/au:+Lin_D/0/1/0/all/0/1\">Dacheng Lin</a>, \\n<a href=\"/find/astro-ph/1/au:+Remillard_R/0/1/0/all/0/1\">Ronald A. Remillard</a>, \\n<a href=\"/find/astro-ph/1/au:+Homan_J/0/1/0/all/0/1\">Jeroen Homan</a> \\n</div>\\n<div class=\"list-authors\">\\n<span class=\"descriptor\">Authors:</span> \\n<a href=\"/find/astro-ph/1/au:+Kosovichev_A/0/1/0/all/0/1\">A.G. Kosovichev</a>\\n</div>\\n\\n<!--There are many other div tags with this structure-->\\n</body>\\n</html>\\n\\n\\nMy point of confusion is that when I do soup.find, it finds the first occurrence of the div tag that I\\'m searching for. After that, I search for all \\'a\\' link tags. At this stage, how do I extract the authors names from each of the link tags and print them out? Is there a way to do it using BeautifulSoup or do I need to use Regex? How do I continue iterating over every other other div tag and extract the authors names?\\n\\nimport re\\nimport urllib2,sys\\nfrom BeautifulSoup import BeautifulSoup, NavigableString\\nhtml = urllib2.urlopen(address).read()\\n    soup = BeautifulSoup(html)\\n\\n    try:\\n\\n        authordiv = soup.find(\\'div\\', attrs={\\'class\\': \\'list-authors\\'})\\n        links=tds.findAll(\\'a\\')\\n\\n\\n        for link in links:\\n            print \\'\\'.join(link[0].contents)\\n\\n        #Iterate through entire page and print authors\\n\\n\\n    except IOError: \\n        print \\'IO error\\'\\n\\n',\n  'completion': \"just use findAll for the divs link you do for the links\\n\\nfor authordiv in soup.findAll('div', attrs={'class': 'list-authors'}):\\n\"},\n {'prompt': \"To learn from good examples, what are the best open source Google App Engine applications out there?\\n\\nI don't care if it is Java or Python based.\\n\\nPlease one app per answer. Feel free to add a link to the live app (if there is) and to the project page.\\n\",\n  'completion': 'Rietveld of course\\n'},\n {'prompt': 'I need to make an export like this in Python :\\n\\n# export MY_DATA=\"my_export\"\\n\\n\\nI\\'ve tried to do :\\n\\n# -*- python-mode -*-\\n# -*- coding: utf-8 -*-\\nimport os\\nos.system(\\'export MY_DATA=\"my_export\"\\')\\n\\n\\nBut when I list export, \"MY_DATA\" not appear :\\n\\n# export\\n\\n\\nHow I can do an export with Python without saving \"my_export\" into a file ?\\n',\n  'completion': 'export is a command that you give directly to the shell (e.g. bash), to tell it to add or modify one of its environment variables. You can\\'t change your shell\\'s environment from a child process (such as Python), it\\'s just not possible.\\n\\nHere\\'s what\\'s happening with you try os.system(\\'export MY_DATA=\"my_export\"\\')...\\n\\n/bin/bash process, command `python yourscript.py` forks python subprocess\\n |_\\n   /usr/bin/python process, command `os.system()` forks /bin/sh subprocess\\n    |_\\n      /bin/sh process, command `export ...` changes local environment\\n\\n\\nWhen the bottom-most /bin/sh subprocess finishes running your export ... command, then it\\'s discarded, along with the environment that you have just changed.\\n'},\n {'prompt': 'I need an Object Pool, and rather than implement it myself, I thought I would look around for a ready-made and tested Python library.\\n\\nWhat I found was plenty of other people looking, but not getting many straight answers, so I have brought it over here to Stack Overflow.\\n\\nIn my case, I have a large number of threads (using the threading module), which need to occasionally call a remote SOAP-based server. They could each establish their own connection to the server, but setting up a socket and completing the authentication process is expensive (it is throttled by the server), so I want to share a pool of connections, creating more only as needed.\\n\\nIf the items to pool were worker subprocesses, I might have chosen multiprocessing.pool, but they are not. If they were worker threads, I might have chosen this implementation, but they are not.\\n\\nIf they were MySQL connections, I might have chosen pysqlpool, but they are not. Similarly the SQLAlchemy Pool is out.\\n\\nIf there was one thread, using a variable number of connections/objects, I would consider this implementation, but I need it to be thread-safe.\\n\\nI know I could implement this again fairly quickly, but given there are many people looking for it, I thought a canonical answer on Stack Overflow would be nice.\\n',\n  'completion': 'It seems to me, from your description, that what you need is a pool of connections, not of objects. For simple thread-safety, just keep the reusable connections in a Queue.Queue instance, call it pool.  When a thread instantiates a connection-wrapping object, the object gets its connection via pool.get() (which automaticaly enqueues it to wait if there are no connections currently availabe and dequeues it when a connection\\'s ready for it); when the object\\'s done using its connection, it puts it back in the pool via pool.put.\\n\\nThere\\'s so little universally-required, general-purpose functionality in this, beyond what Queue.Queue already gives you, that it\\'s not surprising no module providing it is well known or popular -- hard to make a module widespread when it has about 6 lines of functional code in all (e.g. to call a user-supplied connection factory to populate the queue either in advance or just-in-time up to some maximum number -- not a big added value generally, anyway).  \"Thick glue\", thickly wrapping the underlying functionality from a standard library module without substantial added value, is an architectural minus, after all;-).\\n'},\n {'prompt': \"I'm making a 2D list and I would like to initialize it with a list comprehension.  I would like it to do something like this:\\n\\n[[x for i in range(3) if j <= 1: x=1 else x=2] for j in range(3)]\\n\\n\\nso it should return something like:\\n\\n[[1,1,1],\\n [1,1,1],\\n [2,2,2]]\\n\\n\\nHow might I go about doing this?\\n\\nThanks for your help.\\n\",\n  'completion': \"It appears as though you're looking for something like this:\\n\\n[[1 if j <= 1 else 2 for i in range(3)] for j in range(3)]\\n\\n\\nThe Python conditional expression is a bit different from what you might be used to if you're coming from something like C or Java:\\n\\n\\n  The expression x if C else y first evaluates C (not x); if C is true, x is evaluated and its value is returned; otherwise, y is evaluated and its value is returned.\\n\\n\\nA slightly shorter way to do the same thing is:\\n\\n[[1 if j <= 1 else 2]*3 for j in range(3)]\\n\\n\"},\n {'prompt': \"In PHP, I can do this:\\n\\necho '<pre>'\\nprint_r($array);\\necho '</pre>'\\n\\n\\nIn Python, I currently just do this:\\n\\nprint the_list\\n\\n\\nHowever, this will cause a big jumbo of data. Is there any way to print it nicely into a readable tree? (with indents)?\\n\",\n  'completion': 'from pprint import pprint\\npprint(the_list)\\n\\n'},\n {'prompt': \"Anyone know of a good feed parser for python 3.1?\\nI was using feedparser for 2.5 but it doesn't seem to be ported to 3.1 yet, and it's apparently more complicated than just running 2to3.py on it.\\nAny help?\\n\",\n  'completion': 'You may take a look at the Atom Models blog post by Ian Bicking. He proposes not to use any special \"feed parsing\" library because Atom and RSS are just XML so your model is really an XML tree, not some fancy class. You could try his code under Python 3.\\n'},\n {'prompt': 'I have a float: 1.2333333\\n\\nHow do I change it into a two decimal number with a comma as a decimal point separator, eg 1,23?\\n',\n  'completion': 'The locale module can help you with reading and writing numbers in the locale\\'s format.\\n\\n>>> import locale\\n>>> locale.setlocale(locale.LC_ALL, \"\")\\n\\'sv_SE.UTF-8\\'\\n>>> locale.format(\"%f\", 2.2)\\n\\'2,200000\\'\\n>>> locale.format(\"%g\", 2.2)\\n\\'2,2\\'\\n>>> locale.atof(\"3,1415926\")\\n3.1415926000000001\\n\\n'},\n {'prompt': 'I have a series of large text files (up to 1 gig) that are output from an experiment that need to be analysed in Python. They would be best loaded into a 2D numpy array, which presents the first question:\\n\\n\\nAs the number of rows is unknown at the beginning of the loading, how can\\na very large numpy array be most efficiently built, row by row?\\n\\n\\nSimply adding the row to the array would be inefficient in memory terms, as two large arrays would momentarily co-exist. The same problem would seem to be occur if you use numpy.append. The stack functions are promising, but ideally I would want to grow the array in place.\\n\\nThis leads to the second question:\\n\\n\\nWhat is the best way to observe the memory usage of a Python program that heavily\\nuses numpy arrays?\\n\\n\\nTo study the above problem, I\\'ve used the usual memory profiling tools - heapy and pympler - but am only getting the size of the outer array objects (80 bytes) and not the data they are containing. Asides from a crude measuring of how much memory the Python process is using, how can I get at the \"full\" size of the arrays as they grow?\\n\\nLocal details: OSX 10.6, Python 2.6, but general solutions are welcome.\\n',\n  'completion': \"There's no way to ensure you can grow the array in place other than creating an empty array (numpy.empty) of the maximum possible size and then using a view of that at the end.  You can't start small because there's no guarantee that you can expand whatever memory the map is without clobbering some other data.  (And all of this is much lower level than python allows you to get from inside the interpreter.)\\n\\nYour best bet is probably numpy.fromiter.  Looking at the source, as the number of items increase, the array is expanded by a little over 50% each time.  If you can easily get the number of rows (say from counting the lines), you can even pass it a count.\\n\"},\n {'prompt': 'Most likely it\\'s a dumb question for those who knows the answer, but I\\'m a beginner, and here it goes:\\n\\nI have a Python script which I run in a command-line with some parameter, and it prints me some results. Let\\'s say results are some HTML code.\\n\\nI never done any Python programming for web, and couldn\\'t figure it out... I need to have a page (OK, I know how to upload files to a server, Apache is running, Python is installed on the server...) with an edit field, which will accept that parameter, and Submit button, and I need it to \"print\" the results on a web page after the user submitted a proper parameter, or show any output that in a command-line situation are printed.\\n\\nI\\'ve read Dive Into Python\\'s chapters about \"HTML Processing\" and \"HTTP Web Services\", but they do not describe what I\\'m looking for.\\n\\nIf the answer isn\\'t short, I would very much appreciate links to the more relevant stuff to read or maybe the key words to google for it.\\n',\n  'completion': \"For such a simple task, you probably don't need more than CGI. Luckily Python has a built-in cgi module which should do what you want.\\n\\nOr you could look into some of the minimal web frameworks, such as web.py.\\n\"},\n {'prompt': 'I have a Debian system currently running with python 2.5.4. I got virtualenv properly installed, everything is working fine. Is there a possibility that I can use a virtualenv with a different version of Python?\\n\\nI compiled Python 2.6.2 and would like to use it with some virtualenv. Is it enough to overwrite the binary file? Or do I have to change something in respect to the libraries?\\n',\n  'completion': 'Just use the -p flag when creating your virtualenv instance to specify the Python executable you want to use, e.g.:\\n\\nvirtualenv -p /usr/bin/python2.6 <path/to/new/virtualenv/>\\n\\n'},\n {'prompt': \"Looking at comprehensions in Python and Javascript, so far I can't see some of the main features that I consider most powerful in comprehensions in languages like Haskell.  \\n\\nDo they allow things like multiple generators?  Or are they just a basic map-filter form?\\n\\nIf they don't allow multiple generators, I find them quite disappointing - why have such things been left out?\\n\",\n  'completion': \"Python allows multiple generators:\\n\\n>>> [(x,y,x*y) for x in range(1,5) for y in range(1,5)]\\n[(1, 1, 1), (1, 2, 2), (1, 3, 3), (1, 4, 4), \\n (2, 1, 2), (2, 2, 4), (2, 3, 6), (2, 4, 8), \\n (3, 1, 3), (3, 2, 6), (3, 3, 9), (3, 4, 12),\\n (4, 1, 4), (4, 2, 8), (4, 3, 12), (4, 4, 16)]\\n\\n\\nAnd also restrictions:\\n\\n>>> [(x,y,x*y) for x in range(1,5) for y in range(1,5) if x*y > 8]\\n[(3, 3, 9), (3, 4, 12), (4, 3, 12), (4, 4, 16)]\\n\\n\\nUpdate: Javascript's syntax is similar (results from using the javascript shell on firefox):\\n\\nvar nums = [1, 2, 3, 21, 22, 30];\\nvar s = eval('[[i,j] for each (i in nums) for each (j in [3,4]) if (i%2 == 0)]');\\ns.toSource();\\n[[2, 3], [2, 4], [22, 3], [22, 4], [30, 3], [30, 4]]\\n\\n\\n(For some reason, something about the context stuff is evaluated in in the javascript shell requires the eval indirection to have list comprehensions work.  Javascript inside a <script> tag doesn't require that, of course)\\n\"},\n {'prompt': 'A python script is controlling an external application on Linux, passing in input via a pipe to the external applications stdin, and reading output via a pipe from the external applications stdout. \\n\\nThe problem is that writes to pipes are buffered by block, and not by line, and therefore delays occur before the controlling script receives data output by, for example, printf in the external application.\\n\\nThe external application cannot be altered to add explicit fflush(0) calls.\\n\\nHow can the pty module of the python standard library be used with the subprocess module to achieve this?\\n',\n  'completion': \"Doing this is possible, but the only solution I can think of is fairly convoluted, non-portable, and probably fraught with problematic details.  You can use LD_PRELOAD to cause the external application to load a dynamic library which contains a constructor that invokes setvbuf to unbuffer stdout.  You will probably also want to wrap setvbuf in the library to prevent the application from explicitly buffering its own stdout.  And you'll want to wrap fwrite and printf so that they flush on each call.  Writing the .so to be preloaded will take you outside of python.  \\n\"},\n {'prompt': \"I'm writting a small python script notify me when certain condition met. I used smtplib which does the emailing for me, but I also want the script to call my cell phone as well.\\n\\nI can't find a free library for phone callings. Does anyone know any?\\n\",\n  'completion': 'Make the calls using Skype, and use the Skype4Py API.\\n\\nIf you want other suggestions, please specify how you want to make the call (modem? Some software bridge? What?).\\n\\nAlso, might I suggest that you send an SMS instead of placing a call? You can do that via Skype too, btw.\\n'},\n {'prompt': \"I'm not sure if I need a lambda, or something else. But still, I need the following:\\n\\nI have an array = [1,2,3,4,5]. I need to put this array, for instance, into another array. But write it all in one line.\\n\\nfor item in array:\\n    array2.append(item)\\n\\n\\nI know that this is completely possible to iterate through the items and make it one-line. But googling and reading manuals didn't help me that much... if you can just give me a hint or name this thing so that I could find what that is, I would really appreciate it.\\n\\nUpdate: let's say this: array2 = SOME FANCY EXPRESSION THAT IS GOING TO GET ALL THE DATA FROM THE FIRST ONE\\n\\n(the example is NOT real. I'm just trying to iterate through different chunks of data, but that's the best I could come up with) \\n\",\n  'completion': \"The keyword you're looking for is list comprehensions:\\n\\n>>> x = [1, 2, 3, 4, 5]\\n>>> y = [2*a for a in x if a % 2 == 1]\\n>>> print(y)\\n[2, 6, 10]\\n\\n\"},\n {'prompt': 'Summary: Building Python 3.1 on RHEL 5.3 64 bit with --enable-shared fails to compile all extensions.  Building \"normal\" works fine without any problems.\\n\\nPlease note that this question may seem to blur the line between programming and system administration.  However, I believe that because it has to deal directly with getting language support in place, and it very much has to do with supporting the process of programming, that I would cross-post it here.  Also at: http://serverfault.com/questions/73196/python-3-1-1-with-enable-shared-will-not-build-any-extensions.  Thank you!\\n\\nProblem:\\n\\nBuilding Python 3.1 on RHEL 5.3 64 bit with --enable-shared fails to compile all extensions.  Building \"normal\" works fine without any problems.\\n\\nI can build python 3.1 just fine, but when built as a shared library, it emits many warnings (see below), and refuses to build any of the c based modules.  Despite this failure, I can still build mod_wsgi 3.0c5 against it, and run it under apache.  Needless to say, the functionality of Python is greatly reduced...\\n\\nInteresting to note that Python 3.2a0 (from svn) compiles fine with --enable-shared, and mod_wsgi compiles fine against it.  But when starting apache, I get:\\n\\nCannot load /etc/httpd/modules/mod_wsgi.so into server: /etc/httpd/modules/mod_wsgi.so: undefined symbol: PyCObject_FromVoidPtr\\n\\nThe project that this is for is a long-term project, so I\\'m okay with alpha quality software if needed.  Here are some more details on the problem.\\n\\nHost:\\n\\n\\nDell PowerEdge\\nIntel Xenon \\nRHEL 5.3 64bit\\nNothing \"special\"\\n\\n\\nBuild:\\n\\n\\nPython 3.1.1 source distribution\\nWorks fine with ./configure\\nDoes not work fine with ./configure --enable-shared\\n\\n\\n(export CFLAGS=\"-fPIC\" has been done)\\n\\nmake output\\n\\n\\n\\ngcc -pthread -fno-strict-aliasing -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes  -I. -IInclude -I./Include  -fPIC -DPy_BUILD_CORE  -c ./Modules/_weakref.c -o Modules/_weakref.o\\n\\n\\n\\nbuilding \\'bz2\\' extension\\ngcc -pthread -fPIC -fno-strict-aliasing -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I. -I./Include -I/usr/local/include -IInclude -I/home/build/RPMBUILD/BUILD/Python-3.1.1 -c /home/build/RPMBUILD/BUILD/Python-3.1.1/Modules/bz2module.c -o build/temp.linux-x86_64-3.1/home/build/RPMBUILD/BUILD/Python-3.1.1/Modules/bz2module.o\\ngcc -pthread -shared -fno-strict-aliasing -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes build/temp.linux-x86_64-3.1/home/build/RPMBUILD/BUILD/Python-3.1.1/Modules/bz2module.o -L/usr/local/lib -L. -lbz2 -lpython3.1 -o build/lib.linux-x86_64-3.1/bz2.so\\n/usr/bin/ld: /usr/local/lib/libpython3.1.a(abstract.o): relocation R_X86_64_32 against \\'a local symbol\\' can not be used when making a shared object; recompile with -fPIC\\n\\n\\n\\nFailed to build these modules:\\n_bisect            _codecs_cn         _codecs_hk\\n_codecs_iso2022    _codecs_jp         _codecs_kr\\n_codecs_tw         _collections       _csv\\n_ctypes            _ctypes_test       _curses\\n_curses_panel      _dbm               _elementtree\\n_gdbm              _hashlib           _heapq\\n_json              _lsprof            _multibytecodec\\n_multiprocessing   _pickle            _random\\n_socket            _sqlite3           _ssl\\n_struct            _testcapi          array\\natexit             audioop            binascii\\nbz2                cmath              crypt\\ndatetime           fcntl              grp\\nitertools          math               mmap\\nnis                operator           ossaudiodev\\nparser             pyexpat            readline\\nresource           select             spwd\\nsyslog             termios            time\\nunicodedata        zlib\\n\\n',\n  'completion': \"Something is wrong with your build environment. It is picking up a libpython3.1.a from /usr/local/lib; this confuses the error messages. It tries linking with that library, which fails - however, it shouldn't have tried that in the first place, since it should have used the libpython that it just built. I recommend taking the Python 3.1 installation in /usr/local out of the way.\\n\\nYou don't show in your output whether a libpython3.1.so.1.0 was created in the build tree; it would be important to find out whether it exists, how it was linked, and what symbols it has exported.\\n\"},\n {'prompt': 'Sometimes it is useful to \"clone\" a row or column vector to a matrix. By cloning I mean converting a row vector such as\\n\\n[1,2,3]\\n\\n\\nInto a matrix\\n\\n[[1,2,3]\\n [1,2,3]\\n [1,2,3]\\n]\\n\\n\\nor a column vector such as\\n\\n[1\\n 2\\n 3\\n]\\n\\n\\ninto\\n\\n[[1,1,1]\\n [2,2,2]\\n [3,3,3]\\n]\\n\\n\\nIn matlab or octave this is done pretty easily:\\n\\n x = [1,2,3]\\n a = ones(3,1) * x\\n a =\\n\\n    1   2   3\\n    1   2   3\\n    1   2   3\\n\\n b = (x\\') * ones(1,3)\\n b =\\n\\n    1   1   1\\n    2   2   2\\n    3   3   3\\n\\n\\nI want to repeat this in numpy, but unsuccessfully\\n\\nIn [14]: x = array([1,2,3])\\nIn [14]: ones((3,1)) * x\\nOut[14]:\\narray([[ 1.,  2.,  3.],\\n       [ 1.,  2.,  3.],\\n       [ 1.,  2.,  3.]])\\n# so far so good\\nIn [16]: x.transpose() * ones((1,3))\\nOut[16]: array([[ 1.,  2.,  3.]])\\n# DAMN\\n# I end up with \\nIn [17]: (ones((3,1)) * x).transpose()\\nOut[17]:\\narray([[ 1.,  1.,  1.],\\n       [ 2.,  2.,  2.],\\n       [ 3.,  3.,  3.]])\\n\\n\\nWhy wasn\\'t the first method (In[16]) working? Is there a way to achieve this task in python in a more elegant way?\\n',\n  'completion': 'Use numpy.tile:\\n\\n>>> tile(array([1,2,3]), (3, 1))\\narray([[1, 2, 3],\\n       [1, 2, 3],\\n       [1, 2, 3]])\\n\\n\\nor for repeating columns:\\n\\n>>> tile(array([[1,2,3]]).transpose(), (1, 3))\\narray([[1, 1, 1],\\n       [2, 2, 2],\\n       [3, 3, 3]])\\n\\n'},\n {'prompt': 'From what I remember from my C++ class, the professor said that operator overloading is cool, but since it takes relatively a lot of thought and code to cover all end-cases (e.g. when overloading + you probably also want to overload ++ and +=, and also make sure to handle end cases like adding an object to itself etc.), you should only consider it in those cases where this feature will have a major impact on your code, like overloading the operators for the matrix class in a math application.\\n\\nDoes the same apply to python? Would you recommend overriding operator behavior in python? And what rules of thumb can you give me?\\n',\n  'completion': 'Operator overloading is mostly useful when you\\'re making a new class that falls into an existing \"Abstract Base Class\" (ABC) -- indeed, many of the ABCs in standard library module collections rely on the presence of certain special methods (and special methods, one with names starting and ending with double underscores AKA \"dunders\", are exactly the way you perform operator overloading in Python). This provides good starting guidance.\\n\\nFor example, a Container class must override special method __contains__, i.e., the membership check operator item in container (as in, if item in container: -- don\\'t confuse with the for statement, for item in container:, which relies on __iter__!-).\\nSimilarly, a Hashable must override __hash__, a Sized must override __len__, a Sequence or a Mapping must override __getitem__, and so forth.  (Moreover, the ABCs can provide your class with mixin functionality -- e.g., both Sequence and Mapping can provide __contains__ on the basis of your supplied __getitem__ override, and thereby automatically make your class a Container).\\n\\nBeyond the collections, you\\'ll want to override special methods (i.e. provide for operator overloading) mostly if your new class \"is a number\". Other special cases exist, but resist the temptation of overloading operators \"just for coolness\", with no semantic connection to the \"normal\" meanings, as C++\\'s streams do for << and >> and Python strings (in Python 2.*, fortunately not in 3.* any more;-) do for % -- when such operators do not any more mean \"bit-shifting\" or \"division remainder\", you\\'re just engendering confusion.  A language\\'s standard library can get away with it (though it shouldn\\'t;-), but unless your library gets as widespread as the language\\'s standard one, the confusion will hurt!-)\\n'},\n {'prompt': 'Python 2.6.2 (r262:71605, Apr 14 2009, 22:40:02) [MSC v.1500 32 bit (Intel)] on\\nwin32\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> import sqlite3\\n>>> sqlite3.version\\n\\'2.4.1\\'\\n\\n\\nQuestions:\\n\\n\\nWhy is the version of the sqlite**3** module \\'2.4.1\\'\\nWhats the reason behind bundling such an old sqlite with Python? The sqlite releaselog says 2002 Mar 13 (2.4.1).\\n\\n',\n  'completion': \"Python 2.5.1\\n>>> import sqlite3\\n>>> sqlite3.version\\n'2.3.2'\\n>>> sqlite3.sqlite_version\\n'3.3.4'\\n\\n\\nversion - pysqlite version\\nsqlite_version - sqlite version\\n\"},\n {'prompt': 'I just documented loads of my code and learnt how to use sphinx to generate the documentation. I want to include that into my github project page but I do not know how to. Does anyone know existing tutorial or simple step to do so?\\n\\nThanks.\\n',\n  'completion': 'github will serve static content for you using their github pages feature.  Essentially, you create a branch called gh-pages, into which you commit your static pages. The pages are then served at you.github.com/yourproject.\\n\\nSee the instructions at http://pages.github.com/.\\n\\nYou will likely run into an issue using Sphinx on github, because Sphinx uses directories with leading underscores.  You can fix this by adding a file called .nojekyll in the the directory with the generated sphinx html.\\n'},\n {'prompt': 'How can I save a model, such that signals arent sent. (post_save and pre_save)\\n',\n  'completion': \"It's a bit of a hack, but you can do something like this:\\n\\nuse a unique identifier with a filter and then use the update method of the queryset (which does not trigger the signals)\\n\\nuser_id = 142187\\nUser.objects.filter(id=user_id).update(name='tom')\\n\\n\"},\n {'prompt': \"Is is possible to do something similar to this with a list, dictionary or something else even?\\n\\ndata_dict = {\\n    'title' : 'awesome title',\\n    'body' : 'great body of text',\\n}\\nModel.objects.create(data_dict)\\n\\n\\nEven better if I can extend it\\n\\nModel.objects.create(data_dict, extra='hello', extra2='world)\\n\\n\",\n  'completion': \"If title and body are fields in your model, then you can deliver the keyword arguments in your dictionary using the ** operator.\\n\\nAssuming your model is called MyModel:\\n\\n# create instance of model\\nm = MyModel(**data_dict)\\n# don't forget to save to database!\\nm.save()\\n\\n\\nAs for your second question, the dictionary has to be the final argument. Again, extra and extra2 should be fields in the model.\\n\\nm2 =MyModel(extra='hello', extra2='world', **data_dict)\\nm2.save()\\n\\n\"},\n {'prompt': 'I have an array in python that contains a set of values, some of them are\\n\\n2.32313e+07\\n\\n2.1155e+07\\n\\n1.923e+07\\n\\n11856\\n\\n112.32\\n\\nHow do I convert the exponential formats to the decimal format\\n\\nAdditional: Is there a way I can convert the exponent directly to decimal when printing out in UNIX with awk?\\n',\n  'completion': 'I imagine you have a list rather than an array, but here it doesn\\'t make much of a difference; in 2.6 and earlier versions of Python, something like:\\n\\n>>> L = [2.32313e+07, 2.1155e+07, 1.923e+07, 11856, 112.32]\\n>>> for x in L: print \\'%f\\' % x\\n... \\n23231300.000000\\n21155000.000000\\n19230000.000000\\n11856.000000\\n112.320000\\n\\n\\nand in 2.6 or later, the .format method.  I imagine you are aware that the numbers per se, as numbers, aren\\'t in any \"format\" -- it\\'s the strings you obtain by formatting the numbers, e.g. for output, that are in some format.  BTW, variants on that %f can let you control number of decimals, width, alignment, etc -- hard to suggest exactly what you may want without further specs from you.\\n\\nIn awk, you can use printf.\\n'},\n {'prompt': 'Sphinx is a Python library to generate nice documentation from a set of ReST formatted text files.\\n\\nI wonder if any one has written Sphinx plugins to make it generate personal websites and blogs.\\n\\nEspecially for blogs, there needs to be a way to automatically list posts chronologically and generate a RSS feed. One needs to write a Sphinx plugin to do such special page/xml generation.\\n\\nHas anyone tried this before?\\n',\n  'completion': 'I\\'ve done it at http://reinout.vanrees.org/weblog. The key trick is to add a preprocessor step.  I\\'ve got my blog entries in a weblog/yyyy/mm/dd/ folder structure.\\n\\nA script iterates through that folder structure, creating index.txt files in every directory, listing the sub-items.  The normal Sphinx process then renders those index.txt files.\\n\\nI added a custom Sphinx processor for tags.  So \".. tags:: python, buildout\" somewhere at the top of my weblog entry generates the tags.  And the preprocessor again collects those entries and writes out a weblog/tags/TAGNAME.txt file which Sphinx again renders normally.\\n\\nThe preprocessor also creates the root weblog/index.txt with the latest 10 entries.  And an weblog/atom.xml in (hardcoded) the output directory for the rss feed.\\n\\nSo: you need some custom stuff, but it is pretty much plain text, so for me it was a nice exercise.  And you get to write some helper scripts to make life easy, for instance one that copies a textfile from somewhere to today\\'s weblog directory (including creation of missing directories and an \"svn add\").\\n'},\n {'prompt': \"I have the following data structure:\\n\\n  data = [\\n      {'site': 'Stackoverflow', 'id': 1},\\n      {'site': 'Superuser', 'id': 2}, \\n      {'site': 'Serverfault', 'id': 3}\\n  ]\\n\\n\\nI want to search the above list to see if it has any site with a specific value. For instance, search the above to see if the list contain a dictionary with site = 'Superuser' and return True/False.  I can do the above the usual way of looping over each item and comparing them.  Is there an alternative way to achieve a search?\\n\",\n  'completion': \"any(d['site'] == 'Superuser' for d in data)\\n\\n\"},\n {'prompt': 'I need to update a text file whenever my IP address changes, and then run a few commands from the shell afterwards.\\n\\n\\nCreate variable LASTKNOWN = \"212.171.135.53\" \\nThis is the ip address we have while writing this script.\\nGet the current IP address. It will change on a daily basis.\\nCreate variable CURRENT for the new IP.\\nCompare (as strings) CURRENT to LASTKNOWN\\nIf they are the same, exit()\\nIf they differ, \\n\\nA. \"Copy\" the old config file (/etc/ipf.conf) containing LASTKNOWN IP address into /tmp\\nB. Replace LASTKNOWN with CURRENT in the /tmp/ipf.conf file.\\nC. Using subprocess \"mv /tmp/ipf.conf /etc/ipf.conf\"\\nD. Using subprocess execute, \"ipf -Fa -f /etc/ipf.conf\"\\nE. Using subprocess execute, \"ipnat -CF -f /etc/ipnat.conf\"  \\nexit()\\n\\n\\nI know how to do steps 1 through 6. I fall down on the \"file editing\" part, A -> C. I can\\'t tell what module to use or whether I should be editing the file in place. There are so many ways to do this, I can\\'t decide on the best approach. I guess I want the most conservative one.\\n\\nI know how to use subprocess, so you don\\'t need to comment on that.  \\n\\nI don\\'t want to replace entire lines; just a specific dotted quad.   \\n\\nThanks!\\n',\n  'completion': 'Another way to simply edit files in place is to use the fileinput module:\\n\\nimport fileinput, sys\\nfor line in fileinput.input([\"test.txt\"], inplace=True):\\n    line = line.replace(\"car\", \"truck\")\\n    # sys.stdout is redirected to the file\\n    sys.stdout.write(line)\\n\\n'},\n {'prompt': \"As I work on my first django powered site, I am constantly learning new things and making all sorts of changes and additions to my apps as I go.  I try to follow DRY and pythonic principles and be smart in my coding but eventually I will have to take the site live and am certain that not long after I do, something new and exiting will come down the pipe and I will want to implement it.  \\n\\nPreparing for the future:\\n\\nWith this in mind, do folks have any suggestions about how I can prepare my code now to be as future-ready as possible for these currently unforseen/unknown upgrades/additions to my code base?  \\n\\nHindsight is 20/20:\\n\\nWhat do you wish you had done at the start that would have made your life easier now that your site is up and running ?  \\n\\nLittle Things I've Learned (examples):\\n\\n\\nuse UTC as the default timezone (and use datetime.datetime.utcnow())\\nuse South to aid future database changes (haven't done it yet, but it seems wise)\\nnot hard code links in my templates (use get_absolute_url() and reverse lookups)\\ncreate a separate tools app to contain small re-usable templatetags and utility functions that I may want to use in future projects (no need to decouple them later)\\n\\n\\nThese are small tips, and some straight from the django-docs, but I think they help .  \\n\\nHow about you?  What are your best practices for a new app or project that prepare you for the future?\\n\",\n  'completion': \"\\nDeploy into a pure environment using virtualenv.\\nDocument requirements using a pip requirements file.\\n\\n\\nI'm sure others will suggest their deployment strategies, but making these changes were big positives for me.\\n\"},\n {'prompt': 'I\\'m starting to experiment with CouchDB because it looks like the perfect solution for certain problems we have.  Given that all work will be on a brand new project with no legacy dependencies, which client library would you suggest that I use, and why?\\n\\nThis would be easier if there was any overlap on the OSes we use.  FreeBSD only has py-simplecouchdb already available in its ports collection, but that library\\'s project website says to use CouchDBKit instead.  Neither of those come with Ubuntu, which only ships with CouchDB.  Since those two OSes don\\'t have an libraries in common, I\\'ll probably be installing something from source (and hopefully submitting packages to the Ubuntu and FreeBSD folks if I have time).\\n\\nFor those interested, I\\'d like to use CouchDB as a convenient intermediate storage place for data passed between various services - think of a message bus system but with less formality.  For example, we have daemons that download and parse web pages, then send interesting bits to other daemons for further processing.  A lot of those objects are ill-defined until runtime (\"here\\'s some HTML, plus a set of metadata, and some actions to run on it\").  Rather than serialize it to an ad-hoc local network protocol or stick it in PostgreSQL, I\\'d much rather use something designed for the purpose.  We\\'re currently using NetWorkSpaces in this role, but it doesn\\'t have nearly the breadth of support or the user community of CouchDB.\\n',\n  'completion': 'I have been using couchdb-python with quite a lot of success and as far as I know the guys of desktopcouch use it in ubuntu. The prerequisites are very basic and you should have not problems:\\n\\n\\nhttplib2\\nsimplejson or cjson\\nPython\\nCouchDB 0.9.x (earlier or later versions are unlikely to work as the interface is still changing) \\n\\n\\nFor me some of the advantages are:\\n\\n\\nPythonic interface. You can work with the database like if it was a dict.\\nInterface for design documents.\\na CouchDB view server that allows writing view functions in Python \\n\\n\\nIt also provides a couple of command-line tools: \\n\\n\\ncouchdb-dump: Writes a snapshot of a CouchDB database\\ncouchdb-load: Reads a MIME multipart file as generated by couchdb-dump and loads all the documents, attachments, and design documents into a CouchDB database. \\ncouchdb-replicate: Can be used as an update-notification script to trigger replication between databases when data is changed. \\n\\n'},\n {'prompt': \"I wrote a desktop application and was using datetime.datetime.utcnow() for timestamping, however I've recently noticed that some people using the application get wildly different results than I do when we run the program at the same time.  Is there any way to get the UTC time locally without using urllib to fetch it from a website?\\n\",\n  'completion': \"Python depends on the underlying operating system to provide an accurate time-of-day clock.  If it isn't doing that, you don't have much choice other than to bypass the o/s.  There's a pure-Python implementation of an NTP client here.  A very simple-minded approach:\\n\\n>>> import ntplib,datetime\\n>>> x = ntplib.NTPClient()\\n>>> datetime.datetime.utcfromtimestamp(x.request('europe.pool.ntp.org').tx_time)\\ndatetime.datetime(2009, 10, 21, 7, 1, 54, 716657)\\n\\n\\nHowever, it would not be very nice to be continually hitting on other NTP servers out there.  A good net citizen would use the ntp client library to keep track of the offset between the o/s system clock and that obtained from the server and only periodically poll to adjust the time.\\n\"},\n {'prompt': \"I use popen to execute commands in a Python script, and I call it via cron.\\nCron calls out this script but the behavior isn't the same if I call it by hand.\\n\\nSource:\\n\\nfrom subprocess import Popen, PIPE\\n\\npp = Popen('/usr/bin/which iptables', shell=True, stdout=PIPE)\\n\\ndata = ''\\nfor ln in pp.stdout:\\n    data = data+ln\\n\\nif data == '':\\n    print 'ko'\\nelse:\\n    print 'ok : '+data\\n\\n\\nBy hand:\\n\\n# python /home/user/test.py\\n> : /sbin/iptables\\n\\n\\nBy cron (in /tmp/err_cron):\\n\\n* * * * * /usr/bin/python /home/user/test.py >> /tmp/err_cron\\nko\\nko\\nko\\n\\n\\nWhy does cron not run this script normally?\\n\",\n  'completion': 'Normally when processes are run from cron, the PATH is set to a very restrictive value (the man page for my crontab says /usr/bin:/bin). You  may need to add:\\n\\n\\nPATH=/usr/bin:/bin:/sbin\\n\\n\\nto the top of your crontab file.\\n'},\n {'prompt': \"I'm working on a Python library used by third-party developers to write extensions for our core application.\\n\\nI'd like to know if it's possible to modify the traceback when raising exceptions, so the last stack frame is the call to the library function in the developer's code, rather than the line in the library that raised the exception. There are also a few frames at the bottom of the stack containing references to functions used when first loading the code that I'd ideally like to remove too.\\n\\nThanks in advance for any advice!\\n\",\n  'completion': \"You can remove the top of the traceback easily with by raising with the tb_next element of the traceback:\\n\\nexcept:\\n    ei = sys.exc_info()\\n    raise ei[0], ei[1], ei[2].tb_next\\n\\n\\ntb_next is a read_only attribute, so I don't know of a way to remove stuff from the bottom.  You might be able to screw with the properties mechanism to allow access to the property, but I don't know how to do that.\\n\"},\n {'prompt': 'I want to grab the color of a pixel with known coordinates on my Linux desktop.\\n\\nUntil now, I\\'ve used \"import -window SomeWindow -crop 1x1+X+Y /tmp/grab.jpg\"\\nthen extracting the pixel value using Python and PIL.\\n\\nThis does the job, but since import grabs the whole window before cropping, it\\'s very slow :(\\n\\nAre there any clever way to grab the color of only one pixel? I know both relative (window) and absolute coordinates. \\n\\nA Python or shell script would be preferable, but if you know some clever C/X11 functions, also please let me know :)\\n',\n  'completion': 'This does the trick, but requires python-gtk:\\n\\nimport gtk.gdk\\nimport sys\\n\\ndef PixelAt(x, y):\\n    w = gtk.gdk.get_default_root_window()\\n    sz = w.get_size()\\n    pb = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB,False,8,sz[0],sz[1])\\n    pb = pb.get_from_drawable(w,w.get_colormap(),0,0,0,0,sz[0],sz[1])\\n    pixel_array = pb.get_pixels_array()\\n    return pixel_array[y][x]\\n\\nprint PixelAt(int(sys.argv[1]), int(sys.argv[2]))\\n\\n\\nOn Ubuntu 9.10, this also requires python-numpy or it segfaults the python interpreter on the get_pixels_array line. Ubuntu 10.04 it still has this requirement, or it causes an ImportError regarding numpy.core.multiarray.\\n'},\n {'prompt': 'I tried these two methods:\\n\\nos.system(\"python test.py\")\\n\\nsubprocess.Popen(\"python test.py\", shell=True)\\n\\n\\nBoth approaches need to wait until test.py finishes which blocks main process. I know \"nohup\" can do the job. Is there a Python way to launch test.py or any other shell scripts and leave it running in background?\\n\\nSuppose test.py is like this:\\n\\nfor i in range(0, 1000000):\\n    print i\\n\\n\\nBoth os.system() or subprocess.Popen() will block main program until 1000000 lines of output displayed. What I want is let test.py runs silently and display main program output only. Main program may quie while test.py is still running.\\n',\n  'completion': 'subprocess.Popen([\"python\", \"test.py\"]) should work.\\n\\nNote that the job might still die when your main script exits. In this case, try subprocess.Popen([\"nohup\", \"python\", \"test.py\"])\\n'},\n {'prompt': 'Newbie question (I\\'m just getting started with Python and Pydev):\\n\\nI\\'ve created a project \"Playground\" with (standard?) src/root sub-folder. In there I\\'ve created example.py.\\n\\nHow do I import my \"example\" module into Pydev\\'s interactive console?\\n\">>> import example\" gives: \"ImportError: No module named example\"\\n',\n  'completion': \"You need to set your PYTHONPATH accordingly (Google search is your friend) or use *.pth in your installation site-packages directory pointing to your project path.  Don't forget to set your interpreter details with Pydev (Window->Preferences->Pydev->interpreter).\\n\"},\n {'prompt': \"Our framework requires wrapping certain functions in some ugly boilerplate code:\\n\\ndef prefix_myname_suffix(obj):\\n    def actual():\\n        print 'hello world'\\n    obj.register(actual)\\n    return obj\\n\\n\\nI figured this might be simplified with a decorator:\\n\\n@register\\ndef myname():\\n    print 'hello world'\\n\\n\\nHowever, that turned out to be rather tricky, mainly because the framework looks for a certain pattern of function names at module level.\\n\\nI've tried the following within the decorator, to no avail:\\n\\ncurrent_module = __import__(__name__)\\nnew_name = prefix + func.__name__ + suffix\\n# method A\\ncurrent_module[new_name] = func\\n# method B\\nfunc.__name__ = new_name\\ncurrent_module += func\\n\\n\\nAny help would be appreciated!\\n\",\n  'completion': 'use either     \\n\\ncurrent_module.new_name = func\\n\\n\\nor    \\n\\nsetattr(current_module, new_name, func)\\n\\n'},\n {'prompt': 'From http://code.google.com/p/unladen-swallow/wiki/ProjectPlan I quote:\\n\\n\"Using a JIT will also allow us to move Python from a stack-based machine to a register machine, which has been shown to improve performance in other similar languages (Ierusalimschy et al, 2005; Shi et al, 2005).\"\\n\\nIn college I built a simple compiler for a language with recursive procedures - which maintained stack frames for each procedure called - so that they can be called recursively and so that parameters and return values would work....\\n\\n2 things:\\n\\n1) Am I right in thinking that what I implemented would be considered a \"stack-based machine\" given the terminology used in the quotation above?\\n\\n2) If my assumption in point (1) was right, how does a \"register machine\" work? i.e. how is it different from a stack-based machine?\\n\\nThanks! \\n',\n  'completion': 'A register machine is a hardware or software unit that when working with data takes it from memory, puts it in a location where it can work with it quickly, and then returns the result.\\n\\nFor example a regular CPU is a register machine. Since the ALU (the unit that works with numbers in a CPU) can only work with numbers in a register.\\n\\nA stack based machine adds the data onto a stack and then either pops or pushes stuff onto it.\\n\\nFor example, adding two numbers would be\\n\\nPush 2 // Push 2 onto the stack\\nPush 3 // Push 3 onto the stack\\nAdd // Add the top two things on the stack.\\n\\n\\nWhen in a register machine it would be something like this.\\n\\nLoad x, r0 // Load x onto register 0\\nLoad y, r1 // Load y onto register 1\\nAdd r0, r1, r2 // Add 1 and 2 and store the result in register 2\\n\\n'},\n {'prompt': 'I\\'d like to know the best way (more compact and \"pythonic\" way) to do a special treatment for the last element in a for loop. There is a piece of code that should be called only between elements, being suppressed in the last one.\\n\\nHere is how I currently do it:\\n\\nfor i, data in enumerate(data_list):\\n    code_that_is_done_for_every_element\\n    if i != len(data_list) - 1:\\n        code_that_is_done_between_elements\\n\\n\\nIs there any better way?\\n\\nNote: I don\\'t want to make it with hacks such as using reduce ;)\\n',\n  'completion': 'Most of the times it is easier (and cheaper) to make the first iteration the special case instead of the last one:\\n\\nfirst = True\\nfor data in data_list:\\n    if first:\\n        first = False\\n    else:\\n        between_items()\\n\\n    item()\\n\\n\\nThis will work for any iterable, even for those that have no len():\\n\\nfile = open(\\'/path/to/file\\')\\nfor line in file:\\n    process_line(line)\\n\\n    # No way of telling if this is the last line!\\n\\n\\nApart from that, I don\\'t think there is a generally superior solution as it depends on what you are trying to do. For example, if you are building a string from a list, it\\'s naturally better to use str.join() than using a for loop â\\x80\\x9cwith special caseâ\\x80\\x9d.\\n\\n\\n\\nUsing the same principle but more compact:\\n\\nfor i, line in enumerate(data_list):\\n    if i > 0:\\n        between_items()\\n    item()\\n\\n\\nLooks familiar, doesn\\'t it? :)\\n\\n\\n\\nFor @ofko, and others who really need to find out if the current value of an iterable without len() is the last one, you will need to look ahead:\\n\\ndef lookahead(iterable):\\n    \"\"\"Pass through all values from the given iterable, augmented by the\\n    information if there are more values to come after the current one\\n    (True), or if it is the last value (False).\\n    \"\"\"\\n    # Get an iterator and pull the first value.\\n    it = iter(iterable)\\n    last = next(it)\\n    # Run the iterator to exhaustion (starting from the second value).\\n    for val in it:\\n        # Report the *previous* value (more to come).\\n        yield last, True\\n        last = val\\n    # Report the last value.\\n    yield last, False\\n\\n\\nThen you can use it like this:\\n\\n>>> for i, has_more in lookahead(range(3)):\\n...     print(i, has_more)\\n0 True\\n1 True\\n2 False\\n\\n'},\n {'prompt': \"Every Python developer is familiar with easy_install and setup tools. \\n\\nIf I want to install a library that's well known, all I have to do is this:\\n\\nsudo easy_setup install django\\n\\nNow I have a library that I've written and would love to see widespread. How do you get added to this library list?\\n\",\n  'completion': 'Upload it to PyPI. See the tutorial.\\n'},\n {'prompt': 'How to make a multi-thread python program response to Ctrl+C key event?\\n\\nEdit: The code is like this:\\n\\nimport threading\\ncurrent = 0\\n\\nclass MyThread(threading.Thread):\\n    def __init__(self, total):\\n        threading.Thread.__init__(self)\\n        self.total = total\\n\\n    def stop(self):\\n        self._Thread__stop()\\n\\n    def run(self):\\n        global current\\n        while current<self.total:\\n            lock = threading.Lock()\\n            lock.acquire()\\n            current+=1\\n            lock.release()\\n            print current\\n\\nif __name__==\\'__main__\\':\\n\\n    threads = []\\n    thread_count = 10\\n    total = 10000\\n    for i in range(0, thread_count):\\n        t = MyThread(total)\\n        t.setDaemon(True)\\n        threads.append(t)\\n    for i in range(0, thread_count):\\n        threads[i].start()\\n\\n\\nI tried to remove join() on all threads but it still doesn\\'t work. Is it because the lock segment inside each thread\\'s run() procedure?\\n\\nEdit: The above code is supposed to work but it always interrupted when current variable was in 5,000-6,000 range and through out the errors as below\\n\\nException in thread Thread-4 (most likely raised during interpreter shutdown):\\nTraceback (most recent call last):\\n  File \"/usr/lib/python2.5/threading.py\", line 486, in __bootstrap_inner\\n  File \"test.py\", line 20, in run\\n<type \\'exceptions.TypeError\\'>: unsupported operand type(s) for +=: \\'NoneType\\' and \\'int\\'\\nException in thread Thread-2 (most likely raised during interpreter shutdown):\\nTraceback (most recent call last):\\n  File \"/usr/lib/python2.5/threading.py\", line 486, in __bootstrap_inner\\n  File \"test.py\", line 22, in run\\n\\n',\n  'completion': 'Make every thread except the main one a daemon (t.daemon = True in 2.6 or better, t.setDaemon(True) in 2.6 or less, for every thread object t before you start it).  That way, when the main thread receives the KeyboardInterrupt, if it doesn\\'t catch it or catches it but decided to terminate anyway, the whole process will terminate.  See the docs.\\n\\nedit: having just seen the OP\\'s code (not originally posted) and the claim that \"it doesn\\'t work\", it appears I have to add...:\\n\\nOf course, if you want your main thread to stay responsive (e.g. to control-C), don\\'t mire it into blocking calls, such as joining another thread -- especially not totally useless blocking calls, such as joining daemon threads.  For example, just change the final loop in the main thread from the current (utterless and damaging):\\n\\nfor i in range(0, thread_count):\\n    threads[i].join()\\n\\n\\nto something more sensible like:\\n\\nwhile threading.active_count() > 0:\\n    time.sleep(0.1)\\n\\n\\nif your main has nothing better to do than either for all threads to terminate on their own, or for a control-C (or other signal) to be received.\\n\\nOf course, there are many other usable patterns if you\\'d rather have your threads not terminate abruptly (as daemonic threads may) -- unless they, too, are mired forever in unconditionally-blocking calls, deadlocks, and the like;-).\\n'},\n {'prompt': \"I would like to delete selected columns in a numpy.array . This is what I do:\\n\\nn [397]: a = array([[ NaN,   2.,   3., NaN],\\n   .....:        [  1.,   2.,   3., 9]])\\n\\nIn [398]: print a\\n[[ NaN   2.   3.  NaN]\\n [  1.   2.   3.   9.]]\\n\\nIn [399]: z = any(isnan(a), axis=0)\\n\\nIn [400]: print z\\n[ True False False  True]\\n\\nIn [401]: delete(a, z, axis = 1)\\nOut[401]:\\n array([[  3.,  NaN],\\n       [  3.,   9.]])\\n\\n\\nIn this example my goal is to delete all the columns that contain NaN's. I expect the last command \\nto result in:\\n\\narray([[2., 3.],\\n       [2., 3.]])\\n\\n\\nHow can I do that?\\n\",\n  'completion': 'Given its name, I think the standard way should be delete:\\n\\nA = scipy.delete(A, 1, 0)  # delete second row of A\\nB = scipy.delete(B, 2, 0)  # delete third row of B\\nC = scipy.delete(C, 1, 1)  # delete second column of C\\n\\n'},\n {'prompt': 'I\\'m programming in Python and I\\'m obtaining information from a web page through the urllib2 library. The problem is that that page can provide me with non-ASCII characters, like \\'Ã±\\', \\'Ã¡\\', etc. In the very moment urllib2 gets this character, it provokes an exception, like this:\\n\\nFile \"c:\\\\Python25\\\\lib\\\\httplib.py\", line 711, in send\\n    self.sock.sendall(str) \\nFile \"<string>\", line 1, in sendall:\\n    UnicodeEncodeError: \\'ascii\\' codec can\\'t encode character u\\'\\\\xf1\\' in position 74: ordinal not in range(128)\\n\\n\\nI need to handle those characters. I mean, I don\\'t want to handle the exception but to continue the program. Is there any way to, for example (I don\\'t know if this is something stupid), use another codec rather than the ASCII? Because I have to work with those characters, insert them in a database, etc.\\n',\n  'completion': 'You just read a set of bytes from the socket.  If you want a string you have to decode it:\\n\\nyourstring = receivedbytes.decode(\"utf-8\") \\n\\n\\n(substituting whatever encoding you\\'re using for utf-8)\\n\\nThen you have to do the reverse to send it back out:\\n\\noutbytes = yourstring.encode(\"utf-8\")\\n\\n'},\n {'prompt': 'I\\'m relatively new to programming/python, so I\\'d appreciate any help I can get.   I want to save an excel file as a specific format using Excel through COM.  Here is the code:\\n\\nimport win32com.client as win32 \\n\\ndef excel():\\n    app = \\'Excel\\'\\n    x1 = win32.gencache.EnsureDispatch(\\'%s.Application\\' % app)\\n    ss = x1.Workbooks.Add()\\n    sh = ss.ActiveSheet\\n    x1.Visible = True\\n    sh.Cells(1,1).Value = \\'test write\\'\\n    ss.SaveAs(Filename=\"temp.xls\", FileFormat=56)\\n    x1.Application.Quit()\\n\\nif __name__==\\'__main__\\':\\n    excel()\\n\\n\\nMy question is how do I specify the FileFormat if I don\\'t explicitly know the code for it?  Browsing through the documentation I find the reference at about a FileFormat object.  I\\'m clueless on how to access the XlFileFormat object and import it in a way that I can find the enumeration value for it.  \\n\\nThanks!\\n',\n  'completion': \"This question is a bit stale, but for those reaching this page from Google (as I did) my solution was accessing the constants via the win32com.client.constants object instead of on the application object itself as suggested by Eric. This lets you use enum constants just like in the VBE:\\n\\n>>> import win32com.client\\n>>> xl = win32com.client.gencache.EnsureDispatch('Excel.Application')\\n>>> C = win32com.client.constants\\n>>> C.xlWorkbookNormal\\n-4143\\n>>> C.xlCSV\\n6\\n>>> C.xlErrValue\\n2015\\n>>> C.xlThemeColorAccent1\\n5\\n\\n\\nAlso, unless you've manually run the makepy utility, the constants may not be available if initializing the application with the regular win32com.client.Dispatch(..) method, which was another issue I was having. Using win32com.client.gencache.EnsureDispatch(..) (as the questioner does) checks for and generates the Python bindings at runtime if required.\\n\\nI found this ActiveState page to be helpful.\\n\"},\n {'prompt': 'Python has an ordered dictionary, what about an ordered set?\\n',\n  'completion': \"There is an ordered set recipe for this which is referred to from the Python 2 Documentation. This runs on Py2.6 or later and 3.0 or later without any modifications. The interface is almost exactly the same as a normal set, except that initialisation should be done with a list.\\n\\nOrderedSet([1, 2, 3])\\n\\n\\nThis is a MutableSet, so the signature for .union doesn't match that of set, but since it includes __or__ something similar can easily be added:\\n\\n@staticmethod\\ndef union(*sets):\\n    union = OrderedSet()\\n    union.union(*sets)\\n    return union\\n\\ndef union(self, *sets):\\n    for set in sets:\\n        self |= set\\n\\n\"},\n {'prompt': 'I\\'ve written a server in Python that is meant to send data to the client in the form \"Header:Message\"\\n\\nI would like to be able to have each message sent individually so that the client will  need to perform minimal work in order to read the \"header\" and the \"message\"\\n\\nUnfortunately, I can\\'t figure out how to properly flush a python socket so when I have multiple sends execute in quick succession the messages get lumped together in the socket buffer and sent as one big chunk.\\n\\nExample:\\n\\nServer sends...\\n\\nsocket.send (\"header1:message1\")\\nsocket.send (\"header2:message2\")\\nsocket.send (\"header3:message3\")\\n\\n\\nClient receives...\\n\"header1:message1header2:message2header3:message3\"\\n\\nI\\'d like to receive three individual messages\\n\\nheader1:message1\\nheader2:message2\\nheader3:message3\\n\\n\\nI need a way to flush after each send\\n',\n  'completion': \"I guess you are talking over a TCP connection.\\n\\nYour approach is flawed. A TCP stream is defined as a stream of bytes. You always have to use some sort of separator and may not rely on the network stack to separate your messages.\\n\\nIf you really need datagram based services switch to UDP. You'll need to handle retransmission yourself in that case.\\n\\nTo clarify:\\n\\nFlushing the send buffer usually creates new packages, just as you expect. If your client reads these packages fast enough you may get one message per read.\\n\\nNow imagine you communicate over a satellite link. Because of high bandwidth and latency, the last router before the sat waits a short time until enough data is in the buffer and sends all your packets at once. Your client will now receive all packets without delay and will put all the data in the receive buffer at once. So your separation is gone again.\\n\"},\n {'prompt': \"I'm trying to run a google search query from a python app. Is there any python interface out there that would let me do this? If there isn't does anyone know which Google API will enable me to do this. Thanks.\\n\",\n  'completion': \"There's a simple example here (peculiarly missing some quotes;-).  Most of what you'll see on the web is Python interfaces to the old, discontinued SOAP API -- the example I'm pointing to uses the newer and supported AJAX API, that's definitely the one you want!-)\\n\\nEdit: here's a more complete Python 2.6 example with all the needed quotes &c;-)...:\\n\\n#!/usr/bin/python\\nimport json\\nimport urllib\\n\\ndef showsome(searchfor):\\n  query = urllib.urlencode({'q': searchfor})\\n  url = 'http://ajax.googleapis.com/ajax/services/search/web?v=1.0&%s' % query\\n  search_response = urllib.urlopen(url)\\n  search_results = search_response.read()\\n  results = json.loads(search_results)\\n  data = results['responseData']\\n  print 'Total results: %s' % data['cursor']['estimatedResultCount']\\n  hits = data['results']\\n  print 'Top %d hits:' % len(hits)\\n  for h in hits: print ' ', h['url']\\n  print 'For more results, see %s' % data['cursor']['moreResultsUrl']\\n\\nshowsome('ermanno olmi')\\n\\n\"},\n {'prompt': 'I would like to be able to run a nose test script which accepts command line arguments. For example, something along the lines:\\n\\ntest.py\\n\\nimport nose, sys\\n\\ndef test():\\n    # do something with the command line arguments\\n    print sys.argv\\n\\nif __name__ == \\'__main__\\':\\n    nose.runmodule()\\n\\n\\nHowever, whenever I run this with a command line argument, I get an error:\\n\\n$ python test.py arg\\nE\\n======================================================================\\nERROR: Failure: ImportError (No module named arg)\\n----------------------------------------------------------------------\\nTraceback (most recent call last):\\n  File \"/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/site-packages/nose-0.11.1-py2.6.egg/nose/loader.py\", line 368, in loadTestsFromName\\n    module = resolve_name(addr.module)\\n  File \"/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/site-packages/nose-0.11.1-py2.6.egg/nose/util.py\", line 334, in resolve_name\\n    module = __import__(\\'.\\'.join(parts_copy))\\nImportError: No module named arg\\n\\n----------------------------------------------------------------------\\nRan 1 test in 0.001s\\n\\nFAILED (errors=1)\\n\\n\\nApparently, nose tries to do something with the arguments passed in sys.argv. Is there a way to make nose ignore those arguments?\\n',\n  'completion': 'Alright, I hate \"why would you want to do that?\" answers just as much as anyone, but I\\'m going to have to make one here.  I hope you don\\'t mind.\\n\\nI\\'d argue that doing whatever you\\'re wanting to do isn\\'t within the scope of the framework nose.  Nose is intended for automated tests.  If you have to pass in command-line arguments for the test to pass, then it isn\\'t automated.  Now, what you can do is something like this:\\n\\nimport sys\\n\\nclass test_something(object):\\n    def setUp(self):\\n        sys.argv[1] = \\'arg\\'\\n        del sys.argv[2] # remember that -s is in sys.argv[2], see below\\n    def test_method(self):\\n        print sys.argv\\n\\n\\nIf you run that, you get this output:\\n\\n[~] nosetests test_something.py -s\\n[\\'/usr/local/bin/nosetests\\', \\'arg\\']\\n.\\n----------------------------------------------------------------------\\nRan 1 test in 0.001s\\n\\nOK\\n\\n\\n(Remember to pass in the -s flag if you want to see what goes on stdout)\\n\\nHowever, I\\'d probably still recommend against that, as it\\'s generally a bad idea to mess with global state in automated tests if you can avoid it.  What I would likely do is adapt whatever code I\\'m wanting to test to take an argv list.  Then, you can pass in whatever you want during testing and pass in sys.argv in production.\\n\\nUPDATE:\\n\\n\\n  The reason why I need to do it is\\n  because I am testing multiple\\n  implementations of the same library.\\n  To test those implementations are\\n  correct I use a single nose script,\\n  that accepts as a command line\\n  argument the library that it should\\n  import for testing.\\n\\n\\nIt sounds like you may want to try your hand at writing a nose plugin.  It\\'s pretty easy to do.  Here are the latest docs.\\n'},\n {'prompt': \"I'm using urllib2 to fetch a a page via HTTP.  Sometimes the resource throws a HTTP error 400 (Bad Request) when my request contains an error.  However, that response also contains an XML element that gives a detailed error message.  It would be very handy to be able to see that error rather than just the HTTPError exception returned by urllib2.  \\n\\nHow do I return the document contents in spite of the exception?\\n\",\n  'completion': \"import urllib2\\ntry:\\n    request = urllib2.Request('http://www.somesite.com')\\n    response = urllib2.urlopen(req)\\nexcept urllib2.HTTPError as e:\\n    error_message = e.read()\\n    print error_message\\n\\n\"},\n {'prompt': 'In python, I remember there is a function to do this.\\n\\n.count? \\n\\n\"The big brown fox is brown\"\\nbrown = 2.\\n',\n  'completion': 'why not read the docs first, it\\'s very simple:\\n\\n>>> \"The big brown fox is brown\".count(\"brown\")\\n2\\n\\n'},\n {'prompt': \"I'm trying to create an image using matplotlib.pyplot.imshow().  However, when I run the program from my console, it doesn't display anything?\\n\\nThis is the code:\\n\\nimport matplotlib.pyplot\\n\\nmyimage = gen_image()\\n\\nmatplotlib.pyplot.gray()\\nmatplotlib.pyplot.imshow(results)\\n\\n\\nBut this shows nothing.\\n\",\n  'completion': \"You have to call the show function to actually display anything, like\\n\\nmatplotlib.pyplot.show()\\n\\n\\nUnfortunately the matplotlib documentation seems to be currently broken, so I can't provide a link.\\n\\nNote that for interactive plotting one typically uses IPython, which has special support for matplotlib.\\n\\nBy the way, you can do\\n\\nimport matplotlib.pyplot as plt\\n\\n\\nto make the typing less tedious (this is pretty much the official standard way).\\n\"},\n {'prompt': \"I was writing a script to inspect python's version on my system and I've noticed that python -V writes to the error stream, while python -h, for instance, uses the standard output. Is there a good reason for this behavior?\\n\",\n  'completion': 'The -h option also used to print to stderr because it is not part of the output of your program, i.e. the output is not produced by your Python script but by the Python interpreter itself. \\n\\nAs for why they changed the -h to use stdout? Try typing python -h with your terminal window set to the standard 24 lines. It scrolls off the screen.\\n\\nNow most people would react by trying python -h |less but that only works if you send the output of -h to the stdout instead of stderr. So there was a good reason for making -h go to stdout, but no good reason for changing -V.\\n'},\n {'prompt': 'If Beautiful Soup gives me an anchor tag like this:\\n\\n<a class=\"blah blah\" id=\"blah blah\" href=\"link.html\"></a>\\n\\n\\nHow would I retrieve the value of the href attribute?\\n',\n  'completion': 'If you already have the anchor, grab the href attribute like this:\\n\\nhref = anchor[\"href\"]\\n\\n'},\n {'prompt': '\\n  Possible Duplicate:\\n  Python Ternary Operator  \\n\\n\\n\\n\\nIs there a way to write this C/C++ code in Python?\\na = (b == true ? \"123\" : \"456\" )\\n\\nThanks so much!\\n',\n  'completion': \"a = '123' if b else '456'\\n\\n\"},\n {'prompt': \"I am using their default POS tagging and default tokenization..and it seems sufficient.  I'd like their default chunker too.\\n\\nI am reading the NLTK toolkit book, but it does not seem like they have a default chunker?\\n\",\n  'completion': \"You can get out of the box named entity chunking with the nltk.ne_chunk() method.  It takes a list of POS tagged tuples:\\n\\nnltk.ne_chunk([('Barack', 'NNP'), ('Obama', 'NNP'), ('lives', 'NNS'), ('in', 'IN'), ('Washington', 'NNP')])\\n\\nresults in:\\n\\nTree('S', [Tree('PERSON', [('Barack', 'NNP')]), Tree('ORGANIZATION', [('Obama', 'NNP')]), ('lives', 'NNS'), ('in', 'IN'), Tree('GPE', [('Washington', 'NNP')])])\\n\\nIt identifies Barack as a person, but Obama as an organization.  So, not perfect.\\n\"},\n {'prompt': 'While building a new class object in python, I want to be able to create a default value based on the instance name of the class without passing in an extra argument. How can I accomplish this? Here\\'s the basic pseudo-code I\\'m trying for:\\n\\nclass SomeObject():\\n    defined_name = u\"\"\\n\\n    def __init__(self, def_name=None):\\n        if def_name == None:\\n            def_name = u\"%s\" % (<INSTANCE NAME>)\\n        self.defined_name = def_name\\n\\nThisObject = SomeObject()\\nprint ThisObject.defined_name   # Should print \"ThisObject\"\\n\\n',\n  'completion': \"Instances don't have names. By the time the global name ThisObject gets bound to the instance created by evaluating the SomeObject constructor, the constructor has finished running.\\n\\nIf you want an object to have a name, just pass the name along in the constructor.\\n\\ndef __init__(self, name):\\n    self.name = name\\n\\n\"},\n {'prompt': 'What is the pythonic way of watching the tail end of a growing file for the occurrence of certain keywords?\\n\\nIn shell I might say:\\n\\ntail -f \"$file\" | grep \"$string\" | while read hit; do\\n    #stuff\\ndone\\n\\n',\n  'completion': 'Well, the simplest way would be to constantly read from the file, check what\\'s new and test for hits.\\n\\nimport time\\n\\ndef watch(fn, words):\\n    fp = open(fn, \\'r\\')\\n    while True:\\n        new = fp.readline()\\n        # Once all lines are read this just returns \\'\\'\\n        # until the file changes and a new line appears\\n\\n        if new:\\n            for word in words:\\n                if word in new:\\n                    yield (word, new)\\n        else:\\n            time.sleep(0.5)\\n\\nfn = \\'test.py\\'\\nwords = [\\'word\\']\\nfor hit_word, hit_sentence in watch(fn, words):\\n    print \"Found %r in line: %r\" % (hit_word, hit_sentence)\\n\\n\\nThis solution with readline works if you know your data will appear in lines. \\n\\nIf the data is some sort of stream you need a buffer, larger than the largest word you\\'re looking for, and fill it first. It gets a bit more complicated that way...\\n'},\n {'prompt': 'Is there any custom widget (or a special magic way) to upload multiple files (or a whole folder!) through one form field?\\nI have tried this multifile widget but it uses many simple FileFileds.\\n',\n  'completion': 'HTML 5 now allows for multiple file uploads in a single form control.\\n\\nhttp://www.w3.org/TR/html-markup/input.file.html#input.file.attrs.multiple\\n'},\n {'prompt': 'I need to call a Python function from MATLAB. how can I do this?\\n',\n  'completion': 'I had a similar requirement on my system and this was my solution: \\n\\nIn MATLAB there is a function called perl.m, which allows you to call perl scripts from MATLAB. Depending on which version you are using it will be located somewhere like\\n\\nC:\\\\Program Files\\\\MATLAB\\\\R2008a\\\\toolbox\\\\matlab\\\\general\\\\perl.m\\n\\n\\nCreate a copy called python.m, a quick search and replace of perl with python, double check the command path it sets up to point to your installation of python. You should now be able to run python scripts from MATLAB.\\n\\nExample\\n\\nA simple squared function in python saved as \"sqd.py\", naturally if I was doing this properly I\\'d have a few checks in testing input arguments, valid numbers etc.\\n\\nimport sys\\n\\ndef squared(x):\\n    y = x * x\\n    return y\\n\\nif __name__ == \\'__main__\\':\\n    x = float(sys.argv[1])\\n    sys.stdout.write(str(squared(x)))\\n\\n\\nThen in MATLAB\\n\\n>> r=python(\\'sqd.py\\',\\'3.5\\')\\nr =\\n12.25\\n>> r=python(\\'sqd.py\\',\\'5\\')\\nr =\\n25.0\\n>>\\n\\n'},\n {'prompt': 'The XML specification lists a bunch of Unicode characters that are either illegal or \"discouraged\". Given a string, how can I remove all illegal characters from it?\\n\\nI came up with the following regular expression, but it\\'s a bit of a mouthful.\\n\\nillegal_xml_re = re.compile(u\\'[\\\\x00-\\\\x08\\\\x0b-\\\\x1f\\\\x7f-\\\\x84\\\\x86-\\\\x9f\\\\ud800-\\\\udfff\\\\ufdd0-\\\\ufddf\\\\ufffe-\\\\uffff]\\')\\nclean = illegal_xml_re.sub(\\'\\', dirty)\\n\\n\\n(Python 2.5 doesn\\'t know about Unicode chars above 0xFFFF, so no need to filter those.)\\n',\n  'completion': 'Recently we (Trac XmlRpcPlugin maintainers) have been notified of the fact that the regular expression above strips surrogate pairs on Python narrow builds (see th:comment:13:ticket:11050) . An alternative approach consists in using the following regex (see th:changeset:13729) .\\n\\n_illegal_unichrs = [(0x00, 0x08), (0x0B, 0x0C), (0x0E, 0x1F), \\n                        (0x7F, 0x84), (0x86, 0x9F), \\n                        (0xFDD0, 0xFDDF), (0xFFFE, 0xFFFF)] \\nif sys.maxunicode >= 0x10000:  # not narrow build \\n        _illegal_unichrs.extend([(0x1FFFE, 0x1FFFF), (0x2FFFE, 0x2FFFF), \\n                                 (0x3FFFE, 0x3FFFF), (0x4FFFE, 0x4FFFF), \\n                                 (0x5FFFE, 0x5FFFF), (0x6FFFE, 0x6FFFF), \\n                                 (0x7FFFE, 0x7FFFF), (0x8FFFE, 0x8FFFF), \\n                                 (0x9FFFE, 0x9FFFF), (0xAFFFE, 0xAFFFF), \\n                                 (0xBFFFE, 0xBFFFF), (0xCFFFE, 0xCFFFF), \\n                                 (0xDFFFE, 0xDFFFF), (0xEFFFE, 0xEFFFF), \\n                                 (0xFFFFE, 0xFFFFF), (0x10FFFE, 0x10FFFF)]) \\n\\n_illegal_ranges = [\"%s-%s\" % (unichr(low), unichr(high)) \\n                   for (low, high) in _illegal_unichrs] \\n_illegal_xml_chars_RE = re.compile(u\\'[%s]\\' % u\\'\\'.join(_illegal_ranges)) \\n\\n\\np.s. See this post on surrogates explaining what they are for .\\n\\nUpdate so as to not to match (replace) 0x0D which is a valid XML character.\\n'},\n {'prompt': 'In Python, when should you use lists and when tuples?\\n\\nSometimes you don\\'t have a choice, for example if you have\\n\\n\"hello %s you are %s years old\" % x\\n\\n\\nthen x must be a tuple.\\n\\nBut if I am the one who designs the API and gets to choose the data types, then what are the guidelines?\\n',\n  'completion': \"Tuples are fixed size in nature whereas lists are dynamic.\\nIn other words, a tuple is immutable whereas a list is mutable.\\n\\n\\nYou can't add elements to a tuple. Tuples have no append or extend method.\\nYou can't remove elements from a tuple. Tuples have no remove or pop method.\\nYou can find elements in a tuple, since this doesnâ\\x80\\x99t change the tuple. \\nYou can also use the in operator to check if an element exists in the tuple.\\n\\n\\n\\n\\n\\nTuples are faster than lists. If you're defining a constant set of values and all you're ever going to do with it is iterate through it, use a tuple instead of a list.\\nIt makes your code safer if you â\\x80\\x9cwrite-protectâ\\x80\\x9d data that does not need to be changed. Using a tuple instead of a list is like having an implied assert statement that this data is constant, and that special thought (and a specific function) is required to override that.\\nSome tuples can be used as dictionary keys (specifically, tuples that contain immutable values like strings, numbers, and other tuples). Lists can never be used as dictionary keys, because lists are not immutable. \\n\\n\\nSource: Dive into Python 3  \\n\"},\n {'prompt': \"This is the first time I've came across this. Just printed a list and each element seems to have a u in front of it i.e.        \\n\\n[u'hello', u'hi', u'hey']\\n\\n\\nWhat does it mean and why would a list have this in front of each element?\\n\\nAs I don't know how common this is, if you'd like to see how I came across it, I'll happily edit the post.\\n\",\n  'completion': \"it's an indication of unicode string. similar to r'' for raw string.\\n\\n>>> type(u'abc')\\n<type 'unicode'>\\n>>> r'ab\\\\c'\\n'ab\\\\\\\\c'\\n\\n\"},\n {'prompt': 'I am playing with the following code from programming collective intelligence, this is a function from the book that calculated eclidian distance between two movie critics.\\n\\nThis function sums the difference of the rankings in the dictionary, but euclidean distance in n dimensions also includes the square root of that sum.\\n\\nAFAIK since we use the same function to rank everyone it does not matter we square root or not, but i was wondering is there a particular reason for that?\\n\\n\\n\\nfrom math import sqrt \\n# Returns a distance-based similarity score for person1 and person2 \\ndef sim_distance(prefs,person1,person2): \\n  # Get the list of shared_items \\n  si={} \\n  for item in prefs[person1]: \\n    if item in prefs[person2]: \\n       si[item]=1 \\n  # if they have no ratings in common, return 0 \\n  if len(si)==0: return 0 \\n  # Add up the squares of all the differences \\n  sum_of_squares=sum([pow(prefs[person1][item]-prefs[person2][item],2) \\n                      for item in prefs[person1] if item in prefs[person2]]) \\n  return 1/(1+sum_of_squares) \\n\\n',\n  'completion': \"The reason the square root is not used is because it is computationally expensive; it is monotonic (i.e., it preserves order) with the square function, so if all you're interested in is the order of the distances, the square root is unnecessary (and, as mentioned, very expensive computationally).\\n\"},\n {'prompt': 'I am subclassing an object in order to override a method that I want to add some functionality to. I don\\'t want to completely replace it or add a differently named method but remain compatible to the superclasses method by just adding an optional argument to the method.\\nIs it possible to work with *args and **kwargs to pass through all arguments to the superclass and still add an optional argument with a default?\\nI intutively came up with the following but it doesn\\'t work:\\n\\nclass A(object):\\n    def foo(self, arg1, arg2, argopt1=\"bar\"):\\n        print arg1, arg2, argopt1\\n\\nclass B(A):\\n    def foo(self, *args, argopt2=\"foo\", **kwargs):\\n        print argopt2\\n        A.foo(self, *args, **kwargs)\\n\\n\\nb = B()\\nb.foo(\"a\", \"b\", argopt2=\"foo\")\\n\\n\\nOf course I can get it to work when I explcitly add all the arguments of the method of the superclass:\\n\\nclass B(A):\\n    def foo(self, arg1, arg2, argopt1=\"foo\", argopt2=\"bar\"):\\n        print argopt2\\n        A.foo(self, arg1, arg2, argopt1=argopt1)\\n\\n\\nWhat\\'s the right way to do this, do I have to know and explicitly state all of the overridden methods arguments?\\n',\n  'completion': 'class A(object):\\n    def foo(self, arg1, arg2, argopt1=\"bar\"):\\n        print arg1, arg2, argopt1\\n\\nclass B(A):\\n    def foo(self, *args, **kwargs):\\n        argopt2 = kwargs.get(\\'argopt2\\', default_for_argopt2)\\n        # remove the extra arg so the base class doesn\\'t complain. \\n        del kwargs[\\'argopt2\\']\\n        print argopt2\\n        A.foo(self, *args, **kwargs)\\n\\n\\nb = B()\\nb.foo(\"a\", \"b\", argopt2=\"foo\")\\n\\n'},\n {'prompt': \"Is there a way to append a row to a NumPy rec.array()? For example, \\n\\nx1=np.array([1,2,3,4])\\nx2=np.array(['a','dd','xyz','12'])\\nx3=np.array([1.1,2,3,4])\\nr = np.core.records.fromarrays([x1,x2,x3],names='a,b,c')\\n\\nappend(r,(5,'cc',43.0),axis=0)\\n\\n\\nThe easiest way would to extract all the column as nd.array() types, add the separate elements to each column, and then rebuild the rec.array(). This method would be memory inefficient unfortunately. Is there another way to this without separating the rebuilding the rec.array()? \\n\\nCheers,\\n\\nEli\\n\",\n  'completion': \"You can resize numpy arrays in-place. This is faster than converting to lists and then back to numpy arrays, and it uses less memory too.\\n\\nprint (r.shape)\\n# (4,)\\nr.resize(5)   \\nprint (r.shape)\\n# (5,)\\nr[-1] = (5,'cc',43.0)\\nprint(r)\\n\\n# [(1, 'a', 1.1000000000000001) \\n#  (2, 'dd', 2.0) \\n#  (3, 'xyz', 3.0) \\n#  (4, '12', 4.0)\\n#  (5, 'cc', 43.0)]\\n\\n\\nIf there is not enough memory to expand an array in-place, the resizing (or appending) operation may force NumPy to allocate space for an entirely new array and copy the old data to the new location. That, naturally, is rather slow so you should try to avoid using resize or append if possible. Instead, pre-allocate arrays of sufficient size from the very beginning (even if somewhat larger than ultimately necessary).\\n\"},\n {'prompt': \"I'd like to use principal component analysis (PCA) for dimensionality reduction.  Does numpy or scipy already have it, or do I have to roll my own using numpy.linalg.eigh?\\n\\nI don't just want to use singular value decomposition (SVD) because my input data are quite high-dimensional (~460 dimensions), so I think SVD will be slower than computing the eigenvectors of the covariance matrix.\\n\\nI was hoping to find a premade, debugged implementation that already makes the right decisions for when to use which method, and which maybe does other optimizations that I don't know about.\\n\",\n  'completion': 'Months later, here\\'s a small class PCA, and a picture:\\n\\n#!/usr/bin/env python\\n\"\"\" a small class for Principal Component Analysis\\nUsage:\\n    p = PCA( A, fraction=0.90 )\\nIn:\\n    A: an array of e.g. 1000 observations x 20 variables, 1000 rows x 20 columns\\n    fraction: use principal components that account for e.g.\\n        90 % of the total variance\\n\\nOut:\\n    p.U, p.d, p.Vt: from numpy.linalg.svd, A = U . d . Vt\\n    p.dinv: 1/d or 0, see NR\\n    p.eigen: the eigenvalues of A*A, in decreasing order (p.d**2).\\n        eigen[j] / eigen.sum() is variable j\\'s fraction of the total variance;\\n        look at the first few eigen[] to see how many PCs get to 90 %, 95 % ...\\n    p.npc: number of principal components,\\n        e.g. 2 if the top 2 eigenvalues are >= `fraction` of the total.\\n        It\\'s ok to change this; methods use the current value.\\n\\nMethods:\\n    The methods of class PCA transform vectors or arrays of e.g.\\n    20 variables, 2 principal components and 1000 observations,\\n    using partial matrices U\\' d\\' Vt\\', parts of the full U d Vt:\\n    A ~ U\\' . d\\' . Vt\\' where e.g.\\n        U\\' is 1000 x 2\\n        d\\' is diag([ d0, d1 ]), the 2 largest singular values\\n        Vt\\' is 2 x 20.  Dropping the primes,\\n\\n    d . Vt      2 principal vars = p.vars_pc( 20 vars )\\n    U           1000 obs = p.pc_obs( 2 principal vars )\\n    U . d . Vt  1000 obs, p.obs( 20 vars ) = pc_obs( vars_pc( vars ))\\n        fast approximate A . vars, using the `npc` principal components\\n\\n    Ut              2 pcs = p.obs_pc( 1000 obs )\\n    V . dinv        20 vars = p.pc_vars( 2 principal vars )\\n    V . dinv . Ut   20 vars, p.vars( 1000 obs ) = pc_vars( obs_pc( obs )),\\n        fast approximate Ainverse . obs: vars that give ~ those obs.\\n\\n\\nNotes:\\n    PCA does not center or scale A; you usually want to first\\n        A -= A.mean(A, axis=0)\\n        A /= A.std(A, axis=0)\\n    with the little class Center or the like, below.\\n\\nSee also:\\n    http://en.wikipedia.org/wiki/Principal_component_analysis\\n    http://en.wikipedia.org/wiki/Singular_value_decomposition\\n    Press et al., Numerical Recipes (2 or 3 ed), SVD\\n    PCA micro-tutorial\\n    iris-pca .py .png\\n\\n\"\"\"\\n\\nfrom __future__ import division\\nimport numpy as np\\ndot = np.dot\\n    # import bz.numpyutil as nu\\n    # dot = nu.pdot\\n\\n__version__ = \"2010-04-14 apr\"\\n__author_email__ = \"denis-bz-py at t-online dot de\"\\n\\n#...............................................................................\\nclass PCA:\\n    def __init__( self, A, fraction=0.90 ):\\n        assert 0 <= fraction <= 1\\n            # A = U . diag(d) . Vt, O( m n^2 ), lapack_lite --\\n        self.U, self.d, self.Vt = np.linalg.svd( A, full_matrices=False )\\n        assert np.all( self.d[:-1] >= self.d[1:] )  # sorted\\n        self.eigen = self.d**2\\n        self.sumvariance = np.cumsum(self.eigen)\\n        self.sumvariance /= self.sumvariance[-1]\\n        self.npc = np.searchsorted( self.sumvariance, fraction ) + 1\\n        self.dinv = np.array([ 1/d if d > self.d[0] * 1e-6  else 0\\n                                for d in self.d ])\\n\\n    def pc( self ):\\n        \"\"\" e.g. 1000 x 2 U[:, :npc] * d[:npc], to plot etc. \"\"\"\\n        n = self.npc\\n        return self.U[:, :n] * self.d[:n]\\n\\n    # These 1-line methods may not be worth the bother;\\n    # then use U d Vt directly --\\n\\n    def vars_pc( self, x ):\\n        n = self.npc\\n        return self.d[:n] * dot( self.Vt[:n], x.T ).T  # 20 vars -> 2 principal\\n\\n    def pc_vars( self, p ):\\n        n = self.npc\\n        return dot( self.Vt[:n].T, (self.dinv[:n] * p).T ) .T  # 2 PC -> 20 vars\\n\\n    def pc_obs( self, p ):\\n        n = self.npc\\n        return dot( self.U[:, :n], p.T )  # 2 principal -> 1000 obs\\n\\n    def obs_pc( self, obs ):\\n        n = self.npc\\n        return dot( self.U[:, :n].T, obs ) .T  # 1000 obs -> 2 principal\\n\\n    def obs( self, x ):\\n        return self.pc_obs( self.vars_pc(x) )  # 20 vars -> 2 principal -> 1000 obs\\n\\n    def vars( self, obs ):\\n        return self.pc_vars( self.obs_pc(obs) )  # 1000 obs -> 2 principal -> 20 vars\\n\\n\\nclass Center:\\n    \"\"\" A -= A.mean() /= A.std(), inplace -- use A.copy() if need be\\n        uncenter(x) == original A . x\\n    \"\"\"\\n        # mttiw\\n    def __init__( self, A, axis=0, scale=True, verbose=1 ):\\n        self.mean = A.mean(axis=axis)\\n        if verbose:\\n            print \"Center -= A.mean:\", self.mean\\n        A -= self.mean\\n        if scale:\\n            std = A.std(axis=axis)\\n            self.std = np.where( std, std, 1. )\\n            if verbose:\\n                print \"Center /= A.std:\", self.std\\n            A /= self.std\\n        else:\\n            self.std = np.ones( A.shape[-1] )\\n        self.A = A\\n\\n    def uncenter( self, x ):\\n        return np.dot( self.A, x * self.std ) + np.dot( x, self.mean )\\n\\n\\n#...............................................................................\\nif __name__ == \"__main__\":\\n    import sys\\n\\n    csv = \"iris4.csv\"  # wikipedia Iris_flower_data_set\\n        # 5.1,3.5,1.4,0.2  # ,Iris-setosa ...\\n    N = 1000\\n    K = 20\\n    fraction = .90\\n    seed = 1\\n    exec \"\\\\n\".join( sys.argv[1:] )  # N= ...\\n    np.random.seed(seed)\\n    np.set_printoptions( 1, threshold=100, suppress=True )  # .1f\\n    try:\\n        A = np.genfromtxt( csv, delimiter=\",\" )\\n        N, K = A.shape\\n    except IOError:\\n        A = np.random.normal( size=(N, K) )  # gen correlated ?\\n\\n    print \"csv: %s  N: %d  K: %d  fraction: %.2g\" % (csv, N, K, fraction)\\n    Center(A)\\n    print \"A:\", A\\n\\n    print \"PCA ...\" ,\\n    p = PCA( A, fraction=fraction )\\n    print \"npc:\", p.npc\\n    print \"% variance:\", p.sumvariance * 100\\n\\n    print \"Vt[0], weights that give PC 0:\", p.Vt[0]\\n    print \"A . Vt[0]:\", dot( A, p.Vt[0] )\\n    print \"pc:\", p.pc()\\n\\n    print \"\\\\nobs <-> pc <-> x: with fraction=1, diffs should be ~ 0\"\\n    x = np.ones(K)\\n    # x = np.ones(( 3, K ))\\n    print \"x:\", x\\n    pc = p.vars_pc(x)  # d\\' Vt\\' x\\n    print \"vars_pc(x):\", pc\\n    print \"back to ~ x:\", p.pc_vars(pc)\\n\\n    Ax = dot( A, x.T )\\n    pcx = p.obs(x)  # U\\' d\\' Vt\\' x\\n    print \"Ax:\", Ax\\n    print \"A\\'x:\", pcx\\n    print \"max |Ax - A\\'x|: %.2g\" % np.linalg.norm( Ax - pcx, np.inf )\\n\\n    b = Ax  # ~ back to original x, Ainv A x\\n    back = p.vars(b)\\n    print \"~ back again:\", back\\n    print \"max |back - x|: %.2g\" % np.linalg.norm( back - x, np.inf )\\n\\n# end pca.py\\n\\n\\n\\n'},\n {'prompt': 'In Python I\\'m accessing a binary file by reading it into a string and then using struct.unpack(...). Now I want to write to that string using struct.pack_into(...), but I get the error \"Cannot use string as modifiable buffer\". What would be a suitable buffer for use with the struct module?\\n',\n  'completion': \"If you aren't trying to pack it into a specific object, just use struct.pack to return a string.\\n\\nOtherwise, ctypes.create_string_buffer is one way to obtain a mutable buffer.\\n\"},\n {'prompt': \"I got this error:\\n\\nOperationalError at /\\n\\nunable to open database file\\n\\nThings I've tried so far are setting the absolute path of my dev.db file in the settings.py. I've tried adding www-data to my admin group and setting the group of my project folder to the admin, and setting the group to www-data, none of which solved the problem.\\n\\nI'm completely stuck here, if anyone has a solution it would be MUCH appreciated!\\n\\nShawn\\n\",\n  'completion': \"Just passed the last 30 minutes banging my head on this problem ..\\n\\nSolution\\n\\nIn your settings.py:\\n\\nDATABASE_NAME = '/absolute/path/to/your/database.db'\\n\\n\\nSetting rights:\\n\\nchown www-data /absolute/path/to/your/\\nchown www-data /absolute/path/to/your/database.db\\n\\n\"},\n {'prompt': 'How can I take the opt result of\\n\\nopt, args = parser.parse_args()\\n\\n\\nand place it in a dict?  Python calls opt a \"Values Instance\" and I can\\'t find any way to turn a Values Instance into a list or dict.   One can\\'t copy items from opt in this way,\\n\\nfor i in opt:\\n myDict[i] = opt[i]\\n\\n\\ninstead, its a clumsy,\\n\\nmyDict[parm1] = opt.parm1\\nmyDict[parm2] = opt.parm2\\n\\n\\nwhich implies that every time I add an option, I have to update this code as well; there should be a way to let this take care of itself.\\n',\n  'completion': 'options, args = parser.parse_args()\\noption_dict = vars(options)\\n\\n\\n(Source is this python-ideas post.)\\n'},\n {'prompt': 'My program has a gtk.TreeView which displays a gtk.ListStore. The gtk.ListStore contains strings like this: \\n\\n\"<span size=\\'medium\\'><b>\"+site_title+\"</b></span>\"+\"\\\\n\"+URL\\n\\n\\nWhere URL is (obviously) a URL string. Sometimes there are characters in URL that cause pango to fail to parse the markup. \\n\\nIs there a way to escape URL as a whole so that pango will just ignore it so it will be displayed literally? If not, how should I \"escape\" special characters in URLs?\\n',\n  'completion': 'glib.markup_escape_text may be a more canonical approach when using GTK.\\n'},\n {'prompt': 'i am a engineering student and i have to do a lot of numerical processing, plots, simulations etc. The tool that i use currently is Matlab. I use it in my university computers for most of my assignments. However, i want to know what are the free options available. \\n\\ni have done some research and many have said that python is a worthy replacement for matlab in various scenarios. i want to know how to do all this with python. i am using a mac so how do i install the different python packages. what are those packages? is it really a viable alternative? what are the things i can and cannot do using this python setup? \\n',\n  'completion': 'On a Mac the easiest ways to get started are (in no particular order):\\n\\n\\nEnthought Python Distribution which includes most scientific packages you are likely to need. Free for academic/non-commercial use.\\nMacports - up to date with latest releases, so sudo port install py26-numpy py26-scipy py26-matplotlib py26-ipython should get you started.\\nScipy Superpack - script to install recent svn versions of all the important packages.\\n\\n\\nI\\'ve done exactly this (replace Matlab with Python) about 2 years ago and haven\\'t looked back. The broadcasting in Python, more intuitive memory model and other Numpy advantages make numerical work a complete pleasure. Plus with f2py, cython it is incredibly easy to put inner loops in another language. This is a good place to start - other impressive pages to provide motiviation are PerformancePython and ParallelProgramming. Be sure to understand Pythons \"variable is a reference to an object\" semantics... after that adjustment everything is plain sailing. One of the coolest things that beats matlab is in 2 lines I run over 8 cores... p = Pool(8); res = p.map(analysis_function,list_of_data) - MATLAB parallels toolboxes are so expensive I\\'ve yet to see a University that actually has them.\\n'},\n {'prompt': 'I maintain an open source python project. Right now it supports python 2.4, 2.5, 2.6. I am looking for to add support for python 3. I guess it will be easier if I drop 2.4 support.\\n\\nI know it is possible to support all but it is very annoying if I have to install 4 or 5 python versions on my machine and run the tests on all of them. Although it is easy to avoid new features introduced in the language I would like to make use of them! And what is the point of supporting something that possible nobody uses? I do want to drop it, but also dont want to loose users (existing and new).\\n\\nWhen should I drop support for python 2.4? Is there any recommendation on this?\\n',\n  'completion': \"I'd say it depends on your target audience. For enterprise stuff I think RedHat (certainly CentOS 5) are still on 2.4 - so if you want typical RedHat/CentOS using people to able to install without resorting to third party python installations then I think you need to keep 2.4 for a while. If most of your users are more 'desktop' based running Fedora/Ubuntu then they probably have 2.5/2.6 already so it wouldn't be an issue for them.\\n\"},\n {'prompt': \"I have the following code:\\n\\nprint img.size\\nprint 10 * img.size\\n\\n\\nthis will print\\n\\n(70, 70)\\n(70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70)\\n\\n\\nwhile I'd like it to print\\n\\n(700, 700)\\n\\n\\nIs any way there to do this without having to write\\n\\nprint (10 * img.size[0], 10 * img.size[1])\\n\\n\\nPS: img.size is a PIL image. Dunno if that matters anything in this case.\\n\",\n  'completion': 'Might be a nicer way, but this should work\\n\\ntuple([10*x for x in img.size])\\n\\n'},\n {'prompt': \"I want to distribute a Python application to windows users who don't have Python or the correct Python version.\\n\\nI have tried py2exe conversion but my Python program is really complex and involve code import on the fly by xmlrpc process so it is not suitable for py2exe.\\n\\nThe complete Python folder takes around 80MB but this includes docs and a lot of non-essential things. \\n\\nDo you know if there exists a small package of a minimal Python interpreter I can include with my program ? Include a folder of 80MB is a bit big ;)\\n\",\n  'completion': 'PyInstaller is a py2exe \"competitor\" that has many extras (such as being cross-platform, supporting popular third party packages \"out of the box\", and explicitly supporting advanced importing options) -- it might meet your needs.  Just be sure to install the SVN trunk -- the existing (1.3) release is way, WAY obsolete (PyInstaller is under active development again since quite a while, but I can\\'t convince the current maintainers to stop and do a RELEASE already -- they\\'re kind of perfectionists and keep piling more and more great goodies, optimizations, enhancements, etc, into the SVN trunk instead;-).\\n'},\n {'prompt': \"When do I use each ?\\n\\nAlso...is the NLTK lemmatization dependent upon Parts of Speech?\\nWouldn't it be more accurate if it was?\\n\",\n  'completion': 'Short and dense: http://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\\n\\n\\n  The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.\\n  \\n  However, the two words differ in their flavor. Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma .\\n\\n\\nFrom the NLTK docs:\\n\\n\\n  Lemmatization and stemming are special cases of normalization. They identify a canonical representative for a set of related word forms.\\n\\n'},\n {'prompt': 'I have a list of booleans in python. I want to AND (or OR or NOT) them and get the result. The following code works but is not very pythonic.\\n\\ndef apply_and(alist):\\n if len(alist) > 1:\\n     return alist[0] and apply_and(alist[1:])\\n else:\\n     return alist[0]\\n\\n\\nAny suggestions on how to make it more pythonic appreciated.\\n',\n  'completion': \"Logical and across all elements in a_list:\\n\\nall(a_list)\\n\\n\\nLogical or across all elements in a_list:\\n\\nany(a_list)\\n\\n\\n\\n\\nIf you feel creative, you can also do:\\n\\nimport operator\\ndef my_all(a_list):\\n  return reduce(operator.and_, a_list, True)\\n\\ndef my_any(a_list):\\n  return reduce(operator.or_, a_list, False)\\n\\n\\nkeep in mind that those aren't evaluated in short circuit, whilst the built-ins are ;-)\\n\\nanother funny way:\\n\\ndef my_all_v2(a_list):\\n  return len(filter(None,a_list)) == len(a_list)\\n\\ndef my_any_v2(a_list):\\n  return len(filter(None,a_list)) > 0\\n\\n\\nand yet another:\\n\\ndef my_all_v3(a_list):\\n  for i in a_list:\\n    if not i:\\n      return False\\n  return True\\n\\ndef my_any_v3(a_list):\\n  for i in a_list:\\n    if i:\\n      return True\\n  return False\\n\\n\\nand we could go on all day, but yes, the pythonic way is to use all and any :-)\\n\\nBy the way, Python has not tail recursion elimination, so don't try to translate LISP code directly ;-)\\n\"},\n {'prompt': \"Is there a pythonic way to build up a list that contains a running average of some function?\\n\\nAfter reading a fun little piece about Martians, black boxes, and the Cauchy distribution, I thought it would be fun to calculate a running average of the Cauchy distribution myself:\\n\\nimport math \\nimport random\\n\\ndef cauchy(location, scale):\\n    p = 0.0\\n    while p == 0.0:\\n        p = random.random()\\n    return location + scale*math.tan(math.pi*(p - 0.5))\\n\\n# is this next block of code a good way to populate running_avg?\\nsum = 0\\ncount = 0\\nmax = 10\\nrunning_avg = []\\nwhile count < max:\\n    num = cauchy(3,1)\\n    sum += num\\n    count += 1\\n    running_avg.append(sum/count)\\n\\nprint running_avg     # or do something else with it, besides printing\\n\\n\\nI think that this approach works, but I'm curious if there might be a more elegant approach to building up that running_avg list than using loops and counters (e.g. list comprehensions).\\n\\nThere are some related questions, but they address more complicated problems (small window size, exponential weighting) or aren't specific to Python:\\n\\n\\nhttp://stackoverflow.com/questions/488670/calculate-exponential-moving-average-in-python\\nhttp://stackoverflow.com/questions/1174984/how-to-efficiently-calculate-a-running-standard-deviation\\nhttp://stackoverflow.com/questions/1319891/calculating-the-moving-average-of-a-list\\n\\n\",\n  'completion': 'You could write a generator:\\n\\ndef running_average():\\n  sum = 0\\n  count = 0\\n  while True:\\n    sum += cauchy(3,1)\\n    count += 1\\n    yield sum/count\\n\\n\\nOr, given a generator for Cauchy numbers and a utility function for a running sum generator, you can have a neat generator expression:\\n\\n# Cauchy numbers generator\\ndef cauchy_numbers():\\n  while True:\\n    yield cauchy(3,1)\\n\\n# running sum utility function\\ndef running_sum(iterable):\\n  sum = 0\\n  for x in iterable:\\n    sum += x\\n    yield sum\\n\\n# Running averages generator expression (** the neat part **)\\nrunning_avgs = (sum/(i+1) for (i,sum) in enumerate(running_sum(cauchy_numbers())))\\n\\n# goes on forever\\nfor avg in running_avgs:\\n  print avg\\n\\n# alternatively, take just the first 10\\nimport itertools\\nfor avg in itertools.islice(running_avgs, 10):\\n  print avg\\n\\n'},\n {'prompt': \"I spent a few days reading about C++ and Python and I found that Python is so much simpler and easy to learn. \\n\\nSo I wonder does it really worth spending time learning it? Or should I invest that time learning C++ instead?\\n\\nWhat can C++ do and Python can't ?\\n\",\n  'completion': 'Some Python limits :\\n\\n- Python is slow. It can be improved in many ways (see other answers) but the bare bone cPython is 100 times slower that C/C++. \\n\\nThis problem is getter more and more mitigated. With Numpy, Pypy and asyncio, most performance problems are not covered, and only very specific use cases are a bottleneck in Python anymore.\\n\\n- Python is opened to anything. It\\'s really hard to protect / obfuscate / limit Python code. \\n\\n- Python is not hype. Unlike Ruby, there is no \"cool wave\" around Python, and it\\'s still much harder to find a experienced Python coder, than, let\\'s say, a Java or a PHP pro.\\n\\n- After using Python, a lot of languages seems to be a pain to use. You\\'d think it\\'s good, but believe me, not always. When you have to go Javascript after a Python project, your eyes are in tears for at least 3 days. Really hard to get started.\\n\\n- It\\'s harder to find web hosting than for popular solutions, such as PHP.\\n\\n- As a dynamic language, you don\\'t have the very handy refactoring tools you could get with Java and Eclipse or C# and VS. \\n\\n- For the same reason, you can\\'t rely on type checking as a safety net. This is why pythonistas tend to follow best practice and write unit tests more often than others. \\n\\n- It seems I just can\\'t find an IDE with a decent code completion. PyDev, Gedit, Komodo, SPE, etc. just don\\'t do it as good as it could be.\\n\\nWith Python 3 types hints and tools like PyCharm or Sublime Text+Anaconda, the situation has changed a lot.\\n\\n- The best docs are still in English only. Some people don\\'t deal well with it.\\n\\n- You have to get use to the syntax. Not only you get spaces and line breaks instead of bracets, but you can forget about long lambdas, --i, and ternary operation.\\n\\nNow, to me, these are not reasons to not learn a tool that will make you produce more while having more fun. But maybe it\\'s just me :-)\\n\\nHonestly, given that :\\n\\n\\nC++ much harder to learn;\\nYou can do pretty much any thing you want with Python;\\nYou will get quicker result with Python in your projects.\\n\\n\\nUnless you have professional issues involving C++, you\\'d better learn Python first, it\\'s more motivating. You still can learn C++ later, it\\'s a useful language for system programming, embedded devices and such.\\n\\nDon\\'t try to learn both at the same times, multitasking rarely ends well.\\n'},\n {'prompt': 'How can I tell NLTK to treat the text in a particular language?\\n\\nOnce in a while I write a specialized NLP routine to do POS tagging, tokenizing and etc. on a non-english (but still hindo-European) text domain.\\n\\nThis question seem to address only different corpora, not the change in code/settings:\\nNLTK tagging in German\\n\\nAlternatively,are there any specialized Hebrew/Spanish/Polish NLP modules for python?\\n',\n  'completion': 'I\\'m not sure what you\\'re referring to as the changes in code/settings. NLTK mostly relies on machine learning and the \"settings\" are usually extracted from the training data.\\n\\nWhen it comes to POS tagging the results and tagging will be dependant on the tagger you use/train. Should you train your own you\\'ll of course need some spanish / polish training data. The reason these might be hard to find is the lack of gold standard material publicly available. There are tools out there to do that do this, but this one isn\\'t for python (http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/). \\n\\nThe nltk.tokenize.punkt.PunktSentenceTokenizer tokenizer will tokenize sentences according to multilingual sentence boundaries the details of which can be found in this paper (http://www.mitpressjournals.org/doi/abs/10.1162/coli.2006.32.4.485).\\n'},\n {'prompt': \"I've seen plenty of examples of people extracting all of the classes from a module, usually something like:\\n\\n# foo.py\\nclass Foo:\\n    pass\\n\\n# test.py\\nimport inspect\\nimport foo\\n\\nfor name, obj in inspect.getmembers(foo):\\n    if inspect.isclass(obj):\\n        print obj\\n\\n\\nAwesome.\\n\\nBut I can't find out how to get all of the classes from the current module.\\n\\n# foo.py\\nimport inspect\\n\\nclass Foo:\\n    pass\\n\\ndef print_classes():\\n    for name, obj in inspect.getmembers(???): # what do I do here?\\n        if inspect.isclass(obj):\\n            print obj\\n\\n# test.py\\nimport foo\\n\\nfoo.print_classes()\\n\\n\\nThis is probably something really obvious, but I haven't been able to find anything. Can anyone help me out?\\n\",\n  'completion': 'Try this:\\n\\nimport sys\\ncurrent_module = sys.modules[__name__]\\n\\n\\nIn your context:\\n\\nimport sys, inspect\\ndef print_classes():\\n    for name, obj in inspect.getmembers(sys.modules[__name__]):\\n        if inspect.isclass(obj):\\n            print(obj)\\n\\n\\nAnd even better:\\n\\nclsmembers = inspect.getmembers(sys.modules[__name__], inspect.isclass)\\n\\n\\nBecause inspect.getmembers() takes a predicate.\\n'},\n {'prompt': \"I'm having some trouble figuring out the proper way to walk a Python traceback using the C API.  I'm writing an application that embeds the Python interpreter.  I want to be able to execute arbitrary Python code, and if it raises an exception, to translate it to my own application-specific C++ exception.  For now, it is sufficient to extract just the file name and line number where the Python exception was raised.  This is what I have so far:\\n\\nPyObject* pyresult = PyObject_CallObject(someCallablePythonObject, someArgs);\\nif (!pyresult)\\n{\\n    PyObject* excType, *excValue, *excTraceback;\\n    PyErr_Fetch(&excType, &excValue, &excTraceback);\\n    PyErr_NormalizeException(&excType, &excValue, &excTraceback);\\n\\n    PyTracebackObject* traceback = (PyTracebackObject*)traceback;\\n    // Advance to the last frame (python puts the most-recent call at the end)\\n    while (traceback->tb_next != NULL)\\n        traceback = traceback->tb_next;\\n\\n    // At this point I have access to the line number via traceback->tb_lineno,\\n    // but where do I get the file name from?\\n\\n    // ...       \\n}\\n\\n\\nDigging around in the Python source code, I see they access both the filename and module name of the current frame via the _frame structure, which looks like it is a privately-defined struct.  My next idea was to programmatically load the Python 'traceback' module and call its functions with the C API.  Is this sane? Is there a better way to access a Python traceback from C?\\n\",\n  'completion': \"I've discovered that _frame is actually defined in the frameobject.h header included with Python.  Armed with this plus looking at traceback.c in the Python C implementation, we have:\\n\\n#include <Python.h>\\n#include <frameobject.h>\\n\\nPyTracebackObject* traceback = get_the_traceback();\\n\\nint line = traceback->tb_lineno;\\nconst char* filename = PyString_AsString(traceback->tb_frame->f_code->co_filename);\\n\\n\\nBut this still seems really dirty to me.\\n\"},\n {'prompt': \"It seems that Python has some limitations regarding instance methods.\\n\\n\\nInstance methods can't be copied.\\nInstance methods can't be pickled.\\n\\n\\nThis is problematic for me, because I work on a very object-oriented project in which I reference instance methods, and there's use of both deepcopying and pickling. The pickling thing is done mostly by the multiprocessing mechanism.\\n\\nWhat would be a good way to solve this? I did some ugly workaround to the copying issue, but \\nI'm looking for a nicer solution to both problems.\\n\\nDoes anyone have any suggestions?\\n\\nUpdate:\\n\\nMy use case:  I have a tiny event system. Each event has an .action attribute that points to a function it's supposed to trigger, and sometimes that function is an instance method of some object.\\n\",\n  'completion': 'You might be able to do this using copy_reg.pickle. In Python 2.6:\\n\\nimport copy_reg\\nimport types\\n\\ndef reduce_method(m):\\n    return (getattr, (m.__self__, m.__func__.__name__))\\n\\ncopy_reg.pickle(types.MethodType, reduce_method)\\n\\n\\nThis does not store the code of the method, just its name; but that will work correctly in the common case.\\n\\nThis makes both pickling and copying work!\\n'},\n {'prompt': \"I have to deal with a large result set (could be hundreds thousands of rows, sometimes more).\\nThey unfortunately need to be retrieved all at once (on start up). \\n\\nI'm trying to do that by using as less memory as possible.\\nBy looking on SO I've found that using SSCursor might be what I'm looking for, but I still don't really know how to exactly use them.\\n\\nIs doing a fetchall() from a base cursor or a SScursor the same (in term of memory usage)?\\nCan I 'stream' from the sscursor my rows one by one (or a few by a few) and if yes,\\nwhat is the best way to do so?\\n\",\n  'completion': 'I am in agreement with Otto Allmendinger\\'s answer, but to make explicit Denis Otkidach\\'s comment, here is how you can iterate over the results without using Otto\\'s fetch() function:\\n\\nimport MySQLdb.cursors\\nconnection=MySQLdb.connect(\\n    host=\"thehost\",user=\"theuser\",\\n    passwd=\"thepassword\",db=\"thedb\",\\n    cursorclass = MySQLdb.cursors.SSCursor)\\ncursor=connection.cursor()\\ncursor.execute(query)\\nfor row in cursor:\\n    print(row)\\n\\n'},\n {'prompt': \"I'm using the os.path.split() function on a path in my program to get the filename and pathname of a file then passing them into another method, but my current solution seems rather ugly:\\n\\npath = os.path.split(somefile)\\nsome_class(path[0], path[1])\\n\\n\\nIs it possible to unpack the path tuple in a cleaner way within the call to some_class? Something like:\\n\\nsome_class(os.path.split(somefile).unpack())\\n\\n\\nOr should I simply be going about this another way? Maybe a more pythonic way?\\n\",\n  'completion': 'Yes, Python has argument list unpacking. Try this:\\n\\nsome_class(*os.path.split(somefile))\\n\\n'},\n {'prompt': 'What is the simplest way to convert a string of keyword=values to a dictionary, for example the following string:\\n\\nname=\"John Smith\", age=34, height=173.2, location=\"US\", avatar=\":,=)\"\\n\\n\\nto the following python dictionary:\\n\\n{\\'name\\':\\'John Smith\\', \\'age\\':34, \\'height\\':173.2, \\'location\\':\\'US\\', \\'avatar\\':\\':,=)\\'}\\n\\n\\nThe \\'avatar\\' key is just to show that the strings can contain = and , so a simple \\'split\\' won\\'t do. Any ideas? Thanks!\\n',\n  'completion': 'This works for me:\\n\\n# get all the items\\nmatches = re.findall(r\\'\\\\w+=\".+?\"\\', s) + re.findall(r\\'\\\\w+=[\\\\d.]+\\',s)\\n\\n# partition each match at \\'=\\'\\nmatches = [m.group().split(\\'=\\', 1) for m in matches]\\n\\n# use results to make a dict\\nd = dict(matches)\\n\\n'},\n {'prompt': 'In answer to a previous question, several people suggested that I use BeautifulSoup for my project. I\\'ve been struggling with their documentation and I just cannot parse it. Can somebody point me to the section where I should be able to translate this expression to a BeautifulSoup expression?\\n\\nhxs.select(\\'//td[@class=\"altRow\"][2]/a/@href\\').re(\\'/.a\\\\w+\\')\\n\\n\\nThe above expression is from Scrapy. I\\'m trying to apply the regex re(\\'\\\\.a\\\\w+\\') to td class altRow to get the links from there.\\n\\nI would also appreciate pointers to any other tutorials or documentation. I couldn\\'t find any.\\n\\nThanks for your help.\\n\\nEdit:\\nI am looking at this page:\\n\\n>>> soup.head.title\\n<title>White & Case LLP - Lawyers</title>\\n>>> soup.find(href=re.compile(\"/cabel\"))\\n>>> soup.find(href=re.compile(\"/diversity\"))\\n<a href=\"/diversity/committee\">Committee</a>\\n\\n\\nYet, if you look at the page source \"/cabel\" is there:\\n\\n <td class=\"altRow\" valign=\"middle\" width=\"34%\"> \\n <a href=\\'/cabel\\'>Abel, Christian</a>\\n\\n\\nFor some reason, search results are not visible to BeautifulSoup, but they are visible to XPath because hxs.select(\\'//td[@class=\"altRow\"][2]/a/@href\\').re(\\'/.a\\\\w+\\') catches \"/cabel\"\\n\\nEdit:\\ncobbal: It is still not working. But when I search this:\\n\\n>>>soup.findAll(href=re.compile(r\\'/.a\\\\w+\\'))\\n[<link href=\"/FCWSite/Include/styles/main.css\" rel=\"stylesheet\" type=\"text/css\" />, <link rel=\"shortcut icon\" type=\"image/ico\" href=\"/FCWSite/Include/main_favicon.ico\" />, <a href=\"/careers/northamerica\">North America</a>, <a href=\"/careers/middleeastafrica\">Middle East Africa</a>, <a href=\"/careers/europe\">Europe</a>, <a href=\"/careers/latinamerica\">Latin America</a>, <a href=\"/careers/asia\">Asia</a>, <a href=\"/diversity/manager\">Diversity Director</a>]\\n>>>\\n\\n\\nit returns all the links with second character \"a\" but not the lawyer names. So for some reason those links (such as \"/cabel\") are not visible to BeautifulSoup. I don\\'t understand why.\\n',\n  'completion': \"one option is to use lxml (I'm not familiar with beautifulsoup, so I can't say how to do with it), it defaultly supports XPath\\n\\nEdit:\\ntry (untested) tested:\\n\\nsoup.findAll('td', 'altRow')[1].findAll('a', href=re.compile(r'/.a\\\\w+'), recursive=False)\\n\\n\\nI used docs at http://www.crummy.com/software/BeautifulSoup/documentation.html\\n\\nsoup should be a BeautifulSoup object\\n\\nimport BeautifulSoup\\nsoup = BeautifulSoup.BeautifulSoup(html_string)\\n\\n\"},\n {'prompt': 'Am working on a command line python script - throughout the script, I have a lot of information I am print-ing to the terminal window so that I may follow along with what is happening.\\n\\nUsing OptionParser I want to add a --quiet option so I can silence all the output.  I am looking for a pythonic way to go about implementing this throughout the script so that I don\\'t end up doing something like:\\n\\nif not QUIET: # global variable set by OptionParser\\n    print \" my output \"\\n\\n\\nAm new to python and sure there is a better way.  Ideas?  \\n',\n  'completion': 'You could use logging and assign those things that should not be printed if QUIET a different log level.\\n\\nEdit: THC4K\\'s answer shows an example of how to do this, assuming that all output should be silent if QUIET is set. Note that in Python 3 from __future__ import print_function is not necessary:\\n\\nprint = logging.info\\nlogging.basicConfig(level=logging.WARNING if QUIET else logging.INFO,\\n                    format=\"%(message)s\")\\n\\n\\nFor for important output that should not be silenced by --quiet, define e.g. iprint:\\n\\niprint = logging.warning\\n\\n'},\n {'prompt': 'This code opens the url and appends the /names at the end and opens the page and prints the string to test1.csv:\\n\\nimport urllib2\\nimport re\\nimport csv\\n\\nurl = (\"http://www.example.com\")\\nbios = [u\\'/name1\\', u\\'/name2\\', u\\'/name3\\']\\ncsvwriter = csv.writer(open(\"/test1.csv\", \"a\"))\\n\\nfor l in bios:\\n    OpenThisLink = url + l\\n    response = urllib2.urlopen(OpenThisLink)\\n    html = response.read()\\n    item = re.search(\\'(JD)(.*?)(\\\\d+)\\', html)\\n    if item:\\n        JD = item.group()\\n        csvwriter.writerow(JD)\\n    else:\\n        NoJD = \"NoJD\"\\n        csvwriter.writerow(NoJD)\\n\\n\\nBut I get this result:\\n\\nJ,D,\",\", ,C,o,l,u,m,b,i,a, ,L,a,w, ,S,c,h,o,o,l,....\\n\\nIf I change the string to (\"JD\", \"Columbia Law School\" ....) then I get \\n\\nJD, Columbia Law School...)\\n\\nI couldn\\'t find in the documentation how to specify the delimeter. \\n\\nIf I try to use delimenter I get this error:\\n\\nTypeError: \\'delimeter\\' is an invalid keyword argument for this function\\n\\n\\nThanks for the help.\\n',\n  'completion': \"It expects a sequence (eg: a list or tuple) of strings. You're giving it a single string. A string happens to be a sequence of strings too, but it's a sequence of 1 character strings, which isn't what you want.\\n\\nIf you just want one string per row you could do something like this:\\n\\ncsvwriter.writerow([JD])\\n\\n\\nThis wraps JD (a string) with a list.\\n\"},\n {'prompt': \"I have a WSGI application that generates invoices and stores them as PDF.\\n\\nSo far I have solved similar problems with FPDF (or equivalents), generating the PDF from scratch like a GUI. Sadly this means the entire formatting logic (positioning headers, footers and content, styling) is in the application, where it really shouldn't be.\\n\\nAs the templates already exist in Office formats (ODT, DOC, DOCX), I would prefer to simply use those as a basis and fill in the actual content. I've found the Appy framework, which does pretty much that with annotated ODT files.\\n\\nThat still leaves the bigger problem open, tho: converting ODT (or DOC, or DOCX) to PDF. On a server. Running Linux. Without GUI libraries. And thus, without OO.o or MS Office.\\n\\nIs this at all possible or am I better off keeping the styling in my code?\\n\\nThe actual content that would be filled in is actually quite restricted: a few paragraphs, some of which may be optional, a headline or two, always at the same place, and a few rows of a table. In HTML this would be trivial.\\n\\nEDIT: Basically, I want a library that can generate ODT files from ODF files acting as templates and a library that can convert the result into PDF (which is probably the crux).\\n\",\n  'completion': \"I don't know how to go about automatic ODT -> PDF conversion, but a simpler route might be to generate your invoices as HTML and convert them to PDF using http://www.xhtml2pdf.com/.  I haven't tried the library myself, but it definitely seems promising.\\n\"},\n {'prompt': 'In Smalltalk there is a message DoesNotUnderstand that is called when an object does not understand a message (this is, when the object does not have the message sent implemented). \\n\\nSo, I like to know if in python there is a function that does the same thing.\\n\\nIn this example:\\n\\nclass MyObject:\\n    def __init__(self):\\n        print \"MyObject created\"\\n\\nanObject = MyObject() # prints: MyObject created\\nanObject.DoSomething() # raise an Exception\\n\\n\\nSo, can I add a method to MyObject so I can know when DoSomething is intented to be called?\\n\\nPS: Sorry for my poor English.\\n',\n  'completion': 'Here is a proposition for what you want to do:\\n\\nclass callee:\\n    def __init__(self, name):\\n        self.name = name\\n\\n    def __call__(self):\\n        print self.name, \"has been called\"\\n\\n\\nclass A:\\n    def __getattr__(self, attr):\\n        return callee(attr)\\n\\na = A()\\n\\na.DoSomething()\\n>>> DoSomething has been called\\n\\n'},\n {'prompt': 'I run across a lot of \"embarrassingly parallel\" projects I\\'d like to parallelize with the multiprocessing module. However, they often involve reading in huge files (greater than 2gb), processing them line by line, running basic calculations, and then writing results. What\\'s the best way to split a file and process it using Python\\'s multiprocessing module? Should Queue or JoinableQueue in multiprocessing be used? Or the Queue module itself? Or, should I map the file iterable over a pool of processes using multiprocessing? I\\'ve experimented with these approaches but the overhead is immense in distribution the data line by line. I\\'ve settled on a lightweight pipe-filters design by using cat file | process1 --out-file out1 --num-processes 2 | process2 --out-file out2, which passes a certain percentage of the first process\\'s input directly to the second input (see this post), but I\\'d like to have a solution contained entirely in Python. \\n\\nSurprisingly, the Python documentation doesn\\'t suggest a canonical way of doing this (despite a lengthy section on programming guidelines in the multiprocessing documentation).\\n\\nThanks,\\nVince\\n\\nAdditional information: Processing time per line varies. Some problems are fast and barely not I/O bound, some are CPU-bound. The CPU bound, non-dependent tasks will gain the post from parallelization, such that even inefficient ways of assigning data to a processing function would still be beneficial in terms of wall clock time.\\n\\nA prime example is a script that extracts fields from lines, checks for a variety of bitwise flags, and writes lines with certain flags to a new file in an entirely new format. This seems like an I/O bound problem, but when I ran it with my cheap concurrent version with pipes, it was about 20% faster. When I run it with pool and map, or queue in multiprocessing it is always over 100% slower. \\n',\n  'completion': 'One of the best architectures is already part of Linux OS\\'s.  No special libraries required.\\n\\nYou want a \"fan-out\" design.\\n\\n\\nA \"main\" program creates a number of subprocesses connected by pipes.\\nThe main program reads the file, writing lines to the pipes doing the minimum filtering required to deal the lines to appropriate subprocesses.\\n\\n\\nEach subprocess should probably be a pipeline of distinct processes that read and write from stdin.\\n\\nYou don\\'t need a queue data structure, that\\'s exactly what an in-memory pipeline is -- a queue of bytes between two concurrent processes.\\n'},\n {'prompt': 'As part of a program I\\'m writing, I need to solve a cubic equation exactly (rather than using a numerical root finder):\\n\\na*x**3 + b*x**2 + c*x + d = 0.\\n\\n\\nI\\'m trying to use the equations from here. However, consider the following code (this is Python but it\\'s pretty generic code):\\n\\na =  1.0\\nb =  0.0\\nc =  0.2 - 1.0\\nd = -0.7 * 0.2\\n\\nq = (3*a*c - b**2) / (9 * a**2)\\nr = (9*a*b*c - 27*a**2*d - 2*b**3) / (54*a**3)\\n\\nprint \"q = \",q\\nprint \"r = \",r\\n\\ndelta = q**3 + r**2\\n\\nprint \"delta = \",delta\\n\\n# here delta is less than zero so we use the second set of equations from the article:\\n\\nrho = (-q**3)**0.5\\n\\n# For x1 the imaginary part is unimportant since it cancels out\\ns_real = rho**(1./3.)\\nt_real = rho**(1./3.)\\n\\nprint \"s [real] = \",s_real\\nprint \"t [real] = \",t_real\\n\\nx1 = s_real + t_real - b / (3. * a)\\n\\nprint \"x1 = \", x1\\n\\nprint \"should be zero: \",a*x1**3+b*x1**2+c*x1+d\\n\\n\\nBut the output is:\\n\\nq =  -0.266666666667\\nr =  0.07\\ndelta =  -0.014062962963\\ns [real] =  0.516397779494\\nt [real] =  0.516397779494\\nx1 =  1.03279555899\\nshould be zero:  0.135412149064\\n\\n\\nso the output is not zero, and so x1 isn\\'t actually a solution. Is there a mistake in the Wikipedia article?\\n\\nps: I know that numpy.roots will solve this kind of equation but I need to do this for millions of equations and so I need to implement this to work on arrays of coefficients.\\n',\n  'completion': \"Wikipedia's notation (rho^(1/3), theta/3) does not mean that rho^(1/3) is the real part and theta/3 is the imaginary part.  Rather, this is in polar coordinates.  Thus, if you want the real part, you would take rho^(1/3) * cos(theta/3).\\n\\nI made these changes to your code and it worked for me:\\n\\ntheta = arccos(r/rho)\\ns_real = rho**(1./3.) * cos( theta/3)\\nt_real = rho**(1./3.) * cos(-theta/3)\\n\\n\\n(Of course, s_real = t_real here because cos is even.)\\n\"},\n {'prompt': 'How do I compare times in python?\\n\\nI see that date comparisons can be done and there\\'s also \"timedelta\", but I\\'m struggling to find out how to check if the current time (from datetime.now()) is earlier, the same, or later than a specified time (e.g. 8am) regardless of the date.\\n',\n  'completion': 'You can\\'t compare a specific point in time (such as \"right now\") against an unfixed, recurring event (8am happens every day).\\n\\nYou can check if now is before or after today\\'s 8am:\\n\\n>>> import datetime\\n>>> now = datetime.datetime.now()\\n>>> today8am = now.replace(hour=8, minute=0, second=0, microsecond=0)\\n>>> now < today8am\\nTrue\\n>>> now == today8am\\nFalse\\n>>> now > today8am\\nFalse\\n\\n'},\n {'prompt': 'I am using the following class to easily store data of my songs.\\n\\nclass Song:\\n    \"\"\"The class to store the details of each song\"\"\"\\n    attsToStore=(\\'Name\\', \\'Artist\\', \\'Album\\', \\'Genre\\', \\'Location\\')\\n    def __init__(self):\\n        for att in self.attsToStore:\\n            exec \\'self.%s=None\\'%(att.lower()) in locals()\\n    def setDetail(self, key, val):\\n        if key in self.attsToStore:\\n            exec \\'self.%s=val\\'%(key.lower()) in locals()\\n\\n\\nI feel that this is just much more extensible than writing out an if/else block. However, eval seems to be considered a bad practice and unsafe to use. If so, can anyone explain to me why and show me a better way of defining the above class?\\n',\n  'completion': 'Yes, using eval is a bad practice. Just to name a few reasons:\\n\\n\\nThere is almost always a better way to do it\\nVery dangerous and insecure\\nMakes debugging difficult\\nSlow\\n\\n\\nIn your case you can use setattr instead:\\n\\nclass Song:\\n    \"\"\"The class to store the details of each song\"\"\"\\n    attsToStore=(\\'Name\\', \\'Artist\\', \\'Album\\', \\'Genre\\', \\'Location\\')\\n    def __init__(self):\\n        for att in self.attsToStore:\\n            setattr(self, att.lower(), None)\\n    def setDetail(self, key, val):\\n        if key in self.attsToStore:\\n            setattr(self, key.lower(), val)\\n\\n\\nEDIT:\\n\\nThere are some cases where you have to use eval or exec. But they are rare. Using eval in your case is a bad practice for sure. I\\'m emphasizing on bad practice because eval and exec are frequently used in the wrong place.\\n\\nEDIT 2:\\n\\nIt looks like some disagree that eval is \\'very dangerous and insecure\\' in the OP case. That might be true for this specific case but not in general. The question was general and the reasons I listed are true for the general case as well.\\n\\nEDIT 3:\\nReordered point 1 and 4\\n'},\n {'prompt': 'What are the advantages of Python, PowerShell, and other scripting environments?  We would like to standardize our scripting and are currently using bat and cmd files as the standard.  I think Python would be a better option than these, but am also researching PowerShell and other scripting tools.\\n\\nThe scripts would be used to trigger processes such as wget etc to call web services, or other applications/tools that need to run in a specific order with specific parameters.\\n\\nWe primarily work with the Windows stack, but there is a good chance we will need to support Unix in the future.\\n\\nThanks.\\n',\n  'completion': \"Python works as a great, all-purpose tool if you're looking to replace CMD and BAT scripts on your Windows boxes, and can also be written to run scripts on your (L)inux boxes, too. It's a great, flexible language and can handle many tasks you throw at it.\\n\\nThat being said, Powershell is an amazingly versatile tool for administering all manner of Windows boxes; it has all the power of .NET, with many more interfaces into MS products such as Exchange and Active Directory, which are a timesaver. Depending on your situation, you may get more use of of PS than other scripting languages just because of the interfaces available to MS products, and I know MS seems to have made a commitment to providing those APIs in a lot of products. Powershell comes installed on all current versions of Windows (Windows 7+, Windows Server 2008+), and is fairly easily installed on older versions.\\n\\nTo address your edit that your scripts will be used to launch other processes, I think in that case either of the tools fit the bill. I would recommend PS if you plan on adding any admin-ish tasks to the scripts rather than just service calls, but if you stick to what you described, Python is good.\\n\"},\n {'prompt': 'In Python 3.x, a string consists of items of Unicode ordinal. (See the quotation from the language reference below.) What is the internal representation of Unicode string? Is it UTF-16?\\n\\n\\n  The items of a string object are\\n  Unicode code units. A Unicode code\\n  unit is represented by a string object\\n  of one item and can hold either a\\n  16-bit or 32-bit value representing a\\n  Unicode ordinal (the maximum value for\\n  the ordinal is given in\\n  sys.maxunicode, and depends on how\\n  Python is configured at compile time).\\n  Surrogate pairs may be present in the\\n  Unicode object, and will be reported\\n  as two separate items.\\n\\n',\n  'completion': 'The internal representation will change in Python 3.3 which implements PEP 393. The new representation will pick one or several of ascii, latin-1, utf-8, utf-16, utf-32, generally trying to get a compact representation.\\n\\nImplicit conversions into surrogate pairs will only be done when talking to legacy APIs (those only exist on windows, where wchar_t is two bytes); the Python string will be preserved. Here are the release notes.\\n'},\n {'prompt': \"So this thread is definitely NOT a thread for why Python is better than Ruby or the inverse. Instead, this thread is for objective criticism on why you would pick one over the other to write a RESTful web API that's going to be used by many different clients, (mobile, web browsers, tablets etc).\\n\\nAgain, don't compare Ruby on Rails vs Django. This isn't a web app that's dependent on high level frameworks such as RoR or Django. I'd just like to hear why someone might choose one over the other to write a RESTful web API that they had to start tomorrow, completely from scratch and reasons they might go from one to another.\\n\\nFor me, syntax and language features are completely superfluous. The both offer an abundant amount of features and certainly both can achieve the same exact end goals. I think if someone flips a coin, it's a good enough reason to use one over the other. I'd just love to see what some of you web service experts who are very passionate about their work respond to why they would use one over the other in a very objective format.\\n\",\n  'completion': \"I know Ruby, don't know python... you can see which way I'm leaning toward, right?\\n\"},\n {'prompt': \"Is there a Lua equivalent for python's shlex library?\\n\",\n  'completion': 'See also LPeg.\\n'},\n {'prompt': 'I have a Java class library (3rd party, proprietary) and I want my python script to call its functions. I already have java code that uses this library. What is the best way to achieve this?\\n',\n  'completion': \"Can you run your current Python scripts under Jython ? If so, that's probably the best way, since the Java library can be exposed directly into Jython as scriptable objects.\\n\\nFailing that, there are a number of solutions listed here.\\n\"},\n {'prompt': 'I need a list with the following behavior\\n\\n>>> l = SparseList()\\n>>> l\\n[]\\n>>> l[2] = \"hello\"\\n>>> l\\n[ None, None, \"hello\"]\\n>>> l[5]\\nNone\\n>>> l[4] = 22\\n>>> l\\n[ None, None, \"hello\", None, 22]\\n>>> len(l)\\n5\\n>>> for i in l: print i\\nNone\\nNone\\n\"hello\"\\nNone\\n22\\n\\n\\nAlthough it can \"emulated\" via a dictionary, it\\'s not exactly the same. numpy array can behave this way, but I don\\'t want to import the whole numpy for something like this. Before coding it myself, I ask if something similar exists in the standard library.\\n',\n  'completion': 'Here\\'s minimal code to pass your given examples (with indispensable adjustments: you expect weird spacing and quoting, \\'None\\' to be printed out at the prompt without a print statement, etc etc):\\n\\nclass SparseList(list):\\n  def __setitem__(self, index, value):\\n    missing = index - len(self) + 1\\n    if missing > 0:\\n      self.extend([None] * missing)\\n    list.__setitem__(self, index, value)\\n  def __getitem__(self, index):\\n    try: return list.__getitem__(self, index)\\n    except IndexError: return None\\n\\n__test__ = dict(allem=\\'\\'\\'\\n>>> l = SparseList()\\n>>> l\\n[]\\n>>> l[2] = \"hello\"\\n>>> l\\n[None, None, \\'hello\\']\\n>>> print l[5]\\nNone\\n>>> l[4] = 22\\n>>> l\\n[None, None, \\'hello\\', None, 22]\\n>>> len(l)\\n5\\n>>> for i in l: print i\\nNone\\nNone\\nhello\\nNone\\n22\\n\\'\\'\\')\\nimport doctest\\ndoctest.testmod(verbose=1)\\n\\n\\nI imagine you\\'ll want more (to support negative indices, slicing, and whatever else), but this is all your examples are implicitly specifying.\\n'},\n {'prompt': \"I am new to python and don't know the best way to do this.\\n\\nI have a list of tuples which represent points and another list which represents offsets. I need a set of all the combinations that this forms.\\nHere's some code:\\n\\noffsets = [( 0, 0),( 0,-1),( 0, 1),( 1, 0),(-1, 0)]\\npoints = [( 1, 5),( 3, 3),( 8, 7)]\\n\\n\\nSo my set of combined points should be\\n\\n[( 1, 5),( 1, 4),( 1, 6),( 2, 5),( 0, 5),\\n ( 3, 3),( 3, 2),( 3, 4),( 4, 3),( 2, 3),\\n ( 8, 7),( 8, 6),( 8, 8),( 9, 7),( 7, 7)]\\n\\n\\nI'm not able to use NumPy or any other libraries.\\n\",\n  'completion': 'result = [(x+dx, y+dy) for x,y in points for dx,dy in offsets]\\n\\n\\nFor more, see list comprehensions.\\n'},\n {'prompt': 'I wanted to create a throwaway \"struct\" object to keep various status flags. My first approach was this (javascript style)\\n\\n>>> status = object()\\n>>> status.foo = 3  \\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nAttributeError: \\'object\\' object has no attribute \\'foo\\'\\n\\n\\nDefinitely not what I expected, because this works:\\n\\n>>> class Anon: pass\\n... \\n>>> b=Anon()\\n>>> b.foo = 4\\n\\n\\nI guess this is because object() does not have a __dict__. I don\\'t want to use a dictionary, and assuming I don\\'t want to create the Anon object, is there another solution ?\\n',\n  'completion': 'The most concise way to make \"a generic object to which you can assign/fetch attributes\" is probably:\\n\\nb = lambda:0\\n\\n\\nAs most other answers point out, there are many other ways, but it\\'s hard to beat this one for conciseness (lambda:0 is exactly the same number of characters as object()...;-).\\n'},\n {'prompt': 'This seems like it should be pretty trivial, but I am new at Python and want to do it the most Pythonic way.\\n\\nI want to find the n\\'th occurrence of a substring in a string.\\n\\nThere\\'s got to be something equivalent to what I WANT to do which is \\n\\nmystring.find(\"substring\", 2nd)\\n\\nHow can you achieve this in Python?\\n',\n  'completion': 'Here\\'s a more Pythonic version of the straightforward iterative solution:\\n\\ndef find_nth(haystack, needle, n):\\n    start = haystack.find(needle)\\n    while start >= 0 and n > 1:\\n        start = haystack.find(needle, start+len(needle))\\n        n -= 1\\n    return start\\n\\n\\nExample:\\n\\n>>> find_nth(\"foofoofoofoo\", \"foofoo\", 2)\\n6\\n\\n\\nIf you want to find the nth overlapping occurrence of needle, you can increment by 1 instead of len(needle), like this:\\n\\ndef find_nth_overlapping(haystack, needle, n):\\n    start = haystack.find(needle)\\n    while start >= 0 and n > 1:\\n        start = haystack.find(needle, start+1)\\n        n -= 1\\n    return start\\n\\n\\nExample:\\n\\n>>> find_nth_overlapping(\"foofoofoofoo\", \"foofoo\", 2)\\n3\\n\\n\\nThis is easier to read than Mark\\'s version, and it doesn\\'t require the extra memory of the splitting version or importing regular expression module.  It also adheres to a few of the rules in the Zen of python, unlike the various re approaches:\\n\\n\\nSimple is better than complex.\\nFlat is better than nested.\\nReadability counts.\\n\\n'},\n {'prompt': 'How do I get a thread to return a tuple or any value of my choice back to the parent in Python?\\n',\n  'completion': \"I suggest you instantiate a Queue.Queue before starting the thread, and pass it as one of the thread's args: before the thread finishes, it .puts the result on the queue it received as an argument.  The parent can .get or .get_nowait it at will.\\n\\nQueues are generally the best way to arrange thread synchronization and communication in Python: they're intrinsically thread-safe, message-passing vehicles -- the best way to organize multitasking in general!-)\\n\"},\n {'prompt': \"I find the astype() method of numpy arrays not very efficient. I have an array containing\\n3 million of Uint8 point. Multiplying it by a 3x3 matrix takes 2 second, but converting the result from uint16 to uint8 takes another second.\\n\\nMore precisely :\\n\\n    print time.clock()\\n    imgarray = np.dot(imgarray,  M)/255\\n    print time.clock()\\n    imgarray = imgarray.clip(0, 255)\\n    print time.clock()\\n    imgarray = imgarray.astype('B')\\n    print time.clock()\\n\\n\\ndot product and scaling takes 2 sec\\nclipping takes 200 msec\\ntype conversion takes 1 sec\\n\\nGiven the time taken by the other operations, I would expect astype to be faster.\\nIs there a faster way to do type conversion, or am I wrong when guesstimating that type conversion should not be that hard ?\\n\\nEdit : the goal is to save the final 8 bit array to a file\\n\",\n  'completion': \"When you use imgarray = imgarray.astype('B'), you get a copy of the array, cast to the specified type. This requires extra memory allocation, even though you immediately flip imgarray to point to the newly allocated array.\\n\\nIf you use imgarray.view('uint8'), then you get a view of the array. This uses the same data except that it is interpreted as uint8 instead of imgarray.dtype.\\n(np.dot returns a uint32 array, so after the np.dot, imgarray is of type uint32.)\\n\\nThe problem with using view, however, is that a 32-bit integer becomes viewed as 4 8-bit integers, and we only care  about the value in the last 8-bits. So we need to skip to every 4th 8-bit integer. We can do that with slicing:\\n\\nimgarray.view('uint8')[:,::4]\\n\\nIPython's %timeit command shows there is a significant speed up doing things this way:\\n\\nIn [37]: %timeit imgarray2 = imgarray.astype('B')\\n10000 loops, best of 3: 107 us per loop\\n\\nIn [39]: %timeit imgarray3 = imgarray.view('B')[:,::4]\\n100000 loops, best of 3: 3.64 us per loop\\n\\n\"},\n {'prompt': 'It would not be my intention to put a link on my blog, but I don\\'t have any other method to clarify what I really mean. The article is quite long, and it\\'s in three parts (1,2,3), but if you are curious, it\\'s worth the reading.\\n\\nA long time ago (5 years, at least) I programmed a python program which generated \"mathematical bacteria\". These bacteria are python objects with a simple opcode-based genetic code. You can feed them with a number and they return a number, according to the execution of their code. I generate their genetic codes at random, and apply an environmental selection to those objects producing a result similar to a predefined expected value. Then I let them duplicate, introduce mutations, and evolve them. The result is quite interesting, as their genetic code basically learns how to solve simple equations, even for values different for the training dataset.\\n\\nNow, this thing is just a toy. I had time to waste and I wanted to satisfy my curiosity. \\nhowever, I assume that something, in terms of research, has been made... I am reinventing the wheel here, I hope. Are you aware of more serious attempts at creating in-silico bacteria like the one I programmed?\\n\\nPlease note that this is not really \"genetic algorithms\". Genetic algorithms is when you use evolution/selection to improve a vector of parameters against a given scoring function. This is kind of different. I optimize the code, not the parameters, against a given scoring function. \\n',\n  'completion': 'If you are optimising the code, perhaps you are engaged in genetic programming?\\n'},\n {'prompt': 'I have PDF forms that I want to autopopulate with data from my Django web application and then offer to the user to download.  What python library would let me easily pre-populate PDF forms?  These forms are intended to be printed out.\\n',\n  'completion': 'Reportlab is great if you\\'re generating very dynamic PDFs and need to programmatically control all of it: data and layout. \\n\\nTo just fill out forms in existing PDFs, reportlab is overkill and you\\'ll basically have to rebuild the PDF from scratch in reportlab instead of just taking a PDF with a form that\\'s already been made. \\n\\nPDF forms work with FDF data. I ported a PHP FDF library to Python a while back when I had to do this and released it as fdfgen. I use that to generate an fdf file with the data for the form, then use pdftk to push the fdf into a PDF form and generate the output. \\n\\nThe whole process works like this:\\n\\n\\nYou (or a designer) design the PDF in Acrobat or whatever and mark the form fields and take note of the field names (I\\'m not sure exactly how this is done; our designer does this step). Let\\'s say your form has fields \"name\" and \"telephone\". \\nUse fdfgen to create a FDF file:\\n\\nfrom fdfgen import forge_fdf\\nfields = [(\\'name\\',\\'John Smith\\'),(\\'telephone\\',\\'555-1234\\')]\\nfdf = forge_fdf(\"\",fields,[],[],[])\\nfdf_file = open(\"data.fdf\",\"w\")\\nfdf_file.write(fdf)\\nfdf_file.close()\\n\\nThen you run pdftk to merge and flatten:\\n\\npdftk form.pdf fill_form data.fdf output output.pdf flatten\\n\\n\\nand a filled out, flattened (meaning that there are no longer editable form fields) pdf will be in output.pdf.\\n\\n\\nIt\\'s a bit complicated, and pdftk can be a pain to install (requires a java stack and there are bugs on Ubuntu 9.10 that have to be worked around) but it\\'s the simplest process I\\'ve been able to come up with yet and the workflow is convenient (ie, our designers can make all the layout changes to the PDF they want and as long as they don\\'t change the names of the fields, I can drop the new one in and everything keeps working). \\n\\nI apologize for the lack of docs on fdfgen. forge_fdf() is really the only function you should need and it has a docstrings to explain the arguments. I\\'ve just never quite gotten around to doing more with it.\\n'},\n {'prompt': 'I\\'m having an interesting problem with threads and the tempfile module in Python. Something doesn\\'t appear to be getting cleaned up until the threads exit, and I\\'m running against an open file limit. (This is on OS X 10.5.8, Python 2.5.1.)\\n\\nYet if I sort of replicate what the tempfile module is doing (not all the security checks, but just generating a file descriptor and then using os.fdopen to produce a file object) I have no problems.\\n\\nBefore filing this as a bug with Python, I figured I\\'d check here, as it\\'s much more likely that I\\'m doing something subtly wrong. But if I am, a day of trying to figure it out hasn\\'t gotten me anywhere.\\n\\n#!/usr/bin/python\\n\\nimport threading\\nimport thread\\nimport tempfile\\nimport os\\nimport time\\nimport sys\\n\\nNUM_THREADS = 10000\\n\\ndef worker_tempfile():\\n    tempfd, tempfn = tempfile.mkstemp()\\n    tempobj = os.fdopen(tempfd, \\'wb\\')\\n    tempobj.write(\\'hello, world\\')\\n    tempobj.close()\\n    os.remove(tempfn)\\n    time.sleep(10)\\n\\ndef worker_notempfile(index):\\n    tempfn = str(index) + \\'.txt\\'\\n    # The values I\\'m passing os.open may be different than tempfile.mkstemp \\n    # uses, but it works this way as does using the open() function to create\\n    # a file object directly.\\n    tempfd = os.open(tempfn, \\n                     os.O_EXCL | os.O_CREAT | os.O_TRUNC | os.O_RDWR)\\n    tempobj = os.fdopen(tempfd, \\'wb\\')\\n    tempobj.write(\\'hello, world\\')\\n    tempobj.close()\\n    os.remove(tempfn)\\n    time.sleep(10)\\n\\ndef main():\\n    for count in range(NUM_THREADS):\\n        if count % 100 == 0:\\n            print(\\'Opening thread %s\\' % count)\\n        wthread = threading.Thread(target=worker_tempfile)\\n        #wthread = threading.Thread(target=worker_notempfile, args=(count,))\\n        started = False\\n        while not started:\\n            try:\\n                wthread.start()\\n                started = True\\n            except thread.error:\\n                print(\\'failed starting thread %s; sleeping\\' % count)\\n                time.sleep(3)\\n\\nif __name__ == \\'__main__\\':\\n    main()\\n\\n\\nIf I run it with the worker_notempfile line active and the worker_tempfile line commented-out, it runs to completion.\\n\\nThe other way around (using worker_tempfile) I get the following error:\\n\\n$ python threadtempfiletest.py \\nOpening thread 0\\nOpening thread 100\\nOpening thread 200\\nOpening thread 300\\nException in thread Thread-301:\\nTraceback (most recent call last):\\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.5/lib/python2.5/threading.py\", line 460, in __bootstrap\\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.5/lib/python2.5/threading.py\", line 440, in run\\n  File \"threadtempfiletest.py\", line 17, in worker_tempfile\\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.5/lib/python2.5/tempfile.py\", line 302, in mkstemp\\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.5/lib/python2.5/tempfile.py\", line 236, in _mkstemp_inner\\nOSError: [Errno 24] Too many open files: \\'/var/folders/4L/4LtD6bCvEoipksvnAcJ2Ok+++Tk/-Tmp-/tmpJ6wjV0\\'\\n\\n\\nAny ideas what I\\'m doing wrong? Is this a bug in Python, or am I being bone-headed?\\n\\nUPDATE 2009-12-14:\\nI think I\\'ve found the answer, but I don\\'t like it. Since nobody was able to replicate the problem, I went hunting around our office for machines. It passed on everything except my machine. I tested on a Mac with the same software versions I was using. I even went hunting for a Desktop G5 with the EXACT same hardware and software config I had -- same result. Both tests (with tempfile and without tempfile) succeeded on everything.\\n\\nFor kicks, I downloaded Python 2.6.4, and tried it on my desktop, and same pattern on my system as Python 2.5.1: tempfile failed, and notempfile succeeded.\\n\\nThis is leading me to the conclusion that something\\'s hosed on my Mac, but I sure can\\'t figure out what. Any suggestions are welcome.\\n',\n  'completion': \"I am unable to reproduce the problem with (Apple's own build of) Python 2.5.1 on Mac OS X 10.5.9 -- runs to completion just fine!\\n\\nI've tried both on a Macbook Pro, i.e., an Intel processor, and an old PowerMac, i.e., a PPC processor.\\n\\nSo I can only imagine there must have been a bug in 10.5.8 which I never noticed (don't have any 10.5.8 around to test, as I always upgrade promptly whenever software update offers it). All I can suggest is that you try upgrading to 10.5.9 and see if the bug disappears -- if it doesn't, I have no idea how this behavior difference between my machines and yours is possible.\\n\"},\n {'prompt': \"The Data Model section of the Python 3.2 documentation provides the following descriptions for the __int__ and __index__ methods:\\n\\n\\n  object.__int__(self)\\n  \\n  Called to implement the built-in [function int()]. Should return [an integer].\\n  \\n  object.__index__(self)\\n  \\n  Called to implement operator.index(). Also called whenever Python needs an integer object (such as in slicing, or in the built-in bin(), hex() and oct() functions). Must return an integer.\\n\\n\\nI understand that they're used for different purposes, but I've been unable to figure out why two different methods are necessary. What is the difference between these methods? Is it safe to just alias __index__ = __int__ in my classes?\\n\",\n  'completion': 'See PEP 357: Allowing Any Object to be Used for Slicing.\\n\\n\\n  The nb_int method is used for coercion and so means something\\n  fundamentally different than what is requested here.  This PEP\\n  proposes a method for something that can already be thought of as\\n  an integer communicate that information to Python when it needs an\\n  integer.  The biggest example of why using nb_int would be a bad\\n  thing is that float objects already define the nb_int method, but\\n  float objects should not be used as indexes in a sequence.\\n\\n\\nEdit: It seems that it was implemented in Python 2.5.\\n'},\n {'prompt': \"No flaming please, asking as a community wiki so nobody gets reputation here.\\nI know python is not the first language to have list comprehension.\\nI'm just interest in the history of the name.\\n\\nI'm particularly interested in why it's called comprehension\\n\",\n  'completion': 'The name comes from the concept of a set-comprehension\\n\\nComprehension is used here to mean complete inclusion or complete description. A set-comprehension is a (usually short) complete description of a set, not an exhaustive (and possibly infinite) enumeration.\\n'},\n {'prompt': 'I\\'m interested in learning how to Doctests and Unit tests in a more Agile / BDD way.\\nI\\'ve found a few tutorials that seem reasonable, but they are just thumbnails.\\nWhat I would really like to see is the source code of some Django projects that were developed BDD style.\\n\\nThe things I\\'m unclear about are how do you handle request objects etc.\\nI have a situation where I have deployed my app and I\\'m getting completely different behavior in production that I did in development or even from the Python shell on the production server. I\\'m hoping some Doctests will help me diagnose this and well as open the door for a more Agile process of writing the tests first.\\n\\nSpecifically, here is the code I\\'m trying to test:\\n\\ndef match_pictures_with_products( queryset, number_of_images = 3):      \\n    products = []  \\n    i = 0    \\n    for product in queryset:  \\n       if i < ( number_of_images ):  \\n           image =  product.imagemain_set.all()[:1]  \\n           product.photo_url = image[0].photo.url  \\n\\n       products.append(product)  \\n       i += 1  \\n\\n    return products  \\n\\ndef index(request):  \\n    \"\"\"returns the top 10 most clicked products\"\"\"     \\n    products = Product.objects.all()[:10]  \\n    products = match_pictures_with_products( products, 10)  .  \\n    return render_to_response(\\'products/product_list.html\\', {\\'products\\': products})\\n\\n\\nHow do I create a Doctest that ensures that index returns 10 objects?\\nThe Product queries seem to work fine from the shell on the production server. The actual server is not returning any products at all.\\n',\n  'completion': 'I\\'ve asked myself the same question before. I\\'ve found doctests to be of limited utility for things like views, model methods and managers because\\n\\n\\nYou need to be able to setup and teardown a test data set to actually use for testing\\nViews need to take a request object. In a doctest, where does that come from?\\n\\n\\nFor that reason, I\\'ve always used the Django unit testing framework which handles all this for you. Unfortunately, though, you don\\'t get some of the benefits of the doctests and it makes TDD/BDD harder to do. What follows next is pure speculation about how you might make this work:\\n\\nI think you\\'d want to grab doctests from their respective modules and functions and execute them within the unit testing framework. This would take care of test data setup/teardown. If your doctests were executed from within a test method of something that subclasses Django\\'s unittest.TestCase they\\'d be able to use that test DB. You\\'d also be able to pass a mock request object into the doc test\\'s execution context. Here\\'s a Django snippet that provides a mock request object and info on it. Let\\'s say you wanted to test the docstrings from all of an applications views. You could do something like this in tests.py :\\n\\nfrom ??? import RequestFactory\\nfrom doctest import testmod, DocTestFailure\\nfrom django.test import TestCase\\n\\nfrom myapp import views\\n\\nclass MyAppTest(TestCase):\\n\\n    fixtures = [\\'test_data.json\\']\\n\\n    def test_doctests(self):                \\n        try:\\n            testmod(views, extraglobs={\\n                \\'REQUEST\\': RequestFactory()\\n            }, raise_on_error=True)\\n        except DocTestFailure, e:\\n            self.fail(e)\\n\\n\\nThis should allow you to do something like this:\\n\\ndef index(request):  \\n    \"\"\"\\n    returns the top 10 most clicked products\\n\\n    >>> response = index(REQUEST)\\n    >>> [test response content here]\\n\\n    \"\"\"     \\n    products = Product.objects.all()[:10]  \\n    products = match_pictures_with_products( products, 10)  .  \\n    return render_to_response(\\'products/product_list.html\\', {\\'products\\': products})\\n\\n\\nAgain, this is just off the top of my head and not at all tested, but it\\'s the only way that I think you could what you want without just putting all your view tests in the unit testing framework. \\n'},\n {'prompt': 'I started with c++ but as we all know, c++ is a monster. I still have to take it and I do like C++ (it takes programming a step further) \\n\\nHowever, currently I have been working with python for a while. I see how you guys can turn some long algorithm into simple one.\\n\\nI know programming is a progress, and can take up to years of experience.\\nI also know myself - I am not a natural programmer, and software engineering is not my first choice anyway. However, I would like to do heavy programming on my own, and create projects.\\n\\nHow can I become a better python programmer?\\n',\n  'completion': '\\nWrite code\\nRead books, http://www.coderholic.com/free-python-programming-books/\\nRead code \\nRead tutorials, http://www.dabeaz.com/talks.html, ...\\nWrite more code\\nDo exercises, e.g. Building Skills in Python\\nWrite even more code\\nAnswer SO python questions, http://stackoverflow.com/unanswered/tagged/python\\nCheck (your) code regularly, http://pypi.python.org/pypi/pylint\\nWatch talks and presentations: \\n\\n\\nEasy AI in python, \\nAdvanced python or understanding Python, \\nhttp://pycon.blip.tv/, ...\\n\\n\\n'},\n {'prompt': 'I\\'m rewriting a Bash script I wrote into Python. The crux of that script was\\n\\nssh -t first.com \"ssh second.com very_remote_command\"\\n\\n\\nI\\'m having a problem with the nested authentication with paramiko. I wasn\\'t able to find any examples dealing with my precise situation, but I was able to find examples with sudo on a remote host.\\n\\nThe first method writes to stdin\\n\\nssh.connect(\\'127.0.0.1\\', username=\\'jesse\\', password=\\'lol\\')\\nstdin, stdout, stderr = ssh.exec_command(\"sudo dmesg\")\\nstdin.write(\\'lol\\\\n\\')\\nstdin.flush()\\n\\n\\nThe second creates a channel and uses the socket-like send and recv.\\n\\nI was able to get stdin.write to work with sudo, but it doesn\\'t work with ssh on the remote host.\\n\\nimport paramiko\\n\\nssh = paramiko.SSHClient()\\nssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\\nssh.connect(\\'first.com\\', username=\\'luser\\', password=\\'secret\\')\\nstdin, stdout, stderr = ssh.exec_command(\\'ssh luser@second.com\\')\\nstdin.write(\\'secret\\')\\nstdin.flush()\\nprint \\'---- out ----\\'\\nprint stdout.readlines()\\nprint \\'---- error ----\\'\\nprint stderr.readlines()\\n\\nssh.close()\\n\\n\\n...prints...\\n\\n---- out ----\\n[]\\n---- error ----\\n[\\'Pseudo-terminal will not be allocated because stdin is not a terminal.\\\\r\\\\n\\', \\'Permission denied, please try again.\\\\r\\\\n\\', \\'Permission denied, please try again.\\\\r\\\\n\\', \\'Permission denied (publickey,password,keyboard-interactive).\\\\r\\\\n\\']\\n\\n\\nThe pseudo-terminal error reminded me of the -t flag in my original command, so I switched to the second method, using a Channel. Instead of ssh.exec_command and later, I have:\\n\\nt = ssh.get_transport()\\nchan = t.open_session()\\nchan.get_pty()\\nprint \\'---- send ssh cmd ----\\'\\nprint chan.send(\\'ssh luser@second.com\\')\\nprint \\'---- recv ----\\'\\nprint chan.recv(9999)\\nchan = t.open_session()\\nprint \\'---- send password ----\\'\\nprint chan.send(\\'secret\\')\\nprint \\'---- recv ----\\'\\nprint chan.recv(9999)\\n\\n\\n...but it prints \\'---- send ssh cmd ----\\' and just hangs until I kill the process.\\n\\nI\\'m new to Python and none too knowledgeable about networks. In the first case, why does sending the password work with sudo but not with ssh? Are the prompts different? Is paramiko even the right library for this?\\n',\n  'completion': \"I managed to find a solution, but it requires a little manual work. If anyone have a better solution, please tell me.\\n\\nssh = paramiko.SSHClient()\\nssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\\nssh.connect('first.com', username='luser', password='secret')\\n\\nchan = ssh.invoke_shell()\\n\\n# Ssh and wait for the password prompt.\\nchan.send('ssh second.com\\\\n')\\nbuff = ''\\nwhile not buff.endswith('\\\\'s password: '):\\n    resp = chan.recv(9999)\\n    buff += resp\\n\\n# Send the password and wait for a prompt.\\nchan.send('secret\\\\n')\\nbuff = ''\\nwhile not buff.endswith('some-prompt$ '):\\n    resp = chan.recv(9999)\\n    buff += resp\\n\\n# Execute whatever command and wait for a prompt again.\\nchan.send('ls\\\\n')\\nbuff = ''\\nwhile not buff.endswith('some-prompt$ '):\\n    resp = chan.recv(9999)\\n    buff += resp\\n\\n# Now buff has the data I need.\\nprint 'buff', buff\\n\\nssh.close()\\n\\n\\nThe thing to note is that instead of this\\n\\nt = ssh.get_transport()\\nchan = t.open_session()\\nchan.get_pty()\\n\\n\\n...you want this\\n\\nchan = ssh.invoke_shell()\\n\\n\\nIt reminds me of when I tried to write a TradeWars script when I was a kid and gave up coding for ten years. :)\\n\"},\n {'prompt': 'I\\'m trying to write the Haskel function \\'splitEvery\\' in Python. Here is it\\'s definition:\\n\\nsplitEvery :: Int -> [e] -> [[e]]\\n    @\\'splitEvery\\' n@ splits a list into length-n pieces.  The last\\n    piece will be shorter if @n@ does not evenly divide the length of\\n    the list.\\n\\n\\nThe basic version of this works fine, but I want a version that works with generator expressions, lists, and iterators. And, if there is a generator as an input it should return a generator as an output! \\n\\nTests\\n\\n# should not enter infinite loop with generators or lists\\nsplitEvery(itertools.count(), 10)\\nsplitEvery(range(1000), 10)\\n\\n# last piece must be shorter if n does not evenly divide\\nassert splitEvery(5, range(9)) == [[0, 1, 2, 3, 4], [5, 6, 7, 8]]\\n\\n# should give same correct results with generators\\ntmp = itertools.islice(itertools.count(), 10)\\nassert list(splitEvery(5, tmp)) == [[0, 1, 2, 3, 4], [5, 6, 7, 8]]\\n\\n\\nCurrent Implementation \\n\\nHere is the code I currently have but it doesn\\'t work with a simple list. \\n\\ndef splitEvery_1(n, iterable):\\n    res = list(itertools.islice(iterable, n))\\n    while len(res) != 0:\\n        yield res\\n        res = list(itertools.islice(iterable, n))\\n\\n\\nThis one doesn\\'t work with a generator expression (thanks to jellybean for fixing it):\\n\\ndef splitEvery_2(n, iterable): \\n    return [iterable[i:i+n] for i in range(0, len(iterable), n)]\\n\\n\\nThere has to be a simple piece of code that does the splitting. I know I could just have different functions but it seems like it should be and easy thing to do. I\\'m probably getting stuck on an unimportant problem but it\\'s really bugging me. \\n\\n\\n\\nIt is similar to grouper from http://docs.python.org/library/itertools.html#itertools.groupby but I don\\'t want it to fill extra values. \\n\\ndef grouper(n, iterable, fillvalue=None):\\n    \"grouper(3, \\'ABCDEFG\\', \\'x\\') --> ABC DEF Gxx\"\\n    args = [iter(iterable)] * n\\n    return izip_longest(fillvalue=fillvalue, *args)\\n\\n\\nIt does mention a method that truncates the last value. This isn\\'t what I want either.\\n\\n\\n  The left-to-right evaluation order of the iterables is guaranteed. This makes possible an idiom for clustering a data series into n-length groups using izip([iter(s)]n).\\n\\n\\nlist(izip(*[iter(range(9))]*5)) == [[0, 1, 2, 3, 4]]\\n# should be [[0, 1, 2, 3, 4], [5, 6, 7, 8]]\\n\\n',\n  'completion': \"from itertools import islice\\n\\ndef split_every(n, iterable):\\n    i = iter(iterable)\\n    piece = list(islice(i, n))\\n    while piece:\\n        yield piece\\n        piece = list(islice(i, n))\\n\\n\\nSome tests:\\n\\n>>> list(split_every(5, range(9)))\\n[[0, 1, 2, 3, 4], [5, 6, 7, 8]]\\n\\n>>> list(split_every(3, (x**2 for x in range(20))))\\n[[0, 1, 4], [9, 16, 25], [36, 49, 64], [81, 100, 121], [144, 169, 196], [225, 256, 289], [324, 361]]\\n\\n>>> [''.join(s) for s in split_every(6, 'Hello world')]\\n['Hello ', 'world']\\n\\n>>> list(split_every(100, []))\\n[]\\n\\n\"},\n {'prompt': 'I am looking for a rules engine in C or Python, but if you know a rules engine that is implemented in another language I would be glad to know about it.\\n\\nThe engine will be used as way to automate a house, like turning the light off when somebody leaves a room etc. So no \"office\" rules there (aka do you rules in Excel or such).\\n\\nI have looked into Jess and Drools which are in Java and do a perfect job. I would like to know of others and possibly using less memory than Java does.\\nI have heard of RuleCore in Python but couldn\\'t really find any documentation on it (version 1.0 is available at SourceForge but it looks like they are selling v. 2.0).\\n\\nEDIT: By rules engine (inference engine), I mean an implementation of RETE or equivalent.\\n',\n  'completion': \"In your search for RETE based rules engine in Python either Pyke or PyCLIPS could be the one you would want to use. \\n\\nPS: I had left a comment to S.Lott's answer about Pyke. I have posted a separate answer as per his suggestion and also to let other readers readily know that the rules engine mentioned in this answer could be a probable choice if they are searching for one.\\n\"},\n {'prompt': \"Trying to solve a problem of preventing duplicate images to be uploaded.\\n\\nI have two JPGs. Looking at them I can see that they are in fact identical. But for some reason they have different file size (one is pulled from a backup, the other is another upload) and so they have a different md5 checksum. \\n\\nHow can I efficiently and confidently compare two images in the same sense as a human would be able to see that they are clearly identical?\\n\\nExample: http://static.peterbe.com/a.jpg and http://static.peterbe.com/b.jpg\\n\\nUpdate \\n\\nI wrote this script:\\n\\nimport math, operator\\nfrom PIL import Image\\ndef compare(file1, file2):\\n    image1 = Image.open(file1)\\n    image2 = Image.open(file2)\\n    h1 = image1.histogram()\\n    h2 = image2.histogram()\\n    rms = math.sqrt(reduce(operator.add,\\n                           map(lambda a,b: (a-b)**2, h1, h2))/len(h1))\\n    return rms\\n\\nif __name__=='__main__':\\n    import sys\\n    file1, file2 = sys.argv[1:]\\n    print compare(file1, file2)\\n\\n\\nThen I downloaded the two visually identical images and ran the script. Output:\\n\\n58.9830484122\\n\\n\\nCan anybody tell me what a suitable cutoff should be?\\n\\nUpdate II\\n\\nThe difference between a.jpg and b.jpg is that the second one has been saved with PIL:\\n\\nb=Image.open('a.jpg')\\nb.save(open('b.jpg','wb'))\\n\\n\\nThis apparently applies some very very light quality modifications. I've now solved my problem by applying the same PIL save to the file being uploaded without doing anything with it and it now works!\\n\",\n  'completion': 'There is a OSS project that uses WebDriver to take screen shots and then compares the images to see if there are any issues (http://code.google.com/p/fighting-layout-bugs/)). It does it by openning the file into a stream and then comparing every bit. \\n\\nYou may be able to do something similar with PIL.\\n\\nEDIT:\\n\\nAfter more research I found\\n\\nh1 = Image.open(\"image1\").histogram()\\nh2 = Image.open(\"image2\").histogram()\\n\\nrms = math.sqrt(reduce(operator.add,\\n    map(lambda a,b: (a-b)**2, h1, h2))/len(h1))\\n\\n\\non http://snipplr.com/view/757/compare-two-pil-images-in-python/ and http://effbot.org/zone/pil-comparing-images.htm\\n'},\n {'prompt': 'I have a Python project with mutiple extension modules written in C, which talk to a third-party library.  However, depending on the user\\'s environment and options some modules should not be built, and some compiler flags should be enabled/disabled.  The problem is that I have to build the list of extension modules before I call setup(), and ideally I\\'d like to use a distutils.Command subclass to handle the user options.  Right now I have a few options:\\n\\n\\nRequire a \"python setup.py configure\" command be run before building the modules, store the information in a pickle file, and use it to generate the extensions list next time the script runs.  This is how my project currently works, which seems quite silly.\\nManually scrape options out of sys.argv and use them to build the list.  This is not a long-term solution because I will eventually want to run some scripts to check the settings before building.\\nSubclass build_ext from distutils, do my configuration in the beginning of the run() method (possibly also using options sent via (2)) and directly modify self.distribution.ext_modules before building.  I\\'m afraid this may confuse setuptools, however, as it may assume the list of extension modules is fixed when setup() is called.  It also means that when setup() is called with a command other than build_ext the list of extension modules is empty.\\n\\n\\nIs there a preferred way to do this?\\n',\n  'completion': \"\\n  Is there a preferred way to do this?\\n\\n\\nFrom my experience working with other people's modules, I can say there is certainly not consensus on the right way to do this.\\n\\nI have tried and rejected subclassing bits of distutils -- I found it fragile and difficult to get working across different Python versions and different systems.\\n\\nFor our code, after trying the types of things you are considering, I have settled on doing detection and configuration right in setup.py before the main call to \\nsetup().  This is admittedly a bit ugly, but it means that someone trying compile your stuff has one place to figure out e.g. why the include path is wrong.  (And they certainly don't need to be experts on distutils internals).\\n\"},\n {'prompt': 'I am looking for a simple way to visualize some of my data in numpy, and I discovered the mlabwrap package which looks really promising. I am trying to create a simple plot with the ability to be updated as the data changes. \\n\\nHere is the matlab code that I am trying to duplicate\\n\\n>> h = plot([1,2,3], [1,2,3], \\'-o\\');\\n>> set(h, \\'XData\\', [0,0,0]);\\n>> drawnow();\\n\\n\\nto python\\n\\n>> from mlabwrap import mlab\\n>> h = mlab.plot([1,2,3], [1,2,3], \\'-o\\')\\n>> mlab.set(h, \\'XData\\', [0,0,0])\\n>> mlab.drawnow();\\n\\n\\nHowever, the second to last command fails with an error message \\n\\nerror: One or more output arguments not assigned during call to \"set\".\\n\\n\\nAny suggestions on how to fix this?\\n',\n  'completion': \"Maybe mlab is mad that you're not saving matlab's return value for that set() call...\\n\\nI don't have this installed, what does someval = mlab.set(h,'XData') give?\\n\\nedit: you could also try using nout... mlab.set(h,'XData',[0,0,0],nout=0)\\n\"},\n {'prompt': 'I was reading that Python does all it\\'s \"code blocks\" by indentation, rather than with curly braces. Is that right? So functions, if\\'s and stuff like that all appear without surrounding their block with curly braces?\\n',\n  'completion': 'if foo: #{\\n    print \"it\\'s true\"\\n#}\\nelse: #{\\n    print \"it\\'s false!\"\\n#}\\n\\n\\n(Obviously, this is a joke.)\\n'},\n {'prompt': \"In python 2.6, why is the following line valid?\\n\\nmy_line = 'foo' 'bar'\\n\\n\\nand if that is valid, why isn't the following:\\n\\nmy_list = 1 2\\n\\n\\nThe first example is string concatenation, however, the following isn't valid either (thanks god):\\n\\nfoo = 'foo'\\nbar = 'bar'\\nfoo_bar = foo bar\\n\\n\",\n  'completion': 'This is doing string literal concatenation.  As noted in the documentation, advantages include the following:\\n\\n\\n  This feature can be used to reduce the\\n  number of backslashes needed, to split\\n  long strings conveniently across long\\n  lines, or even to add comments to\\n  parts of strings...\\n\\n\\nIt goes on to note that this concatenation is done at compilation time rather than run time.\\n\\nThe history and rationale behind this, and a rejected suggestion to remove the feature, is described in PEP 3126.\\n'},\n {'prompt': \"The below code will not join, when debugged the command does not store the whole path but just the last entry.\\n\\nos.path.join('/home/build/test/sandboxes/', todaystr, '/new_sandbox/')\\n\\n\\nWhen I test this it only stores the /new_sandbox/ part of the code.\\n\",\n  'completion': 'The latter strings shouldn\\'t start with a slash. If they start with a slash, then they\\'re considered an \"absolute path\" and everything before them is discarded.\\n\\nQuoting the Python docs for os.path.join:\\n\\n\\n  If any component is an absolute path, all previous components (on Windows, including the previous drive letter, if there was one) are thrown away, and joining continues. \\n\\n'},\n {'prompt': 'From what I have read, I found that a built-in ternary operator does not exist (I will be happy to know more about it.).\\n\\nI found the following code as a substitute:\\n\\ndef val():\\n    var = float(raw_input(\"Age:\"))\\n    status = (\"Working\",\"Retired\")[var>65]\\n    print \"You should be:\",status\\n\\n\\nI couldn\\'t understand how this code works; can anyone explain me how actually the code is working? I am also interested to know why the ternary operator doesn\\'t exist; any references or links about this will be ore useful. \\n\\nI\\'m running Python 2.6.4 on Windows Vista.\\n',\n  'completion': 'Python has a construct that is sort of like the ternary operator in C, et al. It works something like this:\\n\\nmy_var = \"Retired\" if age > 65 else \"Working\"\\n\\n\\nand is equivalent to this C code:\\n\\nmy_var = age > 65 ? \"Retired\" : \"Working\";\\n\\n\\nAs for how the code you posted works, let\\'s step through it:\\n\\n(\"Working\",\"Retired\")\\n\\n\\ncreates a 2-tuple (an immutable list) with the element \"Working\" at index 0, and \"Retired\" at index 1.\\n\\nvar>65\\n\\n\\nreturns True if var is greater than 65, False if not. When applied to an index, it is converted into 1 (True) or 0 (False). Thus, this boolean value provides an index into the tuple created on the same line.\\n\\nWhy hasn\\'t Python always had a ternary operator? The simple answer is that Guido van Rossum, the author of Python, didn\\'t like/didn\\'t want it, apparently believing that it was an unnecessary construct that could lead to confusing code (and anyone who\\'s seen massively-nested ternary operators in C can probably agree). But for Python 2.5, he relented and added the grammar seen above.\\n'},\n {'prompt': \"I worked on a PHP project earlier where prepared statements made the SELECT queries 20% faster.\\n\\nI'm wondering if it works on Python? I can't seem to find anything that specifically says it does or does NOT.\\n\",\n  'completion': 'Most languages provide a way to do generic parameterized statements, Python is no different.  When a parameterized query is used databases that support preparing statements will automatically do so.\\n\\nIn python a parameterized query looks like this:\\n\\ncursor.execute(\"SELECT FROM tablename WHERE fieldname = %s\", [value])\\n\\n\\nThe specific style of parameterization may be different depending on your driver, you can import your db module and then do a print yourmodule.paramstyle.\\n\\nFrom PEP-249:\\n\\n\\n  paramstyle\\n\\n       String constant stating the type of parameter marker\\n       formatting expected by the interface. Possible values are\\n       [2]:\\n\\n           \\'qmark\\'         Question mark style, \\n                           e.g. \\'...WHERE name=?\\'\\n           \\'numeric\\'       Numeric, positional style, \\n                           e.g. \\'...WHERE name=:1\\'\\n           \\'named\\'         Named style, \\n                           e.g. \\'...WHERE name=:name\\'\\n           \\'format\\'        ANSI C printf format codes, \\n                           e.g. \\'...WHERE name=%s\\'\\n           \\'pyformat\\'      Python extended format codes, \\n                           e.g. \\'...WHERE name=%(name)s\\'\\n\\n\\n'},\n {'prompt': '\\n  Possible Duplicate:\\n  What does <if __name__==”__main__”:> do?  \\n\\n\\nI occasionally notice something like the following in Python scripts:\\n\\nif __name__ == \"__main__\":\\n    # do stuff like call main()\\n\\n\\nWhat\\'s the point of this?\\n',\n  'completion': 'Having all substantial Python code live inside a function (i.e., not at module top level) is a crucial performance optimization as well as an important factor in good organization of code (the Python compiler can optimize access to local variables in a function much better than it can optimize \"local\" variables which are actually a module\\'s globals, since the semantics of the latter are more demanding).\\n\\nMaking the call to the function conditional on the current module being run as the \"main script\" (rather than imported from another module) makes for potential reusability of nuggets of functionality contained in the module (since other modules may import it and just call the appropriate functions or classes), and even more importantly it supports solid unit testing (where all sort of mock-ups and fakes for external subsystems may generally need to be set up before the module\\'s functionality is exercised and tested).\\n'},\n {'prompt': 'Say I have a class object named test.\\n\\ntest has various methods, one of them is whatever() .\\n\\nI have a variable named method = \"whatever\"\\n\\nHow can I access the method using the variable with test?\\n\\nThanks!\\n',\n  'completion': 'Get the attribute with getattr:\\n\\nmethod = \"whatever\"\\ngetattr(test, method)\\n\\n\\nYou can also call it:\\n\\ngetattr(test, method)()\\n\\n'},\n {'prompt': 'What is the name of the method to override the [] operator for a class?\\n',\n  'completion': 'You need to use the __getitem__ method.\\n\\n>>> class MyClass:\\n...     def __getitem__(self,index):\\n...         return index * 2\\n...\\n>>> myobj = MyClass()\\n>>> myobj[3]\\n6\\n\\n\\nAnd if you\\'re going to be setting values you\\'ll need to implement the __setitem__ method too, otherwise this will happen:\\n\\n>>> myobj[5] = 1\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nAttributeError: MyClass instance has no attribute \\'__setitem__\\'\\n\\n'},\n {'prompt': \"Let's say I have such model\\n\\nclass Event(models.Model)\\n    users_count = models.IntegerField(default=0)\\n    users = models.ManyToManyField(User)\\n\\n\\nHow would you recommend to update users_count value if Event add/delete some users ?\\n\",\n  'completion': \"If possible in your case, you could introduce Participation model which would join Event and User:\\n\\nclass Participation(models.Model):\\n    user = models.ForeignKey(User)\\n    event = models.ForeignKey(Event)\\n\\nclass Event(models.Model):\\n    users = models.ManyToManyField(User, through='Participation')\\n\\n\\nAnd handle pre_save signal sent by Participation to update instance.event counts. It would simplify handling of m2m significantly. And in most cases, it turns out later on that some logic and data fits best in the middle model. If that's not your case, try a custom solution (you should not have many code paths adding Users to Events anyway).\\n\"},\n {'prompt': 'Some results file produced by Fortran programs report double precision numbers (in scientific notation) using the letter D instead of E, for instance:\\n\\n1.2345D+02\\n# instead of\\n1.2345E+02\\n\\n\\nI need to process huge amounts of this data using Python, and I just realized it cannot read the numbers in the D notation, for instance:\\n\\n>>> A = 1.0D+01\\n  File \"<stdin>\", line 1\\n    A = 1.0D+01\\n           ^\\nSyntaxError: invalid syntax\\n\\n\\nCan I change my locale and let Python know that D means E? I really would not want to make a global search-and-replace!\\n',\n  'completion': \"If you are dealing with lots of data and/or are doing a lot computations with that data, you might consider using the fortran-friendly numpy module which supports double-precision fortran format out of the box.\\n\\n>>> numpy.float('1.5698D+03')\\n1569.8\\n\\n\"},\n {'prompt': 'I want to select only certain rows from a NumPy array based on the value in the second column. For example, this test array has integers from 1 to 10 in the second column.\\n\\n>>> test = numpy.array([numpy.arange(100), numpy.random.randint(1, 11, 100)]).transpose()\\n>>> test[:10, :]\\narray([[ 0,  6],\\n       [ 1,  7],\\n       [ 2, 10],\\n       [ 3,  4],\\n       [ 4,  1],\\n       [ 5, 10],\\n       [ 6,  6],\\n       [ 7,  4],\\n       [ 8,  6],\\n       [ 9,  7]])\\n\\n\\nIf I wanted only rows where the second value is 4, it is easy:\\n\\n>>> test[test[:, 1] == 4]\\narray([[ 3,  4],\\n       [ 7,  4],\\n       [16,  4],\\n       ...\\n       [81,  4],\\n       [83,  4],\\n       [88,  4]])\\n\\n\\nBut how do I achieve the same result when there is more than one wanted value?\\n\\nThe wanted list can be of arbitrary length. For example, I may want all rows where the second column is either 2, 4 or 6:\\n\\n>>> wanted = [2, 4, 6]\\n\\n\\nThe only way I have come up with is to use list comprehension and then convert this back into an array and seems too convoluted, although it works:\\n\\n>>> test[numpy.array([test[x, 1] in wanted for x in range(len(test))])]\\narray([[ 0,  6],\\n       [ 3,  4],\\n       [ 6,  6],\\n       ...\\n       [90,  2],\\n       [91,  6],\\n       [92,  2]])\\n\\n\\nIs there a better way to do this in NumPy itself that I am missing?\\n',\n  'completion': 'The following solution should be faster than Amnon\\'s solution as wanted gets larger:\\n\\nwanted_set = set(wanted)  # Much faster look up than with lists, for larger lists\\n\\n@numpy.vectorize\\ndef selected(elmt): return elmt in wanted_set  # Or: selected = numpy.vectorize(wanted_set.__contains__)\\n\\nprint test[selected(test[:, 1])]\\n\\n\\nIn fact, it has the advantage of searching through the test array only once (instead of len(wanted) times). It also uses Python\\'s built-in fast element look up in sets, which are much faster for this than lists.  It is also fast because it uses Numpy\\'s fast loops.  You also get the optimization of the in operator: once a wanted element matches, the remaining elements do not have to be tested (as opposed to the \"logical or\" approach of Amnon, were all the elements in wanted are tested no matter what).\\n\\nAlternatively, you could use the following one-liner, which also goes through your array only once:\\n\\ntest[numpy.apply_along_axis(lambda x: x[1] in wanted, 1, test)]\\n\\n\\nThis is much much slower, though, as this extracts the element in the second column at each iteration (instead of doing it in one pass, as in the first solution of this answer).\\n'},\n {'prompt': 'I am confused because there are a lot of programms. But i am looking something like this. I will type a melody like \"a4 c3 h3 a2\" etc. and then i want to hear this. Does anybody know what i am looking for?\\nthanks in advance\\n',\n  'completion': 'computing frequencies from note name is easy. each half-note is 2^(1/12) away from the preceding note, 440 Hz is A4. \\n\\nif by any chance you are on windows, you may try this piece of code, which plays a song through the PC speaker:\\n\\nimport math\\nimport winsound\\nimport time\\n\\nlabels = [\\'a\\',\\'a#\\',\\'b\\',\\'c\\',\\'c#\\',\\'d\\',\\'d#\\',\\'e\\',\\'f\\',\\'f#\\',\\'g\\',\\'g#\\']\\n# name is the complete name of a note (label + octave). the parameter\\n# n is the number of half-tone from A4 (e.g. D#1 is -42, A3 is -12, A5 is 12)\\nname   = lambda n: labels[n%len(labels)] + str(int((n+(9+4*12))/12))\\n# the frequency of a note. the parameter n is the number of half-tones\\n# from a4, which has a frequency of 440Hz, and is our reference note.\\nfreq   = lambda n: int(440*(math.pow(2,1/12)**n))\\n\\n# a dictionnary associating note frequencies to note names\\nnotes  = {name(n): freq(n) for n in range(-42,60)}\\n\\n# the period expressed in second, computed from a tempo in bpm\\nperiod = lambda tempo: 1/(tempo/60)\\n\\n# play each note in sequence through the PC speaker at the given tempo\\ndef play(song, tempo):\\n    for note in song.lower().split():\\n        if note in notes.keys():\\n            winsound.Beep(notes[note], int(period(tempo)*1000))\\n        else:\\n            time.sleep(period(tempo))\\n\\n# \"au clair de la lune\"!! \\'r\\' is a rest\\nplay( \\'c4 c4 C4 d4 e4 r d4 r c4 e4 d4 d4 c4 r r r \\'\\n      \\'c4 C4 c4 d4 e4 r d4 r c4 e4 d4 d4 c4 r r r \\'\\n      \\'d4 d4 d4 d4 A3 r a3 r d4 c4 B3 a3 g3 r r r \\'\\n      \\'c4 c4 c4 d4 e4 r d4 r c4 e4 d4 d4 c4 r r r \\', 180 )\\n\\n\\n(please note that i am using python 3.x, you may need to adapt some part of the code in order to use it on python 2.x.)\\n\\nho, by the way, i used abcdefg as a scale, but you will surely find the way to use h instead of b.\\n'},\n {'prompt': 'I am looking for ideas on how to translate one range values to another in Python. I am working on hardware project and am reading data from a sensor that can return a range of values, I am then using that data to drive an actuator that requires a different range of values.\\n\\nFor example lets say that the sensor returns values in the range 1 to 512, and the actuator is driven by values in the range 5 to 10. I would like a function that I can pass a value and the two ranges and get back the value mapped to the second range. If such a function was named translate it could be used like this:\\n\\nsensor_value = 256\\nactuator_value = translate(sensor_value, 1, 512, 5, 10)\\n\\n\\nIn this example I would expect the output actuator_value to be 7.5 since the sensor_value is in the middle of the possible input range.\\n',\n  'completion': \"One solution would be:\\n\\ndef translate(value, leftMin, leftMax, rightMin, rightMax):\\n    # Figure out how 'wide' each range is\\n    leftSpan = leftMax - leftMin\\n    rightSpan = rightMax - rightMin\\n\\n    # Convert the left range into a 0-1 range (float)\\n    valueScaled = float(value - leftMin) / float(leftSpan)\\n\\n    # Convert the 0-1 range into a value in the right range.\\n    return rightMin + (valueScaled * rightSpan)\\n\\n\\nYou could possibly use algebra to make it more efficient, at the expense of readability.\\n\"},\n {'prompt': \"How do I seek to a particular position on a remote (HTTP) file so I can download only that part?\\n\\nLets say the bytes on a remote file were: 1234567890\\n\\nI wanna seek to 4 and download 3 bytes from there so I would have: 456\\n\\nand also, how do I check if a remote file exists?\\nI tried, os.path.isfile() but it returns False when I'm passing a remote file url.\\n\",\n  'completion': 'If you are downloading the remote file through HTTP, you need to set the Range header.\\n\\nCheck in this example how it can be done. Looks like this:\\n\\nmyUrlclass.addheader(\"Range\",\"bytes=%s-\" % (existSize))\\n\\n\\nEDIT: I just found a better implementation. This class is very simple to use, as it can be seen in the docstring.\\n\\nclass HTTPRangeHandler(urllib2.BaseHandler):\\n\"\"\"Handler that enables HTTP Range headers.\\n\\nThis was extremely simple. The Range header is a HTTP feature to\\nbegin with so all this class does is tell urllib2 that the \\n\"206 Partial Content\" reponse from the HTTP server is what we \\nexpected.\\n\\nExample:\\n    import urllib2\\n    import byterange\\n\\n    range_handler = range.HTTPRangeHandler()\\n    opener = urllib2.build_opener(range_handler)\\n\\n    # install it\\n    urllib2.install_opener(opener)\\n\\n    # create Request and set Range header\\n    req = urllib2.Request(\\'http://www.python.org/\\')\\n    req.header[\\'Range\\'] = \\'bytes=30-50\\'\\n    f = urllib2.urlopen(req)\\n\"\"\"\\n\\ndef http_error_206(self, req, fp, code, msg, hdrs):\\n    # 206 Partial Content Response\\n    r = urllib.addinfourl(fp, hdrs, req.get_full_url())\\n    r.code = code\\n    r.msg = msg\\n    return r\\n\\ndef http_error_416(self, req, fp, code, msg, hdrs):\\n    # HTTP\\'s Range Not Satisfiable error\\n    raise RangeError(\\'Requested Range Not Satisfiable\\')\\n\\n\\nUpdate: The \"better implementation\" has moved to github: excid3/urlgrabber in the \"byterange.py\" file.\\n'},\n {'prompt': \"This is relating to the following: (In Python Code)\\n\\nfor i in object:\\n     doSomething(i)\\n\\n\\nversus\\n\\nmap(doSomething, object)\\n\\n\\nBoth are easy to understand, and short, but is there any speed difference?  Now,  if doSomething had a return value we needed to check it would be returned as a list from map, and in the for loop we could either create our own list or check one at a time.\\n\\nfor i in object:\\n     returnValue = doSomething(i)\\n     doSomethingWithReturnValue(returnValue)\\n\\n\\nversus\\n\\nreturnValue = map(doSomething, object)\\nmap(doSomethingWithReturnValue, returnValue)\\n\\n\\nNow, I feel the two diverge a little bit.  The two doSomethingWithReturnValue functions may be different based on if checking them on the fly as we go through the loop or if checking them all at once at the end produce different results.  Also it seems the for loop would always work, maybe slower, where the map would only work under certain scenarios.  Of course, we could make contortions to make either work, but the whole point is to avoid this type of work.\\n\\nWhat I'm looking for is a scenario where the mapping function truly shines in comparison to a well done for loop in performance, readability, maintainability, or speed of implementation.  If the answer is there really isn't a big difference then I'd like to know when in practice people use one or the other or if it's really completely arbitrary and set by coding standards depending on your institution.\\n\\nThanks!\\n\",\n  'completion': \"Map is useful when you want to apply the function to every item of iterable and return a list of the results. This is simpler and more concise than usng a for loop and constructing a list.\\n\\nFor is often more readable for other situations, and in lisp there were lots of iteration constructs that were written basically using macros and map. So, in cases where map doesn't fit, use a for loop.\\n\\nIn theory, if we had a compiler/interpreter that was smart enough to make use of multiple cpus/processors, then map could be implemented faster as the different operations on each item  could be done in parallel. I don't think this is the case at present, however.\\n\"},\n {'prompt': 'I tried:\\n\\ndocument.doctype = xml.dom.minidom.DocumentType(\\'html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"DTD/xhtml1-strict.dtd\"\\')\\n\\n\\nThere is no doctype in the output. How to fix without inserting it by hand?\\n',\n  'completion': 'You shouldn\\'t instantiate classes from minidom directly. It\\'s not a supported part of the API, the ownerDocumentâ\\x80\\x8bs won\\'t tie up and you can get some strange misbehaviours. Instead use the proper DOM Level 2 Core methods:\\n\\n>>> imp= minidom.getDOMImplementation(\\'\\')\\n>>> dt= imp.createDocumentType(\\'html\\', \\'-//W3C//DTD XHTML 1.0 Strict//EN\\', \\'http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\\')\\n\\n\\n(â\\x80\\x98DTD/xhtml1-strict.dtdâ\\x80\\x99 is a commonly-used but wrong SystemId. That relative URL would only be valid inside the xhtml1 folder at w3.org.)\\n\\nNow you\\'ve got a DocumentType node, you can add it to a document. According to the standard, the only guaranteed way of doing this is at document creation time:\\n\\n>>> doc= imp.createDocument(\\'http://www.w3.org/1999/xhtml\\', \\'html\\', dt)\\n>>> print doc.toxml()\\n<?xml version=\"1.0\" ?><!DOCTYPE html  PUBLIC \\'-//W3C//DTD XHTML 1.0 Strict//EN\\'  \\'http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\\'><html/>\\n\\n\\nIf you want to change the doctype of an existing document, that\\'s more trouble. The DOM standard doesn\\'t require that DocumentType nodes with no ownerDocument be insertable into a document. However some DOMs allow it, eg. pxdom. minidom kind of allows it:\\n\\n>>> doc= minidom.parseString(\\'<html xmlns=\"http://www.w3.org/1999/xhtml\"><head/><body/></html>\\')\\n>>> dt= minidom.getDOMImplementation(\\'\\').createDocumentType(\\'html\\', \\'-//W3C//DTD XHTML 1.0 Strict//EN\\', \\'http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\\')\\n>>> doc.insertBefore(dt, doc.documentElement)\\n<xml.dom.minidom.DocumentType instance>\\n>>> print doc.toxml()\\n<?xml version=\"1.0\" ?><!DOCTYPE html  PUBLIC \\'-//W3C//DTD XHTML 1.0 Strict//EN\\'  \\'http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\\'><html xmlns=\"http://www.w3.org/1999/xhtml\"><head/><body/></html>\\n\\n\\nbut with bugs:\\n\\n>>> doc.doctype\\n# None\\n>>> dt.ownerDocument\\n# None\\n\\n\\nwhich may or may not matter to you.\\n\\nTechnically, the only reliable way per the standard to set a doctype on an existing document is to create a new document and import the whole of the old document into it!\\n\\ndef setDoctype(document, doctype):\\n    imp= document.implementation\\n    newdocument= imp.createDocument(doctype.namespaceURI, doctype.name, doctype)\\n    newdocument.xmlVersion= document.xmlVersion\\n    refel= newdocument.documentElement\\n    for child in document.childNodes:\\n        if child.nodeType==child.ELEMENT_NODE:\\n            newdocument.replaceChild(\\n                newdocument.importNode(child, True), newdocument.documentElement\\n            )\\n            refel= None\\n        elif child.nodeType!=child.DOCUMENT_TYPE_NODE:\\n            newdocument.insertBefore(newdocument.importNode(child, True), refel)\\n    return newdocument\\n\\n'},\n {'prompt': 'Is there a way to map a list onto a dictionary? What I want to do is give it a function that will return the name of a key, and the value will be the original value. For example;\\n\\nsomefunction(lambda a: a[0], [\"hello\", \"world\"])\\n=> {\"h\":\"hello\", \"w\":\"world\"}\\n\\n\\n(This isn\\'t a specific example that I want to do, I want a generic function like map() that can do this)\\n',\n  'completion': 'In Python 3 you can use this dictionary comprehension syntax:\\n\\ndef foo(somelist):\\n    return {x[0]:x for x in somelist}\\n\\n'},\n {'prompt': 'The question is to find the 1000th prime number. I wrote the following python code for this. The problem is, I get the right answer for the 10th , 20th prime but after that each increment of 10 leaves me one off the mark. I can\\'t catch the bug here :(\\n\\ncount=1            #to keep count of prime numbers\\nprimes=()          #tuple to hold primes\\ncandidate=3        #variable to test for primes\\nwhile count<20:\\n    for x in range(2,candidate):\\n        if candidate%x==0:\\n            candidate=candidate+2\\n        else : pass\\n    primes=primes+(candidate,)            \\n    candidate=candidate+2\\n    count=count+1\\nprint primes        \\nprint \"20th prime is \", primes[-1]\\n\\n\\nIn case you\\'re wondering, count is initialised as 1 because I am not testing for 2 as a prime number(I\\'m starting from 3) and candidate is being incremented by 2 because only odd numbers can be prime numbers. I know there are other ways of solving this problem, such as the prime number theorem but I wanna know what\\'s wrong with this approach. Also if there are any optimisations you have in mind, please suggest.\\n\\nThank You             \\n',\n  'completion': 'There is a nice Sieve of Eratosthenes generator implementation in test_generators.py:\\n\\ndef intsfrom(i):\\n     while 1:\\n         yield i\\n         i += 1\\n\\ndef firstn(g, n):\\n     return [g.next() for i in range(n)]\\n\\ndef exclude_multiples(n, ints):\\n     for i in ints:\\n         if i % n:\\n             yield i    \\n\\ndef sieve(ints):\\n     prime = ints.next()\\n     yield prime\\n     not_divisible_by_prime = exclude_multiples(prime, ints)\\n     for p in sieve(not_divisible_by_prime):\\n         yield p\\n\\nprimes = sieve(intsfrom(2))\\n\\n>>> print firstn(primes, 20)\\n[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71]\\n\\n\\n\\n'},\n {'prompt': 'I was trying to implement a \"download link\" and put it beside one of my report table so that users can download a csv file and open it with applications like Excel.\\n\\nThe records are generated dynamically based on the query made by users.\\n\\nSo somewhere in my controller there\\'s something like:\\n\\nresponse.headers[\\'Content-Type\\'] = \\'text/csv\\'\\nresponse.headers[\\'Content-Disposition\\'] = \\'attachment; filename=xxx.csv\\'\\nreturn response.stream(dynamically_generated_csv, request=request)\\n\\n\\nThis works in both FireFox & Chrome, but fails in IE.\\n\\nWhen I print out the response headers, I found that several headers were added to my response by web2py:\\'Expires\\', \\'Cache-Control\\', etc...\\n\\nAnd when I remove the \\'Cache-Control\\' header by doing the following:\\n\\ndel response.headers[\\'Cache-Control\\']\\n\\n\\nIt works in IE.\\n\\nSo it seems like IE has trouble dealing with a downloadable file with \\'Cache-Control\\' set to certain value.\\n\\nNow, my question is:\\n\\n\\nWhy does web2py add these response headers, implicitly? and maybe without a way to set it off?\\nis there any side effect when i delete the \\'Cache-Control\\' header this way?\\n\\n\\nThanks in advance.\\n',\n  'completion': 'I\\'m not sure what Cache control headers are/were being sent but IE has a bug with downloaded files like you are experiencing.\\n\\nFor IE, you MUST enable caching.  When IE loads files (e.g. Excel files), in Excel, it loads them from the cache directory, thus if you don\\'t cache it, Excel (or your other app) will fail to load the file.\\n\\nEric Law (MSFT) on the topic: http://blogs.msdn.com/ieinternals/archive/2009/10/02/Internet-Explorer-cannot-download-over-HTTPS-when-no-cache.aspx\\n\\nUpdate: If however you just want to force the download... e.g. not have IE load the excel file inside the IE window... then be sure to set the full headers for the attachment.\\n\\n//PHP style\\nheader(\\'Content-Type: application/vnd.ms-excel\\');\\nheader(\\'Content-Disposition: attachment; filename=\"downloaded.pdf\"\\');\\n\\n'},\n {'prompt': \"Using Python...\\n\\nHow can I select all of the Sundays (or any day for that matter) in a year?\\n\\n[ '01/03/2010','01/10/2010','01/17/2010','01/24/2010', ...]\\n\\n\\nThese dates represent the Sundays for 2010. This could also apply to any day of the week I suppose.\\n\",\n  'completion': 'You can use date from the datetime module to find the first Sunday in a year and then keep adding seven days, generating new Sundays:\\n\\nfrom datetime import date, timedelta\\n\\ndef allsundays(year):\\n   d = date(year, 1, 1)                    # January 1st\\n   d += timedelta(days = 6 - d.weekday())  # First Sunday\\n   while d.year == year:\\n      yield d\\n      d += timedelta(days = 7)\\n\\nfor d in allsundays(2010):\\n   print d\\n\\n'},\n {'prompt': 'I noticed that in Django models, there is a class Meta which makes some additional definitions about the model.\\n\\nMy question is, why is this done as an old-style class? (i.e. not subclassing object?) Is there a reason for this or is this just a custom? Could I do it as a new-style class in my projects?\\n',\n  'completion': 'I believe that there is no real reason (including history, since new-style classes exist since Python 2.2) and that not only can you choose to use a new-style class instead, but that it would probably be a good idea for you to do so (for all the usual reasons).\\n'},\n {'prompt': 'I have a program, a part of which executes a loop. During the execution of this loop, there are exceptions. Obviously, I would like my program to run without errors, but for the sake of progress, I would like the program to execute over the entire input and not stop when an exception is thrown. The easiest way to do this would be by implementing an except block. \\n\\nHowever, when I do this, it excepts all exceptions and continues with the program and I never get to see the exception message, which I need in order to debug.\\n\\nIs there a way to except any arbitrary exception and be able to print out the exception message in the except block?\\n',\n  'completion': 'try:\\n    #stuff\\nexcept Exception as e:\\n    print e\\n\\n\\nThe traceback module provides various functions for extracting more information from the exception object (e, above).\\n\\nSource Errors and Exceptions\\n'},\n {'prompt': \"my python code is interlaced with lots of function calls used for (debugging|profiling|tracing etc.)\\nfor example:\\n\\nimport logging\\n\\nlogging.root.setLevel(logging.DEBUG)\\nlogging.debug('hello')\\nj = 0\\nfor i in range(10):\\n    j += i\\n    logging.debug('i %d j %d' % (i,j))\\nprint(j)\\nlogging.debug('bye')\\n\\n\\ni want to #define these resource consuming functions out of the code. something like the c equivalent\\n\\n#define logging.debug(val)\\n\\n\\nyes, i know the logging module logging level mechanism can be used to mask out loggings below set log level.  but, im asking for a general way to have the python interpreter skip functions (that take time to run even if they dont do much)\\n\\none idea is to redefine the functions i want to comment out into empty functions:\\n\\ndef lazy(*args): pass\\nlogging.debug = lazy\\n\\n\\nthe above idea still calls a function, and may create a myriad of other problems\\n\",\n  'completion': 'Python does not have a preprocessor, although you could run your python source through an external preprocessor to get the same effect - e.g. sed \"/logging.debug/d\" will strip out all the debug logging commands.  This is not very elegant though - you will end up needing some sort of build system to run all your modules through the preprocessor and perhaps create a new directory tree of the processed .py files before running the main script.\\n\\nAlternatively if you put all your debug statements in an if __debug__: block they will get optimised out when python is run with the -O (optimise) flag.\\n\\nAs an aside, I checked the code with the dis module to ensure that it did get optimised away.  I discovered that both\\n\\nif __debug__: doStuff()\\n\\n\\nand\\n\\nif 0: doStuff()\\n\\n\\nare optimised, but \\n\\nif False: doStuff()\\n\\n\\nis not.  This is because False is a regular Python object, and you can in fact do this:\\n\\n>>> False = True\\n>>> if False: print \"Illogical, captain\"\\nIllogical, captain\\n\\n\\nWhich seems to me a flaw in the language - hopefully it is fixed in Python 3.\\n\\nEdit:\\n\\nThis is fixed in Python 3:  Assigning to True or False now gives a SyntaxError.\\nSince True and False are constants in Python 3, it means that if False: doStuff() is now optimised:\\n\\n>>> def f():\\n...     if False: print( \"illogical\")\\n... \\n>>> dis.dis(f)\\n  2           0 LOAD_CONST               0 (None) \\n              3 RETURN_VALUE         \\n\\n'},\n {'prompt': \"When working in interactive Python, I tend to rely on the built-in help() function to tell me what something expects and/or returns, and print out any documentation that might help me. Is there a Ruby equivalent to this function?\\n\\nI'm looking for something I could use in irb. For example, in interactive Python I could type:\\n\\n>>> help(1)\\n\\n\\nwhich would then print\\n\\nHelp on int object:\\n\\nclass int(object)  |  int(x[, base])\\n-> integer  |    |  \\n\\nConvert a string or number to an integer, if possible. A ...\\n\\n\",\n  'completion': 'Try using ri from the command line.\\n\\nIt takes a class name, method, or module as an argument, and gives you appropriate documentation. Many popular gems come with this form of documentation, as well, so it should typically work even beyond the scope of core Ruby modules.\\n'},\n {'prompt': \"I wasn't aware of this, but apparently the and and or keywords aren't operators.  They don't appear in the list of python operators.  Just out of sheer curiosity, why is this?  And if they aren't operators, what exactly are they?\\n\",\n  'completion': 'Because they\\'re control flow constructs. Specifically:\\n\\n\\nif the left argument to and evaluates to False, the right argument doesn\\'t get evaluated at all\\nif the left argument to or evaluates to True, the right argument doesn\\'t get evaluated at all\\n\\n\\nThus, it is not simply a matter of being reserved words. They don\\'t behave like operators, since operators always evaluate all of their arguments.\\n\\nYou can contrast this with bitwise binary operators which, as the name implies, are operators:\\n\\n>>> 1 | (1/0)\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nZeroDivisionError: integer division or modulo by zero\\n>>> 1 or (1/0)\\n1\\n\\n\\nAs you see, the bitwise OR (|) evaluates both its arguments. The or keyword, however, doesn\\'t evaluate its right argument at all when the left argument evaluates to True; that\\'s why no ZeroDivisionError is raised in the second statement.\\n'},\n {'prompt': 'Hi All\\nI need to download a file from a host using sFTP.\\n\\nDo you know if is it possible to do that using python ftplib?\\nI saw an example here, but when I try to connect I receive EOFError.\\n\\nI tried this code:\\n\\nimport ftplib\\nftp = ftplib.FTP()\\nftp.connect( \"1.2.3.4\", \"22\" )\\n\\n\\nThis method returns with an error after long time so I cannot perform a call to login.\\nI cannot try the constructor FTP([host[, user[, passwd[, acct[, timeout]]]]]) because \\nmy port is 22 but ftplib default is 21.\\n\\nIf I follow the example\\n\\nftp = ftplib.FTP(\"1.2.3.4\")\\nftp = ftplib.FTP(\"1.2.3.4\",\"22\")\\n\\n\\nI receive a connection refused so I cannot enter any username password. Can you help me? Thank you very much\\n',\n  'completion': \"As the question you linked to states, ftplib doesn't support sftp (which is FTP over SSH and has nothing to do with FTPS, FTP over SSL). Use the recommended paramiko instead.\\n\"},\n {'prompt': 'I want to print out a dictionary, sorted by the key. Sorting the keys is easy in the view, by just putting the keys in a list and then sorting the list. How can I loop through the keys in the template and then get the value from the dictionary.\\n\\n{% for company in companies %}\\n    {% for employee, dependents in company_dict.company.items %}\\n    {% endfor %}\\n{% endfor %}\\n\\n\\n(Just made up the example...)\\nThe part that doesn\\'t work is the \"company_dict.company.items\" part. I need the \"company\" to be the value of company. Right now the company prat is looking for a key named \"company\" not the value of \"company\" from the loop above.\\n\\nI\\'m doing a bit of processing to put the dictionary of dictionaries together. Changing the layout of the data isn\\'t really an option. I figure the right approach is to write up a template tag, just wanted to know if there was a built-in way I missed.\\n',\n  'completion': \"create a custom filter, which is like this:\\n\\nfrom django import template\\nfrom django.utils.datastructures import SortedDict\\n\\nregister = template.Library()\\n\\n@register.filter(name='sort')\\ndef listsort(value):\\n    if isinstance(value, dict):\\n        new_dict = SortedDict()\\n        key_list = sorted(value.keys())\\n        for key in key_list:\\n            new_dict[key] = value[key]\\n        return new_dict\\n    elif isinstance(value, list):\\n        return sorted(value)\\n    else:\\n        return value\\n    listsort.is_safe = True\\n\\n\\nthen in your template you shall call it using:\\n\\n{% for key, value in companies.items|sort %}\\n      {{ key }} {{ value }}\\n{% endfor %}\\n\\n\\nYou will be able to get the sorted dict by Key.\\n\"},\n {'prompt': 'I\\'ve got a series of (x,y) values that I want to plot a 2d histogram of using python\\'s matplotlib. Using hexbin, I get something like this:\\n\\nBut I\\'m looking for something like this:\\n\\nExample Code:\\n\\nfrom matplotlib import pyplot as plt\\nimport random\\n\\nfoo = lambda : random.gauss(0.0,1.0)\\n\\nx = [foo() for i in xrange(5000)]\\ny = [foo() for i in xrange(5000)]\\n\\npairs = zip(x,y)\\n\\n#using hexbin I supply the x,y series and it does the binning for me\\nhexfig = plt.figure()\\nhexplt = hexfig.add_subplot(1,1,1)\\nhexplt.hexbin(x, y, gridsize = 20)\\n\\n#to use imshow I have to bin the data myself\\ndef histBin(pairsData,xbins,ybins=None):\\n    if (ybins == None): ybins = xbins\\n    xdata, ydata = zip(*pairsData)\\n    xmin,xmax = min(xdata),max(xdata)\\n    xwidth = xmax-xmin\\n    ymin,ymax = min(ydata),max(ydata)\\n    ywidth = ymax-ymin\\n    def xbin(xval):\\n        xbin = int(xbins*(xval-xmin)/xwidth)\\n        return max(min(xbin,xbins-1),0)\\n    def ybin(yval):\\n        ybin = int(ybins*(yval-ymin)/ywidth)\\n        return max(min(ybin,ybins-1),0)\\n    hist = [[0 for x in xrange(xbins)] for y in xrange(ybins)]\\n    for x,y in pairsData:\\n        hist[ybin(y)][xbin(x)] += 1\\n    extent = (xmin,xmax,ymin,ymax)\\n    return hist,extent\\n\\n#plot using imshow\\nimdata,extent = histBin(pairs,20)\\nimfig = plt.figure()\\nimplt = imfig.add_subplot(1,1,1)\\nimplt.imshow(imdata,extent = extent, interpolation = \\'nearest\\')\\n\\nplt.draw()\\nplt.show()\\n\\n\\nIt seems like there should already be a way to do this without writing my own \"binning\" method and using imshow.\\n',\n  'completion': 'Numpy has a function called histogram2d, whose docstring also shows you how to visualize it using Matplotlib. Add interpolation=nearest to the imshow call to disable the interpolation.\\n'},\n {'prompt': 'I\\'m getting a strange error and can\\'t figure out why. I\\'d appreciate any input. I\\'ve been stuck on this for a few days. Here is my code:\\n\\nmodels.py\\n\\nclass Employee(models.Model): \\n    lastname = models.CharField(max_length=75) \\n    firstname = models.CharField(max_length=75) \\n    position = models.ForeignKey(Position) \\n    jurisdiction = models.ForeignKey(Jurisdiction) \\n    basepay = models.FloatField()\\n    ot = models.FloatField()\\n    benefits = models.FloatField()\\n    totalpay = models.FloatField()\\n\\n    class Meta: \\n        ordering = [\\'lastname\\', \\'firstname\\'] \\n    def __unicode__(self): \\n        return \"%s %s\" % (self.firstname, self.lastname) \\n    def full_name(self): \\n        return \"%s, %s\" % (self.lastname, self.firstname) \\n    def get_absolute_url(self): \\n        return \"/salaries/employee/%s/\" % self.id  \\n\\n\\nurls.py\\n\\nfrom django.conf.urls.defaults import *\\nfrom djangodemo.salaries.models import Employee\\nfrom django.views.generic import list_detail\\n\\nemployee_info = {\\n    \"queryset\" : Employee.objects.all(),\\n    \"template_name\" : \"salaries/employee.html\",\\n}\\n\\nurlpatterns = patterns(\\'\\',     \\n    (r\\'^salaries/employee/$\\', list_detail.object_list, \\'employee_info\\'),\\n)\\n\\n\\nemployee.html\\n\\n{{ object_list }}\\n\\n\\nWhen I run python manage.py runserver and look at http://127.0.0.1:8000/salaries/employee in my browser, I get this error:\\n\\nTraceback (most recent call last):\\n\\n  File \"F:\\\\django\\\\instantdjango\\\\Python26\\\\Lib\\\\site-packages\\\\django\\\\core\\\\servers\\\\basehttp.py\", line 279, in run\\n    self.result = application(self.environ, self.start_response)\\n\\n  File \"F:\\\\django\\\\instantdjango\\\\Python26\\\\Lib\\\\site-packages\\\\django\\\\core\\\\servers\\\\basehttp.py\", line 651, in __call__\\n    return self.application(environ, start_response)\\n\\n  File \"F:\\\\django\\\\instantdjango\\\\Python26\\\\Lib\\\\site-packages\\\\django\\\\core\\\\handlers\\\\wsgi.py\", line 241, in __call__\\n    response = self.get_response(request)\\n\\n  File \"F:\\\\django\\\\instantdjango\\\\Python26\\\\Lib\\\\site-packages\\\\django\\\\core\\\\handlers\\\\base.py\", line 73, in get_response\\n    response = middleware_method(request)\\n\\n  File \"F:\\\\django\\\\instantdjango\\\\Python26\\\\Lib\\\\site-packages\\\\django\\\\middleware\\\\common.py\", line 57, in process_request\\n    _is_valid_path(\"%s/\" % request.path_info)):\\n\\n  File \"F:\\\\django\\\\instantdjango\\\\Python26\\\\Lib\\\\site-packages\\\\django\\\\middleware\\\\common.py\", line 142, in _is_valid_path\\n    urlresolvers.resolve(path)\\n\\n  File \"F:\\\\django\\\\instantdjango\\\\Python26\\\\Lib\\\\site-packages\\\\django\\\\core\\\\urlresolvers.py\", line 294, in resolve\\n    return get_resolver(urlconf).resolve(path)\\n\\n  File \"F:\\\\django\\\\instantdjango\\\\Python26\\\\Lib\\\\site-packages\\\\django\\\\core\\\\urlresolvers.py\", line 218, in resolve\\n    sub_match = pattern.resolve(new_path)\\n\\n  File \"F:\\\\django\\\\instantdjango\\\\Python26\\\\Lib\\\\site-packages\\\\django\\\\core\\\\urlresolvers.py\", line 123, in resolve\\n    kwargs.update(self.default_args)\\n\\nValueError: dictionary update sequence element #0 has length 1; 2 is required\\n\\n',\n  'completion': \"urlpatterns = patterns('',     \\n    (r'^salaries/employee/$', list_detail.object_list, 'employee_info'),\\n)\\n\\n\\nThe third item in the tuple needs to be a dictionary, not a string. Try removing the single quotes around employee_info:\\n\\nurlpatterns = patterns('',     \\n    (r'^salaries/employee/$', list_detail.object_list, employee_info),\\n)\\n\\n\"},\n {'prompt': 'Here is a twofold question, with a theoretical part, and a practical one:\\n\\nWhen subclassing dict:\\n\\nclass ImageDB(dict):\\n    def __init__(self, directory):\\n        dict.__init__(self)  # Necessary?? \\n        ...\\n\\n\\nshould dict.__init__(self) be called, just as a \"safety\" measure (e.g., in case there are some non-trivial implementation details that matter)?  is there a risk that the code break with a future version of Python if dict.__init__() is not called?  I\\'m looking for a fundamental reason of doing one thing or the other, here (practically, calling dict.__init__() is safe).\\n\\nMy guess is that when ImageDB.__init__(self, directory) is called, self is already a new empty dict object, and that there is therefore no need to call dict.__init__ (I do want the dict to be empty, at first).  Is this correct?\\n\\nEdit:\\n\\nThe more practical question behind the fundamental question above is the following.  I was thinking of subclassing dict because I would use the db[â\\x80¦] syntax quite often (instead of doing db.contents[â\\x80¦] all the time); the object\\'s only data (attribute) is indeed really a dict.  I want to add a few methods to the database (such as get_image_by_name(), or get_image_by_code(), for instance), and only override the __init__(), because the image database is defined by the directory that contains it.\\n\\nIn summary, the (practical) question could be: what is a good implementation for something that behaves like a dictionary, except that its initialization is different (it only takes a directory name), and that it has additional methods?\\n\\n\"Factories\" were mentioned in many answers.  So I guess it all boils down to: do you subclass dict, override __init__() and add methods, or do you write a (factory) function that returns a dict, to which you add methods?  I\\'m inclined to prefer the first solution, because the factory function returns an object whose type does not indicate that it has additional semantics and methods, but what do you think?\\n\\nEdit 2:\\n\\nI gather from everybody\\'s answer that it is not a good idea to subclass dict when the new class \"is not a dictionary\", and in particular when its __init__ method cannot take the same arguments as dict\\'s __init__ (which is the case in the \"practical question\" above).  In other words, if I understand correctly, the consensus seems to be: when you subclass, all methods (including initialization) must have the same signature as the base class methods.  This allows isinstance(subclass_instance, dict) to guarantee that subclass_instance.__init__() can be used like dict.__init__(), for instance.\\n\\nAnother practical question then pops up: how should a class which is just like dict, except for its initialization method, be implemented?  without subclassing?  this would require some bothersome boilerplate code, no?\\n',\n  'completion': 'You should probably call dict.__init__(self) when subclassing; in fact, you don\\'t know what\\'s happening precisely in dict (since it\\'s a builtin), and that might vary across versions and implementations. Not calling it may result in improper behaviour, since you can\\'t know where dict is holding its internal data structures.\\n\\nBy the way, you didn\\'t tell us what you want to do; if you want a class with dict (mapping) behaviour, and you don\\'t really need a dict (e.g. there\\'s no code doing isinstance(x, dict) anywhere in your software, as it should be), you\\'re probably better off at using UserDict.UserDict or UserDict.DictMixin if you\\'re on python <= 2.5, or collections.MutableMapping if you\\'re on python >= 2.6 . Those will provide your class with an excellent dict behaviour.\\n\\nEDIT: I read in another comment that you\\'re not overriding any of dict\\'s method! Then there\\'s no point in subclassing at all, don\\'t do it.\\n\\ndef createImageDb(directory):\\n    d = {}\\n    # do something to fill in the dict\\n    return d\\n\\n\\nEDIT 2: you want to inherit from dict to add new methods, but you don\\'t need to override any. Than a good choice might be:\\n\\nclass MyContainer(dict):\\n    def newmethod1(self, args):\\n        pass\\n\\n    def newmethod2(self, args2):\\n        pass\\n\\n\\ndef createImageDb(directory):\\n    d = MyContainer()\\n    # fill the container\\n    return d\\n\\n\\nBy the way: what methods are you adding? Are you sure you\\'re creating a good abstraction? Maybe you\\'d better use a class which defines the methods you need and use a \"normal\" dict internally to it.\\n\\nFactory func:\\nhttp://en.wikipedia.org/wiki/Factory_method_pattern\\n\\nIt\\'s simply a way of delegating the construction of an instance to a function instead of overriding/changing its constructors.\\n'},\n {'prompt': \"I'd like to find out, exactly what variables are available when using zc.buildout.  I can always look at the source, but ideally I'd find a list somewhere, or be able to query buildout to find out what it thinks are the variables available at any one time.  Is this possible?\\n\",\n  'completion': 'I found from the buildout docs  that \\n\\nbin/buildout annotate \\n\\nwas what I was looking for.\\n'},\n {'prompt': \"How can I match an alpha character with a regular expression. I want a character that is in \\\\w but is not in \\\\d. I want it unicode compatible that's why I cannot use [a-zA-Z].\\n\",\n  'completion': 'Your first two sentences contradict each other. \"in \\\\w but is not in \\\\d\" includes underscore. I\\'m assuming from your third sentence that you don\\'t want underscore. \\n\\nUsing a Venn diagram on the back of an envelope helps. Let\\'s look at what we DON\\'T want:\\n\\n(1) characters that are not matched by \\\\w (i.e. don\\'t want anything that\\'s not alpha, digits, or underscore) => \\\\W\\n(2) digits => \\\\d\\n(3) underscore => _  \\n\\nSo what we don\\'t want is anything in the character class [\\\\W\\\\d_] and consequently what we do want is anything in the character class [^\\\\W\\\\d_]\\n\\nHere\\'s a simple example (Python 2.6).\\n\\n>>> import re\\n>>> rx = re.compile(\"[^\\\\W\\\\d_]+\", re.UNICODE)\\n>>> rx.findall(u\"abc_def,k9\")\\n[u\\'abc\\', u\\'def\\', u\\'k\\']\\n\\n\\nFurther exploration reveals a few quirks of this approach:\\n\\n>>> import unicodedata as ucd\\n>>> allsorts =u\"\\\\u0473\\\\u0660\\\\u06c9\\\\u24e8\\\\u4e0a\\\\u3020\\\\u3021\"\\n>>> for x in allsorts:\\n...     print repr(x), ucd.category(x), ucd.name(x)\\n...\\nu\\'\\\\u0473\\' Ll CYRILLIC SMALL LETTER FITA\\nu\\'\\\\u0660\\' Nd ARABIC-INDIC DIGIT ZERO\\nu\\'\\\\u06c9\\' Lo ARABIC LETTER KIRGHIZ YU\\nu\\'\\\\u24e8\\' So CIRCLED LATIN SMALL LETTER Y\\nu\\'\\\\u4e0a\\' Lo CJK UNIFIED IDEOGRAPH-4E0A\\nu\\'\\\\u3020\\' So POSTAL MARK FACE\\nu\\'\\\\u3021\\' Nl HANGZHOU NUMERAL ONE\\n>>> rx.findall(allsorts)\\n[u\\'\\\\u0473\\', u\\'\\\\u06c9\\', u\\'\\\\u4e0a\\', u\\'\\\\u3021\\']\\n\\n\\nU+3021 (HANGZHOU NUMERAL ONE) is treated as numeric (hence it matches \\\\w) but it appears that Python interprets \"digit\" to mean \"decimal digit\" (category Nd) so it doesn\\'t match \\\\d\\n\\nU+2438 (CIRCLED LATIN SMALL LETTER Y) doesn\\'t match \\\\w\\n\\nAll CJK ideographs are classed as \"letters\" and thus match \\\\w\\n\\nWhether any of the above 3 points are a concern or not, that approach is the best you will get out of the re module as currently released. Syntax like \\\\p{letter} is in the future.\\n'},\n {'prompt': 'How can I raise an exception in Python so that it can later be caught via an except block?\\n',\n  'completion': '\\n  How do I manually throw/raise an exception in Python?\\n\\n\\nUse the most specific Exception constructor that semantically fits your issue.  \\n\\nBe specific in your message, e.g.:\\n\\nraise ValueError(\\'A very specific bad thing happened\\')\\n\\n\\nDon\\'t do this:\\n\\nAvoid raising a generic Exception, to catch it, you\\'ll have to catch all other more specific exceptions that subclass it.\\n\\nHiding bugs\\n\\nraise Exception(\\'I know Python!\\') # don\\'t, if you catch, likely to hide bugs.\\n\\n\\nFor example:\\n\\ndef demo_bad_catch():\\n    try:\\n        raise ValueError(\\'represents a hidden bug, do not catch this\\')\\n        raise Exception(\\'This is the exception you expect to handle\\')\\n    except Exception as error:\\n        print(\\'caught this error: \\' + repr(error))\\n\\n>>> demo_bad_catch()\\ncaught this error: ValueError(\\'represents a hidden bug, do not catch this\\',)\\n\\n\\nWon\\'t catch\\n\\nand more specific catches won\\'t catch the general exception:\\n\\ndef demo_no_catch():\\n    try:\\n        raise Exception(\\'general exceptions not caught by specific handling\\')\\n    except ValueError as e:\\n        print(\\'we will not catch e\\')\\n\\n\\n>>> demo_no_catch()\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"<stdin>\", line 3, in demo_no_catch\\nException: general exceptions not caught by specific handling\\n\\n\\nBest Practice:\\n\\nInstead, use the most specific Exception constructor that semantically fits your issue.\\n\\nraise ValueError(\\'A very specific bad thing happened\\')\\n\\n\\nwhich also handily allows an arbitrary number of arguments to be passed to the constructor. This works in Python 2 and 3.\\n\\nraise ValueError(\\'A very specific bad thing happened\\', \\'foo\\', \\'bar\\', \\'baz\\') \\n\\n\\nThese arguments are accessed by the args attribute on the Exception object. For example:\\n\\ntry:\\n    some_code_that_may_raise_our_value_error()\\nexcept ValueError as err:\\n    print(err.args)\\n\\n\\nprints \\n\\n(\\'message\\', \\'foo\\', \\'bar\\', \\'baz\\')    \\n\\n\\nIn Python 2.5, an actual message attribute was added to BaseException in favor of encouraging users to subclass Exceptions and stop using args, but the introduction of message and the original deprecation of args has been retracted.\\n\\nWhen in except clause\\n\\nWhen inside an except clause, you might want to, e.g. log that a specific type of error happened, and then reraise. The best way to do this while preserving the stack trace is to use a bare raise statement, e.g.:\\n\\ntry:\\n    do_something_in_app_that_breaks_easily()\\nexcept AppError as error:\\n    logger.error(error)\\n    raise                 # just this!\\n    # raise AppError      # Don\\'t do this, you\\'ll lose the stack trace!\\n\\n\\nYou can preserve the stacktrace (and error value) with sys.exc_info(), but this is way more error prone, prefer to use a bare raise to reraise. This is the syntax in Python 2:\\n\\n    raise AppError, error, sys.exc_info()[2] # avoid this.\\n    # Equivalently, as error *is* the second object:\\n    raise sys.exc_info()[0], sys.exc_info()[1], sys.exc_info()[2]\\n\\n\\nIn Python 3:\\n\\n    raise error.with_traceback(sys.exc_info()[2])\\n\\n\\nAgain: avoid manually manipulating tracebacks. It\\'s less efficient and more error prone. And if you\\'re using threading and sys.exc_info you may even get the wrong traceback (especially if you\\'re using exception handling for control flow - which I\\'d personally tend to avoid.)\\n\\nPython 3, Exception chaining\\n\\nIn Python 3, you can chain Exceptions, which preserve tracebacks:\\n\\n    raise RuntimeError(\\'specific message\\') from error\\n\\n\\nBut beware, this does change the error type raised.\\n\\nDeprecated Methods:\\n\\nThese can easily hide and even get into production code. You want to raise an exception/error, and doing them will raise an error, but not the one intended!\\n\\nValid in Python 2, but not in Python 3 is the following:\\n\\nraise ValueError, \\'message\\' # Don\\'t do this, it\\'s deprecated!\\n\\n\\nOnly valid in much older versions of Python (2.4 and lower), you may still see people raising strings:\\n\\nraise \\'message\\' # really really wrong. don\\'t do this.\\n\\n\\nIn all modern versions, this will actually raise a TypeError, because you\\'re not raising a BaseException type. If you\\'re not checking for the right exception and don\\'t have a reviewer that\\'s aware of the issue, it could get into production.\\n\\nExample Usage:\\n\\nI raise Exceptions to warn consumers of my API if they\\'re using it incorrectly:\\n\\ndef api_func(foo):\\n    \\'\\'\\'foo should be either \\'baz\\' or \\'bar\\'. returns something very useful.\\'\\'\\'\\n    if foo not in _ALLOWED_ARGS:\\n        raise ValueError(\\'{foo} wrong, use \"baz\" or \"bar\"\\'.format(foo=repr(foo)))\\n\\n\\nCreate your own error types when apropos:\\n\\n\\n  \"I want to make an error on purpose, so that it would go into the except\"\\n\\n\\nYou can create your own error types, if you want to indicate something specific is wrong with your application, just subclass the appropriate point in the exception hierarchy:\\n\\nclass MyAppLookupError(LookupError):\\n    \\'\\'\\'raise this when there\\'s a lookup error for my app\\'\\'\\'\\n\\n\\nand usage:\\n\\nif important_key not in resource_dict and not ok_to_be_missing:\\n    raise MyAppLookupError(\\'resource is missing, and that is not ok.\\')\\n\\n'},\n {'prompt': \"I'm writing a client/server application in Python and I'm finding it necessary to get a new connection to the server for each request from the client. My server is just inheriting from TCPServer and I'm inheriting from BaseRequestHandler to do my processing. I'm not calling self.request.close() anywhere in the handler, but somehow the server seems to be hanging up on my client. What's up?\\n\",\n  'completion': 'According to the docs, neither TCPServer nor BaseRequestHandler close the socket unless prompted to do so.  The default implementations of both handle() and finish() do nothing.  \\n\\nA couple of things might be happening:\\n\\n\\nYou are closing the socket itself or the request which wraps it, or calling server_close somewhere.\\nThe socket timeout could have been hit and you have implemented a timeout handler which closes the socket.\\nThe client could be actually closing the socket.  Code would really help figuring this out.\\n\\n\\nHowever, my testing confirms your results.  Once you return from handle on the server, whether connecting through telnet or Python\\'s socket module, your connection shows up as being closed by the remote host.  Handling socket activity in a loop inside handle seems to work:\\n\\ndef handle(self):\\n    while 1:\\n        try:\\n            data = self.request.recv(1024)\\n            print self.client_address, \"sent\", data\\n        except:\\n            pass\\n\\n\\nA brief Google Code Search confirms that this is a typical way of handling a request: 1 2 3 4. Honestly, there are plenty of other networking libraries available for Python that I might look to if I were facing a disconnect between the abstraction SocketServer provides and my expectations.\\n\\nCode sample that I used to test:\\n\\nfrom SocketServer import BaseRequestHandler, TCPServer\\n\\nclass TestRequestHandler(BaseRequestHandler):\\n    def handle(self):\\n        data = self.request.recv(1024)\\n        print self.client_address, \"sent\", data\\n        self.request.send(data)\\n\\nclass TestServer(TCPServer):\\n    def __init__(self, server_address, handler_class=TestRequestHandler):\\n        TCPServer.__init__(self, server_address, handler_class)\\n\\nif __name__ == \"__main__\":\\n    import socket\\n\\n    address = (\\'localhost\\', 7734)\\n    server = TestServer(address)\\n    server.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\\n\\n'},\n {'prompt': \"how can I load a c# dll in python?\\n\\nDo I have to put some extra code in the c# files? (like export in c++ files)\\n\\nI don't want to use IronPython. I want to import a module to Python!\\n\",\n  'completion': \"The package Python for.NET and the Python Implementation IronPython now work the same way. \\n\\nExample for a C# DLL MyDll.dll:\\n\\nimport clr\\nclr.AddReference('MyDll')\\nfrom MyNamespace import MyClass\\nmy_instance = MyClass()\\n\\n\\nSee this post for more details.\\n\"},\n {'prompt': 'I\\'ve searched a lot but I still have a problem with the static files (css, image,...) with my django website.\\n\\nI\\'m using mod_wsgi with apache on archlinux 64bits\\n\\nI\\'ve added it in my http.conf : \\n\\nLoadModule wsgi_module modules/mod_wsgi.so\\n\\n<VirtualHost *:80>\\n    WSGIDaemonProcess mart.localhost user=mart group=users processes=2 threads=25\\n    WSGIProcessGroup mart.localhost\\n    LogLevel debug\\n\\n    Alias /media /home/mart/programmation/python/django/martfiles/media/\\n    <Directory /home/mart/programmation/python/django/martfiles/>\\n        Order allow,deny\\n        Allow from all\\n    </Directory>\\n\\n    WSGIScriptAlias / /srv/http/wsgi-scripts/django.wsgi\\n</VirtualHost>\\n\\n\\nI tried to use the django.wsgi in my home folder but it doesn\\'t work (permission denied to access /) (strangely it works if I use the test script given here)\\n\\nall the directories and content (apache folder, wsgi-script, martfiles) have the permission 775 root:devusers with the group devusers including my user, http and root\\n\\nin my template base.html, I call the css this way :\\n\\n <html>  <head>\\n     <link rel=\"stylesheet\" href=\"/media/css/style.css\" />\\n\\n\\nand the error in /var/log/http/error.log\\n\\n [Sat Jan 16 13:22:21 2010] [error] [client 127.0.0.1] (13)Permission denied: access to /media/css/style.css denied, referer: http://localhost/\\n [Sat Jan 16 13:22:21 2010] [info] mod_wsgi (pid=14783): Attach interpreter \\'\\'\\n\\n\\n/etc/httpd/conf/http.conf\\n\\n/srv/http/wsgi-script/django.wsgi\\n\\n/home/.../martfiles/settings.py\\n\\nthank you\\n\\n\\n\\nedit : I precise that my django website is working fine (except the sessions but I don\\'t think it\\'s related) so I\\'m not sure it\\'s related to the django.wsgi file (maybe I\\'m wrong) but what is sure is that I should be able to use the django.wsgi from outside the apache folder\\n\\nif I change the line Alias /media /home/mart/programmation/python/django/martfiles/media/ with Alias /media /srv/http/media/ and gives the right permissions, it works. But I don\\'t want (and shouldn\\'t) to put all my media in the apache folder\\n',\n  'completion': \"It is not sufficient for just the directory '/home/mart/programmation/python/django/martfiles/media' containing static files to be readable and searchable. The user that Apache runs as must have read and potentially search access, to all parent directories of it back up to root directory. Since home directories on many systems are 'rwx------' this would deny Apache access irrespective of the Deny/Allow directives in Apache configuration.\\n\\nSuggest you place the Django project and static files outside of your home account somewhere and relax the file system permissions as necessary.\\n\"},\n {'prompt': 'I write scientific software in Numpy/Scipy/Matplotlib. Having developed applications on my home computer, I am now interested in writing simple web applications. Example: user uploads image or audio file, my program processes it using Numpy/Scipy, and output is displayed on the browser using Matplotlib, or perhaps the user can download a processed file. \\n\\nI already pay for hosting that does have Python 2.4.3 installed, but no Numpy/Scipy. I don\\'t have shell access via command line, either. Just drag-and-drop FTP. Pretty limited, but I can get simple Python/CGI scripts working.\\n\\nSurprisingly, a web search revealed few suitable options for web hosting with these capabilities already built in. (Please guide me if I am wrong.) I am learning about the Google App Engine, but I still don\\'t have a full understanding about its tools and limitations. What the web did tell me is that others have similar concerns.\\n\\nHoping for solutions, I thought I would ask these simple questions to the awesome SO community:\\n\\n\\nIs there a simple way of installing numpy (or any third-party package/library) onto my already hosted space? I know the Python path on my hosted space, and I know the relevant Python/Numpy directories on my home computer. Can I simply copy files over and have it work? Both local and remote systems run Ubuntu.\\nWhat hosting sites exist (either free or paid) which have Numpy/Matplotlib installed or, if not installed, the possibility of installing it? Are there any documented sites that you can reference with working applications, no matter how simple? \\nCan Google App Engine help me in any way? Or is it totally for something else? Have you or others used it to write scientific applications in Python/Numpy? If so, could you reference them?\\n\\n\\nThank you for your help.\\n\\nEDIT: After the useful answers below, I bought the $20 plan at Slicehost, and I love it so far! (I first tried Amazon EC2. I must be stupid, but I just couldn\\'t get it to work.) Setting up the Ubuntu server with Apache took mere hours (and I\\'m an Apache novice). It allows me to do exactly what I wanted with Python plus much more. I now have my own remote repository for version control, too. Thanks again!\\n\\nEDIT 2: Nearly two years later, I tried Linode and EC2 (again). Linode is great. EC2 seemed easier this time around -- maybe it\\'s just added experience, or maybe it\\'s the improvements that Amazon made to the AWS management console. For those interested in Numpy/Scipy/Matplotlib/Audiolab, here is my Ubuntu cheat sheet whenever I launch an EC2 instance:\\n\\nec2:~$ sudo aptitude install build-essential python-scipy ipython \\n       python-matplotlib python-dev python-setuptools libsndfile-dev \\n       libasound2-dev mysql-server python-mysqldb \\n\\nUpload scikits.audiolab-0.11.0\\n\\nec2:~/scikits.audiolab-0.11.0$ sudo python setup.py install\\n\\nec2:~$ sudo rm -rf scikits.audiolab-0.11.0\\n\\nec2:~$ nano .ipython/ipy_user_conf.py\\n\\nip.ex(\\'import matplotlib; matplotlib.use(\"Agg\"); import scipy, pylab, \\n       scipy.signal as sig, scipy.linalg as lin, scipy.sparse as spar, \\n       os, sys, MySQLdb, boto; from scikits import audiolab\\')\\n\\nimport ipy_greedycompleter\\n\\nimport ipy_autoreload\\n\\n',\n  'completion': \"1: Installing third party packages to hosted spaces \\n\\nYou can indeed install third party packages to your hosted space. If it's a pure python package, all that's needed is to unpack it to a directory and then add that directory to your PYTHONPATH environment variable or sys.path.\\n\\nThis can be tiring to do often, and won't work easily for compiled modules. If you have shell access to your python host, the excellent virtualenv package allows you to do set up a private python environment with its own libraries.\\n\\nTo set up your virtualenv, you'll do something like this at the shell:\\n\\n$ virtualenv $HOME/my_python\\n$ $HOME/my_python/bin/easy_install numpy\\n\\n\\nYou can keep running easy_install for anything else you want to install in your personal python environment.\\n\\nNow, when you write your python scripts, you will want to use your private python interpreter, if that is possible:\\n\\n#!/home/myuser/my_python/bin/python\\n\\nimport numpy\\n\\n# script here\\n\\n\\nIf your python env cannot be specified (such as if run by mod_wsgi), you will need to add it to the import path:\\n\\nimport sys\\nsys.path.insert(0, '/home/myuser/my_python/lib/python2.5/site-packages')\\n\\nimport numpy\\n\\n\\n2: Hosting sites with numpy\\n\\nI can't think of any hosting sites offhand which offer numpy pre-installed. However, Dreamhost/Bluehost for sharedhosts provide SSH access, and with shell access you can install numpy using the methods I described above.  Any Virtual Private Server such as Linode/Slicehost will allow you to install whatever you desire, as well.\\n\\n3: AppEngine\\n\\nAs mentioned above, AppEngine will not allow you to install C extensions (but pure python ones do work) so it's unlikely numpy will work for you on there, since I suspect some of its features use C speedups.\\n\"},\n {'prompt': \"I'm having troubles with the multiprocessing module. I'm using a Pool of workers with its map method to load data from lots of files and for each of them I analyze data with with a custom function. Each time a file has been processed I would like to have a counter updated so that I can keep track of how many files remains to be processed. \\nHere is sample code:\\n\\ndef analyze_data( args ):\\n    # do something \\n    counter += 1\\n    print counter\\n\\n\\nif __name__ == '__main__':\\n\\n    list_of_files = os.listdir(some_directory)\\n\\n    global counter\\n    counter = 0\\n\\n    p = Pool()\\n    p.map(analyze_data, list_of_files)\\n\\n\\nI can't find a solution for this.\\n\",\n  'completion': \"The problem is that the counter variable is not shared between your processes: each separate process is creating it's own local instance and incrementing that.\\n\\nSee this section of the documentation for some techniques you can employ to share state between your processes.  In your case you might want to share a Value instance between your workers\\n\\nHere's a working version of your example (with some dummy input data).  Note it uses global values which I would really try to avoid in practice:\\n\\nfrom multiprocessing import Pool, Value\\nfrom time import sleep\\n\\ncounter = None\\n\\ndef init(args):\\n    ''' store the counter for later use '''\\n    global counter\\n    counter = args\\n\\ndef analyze_data(args):\\n    ''' increment the global counter, do something with the input '''\\n    global counter\\n    # += operation is not atomic, so we need to get a lock:\\n    with counter.value.get_lock():\\n        counter.value += 1\\n    print counter.value\\n    return args * 10\\n\\nif __name__ == '__main__':\\n    #inputs = os.listdir(some_directory)\\n\\n    #\\n    # initialize a cross-process counter and the input lists\\n    #\\n    counter = Value('i', 0)\\n    inputs = [1, 2, 3, 4]\\n\\n    #\\n    # create the pool of workers, ensuring each one receives the counter \\n    # as it starts. \\n    #\\n    p = Pool(initializer = init, initargs = (counter, ))\\n    i = p.map_async(analyze_data, inputs, chunksize = 1)\\n    i.wait()\\n    print i.get()\\n\\n\"},\n {'prompt': \"While asking this question, I realized I didn't know much about raw strings. For somebody claiming to be a Django trainer, this sucks.\\n\\nI know what an encoding is, and I know what u alone does since I get what is Unicode.\\n\\nBut what does r do exactly? What kind of string does it result in?\\n\\nAnd above all, what the heck does ur do?\\n\\nFinally, is there any reliable way to go back from a Unicode string to a simple raw string?\\n\\nAh, and by the way, if your system and your text editor charset are set to UTF-8, does u actually do anything?\\n\",\n  'completion': 'There\\'s not really any \"raw string\"; there are raw string literals, which are exactly the string literals marked by a \\'r\\' before the opening quote.\\n\\nA \"raw string literal\" is a slightly different syntax for a string literal, in which a backslash, \\\\, is taken as meaning \"just a backslash\" (except when it comes right before a quote that would otherwise terminate the literal) -- no \"escape sequences\" to represent newlines, tabs, backspaces, form-feeds, and so on.  In normal string literals, each backslash must be doubled up to avoid being taken as the start of an escape sequence.\\n\\nThis syntax variant exists mostly because the syntax of regular expression patterns is heavy with backslashes (but never at the end, so the \"except\" clause above doesn\\'t matter) and it looks a bit better when you avoid doubling up each of them -- that\\'s all.  It also gained some popularity to express native Windows file paths (with backslashes instead of regular slashes like on other platforms), but that\\'s very rarely needed (since normal slashes mostly work fine on Windows too) and imperfect (due to the \"except\" clause above).\\n\\nr\\'...\\' is a byte string (in Python 2.*), ur\\'...\\' is a Unicode string (again, in Python 2.*), and any of the other three kinds of quoting also produces exactly the same types of strings (so for example r\\'...\\', r\\'\\'\\'...\\'\\'\\', r\"...\", r\"\"\"...\"\"\" are all byte strings, and so on).\\n\\nNot sure what you mean by \"going back\" - there is no intrinsically back and forward directions, because there\\'s no raw string type, it\\'s just an alternative syntax to express perfectly normal string objects, byte or unicode as they may be.\\n\\nAnd yes, in Python 2.*, u\\'...\\' is of course always distinct from just \\'...\\' -- the former is a unicode string, the latter is a byte string. What encoding the literal might be expressed in is a completely orthogonal issue.\\n\\nE.g., consider (Python 2.6):\\n\\n>>> sys.getsizeof(\\'ciao\\')\\n28\\n>>> sys.getsizeof(u\\'ciao\\')\\n34\\n\\n\\nthe Unicode object of course takes more memory space (very small difference for a very short string, obviously;-).\\n'},\n {'prompt': 'I am trying to grab stdout from a subprocess,Popen call and although I am achieving this easily by doing:\\n\\ncmd = subprocess.Popen(\\'ls -l\\', shell=True, stdout=PIPE)\\nfor line in cmd.stdout.readlines():\\n    print line\\n\\n\\nI would like to grab stdout in \"real time\". With the above method, PIPE is waiting to grab all the stdout and then it returns.\\n\\nSo for logging purposes, this doesn\\'t meet my requirements (e.g. \"see\" what is going on while it happens).\\n\\nIs there a way to get line by line, stdout while is running? Or is this a limitation of subprocess (having to wait until the PIPE closes).\\n\\nEDIT\\nIf I switch readlines() for readline() I only get the last line of the stdout (not ideal):\\n\\nIn [75]: cmd = Popen(\\'ls -l\\', shell=True, stdout=PIPE)\\nIn [76]: for i in cmd.stdout.readline(): print i\\n....: \\nt\\no\\nt\\na\\nl\\n\\n1\\n0\\n4\\n\\n\\nThanks!\\n',\n  'completion': 'Your interpreter is buffering. Add a call to sys.stdout.flush() after your print statement.\\n'},\n {'prompt': 'I\\'m parsing some HTML with Beautiful Soup 3, but it contains HTML entities which Beautiful Soup 3 doesn\\'t automatically decode for me:\\n\\n>>> from BeautifulSoup import BeautifulSoup\\n\\n>>> soup = BeautifulSoup(\"<p>&pound;682m</p>\")\\n>>> text = soup.find(\"p\").string\\n\\n>>> print text\\n&pound;682m\\n\\n\\nHow can I decode the HTML entities in text to get \"Â£682m\" instead of \"&pound;682m\".\\n',\n  'completion': \"Python 3.4+\\n\\nHTMLParser.unescape is deprecated, and was supposed to be removed in 3.5, although it was left in by mistake. It will be removed from the language soon. Instead, use html.unescape():\\n\\nimport html\\nprint(html.unescape('&pound;682m'))\\n\\n\\nsee https://docs.python.org/3/library/html.html#html.unescape\\n\\n\\n\\nPython 2.6-3.3\\n\\nYou can use the HTML parser from the standard library:\\n\\n>>> try:\\n...     # Python 2.6-2.7 \\n...     from HTMLParser import HTMLParser\\n... except ImportError:\\n...     # Python 3\\n...     from html.parser import HTMLParser\\n... \\n>>> h = HTMLParser()\\n>>> print(h.unescape('&pound;682m'))\\nÂ£682m\\n\\n\\nSee http://docs.python.org/2/library/htmlparser.html\\n\\nYou can also use the six compatibility library to simplify the import:\\n\\n>>> from six.moves.html_parser import HTMLParser\\n>>> h = HTMLParser()\\n>>> print(h.unescape('&pound;682m'))\\nÂ£682m\\n\\n\"},\n {'prompt': \"If I'm absolutely new to Python and am literally reading about printing statements to console, variable types, collections, etc:\\n\\n\\n  What version of Python should I use?\\n\\n\\nI'm aware that there is an abundance of 3rd party libraries for Python 2.6.x, but I'm scared I'll learn some things that won't carry over well into Python 3.\\n\\nFor example, in Python 3 you can use input(), in Python 2 you have to use raw_input().\\n\\nThank you very much for the information.\\n\",\n  'completion': \"Python 2.6 (and 2.5, 2.4) are what you will find installed on most machines (Linux) and what you will find most code written in.  Therefore I'd start with Python 2.6.\\n\"},\n {'prompt': 'What do I need to do (modules to load, locale methods to invoke, etc.) so that when I call:\\n\\ndatetime.date(2009,1,16).strftime(\"%A %Y-%b-%d\")\\n\\n\\ninstead of getting:\\n\\nOut[20]: \\'Friday 2009-Jan-16\\'\\n\\n\\ni get spanish/french/german/... output\\n\\nOut[20]: \\'Viernes 2009-Ene-16\\'\\n\\n\\nwithout having to change my whole operating system\\'s locale (i.e. just use python calls to dynamically set the locale and keep the changes scoped within my app)\\n\\nThanks.\\n\\n\\n',\n  'completion': 'locale.setlocale()\\n'},\n {'prompt': 'In visual studio, I could just press ctrl+spacekey and the methods appeared. In Geany is there a way for me to get this functionality?\\n',\n  'completion': 'No, because is Python is dynamically typed language and quite hard to achieve that. Python plugins for netbeans do that partially, but I believe such plugin is not in geany developers plans. There are different things to be done ;-)\\n\\nHowever, geany provides some completions support. First, it analyzes your imports in a file and uses it in completions; furthermore it completes functions from the std library. It also analyzes all you open files for suggestions, although you may need to apply it in preferences. Also you can get call tips, when you hit Ctrl+Shift+Space, which not everyone know about. They are quite good, because they appear in form <Class>.<method>(<args>), which is very helpful.\\n'},\n {'prompt': 'Every time I log on to my server through SSH I need to type the following:\\n\\nexport DJANGO_SETTINGS_MODULE=settings\\n\\n\\nif I do not any usage of the manage.py module fails\\n\\nMy manage.py has the following added code:\\n\\nif \"notification\" in settings.INSTALLED_APPS:\\n    from notification import models as notification\\n\\n    def create_notice_types(app, created_models, verbosity, **kwargs):\\n        notification.create_notice_type(\"friends_invite\", _(\"Invitation Received\"), _(\"you have received an invitation\"))\\n        notification.create_notice_type(\"friends_accept\", _(\"Acceptance Received\"), _(\"an invitation you sent has been accepted\"))\\n\\n    signals.post_syncdb.connect(create_notice_types, sender=notification)\\nelse:\\n    print \"Skipping creation of NoticeTypes as notification app not found\"\\n\\n\\nAny ideas?\\n',\n  'completion': \"Yourmanage.py is referencing an application (notifications). This forces Django to complain about DJANGO_SETTINGS_MODULE being set because the Django environment hasn't been set up yet.\\n\\nIncidentally, you can force the enviroment setup manually, but honestly I wouldn't do this in manage.py.  That's not really a good practice in my opinion.\\n\\nHere is how you can manually setup the Django environment from within any app (or program for that matter):\\n\\n# set up the environment using the settings module\\nfrom django.core.management import setup_environ\\nfrom myapp import settings\\nsetup_environ(settings)\\n\\n\"},\n {'prompt': 'I am writing a Python script in Windows. I want to do something based on the file size. For example, if the size is greater than 0, I will send an email to somebody, otherwise continue to other things. \\n\\nHow do I check the file size?\\n',\n  'completion': 'Like this (credit http://www.daniweb.com/forums/thread78629.html):\\n\\n>>> import os\\n>>> b = os.path.getsize(\"/path/isa_005.mp3\")\\n>>> b\\n2071611L\\n\\n'},\n {'prompt': \"Say I have this simple python script:\\n\\nfile = open('C:\\\\\\\\some_text.txt')\\nprint file.readlines()\\nprint file.readlines()\\n\\n\\nWhen it is run, the first print prints a list containing the text of the file, while the second print prints a blank list. Not completely unexpected I guess. But is there a way to 'wind back' the file so that I can read it again? Or is the fastest way just to re-open it?\\n\",\n  'completion': 'You can reset the file pointer by calling seek():\\n\\nfile.seek(0)\\n\\n\\nwill do it.  You need that line after your first readlines().  Note that file has to support random access for the above to work.\\n'},\n {'prompt': 'I\\'m developing in Python using PyDev in Eclipse, and some of my code generates errors in the code analysis tool.  Specifically:\\n\\nclass Group(object):\\n    def key(self, k):\\n        class Subkey(object):\\n            def __enter__(s):\\n                self._settings.beginGroup(k)\\n                return self\\n\\n            def __exit__(s, type, value, tb):\\n                self._settings.endGroup()\\n\\n         return Subkey()\\n\\n\\nGives me a \"Method \\'__enter__- group\\' should have self as first parameter\" error, and a similar error for __exit__.  Is there a way to solve this without assigning self to another variable and reusing the variable in the other method signatures?\\n',\n  'completion': \"You could disable that error in the preferences...\\n\\nWindow > Preferences > Pydev > Editor > Code Analysis > Others\\n\\n\\nOr refactor the code...\\n\\nclass Group(object):\\n    def key(self, k):\\n        outer_self = self\\n        class Subkey(object):\\n            def __enter__(self):\\n                outer_self._settings.beginGroup(k)\\n                return outer_self\\n\\n            def __exit__(self, type, value, tb):\\n                outer_self._settings.endGroup()\\n\\n         return Subkey()\\n\\n\\nWhat else do you expect?  The error checks are there to help you.  If you don't think they're legitimate errors, disable them or refactor the code.\\n\\nIn this case I'd say refactor the code.  It's more readable, as evidenced by King Radical's answer.  He didn't understand that s was another self.\\n\"},\n {'prompt': 'Is there a way to use a real database(SQLite, Mysql, or even some non-relational one) as  datastore for development, instead of memory/file datastore that is provided.\\n\\nI saw few projects, GAE-SQLite(did not seem to be working) and one tip about accessing production datastore using remote api (still pretty slow for large datasets).\\n',\n  'completion': \"MongoDB works great for that. You will need:\\n\\n\\nThe MongoDB stub: http://github.com/mongodb/mongo-appengine-connector\\nMongoDB: http://www.mongodb.org/display/DOCS/Downloads\\nSome code to set it up like:\\n\\n\\ncode:\\n\\nimport datastore_mongo_stub\\n\\nos.environ['APPLICATION_ID'] = 'test'\\n\\ndatastore = datastore_mongo_stub.DatastoreMongoStub(\\n    os.environ['APPLICATION_ID'], 'woot', '', require_indexes=False)\\n\\napiproxy_stub_map.apiproxy.RegisterStub('datastore_v3', datastore)\\n\\n\\nBut if you're looking for truly faster development (like I was) the datastore is actually not the issue as much is the single threaded web server. I tried to replace it with spawning  but that was a little too hard. You could also try to set up TyphoonAE which will mimic the appengine stack with open alternatives. \\n\\nBe aware that if you do any of these, you might lose some of the exact behavior the current tools provide, meaning that if you deploy you could get results you didn't expect. In other words; make sure you know what you're doing :-)\\n\"},\n {'prompt': 'Option 1:\\n\\ndef f1(c):\\n  d = {\\n    \"USA\": \"N.Y.\",\\n    \"China\": \"Shanghai\"\\n  }\\n\\n  if c in d:\\n    return d[c]\\n\\n  return \"N/A\"\\n\\n\\nOption 2:\\n\\ndef f2(c):\\n  d = {\\n    \"USA\": \"N.Y.\",\\n    \"China\": \"Shanghai\"\\n  }\\n\\n  try:\\n    return d[c]\\n  except:\\n    return \"N/A\"\\n\\n\\nSo that I can then call:\\n\\nfor c in (\"China\", \"Japan\"):\\n  for f in (f1, f2):\\n    print \"%s => %s\" % (c, f(c))\\n\\n\\nThe options are to either determine whether the key is in directory before hand (f1), or just fallback to the exception (f2). Which one is preferred? Why?\\n',\n  'completion': 'Neither, I would go for\\n\\ndef f2(c):\\n  d = {\\n    \"USA\": \"N.Y.\",\\n    \"China\": \"Shanghai\"\\n  }\\n\\n  return d.get(c, \"N/A\")\\n\\n\\nThis way is shorter and \"get\" is designed for the job.\\n\\nAlso an except without an explicit exception is bad pratice, so use except KeyError: not just except. \\n\\nExceptions do not have much overhead in python.  It is generally better to use them if there are not better alternatives or sometimes even when it saves an attribute lookup (to use instead of hasattr). \\n\\nEdit: to clear up general point about exceptions. \\n\\npaxdiablo is correct on the general point. Python is mainly designed for \"its easier to ask forgivness then permission\" i.e try then see what fails (exceptions), then \"look before you leap\" see whats there and then apply.  This is because attribute lookup in python can be expensive, so calling the same stuff again (to check boundries) is a waste of resources. However, internal stuff in python has normally got nicer helpers so its better to use them.\\n'},\n {'prompt': 'Pony references are in several places:\\n\\n\\nhttp://www.mail-archive.com/python-dev@python.org/msg44751.html\\nhttp://pypi.python.org/pypi/django-pony/\\nhttp://djangopony.com/\\n\\n\\nIs there a cultural reference that I am missing? What is the deal with ponies?\\n',\n  'completion': 'When you start listing what you want, \"I want a fast HTTP parser\", \"I want ORM that just works\", \"I want higher order functions\", the idea is that while you\\'re wishing for things, you might as well wish for a pony too.  This is probably a reference to a Calvin and Hobbes strip from \"Someone under the bed is drooling\", in which Susie Derkins says that as long as she\\'s dreaming, she might as well wish for a pony.\\n'},\n {'prompt': \"httplib (now http.client) and friends all have conn.getresponse() and an HTTPResponse class, but the server-side operations of conn.getrequest() and an HTTPRequest class seem to be lacking.\\n\\nI understand that BaseHTTPServer and BaseHTTPRequestHandler can perform this functionality, but they don't expose these methods for use outside of the module.\\n\\nEssentially what I want is BaseHTTPRequestHandler#parse_request to be a static method that returns an HTTPRequest object rather than populating member variables.\\n\",\n  'completion': 'Jeff, to enable parsing I create a small nine-line subclass of the base HTTP request handler:\\n\\nfrom BaseHTTPServer import BaseHTTPRequestHandler\\nfrom StringIO import StringIO\\n\\nclass HTTPRequest(BaseHTTPRequestHandler):\\n    def __init__(self, request_text):\\n        self.rfile = StringIO(request_text)\\n        self.raw_requestline = self.rfile.readline()\\n        self.error_code = self.error_message = None\\n        self.parse_request()\\n\\n    def send_error(self, code, message):\\n        self.error_code = code\\n        self.error_message = message\\n\\n\\nYou can now take a string with the text of an HTTP request inside and parse it by instantiating this class:\\n\\n# Simply instantiate this class with the request text\\n\\nrequest = HTTPRequest(request_text)\\n\\nprint request.error_code       # None  (check this first)\\nprint request.command          # \"GET\"\\nprint request.path             # \"/who/ken/trust.html\"\\nprint request.request_version  # \"HTTP/1.1\"\\nprint len(request.headers)     # 3\\nprint request.headers.keys()   # [\\'accept-charset\\', \\'host\\', \\'accept\\']\\nprint request.headers[\\'host\\']  # \"cm.bell-labs.com\"\\n\\n# Parsing can result in an error code and message\\n\\nrequest = HTTPRequest(\\'GET\\\\r\\\\nHeader: Value\\\\r\\\\n\\\\r\\\\n\\')\\n\\nprint request.error_code     # 400\\nprint request.error_message  # \"Bad request syntax (\\'GET\\')\"\\n\\n'},\n {'prompt': 'public interface IInterface\\n{\\n    void show();\\n}\\n\\n public class MyClass : IInterface\\n{\\n\\n    #region IInterface Members\\n\\n    public void show()\\n    {\\n        Console.WriteLine(\"Hello World!\");\\n    }\\n\\n    #endregion\\n}\\n\\n\\nHow do I implement Python equivalent of this C# code ?\\n\\nclass IInterface(object):\\n    def __init__(self):\\n        pass\\n\\n    def show(self):\\n        raise Exception(\"NotImplementedException\")\\n\\n\\nclass MyClass(IInterface):\\n   def __init__(self):\\n       IInterface.__init__(self)\\n\\n   def show(self):\\n       print \\'Hello World!\\'\\n\\n\\nIs this a good idea?? Please give examples in your answers.\\n',\n  'completion': \"As mentioned by other here:\\n\\nInterfaces is not necessary in Python. This is because Python has proper multiple inheritance, and also ducktyping, which means that the places where you must have interfaces in Java, you don't have to have them in Python.\\n\\nThat said, there is still several uses of interfaces. Some of them are covered by Pythons Abstract Base Classes, introduced in Python 2.6. That's useful if you want to make baseclasses that can not be instantiated, but provide a specific interface or part of an implementation.\\n\\nAnother usage is if you somehow want to specify that an object implements a specific interface, and you can use ABC's for that too by subclassing from them. Another way is zope.interface, a module that is a part of the Zope Component Architecture, a really awesomely cool component framework. Here you don't subclass from the interfaces, but instead mark classes (or even instances) as implementing an interface. This can also be used to look up components from a component registry. Supercool!\\n\"},\n {'prompt': \"I'm coding a small application with Django. But I can't see any error logs in the console when an error (e.g. Python syntax error, etc.) occurs in one of my views -no action at all.\\n\\nHow can I see the error logs of my views? Debugging like a blind is really annoying.\\n\",\n  'completion': 'Django does not print any errors to the console by default. Instead it provides very helpful error pages that are displayed for any errors that occur in your views. Please check what your DEBUG setting is set to. In development this should be True which will give you the nice error pages for 404 and 500 errors.\\n\\nThe pretty error page will look like this:\\n\\n\\nI can also recommend the talk What the Heck Went Wrong? from DjangoCon2009 for some more information on basic debugging technics with django.\\n'},\n {'prompt': \"I have a Django project and I'm trying to use Celery to submit tasks for background processing ( http://ask.github.com/celery/introduction.html ). Celery integrates well with Django and I've been able to submit my custom tasks and get back results.\\n\\nThe only problem is that I can't find a sane way of performing custom initialization in the daemon process. I need to call an expensive function that loads a lot of memory before I start processing the tasks, and I can't afford to call that function every time.\\n\\nHas anyone had this problem before? Any ideas how to work around it without modifying the Celery source code?\\n\\nThanks\\n\",\n  'completion': \"You can either write a custom loader, or use the signals.\\n\\nLoaders have the on_task_init method, which is called when a task is about to be executed,\\nand on_worker_init which is called by the celery+celerybeat main process.\\n\\nUsing signals is probably the easiest, the signals available are:\\n\\n0.8.x:\\n\\n\\ntask_prerun(task_id, task, args, kwargs)\\n\\nDispatched when a task is about to be executed by the worker (or locally\\nif using apply/or if CELERY_ALWAYS_EAGER has been set). \\ntask_postrun(task_id, task, args, kwargs, retval)\\nDispatched after a task has been executed in the same conditions as above.\\ntask_sent(task_id, task, args, kwargs, eta, taskset)\\n\\nCalled when a task is applied (not good for long-running operations)\\n\\n\\nAdditional signals available in 0.9.x (current master branch on github):\\n\\n\\nworker_init()\\n\\nCalled when celeryd has started (before the task is initialized, so if on a\\nsystem supporting fork, any memory changes would be copied to the child\\nworker processes).\\nworker_ready()\\n\\nCalled when celeryd is able to receive tasks.\\nworker_shutdown()\\n\\nCalled when celeryd is shutting down.\\n\\n\\nHere's an example precalculating something the first time a task is run in the process:\\n\\nfrom celery.task import Task\\nfrom celery.registry import tasks\\nfrom celery.signals import task_prerun\\n\\n_precalc_table = {}\\n\\nclass PowersOfTwo(Task):\\n\\n    def run(self, x):\\n        if x in _precalc_table:\\n            return _precalc_table[x]\\n        else:\\n            return x ** 2\\ntasks.register(PowersOfTwo)\\n\\n\\ndef _precalc_numbers(**kwargs):\\n    if not _precalc_table: # it's empty, so haven't been generated yet\\n        for i in range(1024):\\n            _precalc_table[i] = i ** 2\\n\\n\\n# need to use registered instance for sender argument.\\ntask_prerun.connect(_precalc_numbers, sender=tasks[PowerOfTwo.name])\\n\\n\\nIf you want the function to be run for all tasks, just skip the sender argument.\\n\"},\n {'prompt': \"I'm trying to create a game for my little sister. It is a Virtual Pet sort of thing and the Pet has toys to play with.\\n\\nI created a class Toy and want to create a function, getNewToy(name, data1, data2, data3, data4, data5).\\n\\nI want this function to create a new instance of the class Toy, and I want the function to be able to be called multiple times each time creating a new instance.\\n\\nIn my experience you create an instance with:\\n\\nclass Toy:\\n    def __init__(self, name, data1, data2, data3, data4, data5):\\n        pass\\n\\nmyToy = Toy(myToy, 1, 2, 3, 4, 5)\\n\\n\\nthen to use methods from the class with:\\n\\nmyToy.method1()\\n\\n\\nSeeing as I want to have the ability to have multiple toys, each with a playWith() method I want the instance to reflect the name of the Toy each time one is called.\\n\\nI want the instance to be different each time I call the method getNewToy(,...) and the instance to reflect the name.\\n\",\n  'completion': 'Given your edit i assume you have the class name as a string and want to instantiate the class? Just use a dictionary as a dispatcher.\\n\\nclass Foo(object):\\n    pass\\n\\nclass Bar(object):\\n    pass\\n\\ndispatch_dict = {\"Foo\": Foo, \"Bar\": Bar}\\ndispatch_dict[\"Foo\"]() # returns an instance of Foo\\n\\n'},\n {'prompt': 'Is there any way to write unittests or doctests for innerfunc?\\n\\ndef outerfunc():\\n    def innerfunc():\\n        do_something()\\n    return innerfunc()\\n\\n',\n  'completion': 'Only if you provide a way to extract the inner function object itself, e.g.\\n\\ndef outerfunc(calltheinner=True):\\n    def innerfunc():\\n        do_something()\\n    if calltheinner:\\n        return innerfunc()\\n    else:\\n        return innerfunc\\n\\n\\nIf your outer function insists on hiding the inner one entirely inside itself (never letting it percolate outside when properly cajoled to do so), your unit-tests are powerless to defeat this strong bid for extreme and total privacy;-).\\n'},\n {'prompt': \"I want to restrict access to urls serves by django generic views. For my views i know that login_required decorator does the job. Also Create/update/delete generic views takes login_requied argument but I couldn't find a way to do this for other generic views. \\n\",\n  'completion': \"For Django < 1.5, you can add a decorator by wrapping the function in your urls, which allows you to wrap the generic views:\\n\\nfrom django.contrib.auth.decorators import login_required\\nfrom django.views.generic.simple import direct_to_template\\nurlpatterns = patterns('',\\n    (r'^foo/$', login_required(direct_to_template), {'template': 'foo_index.html'}),\\n    )\\n\\n\\nThe function-based generic views are deprecated in Django 1.4 and were removed in Django 1.5. But the same principle applies, just wrap the view function of the class based view with the login_required decorator:\\n\\nlogin_required(TemplateView.as_view(template_name='foo_index.html'))\\n\\n\"},\n {'prompt': 'I did this to test the randomness of randint:\\n\\n>>> from random import randint\\n>>>\\n>>> uniques = []\\n>>> for i in range(4500):  # You can see I was optimistic.\\n...     x = randint(500, 5000)\\n...     if x in uniques:\\n...         raise Exception(\\'We duped %d at iteration number %d\\' % (x, i))\\n...     uniques.append(x)\\n...\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 4, in <module>\\nException: We duped 887 at iteration number 7\\n\\n\\nI tried about 10 times more and the best result I got was 121 iterations before a repeater. Is this the best sort of result you can get from the standard library?\\n',\n  'completion': \"The Birthday Paradox, or why PRNGs produce duplicates more often than you might think.\\n\\nThere are a couple of issues at play in the OP's problem.  One is the birthday paradox as mentioned above and the second is the nature of what you are generating, which does not inherently guarantee that a given number will not be repeated.  \\n\\nThe Birthday Paradox applies where given value can occur more than once during the period of the generator - and therefore duplicates can happen within a sample of values.  The effect of the Birthday Paradox is that the real likelihood of getting such duplicates is quite significant and the average period between them is smaller than one might otherwise have thought.  This dissonance between the percived and actual probabilities makes the Birthday Paradox a good example example of a cognitive bias, where a naive intuitive estimate is likely to be wildly wrong.\\n\\nA quick primer on Pseudo Random Number Generators (PRNGs)\\n\\nThe first part of your problem is that you are taking the exposed value of a random number generator and converting it to a much smaller number, so the space of possible values is reduced.  Although some pseudo-random number generators do not repeat values during their period this transformation changes the domain to a much smaller one.  The smaller domain invalidates the 'no repeats' condition so you can expect a significant likelihood of repeats.   \\n\\nSome algorithms, such as the linear congruential PRNG (A'=AX|M) do guarantee uniqueness for the entire period.  In a LCG the generated value contains the entire state of the accumulator and no additional state is held.  The generator is deterministic and cannot repeat a number within the period - any given accumulator value can imply only one possible successive value.  Therefore, each value can only occur once within the period of the generator.  However, the period of such a PRNG is relatively small - about 2^30 for typical implementations of the LCG algorithm - and cannot possibly be larger than the number of distinct values.\\n\\nNot all PRNG algorithms share this characteristic; some can repeat a given value within the period.  In the OP's problem the Mersenne Twister algorithm (used in Python's random module) has a very long period - much greater than 2^32.   Unlike a Linear Congruential PRNG, the result is not purely a function of the previous output value as the accumulator contains additional state.  With 32 bit integer output and a period of ~2^19937 it cannot possibly provide a such a guarantee.  \\n\\nThe Mersenne Twister is a popular algorithm for PRNGs because it has good statistical and geometric properties and a very long period - desirable characteristics for a PRNG used on simulation models.   \\n\\n\\nGood statistical properties mean that the numbers generated by the algorithm are evenly distributed with no numbers having a significantly higher probability of appearing than others.  Poor statistical properties could produce unwanted skew in the results.\\nGood geometric properies mean that sets of N numbers do not lie on a hyperplane in N dimensional space.  Poor geometric properties can generate spurious correlations in a simulation model and distort the results.\\nA long period means that you can generate a lot of numbers before the sequence wraps around to the start.  If a model needs a large number of iterations or has to be run from several seeds then the 2^30 or so discrete numbers available from a typical LCG implementation may not be sufficient.  The MT19337 algorithm has a very long period - 2^19337-1, or about 10^5821.  By comparison the total number of atoms in the universe is estimated at about 10^80.\\n\\n\\nThe 32 bit integer produced by a MT19337 PRNG cannot possibly represent enough discrete values to avoid repeating during such a large period.  In this case duplicate values are likely to occur and inevitable with a large enough sample.  \\n\\nThe Birthday Paradox in a nutshell\\n\\nThis problem is originally defined as the probability of any two people in the room sharing the same birthday.  The key point is that any two people in the room could share a birthday.  People tend to naively misinterpret the problem as the probability of someone in the room sharing a birthday with a specific individual, which is the source of the cognitive bias that often causes people to underestimate the probability.  This is the incorrect assumption - there is no requirement for the match to be to a specific individual and any two individuals could match.  \\n\\n\\n\\nThe probability of a match occurring between any two individuals is much higher than the probability of a match to a specific individual as the match does not have to be to a specific date.  Rather, you only have to find two individuals that share the same birthday.  From this graph (which can be found on the wikipedia page on the subject), we can see that we only need 23 people in the room for there to be a 50% chance of finding two that match in this way.\\n\\nFrom the Wikipedia entry on the subject we can get a nice summary.  In the OP's problem we have 4,500 possible 'birthdays', rather than 365.  For a given number of random values generated (equating to 'people') we want to know the probability of any two identical values appearing within the sequence.  \\n\\nComputing the likely effect of the Birthday Paradox on the OP's problem\\n\\nFor a sequence of 100 numbers, we have  pairs (see Understanding the Problem) that could potentially match (i.e. the first could match with the second, third etc., the second could match the third, fourth etc. and so on), so the number of combinations that could potentially match is rather more than just 100.  \\n\\nFrom Calculating the Probability we get an expression of .  The following snippet of Python code below does a naive evaluation of the probability of a matching pair occurring.  \\n\\n# === birthday.py ===========================================\\n#\\nfrom math import log10, factorial\\n\\nPV=4500          # Number of possible values\\nSS=100           # Sample size\\n\\n# These intermediate results are exceedingly large numbers;\\n# Python automatically starts using bignums behind the scenes.\\n#\\nnumerator = factorial (PV)          \\ndenominator = (PV ** SS) * factorial (PV - SS)\\n\\n# Now we need to get from bignums to floats without intermediate\\n# values too large to cast into a double.  Taking the logs and \\n# subtracting them is equivalent to division.\\n#  \\nlog_prob_no_pair = log10 (numerator) - log10 (denominator)\\n\\n# We've just calculated the log of the probability that *NO*\\n# two matching pairs occur in the sample.  The probability\\n# of at least one collision is 1.0 - the probability that no \\n# matching pairs exist.\\n#\\nprint 1.0 - (10 ** log_prob_no_pair)\\n\\n\\nThis produces a sensible looking result of p=0.669 for a match occuring within 100 numbers sampled from a population of 4500 possible values. (Maybe someone could verify this and post a comment if it's wrong).  From this we can see that the lengths of runs between matching numbers observed by the OP seem to be quite reasonable.\\n\\nFootnote: using shuffling to get a unique sequence of pseudo-random numbers \\n\\nSee this answer below from S. Mark for a means of getting a guaranteed unique set of random numbers.  The technique the poster refers to takes an array of numbers (which you supply, so you can make them unique) and shuffles them into random order.  Drawing the numbers in sequence from the shuffled array will give you a sequence of pseudo-random numbers that are guaranteed not to repeat.\\n\\nFootnote: Cryptographically Secure PRNGs \\n\\nThe MT algorithm is not cryptographically secure as it is relatively easy to infer the internal state of the generator by observing a sequence of numbers.  Other algorithms such as Blum Blum Shub are used for cryptographic applications, but may be unsuitable for simulation or general random number applications.  Cryptographically secure PRNGs may be expensive (perhaps requiring bignum calculations) or may not have good geometric properties.  In the case of this type of algorithm the primary requirement is that it should be computationally infeasible to infer the internal state of the generator by observing a sequence of values.\\n\"},\n {'prompt': 'I\\'m still relatively new to regex. I\\'m trying to find the shortest string of text that matches a particular pattern, but am having trouble if the shortest pattern is a substring of a larger match. For example:\\n\\nimport re\\nstring = \"A|B|A|B|C|D|E|F|G\"\\nmy_pattern = \\'a.*?b.*?c\\'\\n\\nmy_regex = re.compile(my_pattern, re.DOTALL|re.IGNORECASE)\\nmatches = my_regex.findall(string)\\n\\nfor match in matches:\\n    print match\\n\\n\\nprints: \\n\\nA|B|A|B|C\\n\\n\\nbut I\\'d want it to return:\\n\\nA|B|C\\n\\n\\nIs there a way to do this without having to loop over each match to see if it contains a substring that matches? \\n',\n  'completion': \"Contrary to most other answers here, this can be done in a single regex using a positive lookahead assertion with a capturing group:\\n\\n>>> my_pattern = '(?=(a.*?b.*?c))'\\n>>> my_regex = re.compile(my_pattern, re.DOTALL|re.IGNORECASE)\\n>>> matches = my_regex.findall(string)\\n>>> print min(matches, key=len)\\nA|B|C\\n\\n\\nfindall() will return all possible matches, so you need min() to get the shortest one.\\n\\nHow this works:\\n\\n\\nWe're not matching any text in this regex, just positions in the string (which the regex engine steps through during a match attempt). \\nAt each position, the regex engine looks ahead to see whether your regex would match at this position. \\nIf so, it will be captured by the capturing group. \\nIf not, it won't. \\nIn either case, the regex engine then steps ahead one character and repeats the process until the end of the string. \\nSince the lookahead assertion doesn't consume any characters, all overlapping matches will be found.\\n\\n\"},\n {'prompt': \"How would you find the signed angle theta from vector a to b?\\n\\nAnd yes, I know that theta = arccos((a.b)/(|a||b|)).\\n\\nHowever, this does not contain a sign (i.e. it doesn't distinguish between a clockwise or counterclockwise rotation).\\n\\nI need something that can tell me the minimum angle to rotate from a to b. A positive sign indicates a rotation from +x-axis towards +y-axis. Conversely, a negative sign indicates a rotation from +x-axis towards -y-axis.\\n\\nassert angle((1,0),(0,1)) == pi/2.\\nassert angle((0,1),(1,0)) == -pi/2.\\n\\n\",\n  'completion': 'What you want to use is often called the â\\x80\\x9cperp dot productâ\\x80\\x9d, that is, find the vector perpendicular to one of the vectors, and then find the dot product with the other vector.\\n\\nif(a.x*b.y - a.y*b.x < 0)\\n    angle = -angle;\\n\\n\\nYou can also do this:\\n\\nangle = atan2( a.x*b.y - a.y*b.x, a.x*b.x + a.y*b.y );\\n\\n'},\n {'prompt': \"I need to loop over a list of objects, comparing them like this: 0 vs. 1, 1 vs. 2, 2 vs. 3, etc. (I'm using pysvn to extract a list of diffs.) I wound up just looping over an index, but I keep wondering if there's some way to do it which is more closely idiomatic. It's Python; shouldn't I be using iterators in some clever way? Simply looping over the index seems pretty clear, but I wonder if there's a more expressive or concise way to do it.\\n\\nfor revindex in xrange(len(dm_revisions) - 1):\\n    summary = \\\\\\n        svn.diff_summarize(svn_path,\\n                          revision1=dm_revisions[revindex],\\n                          revision2 = dm_revisions[revindex+1])\\n\\n\",\n  'completion': 'This is called a sliding window. There\\'s an example in the itertools documentation that does it. Here\\'s the code:\\n\\nfrom itertools import islice\\n\\ndef window(seq, n=2):\\n    \"Returns a sliding window (of width n) over data from the iterable\"\\n    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\\n    it = iter(seq)\\n    result = tuple(islice(it, n))\\n    if len(result) == n:\\n        yield result    \\n    for elem in it:\\n        result = result[1:] + (elem,)\\n        yield result\\n\\n\\nWhat that, you can say this:\\n\\nfor r1, r2 in window(dm_revisions):\\n    summary = svn.diff_summarize(svn_path, revision1=r1, revision2=r2)\\n\\n\\nOf course you only care about the case where n=2, so you can get away with something much simpler:\\n\\ndef adjacent_pairs(seq):\\n    it = iter(seq)\\n    a = it.next()\\n    for b in it:\\n        yield a, b\\n        a = b\\n\\nfor r1, r2 in adjacent_pairs(dm_revisions):\\n    summary = svn.diff_summarize(svn_path, revision1=r1, revision2=r2)\\n\\n'},\n {'prompt': 'I have a string in unicode and I need to return the first N characters.\\nI am doing this:\\n\\nresult = unistring[:5]\\n\\n\\nbut of course the length of unicode strings != length of characters.\\nAny ideas? The only solution is using re?\\n\\nEdit: More info\\n\\nunistring = \"Î\\x9cÎµÏ\\x84Î±Î»Î»Î¹ÎºÎ±\" #Metallica written in Greek letters\\nresult = unistring[:1]\\n\\n\\nreturns-> ?\\n\\nI think that unicode strings are two bytes (char), that\\'s why this thing happens. If I do:\\n\\nresult = unistring[:2]\\n\\n\\nI get \\n\\nM\\n\\nwhich is correct,\\nSo, should I always slice*2 or should I convert to something?\\n',\n  'completion': 'When you say:\\n\\nunistring = \"Î\\x9cÎµÏ\\x84Î±Î»Î»Î¹ÎºÎ±\" #Metallica written in Greek letters\\n\\n\\nYou do not have a unicode string. You have a bytestring in (presumably) UTF-8. That is not the same thing. A unicode string is a separate datatype in Python. You get unicode by decoding bytestrings using the right encoding:\\n\\nunistring = \"Î\\x9cÎµÏ\\x84Î±Î»Î»Î¹ÎºÎ±\".decode(\\'utf-8\\')\\n\\n\\nor by using the unicode literal in a source file with the right encoding declaration\\n\\n# coding: UTF-8\\nunistring = u\"Î\\x9cÎµÏ\\x84Î±Î»Î»Î¹ÎºÎ±\"\\n\\n\\nThe unicode string will do what you want when you do unistring[:5].\\n'},\n {'prompt': 'I really like the way fakeweb in Ruby can be used to fake http requests when testing. Is there a similar library or an alternative for Python?\\n',\n  'completion': \"See also http://stackoverflow.com/questions/295438/how-can-one-mock-stub-python-module-like-urllib/295503 . The answer that recommends Mox seems the most like fakeweb, but Mox lets you create fake versions of any module, not just urllib.\\n\\nFor incoming requests, if your web framework uses WebOb (repoze.bfg, Pylons others), you can use webob.Request.blank.\\n\\nfrom webob import Request\\nr = Request.blank('/')\\na_view_function(r)\\n\\n\"},\n {'prompt': \"I have a polar (r,theta) grid (which means that each cell is an annulus section) containing values of some physical quantity (e.g. temperature), and I would like to re-grid (or re-project) these values onto a cartesian grid. Are there any Python packages that can do this?\\n\\nI am not interested in converting the coordinates of the centers of the cells from polar to cartesian - this is very easy. Instead, I'm looking for a package that can actually re-grid the data properly.\\n\\nThanks for any suggestions!\\n\",\n  'completion': \"Thanks for your answers - after thinking a bit more about this I came up with the following code:\\n\\nimport numpy as np\\n\\nimport matplotlib\\nmatplotlib.use('Agg')\\nimport matplotlib.pyplot as mpl\\n\\nfrom scipy.interpolate import interp1d\\nfrom scipy.ndimage import map_coordinates\\n\\n\\ndef polar2cartesian(r, t, grid, x, y, order=3):\\n\\n    X, Y = np.meshgrid(x, y)\\n\\n    new_r = np.sqrt(X*X+Y*Y)\\n    new_t = np.arctan2(X, Y)\\n\\n    ir = interp1d(r, np.arange(len(r)), bounds_error=False)\\n    it = interp1d(t, np.arange(len(t)))\\n\\n    new_ir = ir(new_r.ravel())\\n    new_it = it(new_t.ravel())\\n\\n    new_ir[new_r.ravel() > r.max()] = len(r)-1\\n    new_ir[new_r.ravel() < r.min()] = 0\\n\\n    return map_coordinates(grid, np.array([new_ir, new_it]),\\n                            order=order).reshape(new_r.shape)\\n\\n# Define original polar grid\\n\\nnr = 10\\nnt = 10\\n\\nr = np.linspace(1, 100, nr)\\nt = np.linspace(0., np.pi, nt)\\nz = np.random.random((nr, nt))\\n\\n# Define new cartesian grid\\n\\nnx = 100\\nny = 200\\n\\nx = np.linspace(0., 100., nx)\\ny = np.linspace(-100., 100., ny)\\n\\n# Interpolate polar grid to cartesian grid (nearest neighbor)\\n\\nfig = mpl.figure()\\nax = fig.add_subplot(111)\\nax.imshow(polar2cartesian(r, t, z, x, y, order=0), interpolation='nearest')\\nfig.savefig('test1.png')\\n\\n# Interpolate polar grid to cartesian grid (cubic spline)\\n\\nfig = mpl.figure()\\nax = fig.add_subplot(111)\\nax.imshow(polar2cartesian(r, t, z, x, y, order=3), interpolation='nearest')\\nfig.savefig('test2.png')\\n\\n\\nWhich is not strictly re-gridding, but works fine for what I need. Just posting the code in case it is useful to anyone else. Feel free to suggest improvements!\\n\"},\n {'prompt': 'I am using the builtin Python ElementTree module. It is straightforward to access children, but what about parent nor sibling nodes? - can this be done efficiently without traversing the entire tree?\\n',\n  'completion': \"There's no direct support in the form of a parent attribute, but you can perhaps use the patterns described here to achieve the desired effect. The following one-liner is suggested (from the linked-to post) to create a child-to-parent mapping for a whole tree:\\n\\nparent_map = dict((c, p) for p in tree.getiterator() for c in p)\\n\\n\"},\n {'prompt': \"For lists, the method list.index(x) returns the index in the list of the first item whose value is x. But if I want to look inside the list items, and not just at the whole items, how do I make the most Pythoninc method for this?\\n\\nFor example, with\\n\\nl = ['the cat ate the mouse','the tiger ate the chicken','the horse ate the straw']\\n\\n\\nthis function would return 1 provided with the argument tiger.\\n\",\n  'completion': 'A non-slicky method:\\n\\ndef index_containing_substring(the_list, substring):\\n    for i, s in enumerate(the_list):\\n        if substring in s:\\n              return i\\n    return -1\\n\\n'},\n {'prompt': \"So I've gotten somewhat used to Javadoc style documentation. Looking through various examples of Python code, I'm finding that, at first blush, the documentation seems to be missing a lot of information.\\n\\nThe good: vary rarely do you see self-evident bits of documentation. Docstrings are usually a paragraph or less of English markup that integrates instead of standing out on separate lines.\\n\\nThe bad: in conjunction with Python's duck-typing, I find that many functions are unclear about the parameters they expect. There's no type hinting (duck-hinting?) and often times it would be nice to have some idea that the parameter should be list-like, string-like, stream-like.\\n\\nOf course, Javadoc was designed for a lower-level language, without great introspection abilities of Python, which might account for the less verbose documentation philosophy.\\n\\nAny advice on Python documentation standards and best-practices? \\n\",\n  'completion': \"The reStructuredText format was designed in response to the need for Python documentation that could be embedded in docstrings, so the best thing is to learn reST and format your docstrings with that format. You might find, as I did, that you then go on to format just about any documentation in reST, but that's a side point :-)\\n\\nFor specifically documenting your Python code, the Sphinx system is a set of extensions to the reST format, and a build system for rendering documents. Since it was designed to document Python itself, including the standard library, Sphinx allows for very well-structured documentation of source code, including of course the specifics of function signatures as you're asking. It allows a comprehensive documentation suite to be built, both auto-extracted and hand-written, all using the same formatting system.\\n\\nIf you only want documentation generated from your source code, then Epydoc will extract API documentation from your source code; it, too, reads reST formatting for the text.\\n\"},\n {'prompt': 'I\\'m looking for an equivalent to sscanf() in Python. I want to parse /proc/net/* files, in C I could do something like this:\\n\\nint matches = sscanf(\\n        buffer,\\n        \"%*d: %64[0-9A-Fa-f]:%X %64[0-9A-Fa-f]:%X %*X %*X:%*X %*X:%*X %*X %*d %*d %ld %*512s\\\\n\",\\n        local_addr, &local_port, rem_addr, &rem_port, &inode);\\n\\n\\nI thought at first to use str.split, however it doesn\\'t split on the given characters, but the sep string as a whole:\\n\\n>>> lines = open(\"/proc/net/dev\").readlines()\\n>>> for l in lines[2:]:\\n>>>     cols = l.split(string.whitespace + \":\")\\n>>>     print len(cols)\\n1\\n\\n\\nWhich should be returning 17, as explained above.\\n\\nIs there a Python equivalent to sscanf (not RE), or a string splitting function in the standard library that splits on any of a range of characters that I\\'m not aware of?\\n',\n  'completion': \"When I'm in a C mood, I usually use zip and list comprehensions for scanf-like behavior.  Like this:\\n\\ninput = '1 3.0 false hello'\\n(a, b, c, d) = [t(s) for t,s in zip((int,float,bool,str),input.split())]\\nprint (a, b, c, d)\\n\\n\\nNote that for more complex format strings, you do need to use regular expressions:\\n\\nimport re\\ninput = '1:3.0 false,hello'\\n(a, b, c, d) = [t(s) for t,s in zip((int,float,bool,str),re.search('^(\\\\d+):([\\\\d.]+) (\\\\w+),(\\\\w+)$',input).groups())]\\nprint (a, b, c, d)\\n\\n\"},\n {'prompt': 'I have a folder with 100k text files. I want to put files with over 20 lines in another folder. How do I do this in python? I used os.listdir, but of course, there isn\\'t enough memory for even loading the filenames into memory. Is there a way to get maybe 100 filenames at a time?\\n\\nHere\\'s my code:\\n\\nimport os\\nimport shutil\\n\\ndir = \\'/somedir/\\'\\n\\ndef file_len(fname):\\n    f = open(fname,\\'r\\')\\n    for i, l in enumerate(f):\\n        pass\\n    f.close()\\n    return i + 1\\n\\nfilenames = os.listdir(dir+\\'labels/\\')\\n\\ni = 0\\nfor filename in filenames:\\n    flen = file_len(dir+\\'labels/\\'+filename)\\n    print flen\\n    if flen > 15:\\n        i = i+1\\n        shutil.copyfile(dir+\\'originals/\\'+filename[:-5], dir+\\'filteredOrigs/\\'+filename[:-5])\\nprint i\\n\\n\\nAnd Output:\\n\\nTraceback (most recent call last):\\n  File \"filterimage.py\", line 13, in <module>\\n    filenames = os.listdir(dir+\\'labels/\\')\\nOSError: [Errno 12] Cannot allocate memory: \\'/somedir/\\'\\n\\n\\nHere\\'s the modified script:\\n\\nimport os\\nimport shutil\\nimport glob\\n\\ntopdir = \\'/somedir\\'\\n\\ndef filelen(fname, many):\\n    f = open(fname,\\'r\\')\\n    for i, l in enumerate(f):\\n        if i > many:\\n            f.close()\\n            return True\\n    f.close()\\n    return False\\n\\npath = os.path.join(topdir, \\'labels\\', \\'*\\')\\ni=0\\nfor filename in glob.iglob(path):\\n    print filename\\n    if filelen(filename,5):\\n        i += 1\\nprint i\\n\\n\\nit works on a folder with fewer files, but with the larger folder, all it prints is \"0\"...\\nWorks on linux server, prints 0 on mac... oh well...\\n',\n  'completion': \"you might try using glob.iglob that returns an iterator:\\n\\ntopdir = os.path.join('/somedir', 'labels', '*')\\nfor filename in glob.iglob(topdir):\\n     if filelen(filename) > 15:\\n          #do stuff\\n\\n\\nAlso, please don't use dir for a variable name: you're shadowing the built-in.\\n\\nAnother major improvement that you can introduce is to your filelen function. If you replace it with the following, you'll save a lot of time. Trust me, what you have now is the slowest alternative:\\n\\ndef many_line(fname, many=15):\\n    for i, line in enumerate(open(fname)):\\n        if i > many:\\n            return True\\n    return False\\n\\n\"},\n {'prompt': \"If I have a list [a,b,c,d,e] how can I reorder the items in an arbitrary manner like [d,c,a,b,e]?\\n\\nEdit: I don't want to shuffle them. I want to re-order them in a predefined manner. (for example, I know that the 3rd element in the old list should become the first element in the new list)\\n\",\n  'completion': \"You can do it like this\\n\\nmylist=['a','b','c','d','e']\\nmyorder=[3,2,0,1,4]\\nmylist = [ mylist[i] for i in myorder]\\nprint mylist\\n\\n\"},\n {'prompt': 'In Python, how do you find the number of digits in an integer?\\n',\n  'completion': 'If you want the length of an integer as in the number of digits in the integer, you can always convert it to string like str(133) and find its length like len(str(123)). \\n'},\n {'prompt': 'do you know if Python supports some keyword or expression like in C++ to return values based on if condition, all in the same line (The C++ if expressed with the question mark ?)\\n\\n// C++\\nvalue = ( a > 10 ? b : c )\\n\\n',\n  'completion': \"From Python 2.5 onwards you can do:\\n\\nvalue = b if a > 10 else c\\n\\n\\nPreviously you would have to do something like the following, although the semantics isn't identical as the short circuiting effect is lost:\\n\\nvalue = [c, b][a > 10]\\n\\n\\nThere's also another hack using 'and ... or' but it's best to not use it as it has an undesirable behaviour in some situations that can lead to a hard to find bug. I won't even write the hack here as I think it's best not to use it, but you can read about it on Wikipedia if you want.\\n\"},\n {'prompt': \"What is the upper level exception that I can catch SQLAlechmy exceptions with ?\\n\\n>>> from sqlalchemy import exc\\n>>> dir(exc)\\n['ArgumentError', 'CircularDependencyError', 'CompileError', 'ConcurrentModificationError', 'DBAPIError', 'DataError', 'DatabaseError', 'DisconnectionError', 'FlushError', 'IdentifierError', 'IntegrityError', 'InterfaceError', 'InternalError', 'InvalidRequestError', 'NoReferenceError', 'NoReferencedColumnError', 'NoReferencedTableError', 'NoSuchColumnError', 'NoSuchTableError', 'NotSupportedError', 'OperationalError', 'ProgrammingError', 'SADeprecationWarning', 'SAPendingDeprecationWarning', 'SAWarning', 'SQLAlchemyError', 'SQLError', 'TimeoutError', 'UnboundExecutionError', 'UnmappedColumnError', '__builtins__', '__doc__', '__file__', '__name__', '__package__']\\n>>> \\n\\n\",\n  'completion': 'To catch any exception SQLAlchemy throws:\\n\\nfrom sqlalchemy import exc\\ndb.add(user)\\ntry:\\n  db.commit()\\nexcept exc.SQLAlchemyError:\\n  pass\\n\\n\\nSee help(sqlalchemy.exc) and help(sqlalchemy.orm.exc) for a list of possible exceptions that sqlalchemy can raise.\\n'},\n {'prompt': 'I\\'m writing a Python script that goes through a directory and gathers certain files, but there are a number of files I want excluded that all start the same.\\n\\nExample code:\\n\\nfor name in files:\\n   if name != \"doc1.html\" and name != \"doc2.html\" and name != \"doc3.html\":\\n      print name\\n\\n\\nLet\\'s say there are 100 hundred HTML files in the directory all beginning with \\'doc\\'. What would be the easiest way to exclude them?\\n\\nSorry I\\'m new to Python, I know this is probably basic.\\n\\nThanks in advance.\\n',\n  'completion': \"if not name.startswith('doc'):\\n     print name\\n\\n\\nIf you have more prefixes to exclude you can even do this:\\n\\nif not name.startswith(('prefix', 'another', 'yetanother')):\\n     print name\\n\\n\\nstartswith can accept a tuple of prefixes.\\n\"},\n {'prompt': 'I created a virtualbox with a fresh install of ubuntu 9.10.\\n\\nI am trying to get MySQLdb to run on python but I\\'m failing at the import MySQLdb\\n\\nI first tried sudo easy_install MySQL_python-1.2.3c1-py2.6-linux-i686.egg and then  sudo apt-get install python-mysqldb.\\n\\nBoth apparently installed ok, but gave me the following error message when in python I have the import line:\\n\\nTraceback (most recent call last):\\nFile \"<stdin>\", line 1, in <module>\\nFile \"/usr/local/lib/python2.6/dist-packages/MySQL_python-1.2.3c1-py2.6-linux-i686.egg/MySQLdb/__init__.py\", line 19, in <module>\\n\\nFile \"/usr/local/lib/python2.6/dist-packages/MySQL_python-1.2.3c1-py2.6-linux-i686.egg/_mysql.py\", line 7, in <module>\\nFile \"/usr/local/lib/python2.6/dist-packages/MySQL_python-1.2.3c1-py2.6-linux-i686.egg/_mysql.py\", line 6, in __bootstrap__\\nImportError: libmysqlclient_r.so.15: cannot open shared object file: No such file or directory\\n\\n\\nI have already installed MySQL and it is running, if that matters at all.\\nI tried following this, but failed in step 2\\n',\n  'completion': \"Your MySQLdb egg installation looks like it is not working properly. You should go into /usr/local/lib/python2.6/dist-packages and remove it.\\n\\nThe Ubuntu python-mysqldb package should work fine. Unless you have a good reason, you should stick to your distribution's package manager when installing new software.\\n\"},\n {'prompt': \"How bad is it to redefine a class method from another, third-party module, in Python?\\n\\nIn fact, users can create NumPy matrices that contain numbers with uncertainty; ideally, I would like their code to run unmodified (compared to when the code manipulates float matrices); in particular, it would be great if the inverse of matrix m could still be obtained with m.I, despite the fact that m.I has to be calculated with my own code (the original I method does not work, in general).\\n\\nHow bad is it to redefine numpy.matrix.I?  For one thing, it does tamper with third-party code, which I don't like, as it may not be robust (what if other modules do the same?â\\x80¦).  Another problem is that the new numpy.matrix.I is a wrapper that involves a small overhead when the original numpy.matrix.I can actually be applied in order to obtain the inverse matrix.\\n\\nIs subclassing NumPy matrices and only changing their I method better?  this would force users to update their code and create matrices of numbers with uncertainty with  m = matrix_with_uncert(â\\x80¦) (instead of keeping using numpy.matrix(â\\x80¦), as for a matrix of floats), but maybe this is an inconvenience that should be accepted for the sake of robustness?  Matrix inversions could still be performed with m.I, which is goodâ\\x80¦  On the other hand, it would be nice if users could build all their matrices (of floats or of numbers with uncertainties) with numpy.matrix() directly, without having to bother checking for data types.\\n\\nAny comment, or additional approach would be welcome!\\n\",\n  'completion': 'Subclassing (which does involve overriding, as the term is generally used) is generally much preferable to \"monkey-patching\" (stuffing altered methods into existing classes or modules), even when the latter is available (built-in types, meaning ones implemented in C, can protect themselves against monkey-patching, and most of them do).\\n\\nFor example, if your functionality relies on monkey-patching, it will break and stop upgrades if at any time the class you\\'re monkey patching gets upgraded to be implemented in C (for speed or specifically to defend against monkey patching).  Maintainers of third party packages hate monkey-patching because it means they get bogus bug reports from hapless users who (unbeknownst to them) are in fact using a buggy monkey-patch which breaks the third party package, where the latter (unless broken monkey-wise) is flawless.  You\\'ve already remarked on the possible performance hit.\\n\\nConceptually, a \"matrix of numbers with uncertainty\" is a different concept from a \"matrix of numbers\".  Subclassing expresses this cleanly, monkey-patching tries to hide it.  That\\'s really the root of what\\'s wrong with monkey-patching in general: a covert channel operating through global, hidden means, without clarity and transparency.  All the many practical problems descend in a sense from this root conceptual problem.\\n\\nI strongly urge you to reject monkey-patching in favor of clean solutions such as subclassing.\\n'},\n {'prompt': 'This is not a homework, I am just curious.\\n\\nINFINITE is the key word here.\\n\\nI wish to use it as for p in primes(). I believe that this is a built-in function in Haskell.\\n\\nSo, the answer cannot be as naive as \"Just do a Sieve\".\\n\\nFirst of all, you do not know how many consecutive primes will be consumed. Well, suppose you could concoct 100 of them at a time. Would you use the same Sieve approach as well as the frequency of prime numbers formula?\\n\\nI prefer non-concurrent approach.\\n\\nThank you for reading (and writing ;) )!\\n',\n  'completion': 'â\\x80\\x9cIf I have seen furtherâ\\x80¦â\\x80\\x9d\\n\\nThe erat2 function from the cookbook can be further sped up (by about 20-25%):\\n\\nerat2a\\n\\nimport itertools as it\\ndef erat2a( ):\\n    D = {  }\\n    yield 2\\n    for q in it.islice(it.count(3), 0, None, 2):\\n        p = D.pop(q, None)\\n        if p is None:\\n            D[q*q] = q\\n            yield q\\n        else:\\n            # old code here:\\n            # x = p + q\\n            # while x in D or not (x&1):\\n            #     x += p\\n            # changed into:\\n            x = q + 2*p\\n            while x in D:\\n                x += 2*p\\n            D[x] = p\\n\\n\\nThe not (x&1) check verifies that x is odd. However, since both q and p are odd, by adding 2*p half of the steps are avoided along with the test for oddity.\\n\\nerat3\\n\\nIf one doesn\\'t mind a little extra fanciness, erat2 can be sped up by 35-40% with the following changes (NB: needs Python 2.7+ or Python 3+ because of the itertools.compress function):\\n\\nimport itertools as it\\ndef erat3( ):\\n    D = { 9: 3, 25: 5 }\\n    yield 2\\n    yield 3\\n    yield 5\\n    MASK= 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\\n    MODULOS= frozenset( (1, 7, 11, 13, 17, 19, 23, 29) )\\n\\n    for q in it.compress(\\n            it.islice(it.count(7), 0, None, 2),\\n            it.cycle(MASK)):\\n        p = D.pop(q, None)\\n        if p is None:\\n            D[q*q] = q\\n            yield q\\n        else:\\n            x = q + 2*p\\n            while x in D or (x%30) not in MODULOS:\\n                x += 2*p\\n            D[x] = p\\n\\n\\nThe erat3 function takes advantage of the fact that all primes (except for  2, 3, 5) modulo 30 result to only eight numbers: the ones included in the MODULOS frozenset. Thus, after yielding the initial three primes, we start from 7 and work only with the candidates.\\nThe candidate filtering uses the itertools.compress function; the â\\x80\\x9cmagicâ\\x80\\x9d is in the MASK sequence; MASK has 15 elements (there are 15 odd numbers in every 30 numbers, as chosen by the itertools.islice function) with a 1 for every possible candidate, starting from 7. The cycle repeats as specified by the itertools.cycle function.\\nThe introduction of the candidate filtering needs another modification: the or (x%30) not in MODULOS check. The erat2 algorithm processed all odd numbers; now that the erat3 algorithm processes only r30 candidates, we need to make sure that all D.keys() can only be such â\\x80\\x94falseâ\\x80\\x94 candidates.\\n\\nBenchmarks\\n\\nResults\\n\\nOn an Atom 330 Ubuntu 9.10 server, versions 2.6.4 and 3.1.1+:\\n\\n$ testit\\nup to 8192\\n==== python2 erat2 ====\\n100 loops, best of 3: 18.6 msec per loop\\n==== python2 erat2a ====\\n100 loops, best of 3: 14.5 msec per loop\\n==== python2 erat3 ====\\nTraceback (most recent call last):\\nâ\\x80¦\\nAttributeError: \\'module\\' object has no attribute \\'compress\\'\\n==== python3 erat2 ====\\n100 loops, best of 3: 19.2 msec per loop\\n==== python3 erat2a ====\\n100 loops, best of 3: 14.1 msec per loop\\n==== python3 erat3 ====\\n100 loops, best of 3: 11.7 msec per loop\\n\\n\\nOn an AMD Geode LX Gentoo home server, Python 2.6.5 and 3.1.2:\\n\\n$ testit\\nup to 8192\\n==== python2 erat2 ====\\n10 loops, best of 3: 104 msec per loop\\n==== python2 erat2a ====\\n10 loops, best of 3: 81 msec per loop\\n==== python2 erat3 ====\\nTraceback (most recent call last):\\nâ\\x80¦\\nAttributeError: \\'module\\' object has no attribute \\'compress\\'\\n==== python3 erat2 ====\\n10 loops, best of 3: 116 msec per loop\\n==== python3 erat2a ====\\n10 loops, best of 3: 82 msec per loop\\n==== python3 erat3 ====\\n10 loops, best of 3: 66 msec per loop\\n\\n\\nBenchmark code\\n\\nA primegen.py module contains the erat2, erat2a and erat3 functions. Here follows the testing script:\\n\\n#!/bin/sh\\nmax_num=${1:-8192}\\necho up to $max_num\\nfor python_version in python2 python3\\ndo\\n    for function in erat2 erat2a erat3\\n    do\\n        echo \"==== $python_version $function ====\"\\n        $python_version -O -m timeit -c \\\\\\n        -s  \"import itertools as it, functools as ft, operator as op, primegen; cmp= ft.partial(op.ge, $max_num)\" \\\\\\n            \"next(it.dropwhile(cmp, primegen.$function()))\"\\n    done\\ndone\\n\\n'},\n {'prompt': \"I would like to have the user input a date, something like:\\n\\ndate = input('Date (m/dd/yyyy): ')\\n\\n\\nand then make sure that the input is a valid date.  I don't really care that much about the date format.\\n\\nThanks for any input.\\n\",\n  'completion': \"You can use the time module's strptime() function:\\n\\nimport time\\ndate = input('Date (mm/dd/yyyy): ')\\ntry:\\n  valid_date = time.strptime(date, '%m/%d/%Y')\\nexcept ValueError:\\n  print('Invalid date!')\\n\\n\\nNote that in Python 2.x you'll need to use raw_input instead of input.\\n\"},\n {'prompt': 'I am trying to figure out how to measure the performance of several python threads in my application. I currently have several tasks that are executing on different threads based on user input and I would like to measure the execution time, maybe even memory consumption of each of the threads. I have tried to use cProfile (on each instantiation of the thread, then I would write the data to a file and then aggregate all results) with limited success. Also, I have an added problem of having some blocking IO which is skewing my results. Is there anyway to effectively profile my application? \\n',\n  'completion': \"There are a few different ways to tackle this problem. cProfile is great and comes with Python, however many people see multi-threaded profiling as an issue. One way of getting around this is by running separate instances of cProfile for each thread and then combining the results using Stats.add.\\n\\nShould that not be as useful as you'd hoped, another alternative could be to use Yappi, which I've had success using for a few special multi-threaded cases. It's got great documentation so you shouldn't have too much trouble setting it up.\\n\\nFor memory specific profiling, check out Heapy. But be warned, it may create some of the largest log files you've ever seen if your code is bad!\\n\"},\n {'prompt': 'I\\'m having a problem regarding Unicode in Python. I can print the output fine in a regular terminal, but if I redirect stdout elsewhere (or capture it with the subprocess module), I get a UnicodeEncodeError:\\n\\n$ cat example.py \\nprint u\\'Example: \\\\u00F1\\'\\n$ python example.py \\nExample: Ã±\\n$ python example.py > /dev/null\\nTraceback (most recent call last):\\n  File \"example.py\", line 1, in <module>\\n    print u\\'Example: \\\\u00F1\\'\\nUnicodeEncodeError: \\'ascii\\' codec can\\'t encode character u\\'\\\\xf1\\' in position 9: ordinal not in range(128)\\n\\n\\nWhy is this? How can I fix it?\\n',\n  'completion': \"Pipes that don't lead to the terminal don't have an encoding, therefore you'll need to check sys.stdout.isatty() and encode if needed.\\n\"},\n {'prompt': 'So i have a set of classes and a string with one of the class names. How do I instantiate a class based on that string?\\n\\nclass foo:\\n  def __init__(self, left, right):\\n     self.left = left\\n     self.right = right\\n\\nstr = \"foo\"\\nx = Init(str, A, B)\\n\\n\\nI want x to be an instantiation of class foo.\\n',\n  'completion': 'In your case you can use something like\\n\\nget_class = lambda x: globals()[x]\\nc = get_class(\"foo\")\\n\\n\\nAnd it\\'s even easier no get class from the module\\n\\nimport somemodule\\ngetattr(somemodule, \"SomeClass\")\\n\\n'},\n {'prompt': \"Say I have the following code.\\n\\ndef foo():\\n    foobar = None\\n    if foobar is not None:\\n        raise foobar\\n\\n\\nWhen I run this code through pylint, I get the following error:\\n\\nE0702:4:foo: Raising NoneType while only classes, instances or string are allowed\\n\\n\\nIs this a bug in pylint? Is my pylint too old?\\n\\npylint 0.18.0, \\nastng 0.19.1, common 0.45.0\\nPython 2.5.1 (r251:54863, Aug 25 2008, 09:23:26) \\n\\n\\nNote: I know this code doesn't make any sense, it's distilled to its bare bones to expose the issue at hand, normally stuff happens in between line 2 and 3 which could make foobar not be None, and no I can't just raise an exception there, because that happens in another thread that has restrictions on it.\\n\",\n  'completion': \"It's a known bug. Pylint doesn't do a lot of flow-control inferencing.\\n\"},\n {'prompt': 'I need to mount a directory \"dir\" on a network machine \"data\" using python on a linux machine\\n\\nI know that I can send the command via command line:\\n\\nmkdir ~/mnt/data_dir\\nmount -t data:/dir/ ~/mnt/data_dir\\n\\n\\nbut how would I send those commands from a python script?\\n',\n  'completion': \"I'd recommend you use subprocess.checkcall.\\n\\nfrom subprocess import *\\n\\n#most simply\\ncheck_call( 'mkdir ~/mnt/data_dir', shell=True )\\ncheck_call( 'mount -t whatever data:/dir/ ~/mnt/data_dir', shell=True )\\n\\n\\n#more securely\\nfrom os.path import expanduser\\ncheck_call( [ 'mkdir', expanduser( '~/mnt/data_dir' ) ] )\\ncheck_call( [ 'mount', '-t', 'whatever', 'data:/dir/', expanduser( '~/mnt/data_dir' ) ] )\\n\\n\"},\n {'prompt': \"Im just beginning to mess around a bit with classes; however, I am running across a problem.\\n\\nclass MyClass(object):\\n    def f(self):\\n        return 'hello world'\\nprint MyClass.f\\n\\n\\nThe previous script is returning <unbound method MyClass.f> instead of the intended value. How do I fix this?\\n\",\n  'completion': 'MyClass.f refers to the function object f which is a property of MyClass. In your case, f is an instance method (has a self parameter) so its called on a particular instance. Its \"unbound\" because you\\'re referring to f without specifying a specific class, kind of like referring to a steering wheel without a car.\\n\\nYou can create an instance of MyClass and call f from it like so: \\n\\nx = MyClass()\\nx.f()\\n\\n\\n(This specifies which instance to call f from, so you can refer to instance variables and the like.) \\n\\nYou\\'re using f as a static method. These methods aren\\'t bound to a particular class, and can only reference their parameters.\\n\\nA static method would be created and used like so:\\n\\nclass MyClass(object):\\n    def f():                 #no self parameter\\n        return \\'hello world\\'\\nprint MyClass.f()\\n\\n'},\n {'prompt': \"I'm wondering because CherryPy is, from my knowledge, built purely in Python, which is obviously slower than C et al. Does this mean that it's only good for dev / testing environments, or could I use it behind NGINX like I use Apache with Fast CGI currently?\\n\",\n  'completion': \"CherryPy's WSGI server is about as fast as a pure-Python WSGI server is going to get.  I personally use it behind Nginx in production, but even standalone on my dev machine I can load each instance with several hundred requests / sec. without problems.\\n\\nCan you find a faster server? Yes. Is CherryPy a robust web server, and good enough for most people to use in production? Yes.\\n\"},\n {'prompt': \"In python is it possible to have the above code without raising an exception ?\\n\\ndef myfunc():\\n    pass\\n\\n# TypeError myfunc() takes no arguments (1 given)\\nmyfunc('param')\\n\\n\\nUsually in php in some circumstances I launch a function without parameters and then retrieve the parameters inside the function.\\n\\nIn practice I don't want to declare arguments in myfunc and then passing some arguments to it. The only one solution I found is myfunc(*arg). Are there any other methods ?\\n\",\n  'completion': 'There are two ways to pass args in\\n\\nBy Position\\n\\n>>> def myfunc(*args):\\n...  print \"args\", args\\n...\\n>>> myfunc(\"param\")\\nargs (\\'param\\',)\\n\\n\\nBy Keyword\\n\\n>>> def myfunc(**kw):\\n...  print \"kw\", kw\\n... \\n>>> myfunc(param=\"param\")\\nkw {\\'param\\': \\'param\\'}\\n\\n\\nAnd you can use a combination of both\\n\\n>>> def myfunc(*args, **kw):\\n...  print \"args\", args\\n...  print \"kw\", kw\\n... \\n>>> myfunc(\"param\")\\nargs (\\'param\\',)\\nkw {}\\n>>>\\n>>> myfunc(param=\"param\")\\nargs ()\\nkw {\\'param\\': \\'param\\'}\\n>>>\\n>>> myfunc(\"param\", anotherparam=\"anotherparam\")\\nargs (\\'param\\',)\\nkw {\\'anotherparam\\': \\'anotherparam\\'}\\n\\n'},\n {'prompt': \"Can anyone explain why example 1 below works, when the r prefix is not used?\\nI thought the r prefix must be used whenever escape sequences are used?\\nExample 2 and example 3 demonstrates this..\\n\\n# example 1\\nimport re\\nprint (re.sub('\\\\s+', ' ', 'hello     there      there'))\\n# prints 'hello there there' - not expected as r prefix is not used\\n\\n# example 2\\nimport re\\nprint (re.sub(r'(\\\\b\\\\w+)(\\\\s+\\\\1\\\\b)+', r'\\\\1', 'hello     there      there'))\\n# prints 'hello     there' - as expected as r prefix is used\\n\\n# example 3\\nimport re\\nprint (re.sub('(\\\\b\\\\w+)(\\\\s+\\\\1\\\\b)+', '\\\\1', 'hello     there      there'))\\n# prints 'hello     there      there' - as expected as r prefix is not used\\n\\n\",\n  'completion': 'Because \\\\ begin escape sequences only when they are valid escape sequences.\\n\\n>>> \\'\\\\n\\'\\n\\'\\\\n\\'\\n>>> r\\'\\\\n\\'\\n\\'\\\\\\\\n\\'\\n>>> print \\'\\\\n\\'\\n\\n\\n>>> print r\\'\\\\n\\'\\n\\\\n\\n>>> \\'\\\\s\\'\\n\\'\\\\s\\'\\n>>> r\\'\\\\s\\'\\n\\'\\\\\\\\s\\'\\n>>> print \\'\\\\s\\'\\n\\\\s\\n>>> print r\\'\\\\s\\'\\n\\\\s\\n\\n\\n\\n  Unless an \\'r\\' or \\'R\\' prefix is present, escape sequences in strings are interpreted according to rules similar to those used by Standard C. The recognized escape sequences are:\\n\\nEscape Sequence   Meaning Notes\\n\\\\newline  Ignored  \\n\\\\\\\\    Backslash (\\\\)    \\n\\\\\\'    Single quote (\\')     \\n\\\\\"    Double quote (\")     \\n\\\\a    ASCII Bell (BEL)     \\n\\\\b    ASCII Backspace (BS)     \\n\\\\f    ASCII Formfeed (FF)  \\n\\\\n    ASCII Linefeed (LF)  \\n\\\\N{name}  Character named name in the Unicode database (Unicode only)  \\n\\\\r    ASCII Carriage Return (CR)   \\n\\\\t    ASCII Horizontal Tab (TAB)   \\n\\\\uxxxx    Character with 16-bit hex value xxxx (Unicode only) \\n\\\\Uxxxxxxxx    Character with 32-bit hex value xxxxxxxx (Unicode only) \\n\\\\v    ASCII Vertical Tab (VT)  \\n\\\\ooo  Character with octal value ooo\\n\\\\xhh  Character with hex value hh\\n\\n\\n\\nNever rely on raw strings for path literals, as raw strings have some rather peculiar inner workings, known to have bitten people in the ass:\\n\\n\\n  When an \"r\" or \"R\" prefix is present, a character following a backslash is included in the string without change, and all backslashes are left in the string. For example, the string literal r\"\\\\n\" consists of two characters: a backslash and a lowercase \"n\". String quotes can be escaped with a backslash, but the backslash remains in the string; for example, r\"\\\\\"\" is a valid string literal consisting of two characters: a backslash and a double quote; r\"\\\\\" is not a valid string literal (even a raw string cannot end in an odd number of backslashes). Specifically, a raw string cannot end in a single backslash (since the backslash would escape the following quote character). Note also that a single backslash followed by a newline is interpreted as those two characters as part of the string, not as a line continuation.\\n\\n\\nTo better illustrate this last point:\\n\\n>>> r\\'\\\\\\'\\nSyntaxError: EOL while scanning string literal\\n>>> r\\'\\\\\\'\\'\\n\"\\\\\\\\\\'\"\\n>>> \\'\\\\\\'\\nSyntaxError: EOL while scanning string literal\\n>>> \\'\\\\\\'\\'\\n\"\\'\"\\n>>> \\n>>> r\\'\\\\\\\\\\'\\n\\'\\\\\\\\\\\\\\\\\\'\\n>>> \\'\\\\\\\\\\'\\n\\'\\\\\\\\\\'\\n>>> print r\\'\\\\\\\\\\'\\n\\\\\\\\\\n>>> print r\\'\\\\\\'\\nSyntaxError: EOL while scanning string literal\\n>>> print \\'\\\\\\\\\\'\\n\\\\\\n\\n'},\n {'prompt': 'I am trying to get a user to enter a number between 1 and 4. I have code to check if the number is correct but I want the code to loop around several times until the numbers is correct. Does anyone know how to do this? The code is below:\\n\\ndef Release():\\n\\n\\n    try:\\n        print \\'Please select one of the following?\\\\nCompletion = 0\\\\nRelease ID = 1\\\\nVersion ID = 2\\\\nBuild ID = 3\\\\n\\'\\n        a = int(input(\"Please select the type of release required: \"))\\n        if a == 0:\\n            files(a)\\n        elif a == 1:\\n            files(a)\\n        elif a == 2:\\n            files(a)\\n        elif a == 3:\\n            files(a)\\n        else:\\n            raise \\'incorrect\\'\\n    except \\'incorrect\\':    \\n        print \\'Try Again\\'\\n    except:\\n        print \\'Error\\'\\n\\nRelease()\\n\\n\\nI am also getting an error about the exception I have entered:\\n\\nkill.py:20: DeprecationWarning: catching of string exceptions is deprecated\\n  except \\'incorrect\\':\\nError\\n\\n\\nThanks for any help\\n',\n  'completion': \"def files(a):\\n    pass\\n\\nwhile True:\\n    try:\\n        i = int(input('Select: '))\\n        if i in range(4):\\n            files(i)\\n            break\\n    except:    \\n        pass\\n\\n    print '\\\\nIncorrect input, try again'\\n\\n\"},\n {'prompt': \"I have some pcap files and I want to filter by protocol, i.e., if I want to filter by HTTP  protocol, anything but HTTP packets will remain in the pcap file. \\n\\nThere is a tool called openDPI, and it's perfect for what I need, but there is no wrapper for python language.\\n\\nDoes anyone knows any python modules that can do what I need?\\n\\nThanks\\n\\nEdit 1:\\n\\nHTTP filtering was just an example, there is a lot of protocols that I want to filter.\\n\\nEdit 2:\\n\\nI tried Scapy, but I don't figure how to filter correctly. The filter only accepts Berkeley Packet Filter expression, i.e., I can't apply a msn, or HTTP, or another specific filter from upper layer. Can anyone help me?\\n\",\n  'completion': 'I know this is a super-old question, but I just ran across it thought I\\'d provide my answer.   This is a problem I\\'ve encountered several times over the years, and I keep finding myself falling back to dpkt.  Originally from the very capable dugsong, dpkt is primarily a packet creation/parsing library.  I get the sense the pcap parsing was an afterthought, but it turns out to be a very useful one, because parsing pcaps, IP, TCP and and TCP headers is straightforward.  It\\'s parsing all the higher-level protocols that becomes the time sink! (I wrote my own python pcap parsing library before finding dpkt)\\n\\nThe documentation on using the pcap parsing functionality is a little thin.  Here\\'s an example from my files:\\n\\nimport socket\\nimport dpkt\\nimport sys\\npcapReader = dpkt.pcap.Reader(file(sys.argv[1], \"rb\"))\\nfor ts, data in pcapReader:\\n    ether = dpkt.ethernet.Ethernet(data)\\n    if ether.type != dpkt.ethernet.ETH_TYPE_IP: raise\\n    ip = ether.data\\n    src = socket.inet_ntoa(ip.src)\\n    dst = socket.inet_ntoa(ip.dst)\\n    print \"%s -> %s\" % (src, dst)\\n\\n\\nHope this helps the next guy to run across this post!\\n'},\n {'prompt': \"I am new to Ruby.  I'm looking to import functions from a module that contains a tool I want to continue using separately.  In Python I would simply do this:\\n\\ndef a():\\n    ...\\ndef b():\\n    ...\\nif __name__ == '__main__':\\n    a()\\n    b()\\n\\n\\nThis allows me to run the program or import it as a module to use a() and/or b() separately.  What's the equivalent paradigm in Ruby?\\n\",\n  'completion': \"From the Ruby I've seen out in the wild (granted, not a ton), this is not a standard Ruby design pattern. Modules and scripts are supposed to stay separate, so I wouldn't be surprised if there isn't really a good, clean way of doing this.\\n\\nEDIT: Found it.\\n\\nif __FILE__ == $0\\n    foo()\\n    bar()\\nend\\n\\n\\nBut it's definitely not common.\\n\"},\n {'prompt': 'I use sphinx python documentation generator. Creating pdf documents are very easy and simple but.... i have one problem. \\n\\nAll generated pdf documents have english words like \"chapter\", \"release\", \"part\". \\nIs it possible change it? How set another words or remove it?\\n',\n  'completion': \"In your conf.py, there is the following paragraph (around line 57 in a conf.py created by sphinx-quickstart):\\n\\n# The language for content autogenerated by Sphinx. Refer to documentation\\n# for a list of supported languages.\\n#language = None\\n\\n\\nIn my case, I changed it to:\\n\\nlanguage = nl      # bug!\\n\\n\\nWhich of course should be:\\n\\nlanguage = 'nl'    # don't forget the quotes :-)\\n\\n\\nThis will work for all Sphinx output; in my case, I only checked the html and latex output. On the Spinx website, there is list of supported languages.\\n\"},\n {'prompt': 'Is there a more efficent way for doing this?\\n\\nfor item in item_list:\\n    e, new = Entry.objects.get_or_create(\\n        field1 = item.field1,\\n        field2 = item.field2,\\n    )\\n\\n',\n  'completion': 'You can\\'t do decent bulk insertions with get_or_create (or even create), and there\\'s no API for doing this easily.\\n\\nIf your table is simple enough that creating rows with raw SQL isn\\'t too much of a pain, it\\'s not too hard; something like:\\n\\nINSERT INTO site_entry (field1, field2)\\n(\\n         SELECT i.field1, i.field2\\n         FROM (VALUES %s) AS i(field1, field2)\\n         LEFT JOIN site_entry as existing\\n                 ON (existing.field1 = i.field1 AND existing.field2 = i.field2)\\n         WHERE existing.id IS NULL\\n)\\n\\n\\nwhere %s is a string like (\"field1, field2\"), (\"field3, field4\"), (\"field5, field6\") that you\\'ll have to create and escape properly yourself.\\n'},\n {'prompt': \"I need to save to disk a little dict object which keys are strs and values are ints and then recover it. Something like this:\\n\\n{'juanjo': 2, 'pedro':99, 'other': 333}\\n\\n\\nWhat is the best option and why? Serialize it with pickle or with simplejson?\\n\\nI am using Python 2.6.\\n\",\n  'completion': 'I prefer JSON over pickle for my serialization. Unpickling can run arbitrary code, and using pickle to transfer data between programs or store data between sessions is a security hole. JSON does not introduce a security hole and is standardized, so the data can be accessed by programs in different languages if you ever need to.\\n'},\n {'prompt': \"How can I convert an RGB integer to the corresponding RGB tuple (R,G,B)? Seems simple enough, but I can't find anything on google.\\n\\nI know that for every RGB (r,g,b) you have the integer n = r256^2 + g256 + b, how can I solve the reverse in Python, IE given an n, I need the r,g,b values.\\n\",\n  'completion': \"I'm not a Python expert by all means, but as far as I know it has the same operators as C. \\n\\nIf so this should work and it should also be a lot quicker than using modulo and division.\\n\\nBlue =  RGBint & 255\\nGreen = (RGBint >> 8) & 255\\nRed =   (RGBint >> 16) & 255\\n\\n\\nWhat it does it to mask out the lowest byte in each case (the binary and with 255.. Equals to a 8 one bits). For the green and red component it does the same, but shifts the color-channel into the lowest byte first.\\n\"},\n {'prompt': \"I am trying to implement a calendar system with the ability to schedule other people for appointments. The system has to be able to prevent scheduling a person during another appointment or during their unavailable time.\\n\\nI have looked at all the existing django calendar projects I have found on the internet and none of them seem to have this built-into them (if I missed it somehow, please let me know).\\n\\nPerhaps I am just getting too tired, but the only way I can think of doing this seems a little messy. Here goes in pseudo code:\\n\\n\\nwhen a user tries to create a new appointment, grab the new appointment's start_time and end_time\\nfor each appointment on that same day, check if\\n\\nexisting_start_time < new_start_time AND existing_end_time > new_start_time (is the new appointments start time in between any existing appointment's start and end times)\\nexisting_start_time < new_end_time AND existing_end_time > new_end_time (is the new appointments end time in between any existing appointment's start and end times)\\n\\nif no objects were found, then go ahead and add the new appointment\\n\\n\\nConsidering Django has no filtering based on time, this must all be done using .extra() on the queryset.\\n\\nSo, I am asking if there is a better way. A pythonic trick or module or anything that might simplify this. Or an existing project that has what I need or can lead me in the right direction.\\n\\nThanks.\\n\",\n  'completion': \"What about using Django's range test.\\n\\nFor example:\\n\\nappoinment = Appointment()\\nappointment.start_time = datetime.datetime.now()\\n# 1 hour appointment\\nappointment.end_time = appointment.start_time + datetime.timedelta(hours=1)\\n# more stuff here\\nappointment.save()\\n\\n# Checking for collision\\n# where the start time for an appointment is between the the start and end times\\n# You would want to filter this on user, etc \\n# There is also a problem if you book an appointment within another appointment\\nstart_conflict = Appointment.objects.filter(\\n                     start_time__range=(appointment.start_time,\\n                                        appointment.end_time))\\nend_conflict = Appointment.objects.filter(\\n                   end_time__range=(appointment.start_time,\\n                                    appointment.end_time))\\n\\nduring_conflict = Appointment.objects.filter(\\n                      start_date__lte=appointment.start_time, \\n                      end_date__gte=appointment.end_time)\\n\\nif (start_conflict or end_conflict or during_conflict):\\n    # reject, for there is a conflict\\n\\n\\nSomething like that? I haven't tried this myself so you may have to tweak it a bit.\\n\\nEDIT: Added the during_conflict bit.\\n\"},\n {'prompt': \"As a follow-up to cannot-bind-to-address-after-socket-program-crashes, I was receiving this error after my program was restarted:\\n\\n\\n  socket.error: [Errno 98] Address already in use\\n\\n\\nIn this particular case, instead of using a socket directly, the program is starting its own threaded TCP server:\\n\\nhttpd = SocketServer.ThreadingTCPServer(('localhost', port), CustomHandler)\\nhttpd.serve_forever()\\n\\n\\nHow can I fix this error message?\\n\",\n  'completion': 'The above solution didn\\'t work for me but this one did:\\n\\n   SocketServer.ThreadingTCPServer.allow_reuse_address = True\\n   server = SocketServer.ThreadingTCPServer((\"localhost\", port), CustomHandler)\\n   server.serve_forever()\\n\\n'},\n {'prompt': 'I am just starting Python and I was wondering how I would go about programming web applications without the need of a framework. I am an experiance PHP developer but I have an urge to try out Python and I usually like to write from scratch without the restriction of a framework.\\n',\n  'completion': \"WSGI is the Python standard for web server interfaces.  If you want to create your own framework or operate without a framework, you should look into that.  Specifically I have found Ian Bicking's DIY Framework article helpful.\\n\\nAs an aside, I tend to think frameworks are useful and personally use Django, like the way Pylons works, and have used Bottle in the past for prototyping--you may want to look at Bottle if you want a stay-out-of-your-way microframework.\\n\"},\n {'prompt': 'I have many \"can\\'t encode\" and \"can\\'t decode\" problems with Python when I run my applications from the console. But in the Eclipse PyDev IDE, the default character encoding is set to UTF-8, and I\\'m fine.\\n\\nI searched around for setting the default encoding, and people say that Python deletes the sys.setdefaultencoding function on startup, and we can not use it.\\n\\nSo what\\'s the best solution for it?\\n',\n  'completion': \"Here is a simpler method (hack) that gives you back the setdefaultencoding() function that was deleted from sys:\\n\\nimport sys\\n# sys.setdefaultencoding() does not exist, here!\\nreload(sys)  # Reload does the trick!\\nsys.setdefaultencoding('UTF8')\\n\\n\\nPS: This is obviously a hack, since sys.setdefaultencoding() is purposely removed from sys when Python starts. Reenabling it and changing the default encoding can break code that relies on ASCII being the default (this code can be third-party, which would generally make fixing it impossible or dangerous).\\n\"},\n {'prompt': \"I have a shell script that loops through a text file containing URL:s that I want to visit and take screenshots of.\\n\\nAll this is done and simple. The script initializes a class that when run creates a screenshot of each site in the list. Some sites take a very, very long time to load, and some might not be loaded at all. So I want to wrap the screengrabber-function in a timeout script, making the function return False if it couldn't finish within 10 seconds.\\n\\nI'm content with the simplest solution possible, maybe setting a asynchronous timer that will return False after 10 seconds no matter what actually happens inside the function?\\n\",\n  'completion': 'The process for timing out an operations is described in the documentation for signal.\\n\\nThe basic idea is to use signal handlers to set an alarm for some time interval and raise an exception once that timer expires.\\n\\nNote that this will only work on UNIX.\\n\\nHere\\'s an implementation that creates a decorator (save the following code as timeout.py).\\n\\nfrom functools import wraps\\nimport errno\\nimport os\\nimport signal\\n\\nclass TimeoutError(Exception):\\n    pass\\n\\ndef timeout(seconds=10, error_message=os.strerror(errno.ETIME)):\\n    def decorator(func):\\n        def _handle_timeout(signum, frame):\\n            raise TimeoutError(error_message)\\n\\n        def wrapper(*args, **kwargs):\\n            signal.signal(signal.SIGALRM, _handle_timeout)\\n            signal.alarm(seconds)\\n            try:\\n                result = func(*args, **kwargs)\\n            finally:\\n                signal.alarm(0)\\n            return result\\n\\n        return wraps(func)(wrapper)\\n\\n    return decorator\\n\\n\\nThis creates a decorator called @timeout that can be applied to any long running functions.\\n\\nSo, in your application code, you can use the decorator like so:\\n\\nfrom timeout import timeout\\n\\n# Timeout a long running function with the default expiry of 10 seconds.\\n@timeout\\ndef long_running_function1():\\n    ...\\n\\n# Timeout after 5 seconds\\n@timeout(5)\\ndef long_running_function2():\\n    ...\\n\\n# Timeout after 30 seconds, with the error \"Connection timed out\"\\n@timeout(30, os.strerror(errno.ETIMEDOUT))\\ndef long_running_function3():\\n    ...\\n\\n'},\n {'prompt': \"I have a function name stored in a variable like this:\\n\\nmyvar = 'mypackage.mymodule.myfunction'\\n\\n\\nand I now want to call myfunction like this\\n\\nmyvar(parameter1, parameter2)\\n\\n\\nWhat's the easiest way to achieve this?\\n\",\n  'completion': \"funcdict = {\\n  'mypackage.mymodule.myfunction': mypackage.mymodule.myfunction,\\n    ....\\n}\\n\\nfuncdict[myvar](parameter1, parameter2)\\n\\n\"},\n {'prompt': 'I have a text file with lines like this:\\n\\n2010-02-18 11:46:46.1287 bla\\n2010-02-18 11:46:46.1333 foo\\n2010-02-18 11:46:46.1333 bar\\n2010-02-18 11:46:46.1467 bla\\n\\n\\nA simple sort would swap lines 2 and 3 (bar comes before foo), but I would like to keep lines (that have the same date/time) in their original order.\\n\\nHow can I do this in Python?\\n\\nBonus question: Can GNU sort also do this?\\n',\n  'completion': 'sorted(array, key=lambda x:x[:24])\\n\\n\\nExample:\\n\\n>>> a = [\"wxyz\", \"abce\", \"abcd\", \"bcde\"]\\n>>> sorted(a)\\n[\\'abcd\\', \\'abce\\', \\'bcde\\', \\'wxyz\\']\\n>>> sorted(a, key=lambda x:x[:3])\\n[\\'abce\\', \\'abcd\\', \\'bcde\\', \\'wxyz\\']\\n\\n'},\n {'prompt': \"Recently I started playing around with Python and I came around something peculiar in the way closures work. Consider the following code:\\n\\nadders= [0,1,2,3]\\nfor i in [0,1,2,3]:\\n   adders[i]=lambda a: i+a\\n\\nprint adders[1](3)\\n\\n\\nIt builds a simple array of functions that take a single input and return that input added by a number. The functions are constructed in for loop where the iterator i runs from 0 to 3. For each of these number a lambda funciton is created which captures i and adds it to the function's input. The last line calls the second lambda function with 3 as a parameter. To my surprise the output was:\\n\\n6\\n\\n\\nI expected a 4. My reasoning was: in Python everything is an object and thus every variable is essential a pointer to it. When creating the lambda closures for i, I expected it to store a pointer to the integer object currently pointed to by i. That means that when i assigned a new integer object it shouldn't effect the previously created closures. Sadly, inspecting the adders array within a debugger shows that it does. All lambda functions refer to the last value of i, 3, which results in adders1 returning 6.\\n\\nWhich me the following:\\n\\n\\nwhat does the closures capture exactly?\\nWhat is the most elegant way to convince that lambda functions to capture the current value of i and in a way that will not be affected when i changes it's value. \\n\\n\",\n  'completion': 'you may force the capture of a variable using an argument with a default value:\\n\\n>>> for i in [0,1,2,3]:\\n...    adders[i]=lambda a,i=i: i+a  # note the dummy parameter with a default value\\n...\\n>>> print( adders[1](3) )\\n4\\n\\n\\nthe idea is to declare a parameter (cleverly named i) and give it a default value of the variable you want to capture (the value of  i)\\n'},\n {'prompt': 'I wanted to add 3 features to the robot from the tutorial here:\\nhttp://code.google.com/apis/wave/extensions/robots/python-tutorial.html\\n\\nBefore adding all these features, my robot is working as intended.\\nNow the odd features still shows up (with \"v2\" at the bck of the blip content), but neither of the new features shows up!\\nI tried different ways alr, still doesn\\'t work. So frustrating... Below is the code tt i think looks more logically.\\nCan someone tell me why none seems to work? Thanks...\\n\\nFeature 1 -- wanted to try out AppendText\\nFeature 2 -- wanted the robot to detect a blip is submitted\\nFeature 3 -- wanted the robot to add a blip with the content of the old blip deleted.\\n\\nfrom waveapi import events\\nfrom waveapi import model\\nfrom waveapi import robot\\n\\ndef OnParticipantsChanged(properties, context):\\n  \"\"\"Invoked when any participants have been added/removed.\"\"\"\\n  added = properties[\\'participantsAdded\\']\\n  for p in added:\\n    Notify(context)\\n\\ndef OnRobotAdded(properties, context):\\n  \"\"\"Invoked when the robot has been added.\"\"\"\\n  root_wavelet = context.GetRootWavelet()\\n  \"\"\"feature 1\"\"\"\\n  root_wavelet.CreateBlip().GetDocument().SetText(\"I\\'m alive! v2\").GetDocument().AppendText(\"xxx\")\\n\\ndef Notify(context):\\n  root_wavelet = context.GetRootWavelet()\\n  root_wavelet.CreateBlip().GetDocument().SetText(\"Hi everybody! v2\")\\n\\n  \"\"\"feature 2\"\"\"\\ndef OnBlipSubmitted(properties, context):\\n  blip = context.GetBlipById(properties[\\'blipId\\'])\\n  blip.GetDocument().AppendText(\"xxx\")\\n\\n  \"\"\"feature 3\"\"\"\\ndef OnBlipDeleted(properties, context):\\n  blip = context.GetBlipById(properties[\\'blipId\\'])\\n  contents = blip.GetDocument().GetText()  \\n  root_wavelet = context.GetRootWavelet()\\n  root_wavelet.CreateBlip().GetDocument().SetText(contents)\\n\\nif __name__ == \\'__main__\\':\\n  myRobot = robot.Robot(\\'appName\\', \\n      image_url=\\'http://appName.appspot.com/icon.png\\',\\n      version=\\'1\\',\\n      profile_url=\\'http://appName.appspot.com/\\') \\n  myRobot.RegisterHandler(events.WAVELET_PARTICIPANTS_CHANGED, OnParticipantsChanged)\\n  myRobot.RegisterHandler(events.WAVELET_SELF_ADDED, OnRobotAdded)   \\n  \"\"\"myRobot.RegisterHandler(events.BLIP_SUMBITTED, OnBlipSubmitted)\\n  myRobot.RegisterHandler(events.BLIP_DELETED, OnBlipDeleted)\"\"\"\\n  myRobot.Run()\\n\\n\\nEdit: (Important!)\\nI just noticed that it seems to hv different behaviour on normal mode vs sandbox mode. In normal mode I see both blips \"I\\'m alive! v2\" and \"Hi everybody! v2\", but in sandbox mode I can only see the 1st one. Werid... In neither case I see the appended text...  \\n\\nThe reason why i commented this part \\n  \"\"\"myRobot.RegisterHandler(events.BLIP_SUMBITTED, OnBlipSubmitted)\\n  myRobot.RegisterHandler(events.BLIP_DELETED, OnBlipDeleted)\"\"\"\\nis cos without commenting it, the robot doesn\\'t do anything at all!\\n',\n  'completion': 'events.BLIP_SUMBITTED should be events.BLIP_SUBMITTED\\n'},\n {'prompt': 'Are there any algorithms that will return the equation of a straight line from a set of 3D data points? I can find plenty of sources which will give the equation of a line from 2D data sets, but none in 3D.\\n\\nThanks.\\n',\n  'completion': \"If you are trying to predict one value from the other two, then you should use lstsq with the a argument as your independent variables (plus a column of 1's to estimate an intercept) and b as your dependent variable. \\n\\nIf, on the other hand, you just want to get the best fitting line to the data, i.e. the line which, if you projected the data onto it, would minimize the squared distance between the real point and its projection, then what you want is the first principal component. \\n\\nOne way to define it is the line whose direction vector is the eigenvector of the covariance matrix corresponding to the largest eigenvalue, that passes through the mean of your data. That said, eig(cov(data)) is a really bad way to calculate it, since it does a lot of needless computation and copying and is potentially less accurate than using svd. See below:\\n\\nimport numpy as np\\n\\n# Generate some data that lies along a line\\n\\nx = np.mgrid[-2:5:120j]\\ny = np.mgrid[1:9:120j]\\nz = np.mgrid[-5:3:120j]\\n\\ndata = np.concatenate((x[:, np.newaxis], \\n                       y[:, np.newaxis], \\n                       z[:, np.newaxis]), \\n                      axis=1)\\n\\n# Perturb with some Gaussian noise\\ndata += np.random.normal(size=data.shape) * 0.4\\n\\n# Calculate the mean of the points, i.e. the 'center' of the cloud\\ndatamean = data.mean(axis=0)\\n\\n# Do an SVD on the mean-centered data.\\nuu, dd, vv = np.linalg.svd(data - datamean)\\n\\n# Now vv[0] contains the first principal component, i.e. the direction\\n# vector of the 'best fit' line in the least squares sense.\\n\\n# Now generate some points along this best fit line, for plotting.\\n\\n# I use -7, 7 since the spread of the data is roughly 14\\n# and we want it to have mean 0 (like the points we did\\n# the svd on). Also, it's a straight line, so we only need 2 points.\\nlinepts = vv[0] * np.mgrid[-7:7:2j][:, np.newaxis]\\n\\n# shift by the mean to get the line in the right place\\nlinepts += datamean\\n\\n# Verify that everything looks right.\\n\\nimport matplotlib.pyplot as plt\\nimport mpl_toolkits.mplot3d as m3d\\n\\nax = m3d.Axes3D(plt.figure())\\nax.scatter3D(*data.T)\\nax.plot3D(*linepts.T)\\nplt.show()\\n\\n\\nHere's what it looks like: \\n\"},\n {'prompt': \"I'm new to Django (and Python), and am trying to figure out how to conditionalize certain aspects of form validation. In this case, there's a HTML interface to the application where the user can choose a date and a time from widgets. The clean method on the form object takes the values of the time and date fields and turns them back into a datetime.\\n\\nIn addition to the HTML interface, there's also an iPhone client making calls into the application, and I'd like to pass a UNIX timestamp-style time value in.\\n\\nMy form code looks like this:\\n\\nclass FooForm(forms.ModelForm):\\n    foo_date             = forms.CharField(required=True, widget=forms.RadioSelect(choices=DATE_CHOICES))\\n    foo_time             = forms.CharField(required=True, widget=SelectTimeWidget())\\n    foo_timestamp        = forms.CharField(required=False)\\n\\n\\nHow do I make foo_date and foo_time required unless foo_timestamp is provided?\\n\",\n  'completion': \"This is done with the clean method on the form. You need to set foo_date and foo_time to required=False, though, because clean is only called after every field has been validated (see also the documentation).\\n\\nclass FooForm(forms.Form)\\n    # your field definitions\\n\\n    def clean(self):\\n        data = self.cleaned_data\\n        if data.get('foo_timestamp', None) or (data.get('foo_date', None) and data.get('foo_time', None)):\\n            return data\\n        else:\\n            raise forms.ValidationError('Provide either a date and time or a timestamp')\\n\\n\"},\n {'prompt': '[Update: Problem solved! See bottom of the post]\\n\\nI need to allow python developers to pass an array of packed data (in this case vertices) into my API, which is a series of C++ interfaces exposed manually through the Python C API. My initial impression with this is to use the ctypes Structure class to allow for an interface like this:\\n\\nclass Vertex(Structure):\\n_fields_ = [\\n    (\\'x\\', c_float),\\n    (\\'y\\', c_float),\\n    (\\'z\\', c_float),\\n    (\\'u\\', c_float),\\n    (\\'v\\', c_float),\\n    (\\'color\\', c_int)\\n] \\n\\nverts = (Vertex * 3)()\\nverts[0] = Vertex(0.0, 0.5, 0.0, 0.0, 0.5, 0xFF0000FF)\\nverts[1] = Vertex(0.5, -0.5, 0.0, 0.5, -0.5, 0x00FF00FF)\\nverts[2] = Vertex(-0.5, -0.5, 0.0, -0.5, -0.5, 0x0000FFFF)\\n\\ndevice.ReadVertices(verts, 3) # This is the interfaces to the C++ object\\n\\n\\nWhere the function I\\'m trying to pass to has the following signature:\\n\\nvoid Device::ReadVertices(Vertex* verts, int count);\\n\\n\\nAnd the Python wrapper looks something like this:\\n\\nstatic PyObject* Device_ReadVertices(Py_Device* self, PyObject* args)\\n{\\n    PyObject* py_verts;\\n    int count;\\n\\n    if(!PyArg_ParseTuple(args, \"Oi\", &py_verts, &count)) \\n        return NULL;\\n\\n    // This Doesn\\'t Work!\\n    Vertex* verts = static_cast<Vertex*>(PyCObject_AsVoidPtr(py_verts));\\n\\n    self->device->ReadVertices(verts, count);\\n\\n    Py_RETURN_NONE;\\n}\\n\\n\\nOf course, the biggest issue I have is this: I can retrieve the PyObject for the struct, but I have no idea how I would cast it to the correct type. The above code fails miserably. So how exactly would I go about allowing the user to pass me this kind of data from Python?\\n\\nNow, a couple of things to consider: First is that I already have quite a bit of my Python/C++ layer written, and am perfectly happy with it (I moved away from SWIG so I could have more flexibility). I don\\'t want to re-code it, so I would prefer a solution that works with the C API natively. Second, I do intend to have the Vertex structure be pre-defined in my C++ code, so I would prefer to not have the user need to re-define it in the Python (cuts down on errors that way), but I\\'m not sure how to expose a contiguous structure like that. Third, I have no reason for trying the ctypes structure aside from not knowing another way to do it. Any suggestions are welcome. Finally, since this is (as you may have guessed) for a graphics app I would prefer a faster method over a convenient one, even if the faster method takes a little bit more work.\\n\\nThanks for any help! I\\'m still feeling my way around python extensions, so it\\'s a great help to get community input on some of the stickier parts.\\n\\n[SOLUTION]\\n\\nSo first off, thanks to everyone who pitched in their ideas. It was a lot of little tidbits that added up to the eventual answer. In the end here is what I found: Sam\\'s suggestion of using struct.pack ended up being right on the money. Seeing that I\\'m using Python 3, I had to tweak it ever so slightly, but when all was said and done this actually got a triangle showing up on my screen:\\n\\nverts = bytes()\\nverts += struct.pack(\"fffffI\", 0.0, 0.5, 0.0, 0.0, 0.5, 0xFF0000FF)\\nverts += struct.pack(\"fffffI\", 0.5, -0.5, 0.0, 0.5, -0.5, 0x00FF00FF)\\nverts += struct.pack(\"fffffI\", -0.5, -0.5, 0.0, -0.5, -0.5, 0x0000FFFF)\\n\\ndevice.ReadVertices(verts, 3)\\n\\n\\nWith my tuple parsing now looking like this:\\n\\nstatic PyObject* Device_ReadVertices(Py_Device* self, PyObject* args)\\n{\\n    void* py_verts;\\n    int len, count;\\n\\n    if(!PyArg_ParseTuple(args, \"y#i\", &py_verts, &len, &count)) \\n        return NULL;\\n\\n    // Works now!\\n    Vertex* verts = static_cast<Vertex*>(py_verts);\\n\\n    self->device->ReadVertices(verts, count);\\n\\n    Py_RETURN_NONE;\\n}\\n\\n\\nNote that even though I don\\'t use the len variable in this example (though I will in the final product) I need to parse the tuple using \\'y#\\' instead of just \\'y\\' or else it will stop at the first NULL (according to the documentation). Also to be considered: void* casts like this are quite dangerous, so please do loads more error checking than I show here!\\n\\nSo, job well done, happy day, pack up and go home, yes?\\n\\nWait! Not so fast! There\\'s MORE!\\n\\nFeeling good about how that all worked out I decided, on a whim, to see if my previous attempt still blew up on me and reverted back to the first snippet of python in this post. (Using the new C code, of course) and... it worked! The results were identical to the struct.pack version! Wow! \\n\\nSo this means your users have a choice in how they\\'re going to provide this kind of data, and your code can handle either with no changes. Personally I\\'m going to encourage the ctype.Structure method, since I think it makes for easier readability, but really it\\'s whatever the user is comfortable with. (Heck, they could manually type out a string of bytes in hex if they wanted to. It works. I tried.) \\n\\nHonestly I think this is the best possible outcome, so I\\'m ecstatic. Thank you all again, and good luck to anyone else who runs into this problem!\\n',\n  'completion': 'Not tested but you should give this a try and let us know if its fast enough for your needs.\\n\\nOn the python side, pack the vertices into a string instead of an object.\\n\\nstr = \"\" # byte stream for encoding data\\nstr += struct.pack(\"5f i\", vert1.x, vert1.y, vert1.z, vert1.u, vert1.v, vert1.color) # 5 floats and an int\\n# same for other vertices\\n\\ndevice. ReadVertices( verts, 3) # send vertices to C library\\n\\nOn the C library/python wrapper, modify your PyArgs_ParseTuple to use the format string \"si\". This will convert your python string into a C string (char*) which you can then typecast as a pointer to your vector struct. At this point the C string is a stream of bytes/words/floats and should be what you\\'re looking for.\\n\\nGood luck!\\n'},\n {'prompt': 'I would like to try to write a GUI application in Python. I found out that there are a lot of ways to do it (different toolkits). And, in this context, I have several basic (and I think simple) question?\\n\\n\\nIs it, in general, a good idea to write a GUI application in Python?\\nWhat is the standard (easiest and most stable) way to create a GUI applications in Python?\\nDoes anybody can give me a link to a simple Hello World GUI application written in Python?\\n\\n',\n  'completion': '\\nDepends on what application you are writing. I would use Python for a simple GUI, yes.\\nUse a proper toolkit (such as PyQt - Python bindings for the popular Qt)\\nSure\\n\\n\\nHello world in PyQt:\\n\\nimport qt,sys\\n\\na = qt.QApplication(sys.argv)\\nw = qt.QPushButton(\"Hello World\",None)\\n\\na.setMainWidget(w)\\nw.show()\\na.exec_loop()\\n\\n'},\n {'prompt': 'Looking for a better way to get a machines current external IP #... Below works, but would rather not rely on an outside site to gather the information ... I am restricted to using standard Python 2.5.1 libraries bundled with Mac OS X 10.5.x\\n\\nimport os\\nimport urllib2\\n\\ndef check_in():\\n\\n    fqn = os.uname()[1]\\n    ext_ip = urllib2.urlopen(\\'http://whatismyip.org\\').read()\\n    print (\"Asset: %s \" % fqn, \"Checking in from IP#: %s \" % ext_ip)\\n\\n',\n  'completion': \"I wrote a module for that: ipgetter.\\nIs designed to fetch your external IP address from the internet. It is used mostly when behind a NAT. It picks your IP randomly from a serverlist to minimize request overhead on a single server.\\nActually with 44 server and test function to verify if the servers are returning the same IP.\\n\\nhttps://github.com/phoemur/ipgetter\\n\\ngoes like this:\\n\\n>>> import ipgetter\\n>>> IP = ipgetter.myip()\\n>>> print(IP)\\n'xxx.xxx.xxx.xxx'\\n\\n>>> ipgetter.IPgetter().test()\\nNumber of servers: 44\\nIP's :\\n'xxx.xxx.xxx.xxx' = 44 ocurrencies\\n\\n\"},\n {'prompt': 'I have a small program in PyQt4 and I want to compile the program into an Exe. I am using py2exe to do that. I can successfully set icon in the windows title bar using the following code, but when i compile it into exe the icon is lost and i see the default windows application. here is my program:\\n\\nimport sys\\nfrom PyQt4 import QtGui\\n\\n\\nclass Icon(QtGui.QWidget):\\n    def __init__(self, parent=None):\\n        QtGui.QWidget.__init__(self, parent)\\n\\n        self.setGeometry(300, 300, 250, 150)\\n        self.setWindowTitle(\\'Icon\\')\\n        self.setWindowIcon(QtGui.QIcon(\\'c:/python26_/repy26/icons/iqor1.ico\\'))\\n\\n\\napp = QtGui.QApplication(sys.argv)\\nicon = Icon()\\nicon.show()\\nsys.exit(app.exec_())\\n\\n\\n Here is the setup.py for py2exe**\\n\\nfrom distutils.core import setup\\nimport py2exe\\n\\nsetup(windows=[{\"script\":\"iconqt.py\"\\n               ,\"icon_resources\": [(1, \"Iqor1.ico\")]}]\\n                   ,options={\"py2exe\":{\"includes\":[\"sip\", \"PyQt4.QtCore\"]}})\\n\\n',\n  'completion': 'The problem is that py2exe doesn\\'t include the qt icon reader plugin.  You need to tell it to include it with the data_files parameter.  Something along these lines:\\n\\nsetup(windows=[{\"script\":script_path,\\n                \"icon_resources\":[(1, icon_path)]}], \\n      data_files = [\\n            (\\'imageformats\\', [\\n              r\\'C:\\\\Python26\\\\Lib\\\\site-packages\\\\PyQt4\\\\plugins\\\\imageformats\\\\qico4.dll\\'\\n              ])],\\n      options={\"py2exe\":{\"packages\":[\"gzip\"], \\n                         \"includes\":[\"sip\"]}})\\n\\n'},\n {'prompt': 'If the value is None, I\\'d like to change it to \"\" (empty string).\\n\\nI start off like this, but I forget:\\n\\nfor k, v in mydict.items():\\n    if v is None:\\n... right?\\n\\n',\n  'completion': \"for k, v in mydict.iteritems():\\n    if v is None:\\n        mydict[k] = ''\\n\\n\\nIn a more general case, e.g. if you were adding or removing keys, it might not be safe to change the structure of the container you're looping on -- so using items to loop on an independent list copy thereof might be prudent -- but assigning a different value at a given existing index does not incur any problem, so, in Python 2.any, it's better to use iteritems.\\n\"},\n {'prompt': \"I have a script that creates a virtualenv, installs distribute and pip in it and then optionally clones a git repo.\\n\\nNow I have the project I will be working on, installed. But its dependencies are not installed. How can I make pip install all the dependencies as if I have issued a pip install MyApp?\\n\\nEDIT: Appareantly my question is a duplicate of this one.\\n\\nNot exactly sure but pip install -e . seems to do what I want without too many extra stuff lying around. I'd prefer if my code wasn't linked from site-packages though.\\n\",\n  'completion': 'In my package root issuing pip install -e . installs dependencies.\\n'},\n {'prompt': 'In general I want to disable as little code as possible, and I want it to be explicit: I don\\'t want the code being tested to decide whether it\\'s a test or not, I want the test to tell that code \"hey, BTW, I\\'m running a unit test, can you please not make your call to solr, instead can you please stick what you would send to solr in this spot so I can check it\". I have my ideas but I don\\'t like any of them, I am hoping that there\\'s a good pythonic way to do this.\\n',\n  'completion': \"You can use Mock objects to intercept the method calls that you do not want to execute. \\nE.g. You have some class A, where you don't want method no() to be called during a test.\\n\\nclass A:\\n  def do(self):\\n    print('do')\\n  def no(self):\\n    print('no')\\n\\n\\nA mock object could inherit from A and override no() to do nothing.\\n\\nclass MockA(A):\\n  def no(self):\\n    pass\\n\\n\\nYou would then create MockA objects instead of As in your test code. Another way to do mocking would be to have A and MockA implement a common interface say InterfaceA. \\n\\nThere are tons of mocking frameworks available. See StackOverflow: Python mocking frameworks.\\n\\nIn particular see: Google's Python mocking framework.\\n\"},\n {'prompt': 'In my python program, when I send the user to create a gmail account by use of the webbrowser module, python displays:\\n\\n\"Please enter your Gmail username: Created new window in existing browser session.\"\\n\\nIs there any way to get rid of \"created new window in existing browser session\", as it takes up the space where the user types in their Gmail account.\\n\\nThe code for this is:  \\n\\nwebbrowser.open(\\'https://www.google.com/accounts/NewAccount?service=mail\\')  \\ngmail_user = raw_input(\\'Please enter your Gmail username: \\')\\n\\n\\nEDIT: After trying out both of Alex Martelli\\'s suggestions, the code is: http://pastebin.com/3uu9QS4A\\n\\nEDIT 2: I have decided just to tell users to go to the gmail registration page instead of actually sending them there, as that is much simpler to do and results in no (currently-unsolvable-by-me) errors.\\n',\n  'completion': 'As S.Lott hints in a comment, you should probably do the raw_input first; however, that, per se, doesn\\'t suppress the message from webbrowser, as you ask -- it just postpones it.\\n\\nTo actually suppress the message, you can temporarily redirect standard-output or standard-error -- whichever of the two your chosen browser uses to emit that message.  It\\'s probably no use to redirect them at Python level (via sys.stdout or sys.stderr), since your browser is going to be doing its output directly; rather, you can do it at the operating-system level, e.g., for standard output:\\n\\nimport os\\ngmail_user = raw_input(\\'Please enter your Gmail username: \\')\\nsavout = os.dup(1)\\nos.close(1)\\nos.open(os.devnull, os.O_RDWR)\\ntry:\\n   webbrowser.open(whatever)\\nfinally:\\n   os.dup2(savout, 1)\\n\\n\\n(for standard error instead of standard output, use 2 instead of 1).  This is pretty low-level programming, but since the webbrowser module does not give you \"hooks\" to control the way in which the browser gets opened, it\\'s pretty much the only choice to (more or less) ensure suppression of that message.\\n'},\n {'prompt': 'I\\'m coding an application that needs to select an area of the screen. I need to change the cursor to a cross and then draw a rectangle on the user selection. The first thing I searched for is how to manipulate the cursor and I came across wxPython. With wxPython I could easily do this on a Frame with a Panel, the thing is that I\\'d need the window to be transparent so the user can see his screen while is selecting the desired area, but if I make the Frame and the Panel objects transparent everything gets buggy.\\n\\nSo, I\\'m open to any solution, either using wxPython or not using it because I don\\'t really know if I\\'m using it right.\\n\\nI\\'m new to Python and I\\'m not a native english speaker, so I\\'m sorry if you can\\'t understand something.\\n\\nThis is what I coded\\n\\nimport wx\\n\\nclass SelectableFrame(wx.Frame):\\n\\n    c1 = None\\n    c2 = None\\n\\n    def __init__(self, parent=None, id=-1, title=\"\"):\\n        wx.Frame.__init__(self, parent, id, title, size=wx.DisplaySize(), style=wx.TRANSPARENT_WINDOW)\\n\\n        self.panel = wx.Panel(self, size=self.GetSize(), style=wx.TRANSPARENT_WINDOW)\\n\\n        self.panel.Bind(wx.EVT_MOTION, self.OnMouseMove)\\n        self.panel.Bind(wx.EVT_LEFT_DOWN, self.OnMouseDown)\\n        self.panel.Bind(wx.EVT_LEFT_UP, self.OnMouseUp)\\n        self.panel.Bind(wx.EVT_PAINT, self.OnPaint)\\n\\n        self.SetCursor(wx.StockCursor(wx.CURSOR_CROSS))\\n\\n    def OnMouseMove(self, event):\\n        if event.Dragging() and event.LeftIsDown():\\n            self.c2 = event.GetPosition()\\n            self.Refresh()\\n\\n    def OnMouseDown(self, event):\\n        self.c1 = event.GetPosition()\\n\\n    def OnMouseUp(self, event):\\n        self.SetCursor(wx.StockCursor(wx.CURSOR_ARROW))\\n\\n    def OnPaint(self, event):\\n        if self.c1 is None or self.c2 is None: return\\n\\n        dc = wx.PaintDC(self.panel)\\n        dc.SetPen(wx.Pen(\\'red\\', 1))\\n        dc.SetBrush(wx.Brush(wx.Color(0, 0, 0), wx.TRANSPARENT))\\n\\n        dc.DrawRectangle(self.c1.x, self.c1.y, self.c2.x - self.c1.x, self.c2.y - self.c1.y)\\n\\n    def PrintPosition(self, pos):\\n        return str(pos.x) + \" \" + str(pos.y)\\n\\n\\nclass MyApp(wx.App):\\n\\n    def OnInit(self):\\n        frame = SelectableFrame()\\n        frame.Show(True)\\n        self.SetTopWindow(frame)\\n\\n        return True\\n\\n\\n\\napp = MyApp(0)\\napp.MainLoop()\\n\\n',\n  'completion': 'You shouldn\\'t be using wx.TRANSPARENT in window creation, that is mostly used for wxDC paint commands. To make a window transparent just call win.SetTransparent(amount), where amount is from 0-255, 255 means opaque, 0 means totally transparent. see http://www.wxpython.org/docs/api/wx.Window-class.html#SetTransparent\\n\\nI have modified your code, it will work only if your platform supports transparent windows, you can check that by CanSetTransparent. I tested it on windows XP.\\n\\nimport wx\\n\\nclass SelectableFrame(wx.Frame):\\n\\n    c1 = None\\n    c2 = None\\n\\n    def __init__(self, parent=None, id=-1, title=\"\"):\\n        wx.Frame.__init__(self, parent, id, title, size=wx.DisplaySize())\\n\\n        self.panel = wx.Panel(self, size=self.GetSize())\\n\\n        self.panel.Bind(wx.EVT_MOTION, self.OnMouseMove)\\n        self.panel.Bind(wx.EVT_LEFT_DOWN, self.OnMouseDown)\\n        self.panel.Bind(wx.EVT_LEFT_UP, self.OnMouseUp)\\n        self.panel.Bind(wx.EVT_PAINT, self.OnPaint)\\n\\n        self.SetCursor(wx.StockCursor(wx.CURSOR_CROSS))\\n\\n        self.SetTransparent(50)\\n\\n    def OnMouseMove(self, event):\\n        if event.Dragging() and event.LeftIsDown():\\n            self.c2 = event.GetPosition()\\n            self.Refresh()\\n\\n    def OnMouseDown(self, event):\\n        self.c1 = event.GetPosition()\\n\\n    def OnMouseUp(self, event):\\n        self.SetCursor(wx.StockCursor(wx.CURSOR_ARROW))\\n\\n    def OnPaint(self, event):\\n        if self.c1 is None or self.c2 is None: return\\n\\n        dc = wx.PaintDC(self.panel)\\n        dc.SetPen(wx.Pen(\\'red\\', 1))\\n        dc.SetBrush(wx.Brush(wx.Color(0, 0, 0), wx.TRANSPARENT))\\n\\n        dc.DrawRectangle(self.c1.x, self.c1.y, self.c2.x - self.c1.x, self.c2.y - self.c1.y)\\n\\n    def PrintPosition(self, pos):\\n        return str(pos.x) + \" \" + str(pos.y)\\n\\n\\nclass MyApp(wx.App):\\n\\n    def OnInit(self):\\n        frame = SelectableFrame()\\n        frame.Show(True)\\n        self.SetTopWindow(frame)\\n\\n        return True\\n\\n\\napp = MyApp(0)\\napp.MainLoop()\\n\\n'},\n {'prompt': \"I'm a relatively new hire, and I'm starting on a small, fairly simple project. The language that this project will be implemented in is still to be determined. The question basically boils down to - Java or Python? \\n\\nHere's the dilemma: My manager would prefer it to be done in Python. I don't object to that, but I have no experience in Python. I'd really love to learn Python and think I could manage it fairly quickly (especially as it's a small project). BUT the project is due at the end of March and must be ready by then. So they'd rather have it in Java and on time than in Python and late, and they don't want to pressure me to do it in Python if I think I can't make it on time.\\n\\nSorry about the background - but my question basically is, how long does it take, on average, to adapt to a new language? I know this is subjective and personalized, and depends on how fast the particular programmer is... but talking about an average programmer, or even a somewhat fast one that picks up things quickly, what percentage of an increase does programming in a non-native language (but with similar concepts) cause? As in, if this project would take me about 2 weeks in Java or a .NET language, how much longer can it take me in Python? Can I assume that having double the amount of time (i.e. a new, unfamiliar language causes a 50% increase in programming time) is adequate?\\n\\nAnd included in this question - from what I've heard, it seems to be pretty easy/intuitive to switch over from Java to Python. Is this true...?\\n\\nThanks everyone for all the answers! I didn't realize there are so many sides to this question... I will try to choose an answer soon - each response made me look at it a different way and it's hard to choose one answer.\\n\",\n  'completion': \"I think it depends on the area of the project. While GUI is not hard in Python, any kind of GUI-framework will have a somewhat steep learning curve.\\nIf it is a webapp, I'd say go for Python. The added time for learning is quickly gained back by easy of use of the many Python webframeworks.\\n\\nThe big risk is that you will code Python just like you code Java. Many of the things true in Java are not true in Python and vice versa. It will probably make your Python code slow and verbose.\\n\\nIf you decide to try Python, read up on common pitfalls coming from Java, for example:\\nhttp://dirtsimple.org/2004/12/python-is-not-java.html\\n\"},\n {'prompt': \"When you define a function in Python with an array parameter, what is the scope of that parameter?\\n\\nThis example is taken from the Python tutorial:\\n\\ndef f(a, L=[]):\\n    L.append(a)\\n    return L\\n\\nprint f(1)\\nprint f(2)\\nprint f(3)\\n\\n\\nPrints:\\n\\n[1]\\n[1, 2]\\n[1, 2, 3]\\n\\n\\nI'm not quite sure if I understand what's happening here. Does this mean that the scope of the array is outside of the function? Why does the array remember its values from call to call? Coming from other languages, I would expect this behavior only if the variable was static. Otherwise it seems it should be reset each time. And actually, when I tried the following:\\n\\ndef f(a):\\n    L = []\\n    L.append(a)\\n    return L\\n\\n\\nI got the behavior I expected (the array was reset on each call).\\n\\nSo it seems to me that I just need the line def f(a, L=[]): explained - what is the scope of the L variable?\\n\",\n  'completion': \"The scope is as you would expect.\\n\\nThe perhaps surprising thing is that the default value is only calculated once and reused, so each time you call the function you get the same list, not a new list initialized to [].\\n\\nThe list is stored in f.func_defaults.\\n\\ndef f(a, L=[]):\\n    L.append(a)\\n    return L\\n\\nprint f(1)\\nprint f(2)\\nprint f(3)\\nprint f.func_defaults\\nf.func_defaults = (['foo'],) # Don't do this!\\nprint f(4)\\n\\n\\nResult:\\n\\n[1]\\n[1, 2]\\n[1, 2, 3]\\n([1, 2, 3],)\\n['foo', 4]\\n\\n\"},\n {'prompt': 'I want to know if open a transaction inside another is safe and encouraged?\\n\\nI have a method:\\n\\ndef foo():\\n    session.begin\\n    try:\\n          stuffs\\n    except Exception, e:\\n         session.rollback()\\n         raise e\\n    session.commit()\\n\\n\\nand a method that calls the first one, inside a transaction:\\n\\ndef bar():\\n    stuffs\\n    try:\\n         foo()   #<<<< there it is :)\\n         stuffs\\n    except Exception, e:\\n        session.rollback()\\n        raise e\\n    session.commit()\\n\\n\\nif I get and exception on the foo method, all the operations will be\\nrolled back? and everything else will work just fine?\\nthanks!!\\n',\n  'completion': \"there are two ways two nest transactions in SQLAlchemy. One is virtual transactions, where SQLAlchemy keeps track of how many begin's you have issued and issues the commit only when the outermost transaction commits. The rollback however is issued immediately. Because the transaction is virtual - i.e. the database knows nothing of the nesting, you can't do anything with that session after the rollback until you rollback all the outer transactions too. To allow the use virtual transactions add subtransactions=True argument to the begin() call. This feature exists to allow you to use transaction control inside functions that might call each other without keeping track if you are inside a transaction or not. For it to make sense, configure the session with autocommit=True and always issue a session.begin(subtransactions=True) in a transactional function.\\n\\nThe other way to nest transactions is to use real nested transactions. They are implemented using savepoints. If you rollback a nested transaction, all changes made within that transaction are rolled back, but the outer transaction remains usable and any changes made by the outer transaction are still there. To use nested transaction issue session.begin(nested=True) or just session.begin_nested(). Nested transactions aren't supported for all databases. SQLAlchemy test suite library configuration function sqlalchemy.test.requires.savepoints says this about the support:\\n\\n    emits_warning_on('mssql', 'Savepoint support in mssql is experimental and may lead to data loss.'),\\n    no_support('access', 'not supported by database'),\\n    no_support('sqlite', 'not supported by database'),\\n    no_support('sybase', 'FIXME: guessing, needs confirmation'),\\n    exclude('mysql', '<', (5, 0, 3), 'not supported by database')\\n\\n\\nOn PostgreSQL SQLAlchemy nested transactions work just fine.\\n\"},\n {'prompt': 'I have an iterator of numbers, for example a file object:\\n\\nf = open(\"datafile.dat\")\\n\\n\\nnow I want to compute:\\n\\nmean = get_mean(f)\\nsigma = get_sigma(f, mean)\\n\\n\\nWhat is the best implementation? Suppose that the file is big and I would like to avoid to read it twice.\\n',\n  'completion': \"If you want to iterate once, you can write your sum function:\\n\\ndef mysum(l):\\n    s2 = 0\\n    s = 0\\n    for e in l:\\n        s += e\\n        s2 += e * e\\n    return (s, s2)\\n\\n\\nand use the result in your sigma function.\\n\\nEdit: now you can calculate the variance like this: (s2 - (s*s) / N) / N\\n\\nBy taking account of @Adam Bowen's comment,\\nkeep in mind that if we use mathematical tricks and transform the original formulas\\nwe may degrade the results.\\n\"},\n {'prompt': \"I am attaching a method to the post_save signal of my Django model. This way I can clear some cached items whenever the model is modified. \\n\\nThe problem I am having is that the signal is being triggered twice when the model is saved. It doesn't necessarily hurt anything (the code will just gracefully error out) but it can't be right.\\n\\nA quick example, just printing the model to the console (using the dev server):\\n\\nfrom blog.models import Post\\nfrom django.db.models import signals\\n\\ndef purge_cache(sender, **kwargs):\\n    print 'Purging %s' % sender\\n\\nsignals.post_save.connect(purge_cache, sender=Post)\\n\\n\\nThis is using the stable 1.1.1 release of Django.\\n\\nUpdated Information:\\n\\nWith feedback from everyone's comments, I have modified my question because the issue is now discovering why the post_save is being triggered twice. My guess at the moment is that my models.py code is imported twice and that the post_save is getting connected multiple times.\\n\\nWhat would be the best way to figure out why it is being imported/ran twice?\\n\",\n  'completion': 'Apparently, Python is sensitive to the way you import modules. In my case, it wasn\\'t an issue with any of import code inside my blog application but an issue with the INSTALLED_APPS configuration, which I assume is used by Django to do an initial import.\\n\\nInside my blog application I was using imports such as:\\n\\nfrom blog.models import *\\n\\n\\nMy settings.py was configured as:\\n\\nINSTALLED_APPS = (\\n    \\'django.contrib.admin\\',\\n    \\'django.contrib.auth\\',\\n    ...snip...\\n    \\'sorl.thumbnail\\',\\n    \\'mysite.blog\\',\\n)\\n\\n\\nThe \"mysite\" prefix was added because I originally had import path issues when deploying the site. Later I fixed this issue (so it acted the same as the development server) by adding multiple paths in my WSGI script.\\n\\nRemoving the \"mysite\" prefix from the settings.py fixed the issue:\\n\\nINSTALLED_APPS = (\\n    \\'django.contrib.admin\\',\\n    \\'django.contrib.auth\\',\\n    ...snip...\\n    \\'sorl.thumbnail\\',\\n    \\'blog\\',\\n)\\n\\n'},\n {'prompt': 'I\\'m trying to batch up a bunch of vertices and texture coords in an interleaved array before sending it to pyOpengl\\'s glInterleavedArrays/glDrawArrays.  The only problem is that I\\'m unable to find a suitably fast enough way to append data into a numpy array.  \\n\\nIs there a better way to do this?  I would have thought it would be quicker to preallocate the array and then fill it with data but instead, generating a python list and converting it to a numpy array is \"faster\".  Although 15ms for 4096 quads seems slow.\\n\\nI have included some example code and their timings.\\n\\n#!/usr/bin/python\\n\\nimport timeit\\nimport numpy\\nimport ctypes\\nimport random\\n\\nUSE_RANDOM=True\\nUSE_STATIC_BUFFER=True\\n\\nSTATIC_BUFFER = numpy.empty(4096*20, dtype=numpy.float32)\\n\\ndef render(i):\\n    # pretend these are different each time\\n    if USE_RANDOM:\\n        tex_left, tex_right, tex_top, tex_bottom = random.random(), random.random(), random.random(), random.random()\\n        left, right, top, bottom = random.random(), random.random(), random.random(), random.random()\\n    else:\\n        tex_left, tex_right, tex_top, tex_bottom = 0.0, 1.0, 1.0, 0.0\\n        left, right, top, bottom = -1.0, 1.0, 1.0, -1.0\\n\\n    ibuffer = (\\n        tex_left, tex_bottom,   left, bottom, 0.0,  # Lower left corner\\n        tex_right, tex_bottom,  right, bottom, 0.0, # Lower right corner\\n        tex_right, tex_top,     right, top, 0.0,    # Upper right corner\\n        tex_left, tex_top,      left, top, 0.0,     # upper left\\n    )\\n\\n    return ibuffer\\n\\n\\n\\n# create python list.. convert to numpy array at end\\ndef create_array_1():\\n    ibuffer = []\\n    for x in xrange(4096):\\n        data = render(x)\\n        ibuffer += data\\n\\n    ibuffer = numpy.array(ibuffer, dtype=numpy.float32)\\n    return ibuffer\\n\\n# numpy.array, placing individually by index\\ndef create_array_2():\\n    if USE_STATIC_BUFFER:\\n        ibuffer = STATIC_BUFFER\\n    else:\\n        ibuffer = numpy.empty(4096*20, dtype=numpy.float32)\\n    index = 0\\n    for x in xrange(4096):\\n        data = render(x)\\n        for v in data:\\n            ibuffer[index] = v\\n            index += 1\\n    return ibuffer\\n\\n# using slicing\\ndef create_array_3():\\n    if USE_STATIC_BUFFER:\\n        ibuffer = STATIC_BUFFER\\n    else:\\n        ibuffer = numpy.empty(4096*20, dtype=numpy.float32)\\n    index = 0\\n    for x in xrange(4096):\\n        data = render(x)\\n        ibuffer[index:index+20] = data\\n        index += 20\\n    return ibuffer\\n\\n# using numpy.concat on a list of ibuffers\\ndef create_array_4():\\n    ibuffer_concat = []\\n    for x in xrange(4096):\\n        data = render(x)\\n        # converting makes a diff!\\n        data = numpy.array(data, dtype=numpy.float32)\\n        ibuffer_concat.append(data)\\n    return numpy.concatenate(ibuffer_concat)\\n\\n# using numpy array.put\\ndef create_array_5():\\n    if USE_STATIC_BUFFER:\\n        ibuffer = STATIC_BUFFER\\n    else:\\n        ibuffer = numpy.empty(4096*20, dtype=numpy.float32)\\n    index = 0\\n    for x in xrange(4096):\\n        data = render(x)\\n        ibuffer.put( xrange(index, index+20), data)\\n        index += 20\\n    return ibuffer\\n\\n# using ctype array\\nCTYPES_ARRAY = ctypes.c_float*(4096*20)\\ndef create_array_6():\\n    ibuffer = []\\n    for x in xrange(4096):\\n        data = render(x)\\n        ibuffer += data\\n    ibuffer = CTYPES_ARRAY(*ibuffer)\\n    return ibuffer\\n\\ndef equals(a, b):\\n\\n    for i,v in enumerate(a):\\n        if b[i] != v:\\n            return False\\n    return True\\n\\n\\n\\nif __name__ == \"__main__\":\\n    number = 100\\n\\n    # if random, don\\'t try and compare arrays\\n    if not USE_RANDOM and not USE_STATIC_BUFFER:\\n        a =  create_array_1()\\n        assert equals( a, create_array_2() )\\n        assert equals( a, create_array_3() )\\n        assert equals( a, create_array_4() )\\n        assert equals( a, create_array_5() )\\n        assert equals( a, create_array_6() )\\n\\n    t = timeit.Timer( \"testing2.create_array_1()\", \"import testing2\" )\\n    print \\'from list:\\', t.timeit(number)/number*1000.0, \\'ms\\'\\n\\n    t = timeit.Timer( \"testing2.create_array_2()\", \"import testing2\" )\\n    print \\'array: indexed:\\', t.timeit(number)/number*1000.0, \\'ms\\'\\n\\n    t = timeit.Timer( \"testing2.create_array_3()\", \"import testing2\" )\\n    print \\'array: slicing:\\', t.timeit(number)/number*1000.0, \\'ms\\'\\n\\n    t = timeit.Timer( \"testing2.create_array_4()\", \"import testing2\" )\\n    print \\'array: concat:\\', t.timeit(number)/number*1000.0, \\'ms\\'\\n\\n    t = timeit.Timer( \"testing2.create_array_5()\", \"import testing2\" )\\n    print \\'array: put:\\', t.timeit(number)/number*1000.0, \\'ms\\'\\n\\n    t = timeit.Timer( \"testing2.create_array_6()\", \"import testing2\" )\\n    print \\'ctypes float array:\\', t.timeit(number)/number*1000.0, \\'ms\\'\\n\\n\\nTimings using random numbers:\\n\\n$ python testing2.py\\nfrom list: 15.0486779213 ms\\narray: indexed: 24.8184704781 ms\\narray: slicing: 50.2214789391 ms\\narray: concat: 44.1691994667 ms\\narray: put: 73.5879898071 ms\\nctypes float array: 20.6674289703 ms\\n\\n\\nedit note: changed code to produce random numbers for each render to reduce object reuse and to simulate different vertices each time.\\n\\nedit note2: added static buffer and force all numpy.empty() to use dtype=float32\\n\\nnote 1/Apr/2010: still no progress and I don\\'t really feel that any of the answers have solved the problem yet.\\n',\n  'completion': 'The reason that create_array_1 is so much faster seems to be that the items in the (python) list all point to the same object. You can see this if you test:\\n\\nprint (ibuffer[0] is ibuffer[1])\\n\\n\\ninside the subroutines. In create_array_1 this is true (before you create the numpy array), while in create_array_2 this is always going to be false. I guess this means that data conversion step in the array conversion only has to happen once in create_array_1, while it happens 4096 times in create_array_2.\\n\\nIf this is the reason, I guess the timings will be different if you make render generate random data. Create_array_5 is slowest as it makes a new array each time you add data to the end.\\n'},\n {'prompt': 'I\\'m trying to parse a huge xml file with lxml in a memory efficient manner (ie streaming lazily from disk instead of loading the whole file in memory).  Unfortunately, the file contains some bad ascii characters that break the default parser.  The parser works if I set recover=True, but the iterparse method doesn\\'t take the recover parameter or a custom parser object.  Does anyone know how to use iterparse to parse broken xml?\\n\\n#this works, but loads the whole file into memory\\nparser = lxml.etree.XMLParser(recover=True) #recovers from bad characters.\\ntree = lxml.etree.parse(filename, parser)\\n\\n#how do I do the equivalent with iterparse?  (using iterparse so the file can be streamed lazily from disk)\\ncontext = lxml.etree.iterparse(filename, tag=\\'RECORD\\')\\n#record contains 6 elements that I need to extract the text from\\n\\n\\nThanks for your help!\\n\\nEDIT -- Here is an example of the types of encoding errors I\\'m running into:\\n\\nIn [17]: data\\nOut[17]: \\'\\\\t<articletext>&lt;p&gt;The cafeteria rang with excited voices.  Our barbershop quartet, The Bell \\\\r Tones was asked to perform at the local Home for the Blind in the next town.  We, of course, were glad to entertain such a worthy group and immediately agreed .  One wag joked, \"Which uniform should we wear?\"  followed with, \"Oh, that\\\\\\'s right, they\\\\\\'ll never notice.\"  The others didn\\\\\\'t respond to this, in fact, one said that we should wear the nicest outfit we had.&lt;/p&gt;&lt;p&gt;A small stage was set up for us and a pretty decent P.A. system was donated for the occasion.  The audience was made up of blind persons of every age, from the thirties to the nineties.  Some sported sighted companions or nurses who stood or sat by their side, sharing the moment equally.  I observed several German shepherds lying at their feet, adoration showing in their eyes as they wondered what was going on.  After a short introduction in which we identified ourselves, stating our voice part and a little about our livelihood, we began our program.  Some songs were completely familiar and others, called \"Oh, yeah\" songs, only the chorus came to mind.  We didn\\\\\\'t mind at all that some sang along \\\\x1e they enjoyed it so much.&lt;/p&gt;&lt;p&gt;In fact, a popular part of our program is when the audience gets to sing some of the old favorites.  The harmony parts were quite evident as they tried their voices to the different parts.  I think there was more group singing in the old days than there is now, but to blind people, sound and music is more important.   We received a big hand at the finale and were made to promise to return the following year.  Everyone was treated to coffee and cake, our quartet going around to the different circles of friends to sing a favorite song up close and personal.  As we approached a new group, one blind lady amazed me by turning to me saying, \"You\\\\\\'re the baritone, aren\\\\\\'t you?\"  Previously no one had ever been able to tell which singer sang which part but this lady was listening with her whole heart.&lt;/p&gt;&lt;p&gt;Retired portrait photographer.  Main hobby - quartet singing.&lt;/p&gt;</articletext>\\\\n\\'\\n\\nIn [18]: lxml.etree.from\\nlxml.etree.fromstring      lxml.etree.fromstringlist  \\n\\nIn [18]: lxml.etree.fromstring(data)\\n---------------------------------------------------------------------------\\nXMLSyntaxError                            Traceback (most recent call last)\\n\\n/mnt/articles/<ipython console> in <module>()\\n\\n/usr/lib/python2.5/site-packages/lxml-2.2.4-py2.5-linux-i686.egg/lxml/etree.so in lxml.etree.fromstring (src/lxml/lxml.etree.c:48270)()\\n\\n/usr/lib/python2.5/site-packages/lxml-2.2.4-py2.5-linux-i686.egg/lxml/etree.so in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:71812)()\\n\\n/usr/lib/python2.5/site-packages/lxml-2.2.4-py2.5-linux-i686.egg/lxml/etree.so in lxml.etree._parseDoc (src/lxml/lxml.etree.c:70673)()\\n\\n/usr/lib/python2.5/site-packages/lxml-2.2.4-py2.5-linux-i686.egg/lxml/etree.so in lxml.etree._BaseParser._parseDoc (src/lxml/lxml.etree.c:67442)()\\n\\n/usr/lib/python2.5/site-packages/lxml-2.2.4-py2.5-linux-i686.egg/lxml/etree.so in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:63824)()\\n\\n/usr/lib/python2.5/site-packages/lxml-2.2.4-py2.5-linux-i686.egg/lxml/etree.so in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:64745)()\\n\\n/usr/lib/python2.5/site-packages/lxml-2.2.4-py2.5-linux-i686.egg/lxml/etree.so in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:64088)()\\n\\nXMLSyntaxError: PCDATA invalid Char value 30, line 1, column 1190\\n\\nIn [19]: chardet.detect(data)\\nOut[19]: {\\'confidence\\': 1.0, \\'encoding\\': \\'ascii\\'}\\n\\n\\nAs you can see, chardet thinks it is an ascii file, but there is a \"\\\\x1e\" right in the middle of this example which is making lxml raise an exception.\\n',\n  'completion': 'The currently accepted answer is, well, not what one should do.\\nThe question itself also has a bad assumption:\\n\\n\\n  parser = lxml.etree.XMLParser(recover=True) #recovers from bad characters.\\n\\n\\nActually recover=True is for recovering from misformed XML. There is however an \"encoding\" option which would have fixed your issue. \\n\\nparser = lxml.etree.XMLParser(encoding=\\'utf-8\\' #Your encoding issue.\\n                              recover=True, #I assume you probably still want to recover from bad xml, it\\'s quite nice. If not, remove.\\n                              )\\n\\n\\nThat\\'s it, that\\'s the solution.\\n\\n\\n\\nBTW -- For anyone struggling with parsing XML in python, especially from third party sources. I know, I know, the documentation is bad and there are a lot of SO red herrings; a lot of bad advice. \\n\\n\\nlxml.etree.fromstring()? - That\\'s for perfectly formed XML, silly\\nBeautifulStoneSoup? - Slow, and has a way-stupid policy for self\\nclosing tags\\nlxml.etree.HTMLParser()? - (because the xml is broken)\\nHere\\'s a secret - HTMLParser() is... a Parser with recover=True\\nlxml.html.soupparser? - The encoding detection is supposed to be better, but it has the same failings of BeautifulSoup for self closing tags. Perhaps you can combine XMLParser with BeautifulSoup\\'s UnicodeDammit\\nUnicodeDammit and other cockamamie stuff to fix encodings? - Well, UnicodeDammit is kind of cute, I like the name and it\\'s useful for stuff beyond xml, but things are usually fixed if you do the right thing with XMLParser()\\n\\n\\nYou could be trying all sorts of stuff from what\\'s available online. lxml documentation could be better. The code above is what you need for 90% of your XML parsing cases. Here I\\'ll restate it:\\n\\nmagical_parser = XMLParser(encoding=\\'utf-8\\', recover=True)\\ntree = etree.parse(StringIO(your_xml_string), magical_parser) #or pass in an open file object\\n\\n\\nYou\\'re welcome. My headaches == your sanity. Plus it has other features you might need for, you know, XML.\\n'},\n {'prompt': 'Having a background in Java, which is very verbose and strict, I find the ability to mutate Python objects as to give them with fields other than those presented to the constructor really \"ugly\".\\n\\nTrying to accustom myself to a Pythonic way of thinking, I\\'m wondering how I should allow my objects to be constructed.\\n\\nMy instinct is to have to pass the fields at construction time, such as:\\n\\ndef __init__(self, foo, bar, baz=None):\\n    self.foo = foo\\n    self.bar = bar\\n    self.baz = baz\\n\\n\\nBut that can become overly verbose and confusing with many fields to pass. To overcome this I assume the best method is to pass one dictionary to the constructor, from which the fields are extracted:\\n\\ndef __init__(self, field_map):\\n    self.foo = field_map[\"foo\"]\\n    self.bar = field_map[\"bar\"]\\n    self.baz = field_map[\"baz\"] if baz in field_map else None\\n\\n\\nThe other mechanism I can think of is to have the fields added elsewhere, such as:\\n\\nclass Blah(object):\\n\\n    def __init__(self):\\n        pass\\n\\n...\\n\\nblah = Blah()\\nblah.foo = var1\\n\\n\\nBut as that feels way too loose for me.\\n\\n(I suppose the issue in my head is how I deal with interfaces in Python...)\\n\\nSo, to reiterate the question: How I should construct my objects in Python? Is there an accepted convention?\\n',\n  'completion': \"The first you describe is very common. Some use the shorter\\n\\nclass Foo:\\n   def __init__(self, foo, bar):\\n       self.foo, self.bar = foo, bar\\n\\n\\nYour second approach isn't common, but a similar version is this:\\n\\nclass Thing:\\n   def __init__(self, **kwargs):\\n       self.something = kwargs['something']\\n       #..\\n\\n\\nwhich allows to create objects like\\n\\nt = Thing(something=1)\\n\\n\\nThis can be further modified to \\n\\nclass Thing:\\n   def __init__(self, **kwargs):\\n       self.__dict__.update(kwargs)\\n\\n\\nallowing\\n\\nt = Thing(a=1, b=2, c=3)\\nprint t.a, t.b, t.c # prints 1, 2, 3\\n\\n\\nAs Debilski points out in the comments, the last method is a bit unsafe, you can add a list of accepted parameters like this:\\n\\nclass Thing:\\n    keywords = 'foo', 'bar', 'snafu', 'fnord'\\n    def __init__(self, **kwargs):\\n        for kw in self.keywords:\\n            setattr(self, kw, kwargs[kw])\\n\\n\\nThere are many variations, there is no common standard that I am aware of.\\n\"},\n {'prompt': 'Is there a generally accepted way to do this?  Is this acceptable:\\n\\n#########################################################\\n# Create a new user\\n#########################################################\\ndef add(self):\\n\\n',\n  'completion': 'The correct way to do it is to provide a docstring. That way, help(add) will also spit out your comment.\\n\\ndef add(self):\\n    \"\"\"Create a new user.\\n    Line 2 of comment...\\n    And so on... \\n    \"\"\"\\n\\n\\nThat\\'s three double quotes to open the comment and another three double quotes to end it. You can also use any valid Python string. It doesn\\'t need to be multiline and double quotes can be replaced by single quotes. \\n\\nSee: PEP 257\\n'},\n {'prompt': \"I'm using the Django manage.py runserver for developing my application (obviously), but it takes 10 seconds to completely load a page because the development server is very, very slow at serving static media.\\n\\nIs there any way to speed it up or some kind of workaround? I'm using Windows 7.\\n\",\n  'completion': 'Consider using mod_wsgi instead, and having httpd handle the static media.\\n'},\n {'prompt': \"I'm looking to speed along my discovery process here quite a bit, as this is my first venture into the world of lexical analysis. Maybe this is even the wrong path. First, I'll describe my problem:\\n\\nI've got very large properties files (in the order of 1,000 properties), which when distilled, are really just about 15 important properties and the rest can be generated or rarely ever change. \\n\\nSo, for example:\\n\\ngeneral {\\n  name = myname\\n  ip = 127.0.0.1\\n}\\n\\ncomponent1 {\\n   key = value\\n   foo = bar\\n}\\n\\n\\nThis is the type of format I want to create to tokenize something like:\\n\\nproperty.${general.name}blah.home.directory = /blah\\nproperty.${general.name}.ip = ${general.ip}\\nproperty.${component1}.ip = ${general.ip}\\nproperty.${component1}.foo = ${component1.foo}\\n\\n\\ninto\\n\\nproperty.mynameblah.home.directory = /blah\\nproperty.myname.ip = 127.0.0.1\\nproperty.component1.ip = 127.0.0.1\\nproperty.component1.foo = bar\\n\\n\\nLexical analysis and tokenization sounds like my best route, but this is a very simple form of it. It's a simple grammar, a simple substitution and I'd like to make sure that I'm not bringing a sledgehammer to knock in a nail.\\n\\nI could create my own lexer and tokenizer, or ANTlr is a possibility, but I don't like re-inventing the wheel and ANTlr sounds like overkill.\\n\\nI'm not familiar with compiler techniques, so pointers in the right direction & code would be most appreciated.\\n\\nNote: I can change the input format.\\n\",\n  'completion': 'There\\'s an excellent article on Using Regular Expressions for Lexical Analysis at effbot.org.\\n\\nAdapting the tokenizer to your problem:\\n\\nimport re\\n\\ntoken_pattern = r\"\"\"\\n(?P<identifier>[a-zA-Z_][a-zA-Z0-9_]*)\\n|(?P<integer>[0-9]+)\\n|(?P<dot>\\\\.)\\n|(?P<open_variable>[$][{])\\n|(?P<open_curly>[{])\\n|(?P<close_curly>[}])\\n|(?P<newline>\\\\n)\\n|(?P<whitespace>\\\\s+)\\n|(?P<equals>[=])\\n|(?P<slash>[/])\\n\"\"\"\\n\\ntoken_re = re.compile(token_pattern, re.VERBOSE)\\n\\nclass TokenizerException(Exception): pass\\n\\ndef tokenize(text):\\n    pos = 0\\n    while True:\\n        m = token_re.match(text, pos)\\n        if not m: break\\n        pos = m.end()\\n        tokname = m.lastgroup\\n        tokvalue = m.group(tokname)\\n        yield tokname, tokvalue\\n    if pos != len(text):\\n        raise TokenizerException(\\'tokenizer stopped at pos %r of %r\\' % (\\n            pos, len(text)))\\n\\n\\nTo test it, we do:\\n\\nstuff = r\\'property.${general.name}.ip = ${general.ip}\\'\\nstuff2 = r\\'\\'\\'\\ngeneral {\\n  name = myname\\n  ip = 127.0.0.1\\n}\\n\\'\\'\\'\\n\\nprint \\' stuff \\'.center(60, \\'=\\')\\nfor tok in tokenize(stuff):\\n    print tok\\n\\nprint \\' stuff2 \\'.center(60, \\'=\\')\\nfor tok in tokenize(stuff2):\\n    print tok\\n\\n\\nfor:\\n\\n========================== stuff ===========================\\n(\\'identifier\\', \\'property\\')\\n(\\'dot\\', \\'.\\')\\n(\\'open_variable\\', \\'${\\')\\n(\\'identifier\\', \\'general\\')\\n(\\'dot\\', \\'.\\')\\n(\\'identifier\\', \\'name\\')\\n(\\'close_curly\\', \\'}\\')\\n(\\'dot\\', \\'.\\')\\n(\\'identifier\\', \\'ip\\')\\n(\\'whitespace\\', \\' \\')\\n(\\'equals\\', \\'=\\')\\n(\\'whitespace\\', \\' \\')\\n(\\'open_variable\\', \\'${\\')\\n(\\'identifier\\', \\'general\\')\\n(\\'dot\\', \\'.\\')\\n(\\'identifier\\', \\'ip\\')\\n(\\'close_curly\\', \\'}\\')\\n========================== stuff2 ==========================\\n(\\'newline\\', \\'\\\\n\\')\\n(\\'identifier\\', \\'general\\')\\n(\\'whitespace\\', \\' \\')\\n(\\'open_curly\\', \\'{\\')\\n(\\'newline\\', \\'\\\\n\\')\\n(\\'whitespace\\', \\'  \\')\\n(\\'identifier\\', \\'name\\')\\n(\\'whitespace\\', \\' \\')\\n(\\'equals\\', \\'=\\')\\n(\\'whitespace\\', \\' \\')\\n(\\'identifier\\', \\'myname\\')\\n(\\'newline\\', \\'\\\\n\\')\\n(\\'whitespace\\', \\'  \\')\\n(\\'identifier\\', \\'ip\\')\\n(\\'whitespace\\', \\' \\')\\n(\\'equals\\', \\'=\\')\\n(\\'whitespace\\', \\' \\')\\n(\\'integer\\', \\'127\\')\\n(\\'dot\\', \\'.\\')\\n(\\'integer\\', \\'0\\')\\n(\\'dot\\', \\'.\\')\\n(\\'integer\\', \\'0\\')\\n(\\'dot\\', \\'.\\')\\n(\\'integer\\', \\'1\\')\\n(\\'newline\\', \\'\\\\n\\')\\n(\\'close_curly\\', \\'}\\')\\n(\\'newline\\', \\'\\\\n\\')\\n\\n'},\n {'prompt': 'I apologize for a simple question, but I did not see this in the tutorials.\\n\\nI have a very simple gui, but I would like the user to be able to press the TAB key and have it move from one input field to another.  I am using wxPython with Python 2.6.\\n',\n  'completion': 'It should just work in the general case; what specific controls are you having issues with? You may need to pass wx.TAB_TRAVERSAL as a style, or if you need to manipulate the order, you can use the Move(After|Before)InTabOrder(otherControl) methods on the control.\\n\\nSee http://wiki.wxpython.org/Getting%20Started#How_to_get_tabs_to_work for examples of both of these techniques!\\n'},\n {'prompt': 'For example, we have some file like that:\\n\\n\\n  first line\\n  second line\\n  \\n  third line\\n\\n\\nAnd in result we have to get:\\n\\n\\n  first line\\n  second line\\n  third line\\n\\n\\nUse ONLY python\\n',\n  'completion': 'import fileinput\\nfor line in fileinput.FileInput(\"file\",inplace=1):\\n    if line.rstrip():\\n        print line\\n\\n'},\n {'prompt': \"Is there a convenient way to calculate percentiles for a sequence or single-dimensional numpy array?\\n\\nI am looking for something similar to Excel's percentile function.\\n\\nI looked in NumPy's statistics reference, and couldn't find this. All I could find is the median (50th percentile), but not something more specific.\\n\",\n  'completion': \"You might be interested in the SciPy Stats package. It has the percentile function you're after and many other statistical goodies.\\n\\npercentile() is available in numpy too.\\n\\nimport numpy as np\\na = np.array([1,2,3,4,5])\\np = np.percentile(a, 50) # return 50th percentile, e.g median.\\nprint p\\n3.0\\n\\n\\nThis ticket leads me to believe they won't be integrating percentile() into numpy anytime soon.\\n\"},\n {'prompt': 'I\\'m running a Django site (via Apache/mod_python) and I use Django\\'s facilities to inform me and other developers about internal server errors. Sometimes errors like those appear:\\n\\nTraceback (most recent call last):\\n\\n  File \"/opt/webapp/externals/lib/django/core/handlers/base.py\", line 92, in get_response\\n    response = callback(request, *callback_args, **callback_kwargs)\\n\\n  File \"/opt/webapp/csite/apps/customers/views.py\", line 29, in feedback\\n    form = FeedbackForm(request.POST)\\n\\n  File \"/opt/webapp/externals/lib/django/core/handlers/modpython.py\", line 113, in _get_post\\n    self._load_post_and_files()\\n\\n  File \"/opt/webapp/externals/lib/django/core/handlers/modpython.py\", line 96, in _load_post_and_files\\n    self._post, self._files = http.QueryDict(self.raw_post_data, encoding=self._encoding), datastructures.MultiValueDict()\\n\\n  File \"/opt/webapp/externals/lib/django/core/handlers/modpython.py\", line 163, in _get_raw_post_data\\n    self._raw_post_data = self._req.read()\\n\\nIOError: Client read error (Timeout?)\\n\\n\\nAs far as I found out, those IOErrors are generated by clients that disconnect in the wrong moment and that it\\'s not a problem of my site.\\n\\nIf that is the case: Can I disable the emails for those errors somehow? I really don\\'t want to know about errors that I cannot fix and that aren\\'t really errors.\\n',\n  'completion': \"Extending the solution by @dlowe for Django 1.3, we can write the full working example as:\\n\\nsettings.py\\n\\nLOGGING = {\\n    'version': 1,\\n    'disable_existing_loggers': False,\\n    'filters': {\\n        'supress_unreadable_post': {\\n            '()': 'common.logging.SuppressUnreadablePost',\\n        }\\n    },\\n    'handlers': {\\n        'mail_admins': {\\n            'level': 'ERROR',\\n            'class': 'django.utils.log.AdminEmailHandler',\\n            'filters': ['supress_unreadable_post'],\\n        }\\n    },\\n    'loggers': {\\n        'django.request': {\\n            'handlers': ['mail_admins'],\\n            'level': 'ERROR',\\n            'propagate': True,\\n        },\\n    }\\n}\\n\\n\\ncommon/logging.py\\n\\nimport sys, traceback\\n\\nclass SuppressUnreadablePost(object):\\n    def filter(self, record):\\n        _, exception, tb = sys.exc_info()\\n        if isinstance(exception, IOError):\\n            for _, _, function, _ in traceback.extract_tb(tb):\\n                if function == '_get_raw_post_data':\\n                    return False\\n        return True\\n\\n\"},\n {'prompt': \"I've tried the obvious path in my pet open source project RevitPythonShell (a plugin for the building modeling software Autodesk Revit Architecture 2010): code.interact() with the IronPython engine set up to use .NET streams for STDIN and STDOUT. These I then redirect to a TextBox control. It kinda works, but really is only an ugly hack.\\n\\nThe main problem is getting all the shell stuff to work: Up-arrow and down-arrow for history, editing, copy & paste, EOF, syntax highlighting, tool tips etc. It takes a lot of work to get this right, and it is not really the problem I'm trying to solve (I'm trying to get an interactive shell hosted in Revit, not make the perfect shell GUI).\\n\\nIf this weren't a .NET project, I'd probably look into reusing PyCrust/PyWrap, but I'm not sure if that can be done from a WinForms project. Is there anything similar for .NET?\\n\\nHas anyone ever implemented the IConsole interface and can show an example of what I'd need to do? It seems this would be the proper route to go (as opposed to using the code module), but for the life of me I can't figure it out. IronPython source code has no comments whatsoever.\\n\\nUPDATE: After trying out some stuff, I eventually settled on the superb IronLab code. It includes an example shell with syntax highlighting and all. The code was nice and easy to integrate. Check the RevitPythonShell code on hints on how to embed it.\\n\",\n  'completion': 'I was looking for a similar thing and I discovered that the IronLab project contains a nice IronPython console. The source code can be found here http://code.google.com/p/ironlab/source/browse/trunk/IronPythonConsole/.\\n'},\n {'prompt': \"Writing an app in Python, and been playing with various ORM setups and straight SQL. All of which are ugly as sin.\\n\\nI have been looking at ZODB as an object store, and it looks a promising alternative... would you recommend it? What are your experiences, problems, and criticism, particularly regarding developer's perspectives, scalability, integrity, long-term maintenance and alternatives? Anyone start a project with it and ditch it? Why?\\n\\nWhilst the ideas behind ZODB, Pypersyst and others are interesting, there seems to be a lack of enthusiasm around for them :(\\n\",\n  'completion': \"I've used ZODB for more than ten years now, in Zope and outside.  It's great if your data is hierarchical.  The largest data store a customer operates has maybe.. I dunno... 100GB in it?  Something on that order of magnitude anyway.\\n\\nHere is a performance comparison against Postgres.\\n\\nIf you're writing a WSGI web app, these packages may be useful:\\n\\n\\nrepoze.tm2 (docs)\\nrepoze.zodbconn (docs)\\n\\n\"},\n {'prompt': \"I'm a new Python programmer who is making the leap from 2.6.4 to 3.1.1. Everything has gone fine until I tried to use the 'else if' statement. The interpreter gives me a syntax error after the 'if' in 'else if' for a reason I can't seem to figure out.\\n\\ndef function(a):\\n    if a == '1':\\n        print ('1a')\\n    else if a == '2'\\n        print ('2a')\\n    else print ('3a')\\n\\nfunction(input('input:'))\\n\\n\\nI'm probably missing something very simple; however, I haven't been able to find the answer on my own. \\n\",\n  'completion': 'In python \"else if\" is spelled \"elif\".\\nAlso, you need a colon after the elif and the else.\\n\\nSimple answer to a simple question. I had the same problem, when I first started (in the last couple of weeks).\\n\\nSo your code should read:\\n\\ndef function(a):\\n    if a == \\'1\\':\\n        print(\\'1a\\')\\n    elif a == \\'2\\':\\n        print(\\'2a\\')\\n    else:\\n        print(\\'3a\\')\\n\\nfunction(input(\\'input:\\'))\\n\\n'},\n {'prompt': \"So if I go into QtDesigner and build a UI, it'll be saved as a .ui file.  How can I make this as a python file or use this in python?\\n\",\n  'completion': \"Another way to use .ui in your code is:\\n\\nfrom PyQt4 import QtCore, QtGui, uic\\nclass MyWidget(QtGui.QWidget)\\n    ...\\n    #somewhere in constructor:\\n    uic.loadUi('MyWidget.ui', self)\\n\\n\\nboth approaches are good. Do not forget, that if you use Qt resource files (extremely useful) for icons and so on, you must compile it too:\\n\\npyrcc4.exe -o ui/images_rc.py ui/images/images.qrc\\n\\n\\nNote, when uic compiles interface, it adds 'import images_rc' at the end of .py file, so you must compile resources into the file with this name, or rename it in generated code.\\n\"},\n {'prompt': 'Given a list of numbers how to find differences between every (i)-th and (i+1)-th of its elements? Should one better use lambda or maybe lists comprehension?\\n\\nExample:\\nGiven a list t=[1,3,6,...] it is to find a list v=[2,3,...] because 3-1=2, 6-3=3, etc.\\n',\n  'completion': '>>> t\\n[1, 3, 6]\\n>>> [j-i for i, j in zip(t[:-1], t[1:])]  # or use itertools.izip in py2k\\n[2, 3]\\n\\n'},\n {'prompt': \"If I do the following, does filehandle get closed automatically as it goes out of scope in Python:\\n\\ndef read_contents(file_path):\\n  return file(file_path).read()\\n\\n\\nIf it doesn't, how can I write this function to close the scope automatically?\\n\",\n  'completion': \"To expand on FogleBird's answer, if you do not explicitly close it then the file will be closed automatically when the file object is destroyed.  In CPython this will happen as soon as there are no more references to it, e.g. if it is a local variable in a function and the function ends.  However if an exception is thrown in the function and file is not explicitly closed using a with statement or a try:...finally: then a reference to the file will be kept as part of the stack trace in the traceback object and the file will not be closed, at least until the next exception is thrown.\\n\\nAlso IronPython and Jython use the garbage collection facilities of the .Net CLR and Java JVM respectively. These are not reference counted, so the file will remain open indefinitely until the garbage collector decides to reclaim the object's memory or the program terminates.\\n\\nSo in general it is important to explicitly close the file using either with: or try:...finally:.\\n\\nOf course all this is holds true for any other type of object that requires explicit cleanup.\\n\"},\n {'prompt': \"I want to override the __getattr__ method on a class to do something fancy but I don't want to break the default behavior.\\n\\nWhat's the correct way to do this?\\n\",\n  'completion': \"Overriding __getattr__ should be fine -- __getattr__ is only called as a last resort i.e. if there are no attributes in the instance that match the name. For instance, if you access foo.bar, then __getattr__ will only be called if foo has no attribute called bar. If the attribute is one you don't want to handle, raise AttributeError:\\n\\nclass Foo(object):\\n    def __getattr__(self, name):\\n        if some_predicate(name):\\n            # ...\\n        else:\\n            # Default behaviour\\n            raise AttributeError\\n\\n\\nHowever, unlike __getattr__, __getattribute__ will be called first (only works for new style classes i.e. those that inherit from object). In this case, you can preserve default behaviour like so:\\n\\nclass Foo(object):\\n    def __getattribute__(self, name):\\n        if some_predicate(name):\\n            # ...\\n        else:\\n            # Default behaviour\\n            return object.__getattribute__(self, name)\\n\\n\\nSee the Python docs for more.\\n\"},\n {'prompt': 'Is there a way to get Matplotlib to render accented chars (Ã©,Ã£,Ã¢,etc)?\\n\\nFor instance, I\\'m trying to use accented characters on set_yticklabels() and Matplotlib renders squares instead, and when I use unicode() it renders the wrong characters.\\n\\nIs there a way to make this work?\\n\\nIt turns out you can use u\"Ã©Ã£\", but first you have to set the file encoding:\\n\\n# Using the magic encoding\\n# -*- coding: utf-8 -*-\\n\\n\\nAfter that Matplotlib correctly renders\\n\\nu\"Ã©\"\\n\\n\\nI also learned that you can use\\n\\nimport matplotlib.font_manager as fm\\nfp1=fm.FontProperties(fname=\"/path/to/somefont.ttf\")\\nax.title(\"Ã©\",fontproperties=fp1)\\n\\n\\nin case you need to render a characters that Matplotlib does not have.\\n',\n  'completion': \"Prefix the strings with u to tell Python that they are Unicode strings:\\n\\nax.set_yticklabels([u'Ã©', u'Ã£', u'Ã¢'])\\n\\n\"},\n {'prompt': \"I am trying to make a simple IRC client in Python (as kind of a project while I learn the language).\\n\\nI have a loop that I use to receive and parse what the IRC server sends me, but if I use raw_input to input stuff, it stops the loop dead in its tracks until I input something (obviously).\\n\\nHow can I input something without the loop stopping?\\n\\nThanks in advance.\\n\\n(I don't think I need to post the code, I just want to input something without the while 1 loop stopping.)\\n\\nEDIT: I'm on Windows.\\n\",\n  'completion': 'For Windows, console only, use the msvcrt module:\\n\\nimport msvcrt\\n\\nnum = 0\\ndone = False\\nwhile not done:\\n    print num\\n    num += 1\\n\\n    if msvcrt.kbhit():\\n        print \"you pressed\",msvcrt.getch(),\"so now i will quit\"\\n        done = True\\n\\n\\nFor Linux, this article describes the following solution, it requires the termios module:\\n\\nimport sys\\nimport select\\nimport tty\\nimport termios\\n\\ndef isData():\\n    return select.select([sys.stdin], [], [], 0) == ([sys.stdin], [], [])\\n\\nold_settings = termios.tcgetattr(sys.stdin)\\ntry:\\n    tty.setcbreak(sys.stdin.fileno())\\n\\n    i = 0\\n    while 1:\\n        print i\\n        i += 1\\n\\n        if isData():\\n            c = sys.stdin.read(1)\\n            if c == \\'\\\\x1b\\':         # x1b is ESC\\n                break\\n\\nfinally:\\n    termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old_settings)\\n\\n\\nFor cross platform, or in case you want a GUI as well, you can use Pygame:\\n\\nimport pygame\\nfrom pygame.locals import *\\n\\ndef display(str):\\n    text = font.render(str, True, (255, 255, 255), (159, 182, 205))\\n    textRect = text.get_rect()\\n    textRect.centerx = screen.get_rect().centerx\\n    textRect.centery = screen.get_rect().centery\\n\\n    screen.blit(text, textRect)\\n    pygame.display.update()\\n\\npygame.init()\\nscreen = pygame.display.set_mode( (640,480) )\\npygame.display.set_caption(\\'Python numbers\\')\\nscreen.fill((159, 182, 205))\\n\\nfont = pygame.font.Font(None, 17)\\n\\nnum = 0\\ndone = False\\nwhile not done:\\n    display( str(num) )\\n    num += 1\\n\\n    pygame.event.pump()\\n    keys = pygame.key.get_pressed()\\n    if keys[K_ESCAPE]:\\n        done = True\\n\\n'},\n {'prompt': \"what I'm trying to do is this:\\n\\n\\nget the 30 Authors with highest score ( Author.objects.order_by('-score')[:30] )\\norder the authors by last_name\\n\\n\\n\\n\\nAny suggestions?\\n\",\n  'completion': 'What about\\n\\nimport operator\\n\\nauths = Author.objects.order_by(\\'-score\\')[:30]\\nordered = sorted(auths, key=operator.attrgetter(\\'last_name\\'))\\n\\n\\nIn Django 1.4 and newer you can order by providing multiple fields.\\nReference: https://docs.djangoproject.com/en/dev/ref/models/querysets/#order-by\\n\\norder_by(*fields)\\n\\nBy default, results returned by a QuerySet are ordered by the ordering tuple given by the ordering option in the modelâ\\x80\\x99s Meta. You can override this on a per-QuerySet basis by using the order_by method.\\n\\nExample:\\n\\nordered_authors = Author.objects.order_by(\\'-score\\', \\'last_name\\')[:30]\\n\\n\\nThe result above will be ordered by score descending, then by last_name ascending. The negative sign in front of \"-score\" indicates descending order. Ascending order is implied.\\n'},\n {'prompt': 'I\\'d like to use doctests to test the presence of certain warnings.  For example, suppose I have the following module:\\n\\nfrom warnings import warn\\n\\nclass Foo(object):\\n    \"\"\"\\n    Instantiating Foo always gives a warning:\\n\\n    >>> foo = Foo()\\n    testdocs.py:14: UserWarning: Boo!\\n      warn(\"Boo!\", UserWarning)\\n    >>> \\n    \"\"\"\\n\\n    def __init__(self):\\n        warn(\"Boo!\", UserWarning)\\n\\n\\nIf I run python -m doctest testdocs.py to run the doctest in my class and make sure that the warning is printed, I get:\\n\\ntestdocs.py:14: UserWarning: Boo!\\n  warn(\"Boo!\", UserWarning)\\n**********************************************************************\\nFile \"testdocs.py\", line 7, in testdocs.Foo\\nFailed example:\\n    foo = Foo()\\nExpected:\\n    testdocs.py:14: UserWarning: Boo!\\n      warn(\"Boo!\", UserWarning)\\nGot nothing\\n**********************************************************************\\n1 items had failures:\\n   1 of   1 in testdocs.Foo\\n***Test Failed*** 1 failures.\\n\\n\\nIt looks like the warning is getting printed but not captured or noticed by doctest.  I\\'m guessing that this is because warnings are printed to sys.stderr instead of sys.stdout.  But this happens even when I say sys.stderr = sys.stdout at the end of my module.\\n\\nSo is there any way to use doctests to test for warnings?  I can find no mention of this one way or the other in the documentation or in my Google searching.\\n',\n  'completion': 'The Testing Warnings sections of the Python documentation is dedicated to this topic. However, to summarize, you have two options:\\n\\n(A) Use the catch_warnings context manager\\n\\nThis is recommended course in the official documentation. However, the catch_warnings context manager only came into existence with Python 2.6.\\n\\nimport warnings\\n\\ndef fxn():\\n    warnings.warn(\"deprecated\", DeprecationWarning)\\n\\nwith warnings.catch_warnings(record=True) as w:\\n    # Cause all warnings to always be triggered.\\n    warnings.simplefilter(\"always\")\\n    # Trigger a warning.\\n    fxn()\\n    # Verify some things\\n    assert len(w) == 1\\n    assert issubclass(w[-1].category, DeprecationWarning)\\n    assert \"deprecated\" in str(w[-1].message)\\n\\n\\n(B) Upgrade Warnings to Errors\\n\\nIf the warning hasn\\'t been seen before— and thus was registered in the warnings registry— then you can set warnings to raise exceptions and catch it.\\n\\nimport warnings\\n\\n\\ndef fxn():\\n    warnings.warn(\"deprecated\", DeprecationWarning)\\n\\n\\nif __name__ == \\'__main__\\':\\n    warnings.simplefilter(\"error\", DeprecationWarning)\\n\\n    try:\\n        fxn()\\n    except DeprecationWarning:\\n        print \"Pass\"\\n    else:\\n        print \"Fail\"\\n    finally:\\n        warnings.simplefilter(\"default\", DeprecationWarning)\\n\\n'},\n {'prompt': 'I\\'m trying to define a new URL handler under OSX that will point at a python script.\\n\\nI\\'ve wrapped the Python script up into an applet (right-clicked on the .py, and gone Open With -> Build Applet)\\n\\nI\\'ve added the following into the applet\\'s Info.plist:\\n\\n<key>CFBundleURLTypes</key>\\n<array>\\n    <dict>\\n        <key>CFBundleURLName</key>\\n        <string>Do My Thing</string>\\n        <key>CFBundleURLSchemes</key>\\n        <array>\\n            <string>dmt</string>\\n        </array>\\n    </dict>\\n</array>\\n\\n\\nI\\'ve also used the More Internet preferences pane to specify \"dmt\" as a protocol, but when I try to get it to link the protocol to my applet, it says that \"There was a problem setting the app as the helper\"\\n\\nAnyone know where I should go from here?\\n\\nThanks\\n',\n  'completion': 'After a lot of messing around, I\\'ve managed to get this working under OSX...\\n\\nThis is how I\\'m doing it:\\n\\nin the AppleScript Script Editor, write the following script:\\n\\non open location this_URL\\n    do shell script \"/scripts/runLocalCommand.py \\'\" & this_URL & \"\\'\"\\nend open location\\n\\n\\nIf you want to make sure you\\'re running the Python from a certain shell (in my case, I\\'m using tcsh generally, and have a .tcshrc file that defines some environment variables that I want to have access to) then that middle line might want to be:\\n\\ndo shell script \"tcsh -c \\\\\"/scripts/localCommand.py \\'\" & this_URL & \"\\'\\\\\"\"\\n\\n\\nI was wanting to do all of my actual processing inside a python script - but because of the way URL handers work in OSX, they have to call an application bundle rather than a script, so doing this in AppleScript seemed to be the easiest way to do it.\\n\\nin the Script Editor, Save As an \"Application Bundle\"\\n\\nFind the saved Application Bundle, and Open Contents. Find the Info.plist file, and open it. Add the following:\\n\\n<key>CFBundleIdentifier</key>\\n<string>com.mycompany.AppleScript.LocalCommand</string>\\n<key>CFBundleURLTypes</key>\\n<array>\\n  <dict>\\n    <key>CFBundleURLName</key>\\n    <string>LocalCommand</string>\\n    <key>CFBundleURLSchemes</key>\\n    <array>\\n      <string>local</string>\\n    </array>\\n  </dict>\\n</array>\\n\\n\\nJust before the last two lines, which should be:\\n\\n</dict>\\n</plist>\\n\\n\\nThere are three strings in there that might want to be changed:\\n\\ncom.mycompany.AppleScript.LocalCommand\\nLocalCommand\\nlocal\\n\\n\\nThe third of these is the handler ID - so a URL would be local://something\\n\\nSo, then this passes over to the Python script.\\n\\nThis is what I\\'ve got for this:\\n\\n#!/usr/bin/env python\\nimport sys\\nimport urllib\\narg = sys.argv[1]\\nhandler, fullPath = arg.split(\":\", 1)\\npath, fullArgs = fullPath.split(\"?\", 1)\\naction = path.strip(\"/\")\\nargs = fullArgs.split(\"&\")\\nparams = {}\\nfor arg in args:\\n    key, value = map(urllib.unquote, arg.split(\"=\", 1))\\n    params[key] = value\\n\\n'},\n {'prompt': 'Very basic question - how to get one value from a generator in Python?\\n\\nSo far I found I can get one by writing gen.next(). I just want to make sure this is the right way?\\n',\n  'completion': 'Yes, or next(gen) in 2.6+.\\n'},\n {'prompt': \"Are there any Pythonic solutions to reading and processing RAW images. Even if it's simply accessing a raw photo file (eg. cr2 or dng) and then outputting it as a jpeg.  \\n\\nIdeally a dcraw bindings for python, but anything else that can accomplish the came would be sufficient as well. \\n\",\n  'completion': 'ImageMagick supports most RAW formats and provides Python bindings.\\n\\nAs for dcraw bindings for Python: dcraw is written in C, so you can access it through ctypes module. \\n'},\n {'prompt': \"Currently I'm using this:\\n\\nf = open(filename, 'r+')\\ntext = f.read()\\ntext = re.sub('foobar', 'bar', text)\\nf.seek(0)\\nf.write(text)\\nf.close()\\n\\n\\nBut the problem is that the old file is larger than the new file. So I end up with a new file that has a part of the old file on the end of it.\\n\",\n  'completion': \"If you don't want to close and reopen the file, to avoid race conditions, you could truncate it:\\n\\nf = open(filename, 'r+')\\ntext = f.read()\\ntext = re.sub('foobar', 'bar', text)\\nf.seek(0)\\nf.write(text)\\nf.truncate()\\nf.close()\\n\\n\\nThe functionality may also be cleaner and safer using with open as per  mVChr's comment, which is will close the handler, even if an error occurs.\\n\\nwith open(filename, 'r+') as f:\\n    text = f.read()\\n    text = re.sub('foobar', 'bar', text)\\n    f.seek(0)\\n    f.write(text)\\n    f.truncate()\\n\\n\"},\n {'prompt': \"I can't figure out how to look ahead one element in a Python generator. As soon as I look it's gone.\\n\\nHere is what I mean:\\n\\ngen = iter([1,2,3])\\nnext_value = gen.next()  # okay, I looked forward and see that next_value = 1\\n# but now:\\nlist(gen)  # is [2, 3]  -- the first value is gone!\\n\\n\\nHere is a more real example:\\n\\ngen = element_generator()\\nif gen.next_value() == 'STOP':\\n  quit_application()\\nelse:\\n  process(gen.next())\\n\\n\\nCan anyone help me write a generator that you can look one element forward?\\n\\nThanks, Boda Cydo.\\n\",\n  'completion': \"The Python generator API is one way: You can't push back elements you've read. But you can create a new iterator using the itertools module and prepend the element:\\n\\nimport itertools\\n\\ngen = iter([1,2,3])\\npeek = gen.next()\\nprint list(itertools.chain([peek], gen))\\n\\n\"},\n {'prompt': \"Something I wrote throws a lot of AttributeError exceptions when using time.strptime() inside a thread. This only seems to happen on Windows (not on Linux) but whatever- upon a'Googling, it seems that time.strptime() isn't considered thread-safe.\\n\\nIs there a better way to create a datetime object from a string? Current code looks like:\\n\\nval = DateFromTicks(mktime(strptime(val, '%B %d, %Y')))\\n\\n\\nBut, that yields the exceptions as it's run inside a thread.\\n\\nThanks!\\n\",\n  'completion': \"According to the bug report, this doesn't happen if you call strptime once before creating your threads. I've done a little testing which seems to confirm this. So just make any call to strptime during initialization as a workaround.\\n\"},\n {'prompt': 'I was wondering how to achieve the following in python:\\n\\nfor( int i = 0; cond...; i++)\\n  if cond...\\n    i++; //to skip an run-through\\n\\n\\nI tried this with no luck.\\n\\nfor i in range(whatever):\\n  if cond... :\\n    i += 1\\n\\n',\n  'completion': \"Python's for loops are different.  i gets reassigned to the next value every time through the loop.\\n\\nThe following will do what you want, because it is taking the literal version of what C++ is doing:\\n\\ni = 0\\nwhile i < some_value:\\n    if cond...:\\n        i+=1\\n    ...code...\\n    i+=1\\n\\n\\nHere's why:\\n\\nin C++, the following code segments are equivalent:\\n\\nfor(..a..; ..b..; ..c..) {\\n    ...code...\\n}\\n\\n\\nand\\n\\n..a..\\nwhile(..b..) {\\n     ..code..\\n     ..c..\\n}\\n\\n\\nwhereas the python for loop looks something like:\\n\\nfor x in ..a..:\\n    ..code..\\n\\n\\nturns into\\n\\nmy_iter = iter(..a..)\\nwhile (my_iter is not empty):\\n    x = my_iter.next()\\n    ..code..\\n\\n\"},\n {'prompt': \"I'm writing a Python+Qt4 application that would ideally need to pop up a window every once in a while, to display pdf documents and allow very basic operations, namely scrolling through the different pages and printing the document.\\n\\nI've found the reportLab to create pdf files, but nothing about pdf viewers. Does anyone knows anything that might help. i was really hoping for the existence of something like the QWebView widget...\\n\\nthanks in advance to all\\n\",\n  'completion': 'you can use Poppler for that.\\n'},\n {'prompt': \"How can you calculate the following Friday at 3am as a datetime object?\\n\\nClarification: i.e., the calculated date should always be greater than 7 days away, and less than or equal to 14.\\n\\n\\n\\nGoing with a slightly modified version of Mark's solution:\\n\\ndef _next_weekday(day_of_week=4, time_of_day=datetime.time(hour=3), dt=None):\\n    if dt is None: dt = datetime.datetime.now()\\n    dt += datetime.timedelta(days=7)\\n    if dt.time() < time_of_day: dt = dt.combine(dt.date(), time_of_day)\\n    else: dt = dt.combine(dt.date(), time_of_day) + datetime.timedelta(days=1)\\n    return dt + datetime.timedelta((day_of_week - dt.weekday()) % 7)\\n\\n\",\n  'completion': \"If you install dateutil, then you could do something like this:\\n\\nimport datetime\\nimport dateutil.relativedelta as reldate\\n\\ndef following_friday(dt):   \\n    rd=reldate.relativedelta(\\n        weekday=reldate.FR(+2),\\n        hours=+21)\\n    rd2=reldate.relativedelta(\\n        hour=3,minute=0,second=0,microsecond=0)\\n    return dt+rd+rd2\\n\\n\\nAbove, hours=+21 tells relativedelta to increment the dt by 21 hours before finding the next Friday. So, if dt is March 12, 2010 at 2am, adding 21 hours makes it 11pm of the same day, but if dt is after 3am, then adding 21 hours pushs dt into Saturday.\\n\\nHere is some test code.\\n\\nif __name__=='__main__':\\n    today=datetime.datetime.now()\\n    for dt in [today+datetime.timedelta(days=i) for i in range(-7,8)]:\\n        print('%s --> %s'%(dt,following_friday(dt)))\\n\\n\\nwhich yields:\\n\\n2010-03-05 20:42:09.246124 --> 2010-03-19 03:00:00\\n2010-03-06 20:42:09.246124 --> 2010-03-19 03:00:00\\n2010-03-07 20:42:09.246124 --> 2010-03-19 03:00:00\\n2010-03-08 20:42:09.246124 --> 2010-03-19 03:00:00\\n2010-03-09 20:42:09.246124 --> 2010-03-19 03:00:00\\n2010-03-10 20:42:09.246124 --> 2010-03-19 03:00:00\\n2010-03-11 20:42:09.246124 --> 2010-03-19 03:00:00\\n2010-03-12 20:42:09.246124 --> 2010-03-26 03:00:00 \\n2010-03-13 20:42:09.246124 --> 2010-03-26 03:00:00\\n2010-03-14 20:42:09.246124 --> 2010-03-26 03:00:00\\n2010-03-15 20:42:09.246124 --> 2010-03-26 03:00:00\\n2010-03-16 20:42:09.246124 --> 2010-03-26 03:00:00\\n2010-03-17 20:42:09.246124 --> 2010-03-26 03:00:00\\n2010-03-18 20:42:09.246124 --> 2010-03-26 03:00:00\\n2010-03-19 20:42:09.246124 --> 2010-04-02 03:00:00\\n\\n\\nwhile before 3am:\\n\\ntwo = datetime.datetime(2010, 3, 12, 2, 0)\\nfor date in [two+datetime.timedelta(days=i) for i in range(-7,8)]:\\n    result = following_friday(date)\\n    print('{0}-->{1}'.format(date,result))\\n\\n\\nyields:\\n\\n2010-03-05 02:00:00-->2010-03-12 03:00:00\\n2010-03-06 02:00:00-->2010-03-19 03:00:00\\n2010-03-07 02:00:00-->2010-03-19 03:00:00\\n2010-03-08 02:00:00-->2010-03-19 03:00:00\\n2010-03-09 02:00:00-->2010-03-19 03:00:00\\n2010-03-10 02:00:00-->2010-03-19 03:00:00\\n2010-03-11 02:00:00-->2010-03-19 03:00:00\\n2010-03-12 02:00:00-->2010-03-19 03:00:00\\n2010-03-13 02:00:00-->2010-03-26 03:00:00\\n2010-03-14 02:00:00-->2010-03-26 03:00:00\\n2010-03-15 02:00:00-->2010-03-26 03:00:00\\n2010-03-16 02:00:00-->2010-03-26 03:00:00\\n2010-03-17 02:00:00-->2010-03-26 03:00:00\\n2010-03-18 02:00:00-->2010-03-26 03:00:00\\n2010-03-19 02:00:00-->2010-03-26 03:00:00\\n\\n\"},\n {'prompt': \"I'm a newbie with a little experience writing in BASIC, Python and, of all things, a smidgeon of assembler (as part of a videogame ROM hack). I wanted to create small tool for modifying the hex values at particular points, in a particular file, that would have a GUI interface.\\n\\nWhat I'm looking for is the ability to create small GUI program, that I can distribute as an EXE (or, at least a standalone directory). I'm not keen on the idea of the .NET languages, because I don't want to force people to download a massive .NET framework package. I currently have Python with IDLE and Boa Constructor set up, and the application runs there. I've tried looking up information on compiling a python app that relies on Wxwidgets, but the search results and the information I've found has been confusing, or just completely incomprehensible. \\n\\nMy questions are:\\n\\n\\nIs python a good language to use for this sort of project?\\nIf I use Py2Exe, will WxWidgets already be included? Or will my users have to somehow install WxWidgets on their machines? Am I right in thinking at Py2Exe just produces a standalone directory, 'dist', that has the necessary files for the user to just double click and run the application?\\nIf the program just relies upon Tkinter for GUI stuff, will that be included in the EXE Py2Exe produces? If so, are their any 'visual' GUI builders / IDEs for Python with only Tkinter?\\n\\n\\nThankyou for your time,\\n\\nJBMK\\n\",\n  'completion': \"You'd be better off thinking/saying/googling wxPython (not wxWidgets), since wxPython is the python wrapper for the wxWidgets C++.\\n\\n1.) Python is a good language for this.  If you are only targeting windows, I'd still do it in .NET/C# though.  If you want cross-platform, Python/wxPython all the way.\\n\\n2.) Yes, the wxPython files should be included in the dist directory. You'll have to of course install wxPython to your development machine. See here for some instructions on how to build.  py2exe does produce a single directory with everything you need to run you program.  It'll give you an EXE that you can double-click.\\n\\n3.) I've never used Python's Tkinter with py2exe, but I can't see why it wouldn't work along the lines of wxPython.\\n\\nYou should keep in mind that your finally distributable directory will be 10s of megs (py2exe packs the python interpreter and other libraries needed for you app).  Not quite as much as the .NET framework, but doesn't almost everybody have that installed already by now?\\n\"},\n {'prompt': 'I need to grab the duration of a video file via python as part of a larger script. I know I can use ffmpeg to grab the duration, but I need to be able to save that output as a variable back in python. I thought this would work, but it\\'s giving me a value of 0:\\n\\ncmd = \\'ffmpeg -i %s 2>&1 | grep \"Duration\" | cut -d \\\\\\' \\\\\\' -f 4 | sed s/,//\\' % (\"Video.mov\")\\nduration = os.system(cmd)\\nprint duration\\n\\n\\nAm I doing the output redirect wrong? Or is there simply no way to pipe the terminal output back into python?\\n',\n  'completion': 'os.system returns a return value indicating the success or failure of the command. It does not return the output from stdout or stderr. To grab the output from stdout (or stderr), use subprocess.Popen.\\n\\nimport subprocess\\nproc=subprocess.Popen(\\'echo \"to stdout\"\\', shell=True, stdout=subprocess.PIPE, )\\noutput=proc.communicate()[0]\\nprint output\\n\\n\\nSee the wonderfully written Python Module of the Week blog.\\n'},\n {'prompt': \"First, some background: I'm developing a web application using Python. All of my (text) files are currently stored in UTF-8 with the BOM. This includes all my HTML templates and CSS files. These resources are stored as binary data (BOM and all) in my DB.\\n\\nWhen I retrieve the templates from the DB, I decode them using template.decode('utf-8'). When the HTML arrives in the browser, the BOM is present at the beginning of the HTTP response body. This generates a very interesting error in Chrome:\\n\\nExtra <html> encountered.  Migrating attributes back to the original <html> element and ignoring the tag.\\n\\nChrome seems to generate an <html> tag automatically when it sees the BOM and mistakes it for content, making the real <html> tag an error.\\n\\nSo, using Python, what is the best way to remove the BOM from my UTF-8 encoded templates (if it exists -- I can't guarantee this in the future)?\\n\\nFor other text-based files like CSS, will major browsers correctly interpret (or ignore) the BOM? They are being sent as plain binary data without .decode('utf-8').\\n\\nNote: I am using Python 2.5.\\n\\nThanks!\\n\",\n  'completion': \"Since you state:\\n\\n\\n  All of my (text) files are currently\\n  stored in UTF-8 with the BOM\\n\\n\\nthen use the 'utf-8-sig' codec to decode them:\\n\\n>>> s = u'Hello, world!'.encode('utf-8-sig')\\n>>> s\\n'\\\\xef\\\\xbb\\\\xbfHello, world!'\\n>>> s.decode('utf-8-sig')\\nu'Hello, world!'\\n\\n\\nIt automatically removes the expected BOM, and works correctly if the BOM is not present as well.\\n\"},\n {'prompt': \"Is there a Python library that allows manipulation of zip archives in memory, without having to use actual disk files? \\n\\nThe ZipFile library does not allow you to update the archive. The only way seems to be to extract it to a directory, make your changes, and create a new zip from that directory. I want to modify zip archives without disk access, because I'll be downloading them, making changes, and uploading them again, so I have no reason to store them. \\n\\nSomething similar to Java's ZipInputStream/ZipOutputStream would do the trick, although any interface at all that avoids disk access would be fine.\\n\",\n  'completion': 'According to the Python docs:\\n\\nclass zipfile.ZipFile(file[, mode[, compression[, allowZip64]]])\\n\\n  Open a ZIP file, where file can be either a path to a file (a string) or a file-like object. \\n\\n\\nSo, to open the file in memory, just create a file-like object (perhaps using BytesIO).\\n\\nfile_like_object = io.BytesIO(my_zip_data)\\nzipfile_ob = zipfile.ZipFile(file_like_object)\\n\\n'},\n {'prompt': \"I unsuccessfully tried using txredis (the non blocking twisted api for redis) for a persisting message queue I'm trying to set up with a scrapy project I am working on. I found that although the client was not blocking, it became much slower than it could have been because what should have been one event in the reactor loop was split up into thousands of steps.\\n\\nSo instead, I tried making use of redis-py (the regular blocking twisted api) and wrapping the call in a deferred thread.  It works great, however I want to perform an inner deferred when I make a call to redis as I would like to set up connection pooling in attempts to speed things up further.  \\n\\nBelow is my interpretation of some sample code taken from the twisted docs for a deferred thread to illustrate my use case: \\n\\n#!/usr/bin/env python\\nfrom twisted.internet import reactor,threads\\nfrom twisted.internet.task import LoopingCall\\nimport time\\n\\ndef main_loop():\\n    print 'doing stuff in main loop.. do not block me!'\\n\\n\\ndef aBlockingRedisCall():\\n    print 'doing lookup... this may take a while'\\n    time.sleep(10)\\n    return 'results from redis'\\n\\ndef result(res):\\n    print res\\n\\ndef main():\\n    lc = LoopingCall(main_loop)\\n    lc.start(2)\\n    d = threads.deferToThread(aBlockingRedisCall)\\n    d.addCallback(result)\\n    reactor.run()\\n\\nif __name__=='__main__':\\n    main()\\n\\n\\nAnd here is my alteration for connection pooling that makes the code in the deferred thread blocking :\\n\\n#!/usr/bin/env python\\nfrom twisted.internet import reactor,defer\\nfrom twisted.internet.task import LoopingCall\\nimport time\\n\\ndef main_loop():\\n    print 'doing stuff in main loop.. do not block me!'\\n\\ndef aBlockingRedisCall(x):\\n    if x<5: #all connections are busy, try later\\n        print '%s is less than 5, get a redis client later' % x\\n        x+=1\\n        d = defer.Deferred()\\n        d.addCallback(aBlockingRedisCall)\\n        reactor.callLater(1.0,d.callback,x)\\n        return d\\n\\n    else: \\n        print 'got a redis client; doing lookup.. this may take a while'\\n        time.sleep(10) # this is now blocking.. any ideas?\\n        d = defer.Deferred()\\n        d.addCallback(gotFinalResult)\\n        d.callback(x)\\n        return d\\n\\ndef gotFinalResult(x):\\n    return 'final result is %s' % x\\n\\ndef result(res):\\n    print res\\n\\ndef aBlockingMethod():\\n    print 'going to sleep...'\\n    time.sleep(10)\\n    print 'woke up'\\n\\ndef main():\\n    lc = LoopingCall(main_loop)\\n    lc.start(2)\\n\\n\\n    d = defer.Deferred()\\n    d.addCallback(aBlockingRedisCall)\\n    d.addCallback(result)\\n    reactor.callInThread(d.callback, 1)\\n    reactor.run()\\n\\nif __name__=='__main__':\\n    main()\\n\\n\\nSo my question is, does anyone know why my alteration causes the deferred thread to be blocking and/or can anyone suggest a better solution?\\n\",\n  'completion': 'Well, as the twisted docs say:\\n\\n\\n  Deferreds do not make the code\\n  magically not block\\n\\n\\nWhenever you\\'re using blocking code, such as sleep, you have to defer it to a new thread.\\n\\n#!/usr/bin/env python\\nfrom twisted.internet import reactor,defer, threads\\nfrom twisted.internet.task import LoopingCall\\nimport time\\n\\ndef main_loop():\\n    print \\'doing stuff in main loop.. do not block me!\\'\\n\\ndef aBlockingRedisCall(x):\\n    if x<5: #all connections are busy, try later\\n        print \\'%s is less than 5, get a redis client later\\' % x\\n        x+=1\\n        d = defer.Deferred()\\n        d.addCallback(aBlockingRedisCall)\\n        reactor.callLater(1.0,d.callback,x)\\n        return d\\n\\n    else: \\n        print \\'got a redis client; doing lookup.. this may take a while\\'\\n        def getstuff( x ):\\n            time.sleep(3)\\n            return \"stuff is %s\" % x\\n\\n        # getstuff is blocking, so you need to push it to a new thread\\n        d = threads.deferToThread(getstuff, x)\\n        d.addCallback(gotFinalResult)\\n        return d\\n\\ndef gotFinalResult(x):\\n    return \\'final result is %s\\' % x\\n\\ndef result(res):\\n    print res\\n\\ndef aBlockingMethod():\\n    print \\'going to sleep...\\'\\n    time.sleep(10)\\n    print \\'woke up\\'\\n\\ndef main():\\n    lc = LoopingCall(main_loop)\\n    lc.start(2)\\n\\n\\n    d = defer.Deferred()\\n    d.addCallback(aBlockingRedisCall)\\n    d.addCallback(result)\\n    reactor.callInThread(d.callback, 1)\\n    reactor.run()\\n\\nif __name__==\\'__main__\\':\\n    main()\\n\\n\\nIn case the redis api is not very complex it might be more natural to rewrite it using twisted.web, instead of just calling the blocking api in a lot threads.\\n'},\n {'prompt': \"I've got some dynamically-generated boolean logic expressions, like:\\n\\n\\n(A or B) and (C or D)\\nA or (A and B)\\nA\\nempty - evaluates to True\\n\\n\\nThe placeholders get replaced with booleans. Should I,\\n\\n\\nConvert this information to a Python expression like True or (True or False) and eval it?\\nCreate a binary tree where a node is either a bool or Conjunction/Disjunction object and recursively evaluate it?\\nConvert it into nested S-expressions and use a Lisp parser?\\nSomething else?\\n\\n\\nSuggestions welcome.\\n\",\n  'completion': 'Here\\'s a small (possibly, 74 lines including whitespace) module I built in about an hour and a half (plus almost an hour to refactoring):\\n\\nstr_to_token = {\\'True\\':True,\\n                \\'False\\':False,\\n                \\'and\\':lambda left, right: left and right,\\n                \\'or\\':lambda left, right: left or right,\\n                \\'(\\':\\'(\\',\\n                \\')\\':\\')\\'}\\n\\nempty_res = True\\n\\n\\ndef create_token_lst(s, str_to_token=str_to_token):\\n    \"\"\"create token list:\\n    \\'True or False\\' -> [True, lambda..., False]\"\"\"\\n    s = s.replace(\\'(\\', \\' ( \\')\\n    s = s.replace(\\')\\', \\' ) \\')\\n\\n    return [str_to_token[it] for it in s.split()]\\n\\n\\ndef find(lst, what, start=0):\\n    return [i for i,it in enumerate(lst) if it == what and i >= start]\\n\\n\\ndef parens(token_lst):\\n    \"\"\"returns:\\n        (bool)parens_exist, left_paren_pos, right_paren_pos\\n    \"\"\"\\n    left_lst = find(token_lst, \\'(\\')\\n\\n    if not left_lst:\\n        return False, -1, -1\\n\\n    left = left_lst[-1]\\n\\n    #can not occur earlier, hence there are args and op.\\n    right = find(token_lst, \\')\\', left + 4)[0]\\n\\n    return True, left, right\\n\\n\\ndef bool_eval(token_lst):\\n    \"\"\"token_lst has length 3 and format: [left_arg, operator, right_arg]\\n    operator(left_arg, right_arg) is returned\"\"\"\\n    return token_lst[1](token_lst[0], token_lst[2])\\n\\n\\ndef formatted_bool_eval(token_lst, empty_res=empty_res):\\n    \"\"\"eval a formatted (i.e. of the form \\'ToFa(ToF)\\') string\"\"\"\\n    if not token_lst:\\n        return empty_res\\n\\n    if len(token_lst) == 1:\\n        return token_lst[0]\\n\\n    has_parens, l_paren, r_paren = parens(token_lst)\\n\\n    if not has_parens:\\n        return bool_eval(token_lst)\\n\\n    token_lst[l_paren:r_paren + 1] = [bool_eval(token_lst[l_paren+1:r_paren])]\\n\\n    return formatted_bool_eval(token_lst, bool_eval)\\n\\n\\ndef nested_bool_eval(s):\\n    \"\"\"The actual \\'eval\\' routine,\\n    if \\'s\\' is empty, \\'True\\' is returned,\\n    otherwise \\'s\\' is evaluated according to parentheses nesting.\\n    The format assumed:\\n        [1] \\'LEFT OPERATOR RIGHT\\',\\n        where LEFT and RIGHT are either:\\n                True or False or \\'(\\' [1] \\')\\' (subexpression in parentheses)\\n    \"\"\"\\n    return formatted_bool_eval(create_token_lst(s))\\n\\n\\nThe simple tests give:\\n\\n>>> print nested_bool_eval(\\'\\')\\nTrue\\n>>> print nested_bool_eval(\\'False\\')\\nFalse\\n>>> print nested_bool_eval(\\'True or False\\')\\nTrue\\n>>> print nested_bool_eval(\\'True and False\\')\\nFalse\\n>>> print nested_bool_eval(\\'(True or False) and (True or False)\\')\\nTrue\\n>>> print nested_bool_eval(\\'(True or False) and (True and False)\\')\\nFalse\\n>>> print nested_bool_eval(\\'(True or False) or (True and False)\\')\\nTrue\\n>>> print nested_bool_eval(\\'(True and False) or (True and False)\\')\\nFalse\\n>>> print nested_bool_eval(\\'(True and False) or (True and (True or False))\\')\\nTrue\\n\\n\\n[Partially off-topic possibly]\\n\\nNote, the you can easily configure the tokens (both operands and operators) you use with the poor-mans dependency-injection means provided (token_to_char=token_to_char and friends) to have multiple different evaluators at the same time (just resetting the \"injected-by-default\" globals will leave you with a single behavior).\\n\\nFor example:\\n\\ndef fuzzy_bool_eval(s):\\n    \"\"\"as normal, but:\\n    - an argument \\'Maybe\\' may be :)) present\\n    - algebra is:\\n    [one of \\'True\\', \\'False\\', \\'Maybe\\'] [one of \\'or\\', \\'and\\'] \\'Maybe\\' -> \\'Maybe\\'\\n    \"\"\"\\n    Maybe = \\'Maybe\\' # just an object with nice __str__\\n\\n    def or_op(left, right):\\n        return (Maybe if Maybe in [left, right] else (left or right))\\n\\n    def and_op(left, right):\\n        args = [left, right]\\n\\n        if Maybe in args:\\n            if True in args:\\n                return Maybe # Maybe and True -> Maybe\\n            else:\\n                return False # Maybe and False -> False\\n\\n        return left and right\\n\\n    str_to_token = {\\'True\\':True,\\n                    \\'False\\':False,\\n                    \\'Maybe\\':Maybe,\\n                    \\'and\\':and_op,\\n                    \\'or\\':or_op,\\n                    \\'(\\':\\'(\\',\\n                    \\')\\':\\')\\'}\\n\\n    token_lst = create_token_lst(s, str_to_token=str_to_token)\\n\\n    return formatted_bool_eval(token_lst)\\n\\n\\ngives:\\n\\n>>> print fuzzy_bool_eval(\\'\\')\\nTrue\\n>>> print fuzzy_bool_eval(\\'Maybe\\')\\nMaybe\\n>>> print fuzzy_bool_eval(\\'True or False\\')\\nTrue\\n>>> print fuzzy_bool_eval(\\'True or Maybe\\')\\nMaybe\\n>>> print fuzzy_bool_eval(\\'False or (False and Maybe)\\')\\nFalse\\n\\n'},\n {'prompt': 'I\\'m trying to solve this programming riddle and although the solution (see code below) works correctly, it is too slow for succesful submission.\\n\\n\\nAny pointers as how to make this run\\nfaster (removal of every n-th element from a list)?\\nOr suggestions for a better algorithm to calculate the same; seems I can\\'t think of anything\\nelse than brute-force for now...\\n\\n\\nBasically, the task at hand is:\\n\\n\\nGIVEN:\\nL = [2,3,4,5,6,7,8,9,10,11,........]\\n1. Take the first remaining item in list L (in the general case \\'n\\'). Move it to \\n   the \\'lucky number list\\'. Then drop every \\'n-th\\' item from the list.\\n2. Repeat 1\\n\\nTASK:\\nCalculate the n-th number from the \\'lucky number list\\' ( 1 <= n <= 3000)\\n\\n\\nMy original code (it calculated the 3000 first lucky numbers in about a second on my machine - unfortunately too slow):\\n\\n\"\"\"\\nSPOJ Problem Set (classical) 1798. Assistance Required\\nURL: http://www.spoj.pl/problems/ASSIST/\\n\"\"\"\\n\\nsieve = range(3, 33900, 2)\\nluckynumbers = [2]\\n\\nwhile True:\\n    wanted_n = input()\\n    if wanted_n == 0:\\n        break\\n\\n    while len(luckynumbers) < wanted_n:\\n        item = sieve[0]\\n        luckynumbers.append(item)\\n        items_to_delete = set(sieve[::item])\\n        sieve = filter(lambda x: x not in items_to_delete, sieve)\\n    print luckynumbers[wanted_n-1]\\n\\n\\nEDIT: thanks to the terrific contributions of Mark Dickinson, Steve Jessop and gnibbler, I got at the following, which is quite a whole lot faster than my original code (and succesfully got submitted at http://www.spoj.pl with 0.58 seconds!)...\\n\\nsieve = range(3, 33810, 2)\\nluckynumbers = [2]\\n\\nwhile len(luckynumbers) < 3000:\\n    if len(sieve) < sieve[0]:\\n        luckynumbers.extend(sieve)\\n        break\\n    luckynumbers.append(sieve[0])\\n    del sieve[::sieve[0]]\\n\\nwhile True:\\n    wanted_n = input()\\n    if wanted_n == 0:\\n        break\\n    else:\\n        print luckynumbers[wanted_n-1]\\n\\n',\n  'completion': 'This series is called ludic numbers\\n\\n__delslice__ should be faster than __setslice__+filter\\n\\n>>> L=[2,3,4,5,6,7,8,9,10,11,12]\\n>>> lucky=[]\\n>>> lucky.append(L[0])\\n>>> del L[::L[0]]\\n>>> L\\n[3, 5, 7, 9, 11]\\n>>> lucky.append(L[0])\\n>>> del L[::L[0]]\\n>>> L\\n[5, 7, 11]\\n\\n\\nSo the loop becomes.\\n\\nwhile len(luckynumbers) < 3000:\\n    item = sieve[0]\\n    luckynumbers.append(item)\\n    del sieve[::item] \\n\\n\\nWhich runs in less than 0.1 second\\n'},\n {'prompt': \"I've been searching the net for ~3 hours but I couldn't find a solution yet. I want to give a precomputed kernel to libsvm and classify a dataset, but:\\n\\n\\nHow can I generate a precomputed kernel? (for example, what is the basic precomputed kernel for Iris data?)\\nIn the libsvm documentation, it is stated that:\\n\\nFor precomputed kernels, the first element of each instance must be\\nthe ID. For example,\\n\\n        samples = [[1, 0, 0, 0, 0], [2, 0, 1, 0, 1], [3, 0, 0, 1, 1], [4, 0, 1, 1, 2]]\\n        problem = svm_problem(labels, samples)\\n        param = svm_parameter(kernel_type=PRECOMPUTED)\\n\\n\\n\\nWhat is a ID? There's no further details on that. Can I assign ID's sequentially?\\n\\nAny libsvm help and an example of precomputed kernels really appreciated.\\n\",\n  'completion': \"First of all, some background to kernels and SVMs...\\n\\nIf you want to pre-compute a kernel for n vectors (of any dimension), what need to do is calculate the kernel function between each pair of examples. The kernel function takes two vectors and gives a scalar, so you can think of a precomputed kernel as a nxn matrix of scalars. It's usually called the kernel matrix, or sometimes the Gram matrix.\\n\\nThere are many different kernels, the simplest is the linear kernel (also known as the dot product):\\n\\nsum(x_i * y_i) for i in [1..N]  where (x_1,...,x_N) (y_1,..,y_N) are vectors\\n\\nSecondly, trying to answer your problem...\\n\\nThe documentation about precomputed kernels in libsvm is actually pretty good...\\n\\nAssume the original training data has three four-feature instances \\nand testing data has one instance:\\n\\n15  1:1 2:1 3:1 4:1\\n45      2:3     4:3\\n25          3:1\\n15  1:1     3:1\\n\\nIf the linear kernel is used, we have the following \\nnew training/testing sets:\\n\\n15  0:1 1:4 2:6  3:1\\n45  0:2 1:6 2:18 3:0 \\n25  0:3 1:1 2:0  3:1\\n\\n15  0:? 1:2 2:0  3:1\\n\\n\\nEach vector here in the second example is a row in the kernel matrix. The value at index zero is the ID value and it just seems to be a sequential count. The value at index 1 of the first vector is the value of the kernel function of the first vector from the first example with itself (i.e. (1x1)+(1x1)+(1x1)+(1x1) = 4), the second is the value of the kernel function of the first vector with the second (i.e. (1x3)+(1x3)=6). It follows on like that for the rest of the example. You can see in that the kernel matrix is symmetric, as it should be, because K(x,y) = K(y,x).\\n\\nIt's worth pointing out that the first set of vectors are represented in a sparse format (i.e. missing values are zero), but the kernel matrix isn't and shouldn't be sparse. I don't know why that is, it just seems to be a libsvm thing.\\n\"},\n {'prompt': 'I\\'m having trouble using os.utime to correctly set the modification time on the mac (Mac OS X 10.6.2, running Python 2.6.1 from /usr/bin/python). It\\'s not consistent with the touch utility, and it\\'s not consistent with the properties displayed in the Finder\\'s \"get info\" window.\\n\\nConsider the following command sequence. The \\'created\\' and \\'modified\\' times in the plain text refer to the attributes shown in the \"get info\" window in the finder. As a reminder, os.utime takes arguments (filename, (atime, mtime)).\\n\\n>>> import os\\n>>> open(\\'tempfile\\',\\'w\\').close()\\n\\n\\n\\'created\\' and \\'modified\\' are both the current time.\\n\\n>>> os.utime(\\'tempfile\\', (1000000000, 1500000000) )\\n\\n\\n\\'created\\' is the current time, \\'modified\\' is July 13, 2017.\\n\\n>>> os.utime(\\'tempfile\\', (1000000000, 1000000000) )\\n\\n\\n\\'created\\' and \\'modified\\' are both September 8, 2001.\\n\\n>>> os.path.getmtime(\\'tempfile\\')\\n1000000000.0\\n>>> os.path.getctime(\\'tempfile\\')\\n1269021939.0\\n>>> os.path.getatime(\\'tempfile\\')\\n1269021951.0\\n\\n\\n...but the os.path.get?time and os.stat don\\'t reflect it.\\n\\n>>> os.utime(\\'tempfile\\', (1500000000, 1000000000) )\\n\\n\\n\\'created\\' and \\'modified\\' are still both September 8, 2001.\\n\\n>>> os.utime(\\'tempfile\\', (1500000000, 1500000000) )\\n\\n\\n\\'created\\' is September 8, 2001, \\'modified\\' is July 13, 2017.\\n\\nI\\'m not sure if this is a Python problem or a Mac stat problem. When I exit the Python shell and run\\n\\ntouch -a -t 200011221234 tempfile\\n\\n\\nneither the modification nor the creation times are changed, as expected. Then I run\\n\\ntouch -m -t 200011221234 tempfile\\n\\n\\nand both \\'created\\' and \\'modified\\' times are changed.\\n\\nDoes anyone have any idea what\\'s going on? How do I change the modification and creation times consistently on the mac? (Yes, I am aware that on Unixy systems there is no \"creation time.\")\\n\\n\\n\\nResult from running Chris Johnsen\\'s script:\\n\\nseth@local:~$ /usr/bin/python timetest.py tempfile 5\\ninitial:\\n(1269631281.0, 1269631281.0, 1269631281.0, 1269631281, 1269631281, 1269631281)\\n\\ntest: (1000000000, 1000000000)\\n(1000000000.0, 1000000000.0, 1269631281.0, 1000000000, 1000000000, 1269631281)\\n(1269631281.0, 1000000000.0, 1269631281.0, 1269631281, 1000000000, 1269631281)\\n\\ntest: (1000000000, 1500000000)\\n(1000000000.0, 1500000000.0, 1269631286.0, 1000000000, 1500000000, 1269631286)\\n(1269631286.0, 1500000000.0, 1269631286.0, 1269631286, 1500000000, 1269631286)\\n\\ntest: (1500000000, 1000000000)\\n(1500000000.0, 1000000000.0, 1269631291.0, 1500000000, 1000000000, 1269631291)\\n(1269631291.0, 1000000000.0, 1269631291.0, 1269631291, 1000000000, 1269631291)\\n\\ntest: (1500000000, 1500000000)\\n(1500000000.0, 1500000000.0, 1269631296.0, 1500000000, 1500000000, 1269631296)\\n(1269631296.0, 1500000000.0, 1269631296.0, 1269631296, 1500000000, 1269631296)\\n\\n\\nAt the end of the exercise, the \\'created\\' date as visible in the finder is 9/8/01 and the \\'modified\\' date is 7/13/17. (The access date, thanks to presumably spotlight as you suggest and as I\\'ve read about, is roughly \\'now.\\') The created and modified dates visible in the finder still make no sense.\\n',\n  'completion': 'POSIX atime, mtime, ctime\\n\\nIt might help if you included a full script and its actual and expected outputs instead of the REPL fragments.\\n\\nimport sys, os, stat, time\\n\\ndef get_times(p):\\n    s = os.stat(p)\\n    return ( \\n        os.path.getatime(p),\\n        os.path.getmtime(p),\\n        os.path.getctime(p),\\n        s[stat.ST_ATIME],\\n        s[stat.ST_MTIME],\\n        s[stat.ST_CTIME],\\n    )\\n\\ndef main(p, delay=1):\\n    delay = float(delay)\\n    (a,b) = (1000000000, 1500000000)\\n\\n    open(p,\\'w\\').close()\\n\\n    print \\'initial:\\'\\n    print get_times(p)\\n\\n    for t in [ (a,a), (a,b), (b,a), (b,b) ]:\\n        print\\n        print \\'test:\\', t\\n        os.utime(p,t)\\n        print get_times(p)\\n        time.sleep(delay)\\n        print get_times(p)\\n\\nmain(*sys.argv[1:])\\n\\n\\nI get this on my 10.4 system with cd \"$HOME\" && python test.py tempfile 5 (system default Python 2.3.6 and MacPorts Python 2.6.4 both give the same result (leaving out the initial times and ctime, of course)):\\n\\n% python /tmp/test.py tempfile 5\\ninitial:\\n(1000000000.0, 1000000000.0, 1269629881.0, 1000000000, 1000000000, 1269629881)\\n\\ntest: (1000000000, 1000000000)\\n(1000000000.0, 1000000000.0, 1269629881.0, 1000000000, 1000000000, 1269629881)\\n(1000000000.0, 1000000000.0, 1269629881.0, 1000000000, 1000000000, 1269629881)\\n\\ntest: (1000000000, 1500000000)\\n(1000000000.0, 1500000000.0, 1269629886.0, 1000000000, 1500000000, 1269629886)\\n(1000000000.0, 1500000000.0, 1269629886.0, 1000000000, 1500000000, 1269629886)\\n\\ntest: (1500000000, 1000000000)\\n(1500000000.0, 1000000000.0, 1269629891.0, 1500000000, 1000000000, 1269629891)\\n(1500000000.0, 1000000000.0, 1269629891.0, 1500000000, 1000000000, 1269629891)\\n\\ntest: (1500000000, 1500000000)\\n(1500000000.0, 1500000000.0, 1269629896.0, 1500000000, 1500000000, 1269629896)\\n(1500000000.0, 1500000000.0, 1269629896.0, 1500000000, 1500000000, 1269629896)\\n\\n\\nThat seems reasonable. I wonder what you get.\\n\\nI have heard that Spotlight can sometimes aggressively reset atime due to re-indexing changed files. I would not expect it to re-index a file that has only undergone utime()/utimes(), but I suppose it is possible. To eliminate Spotlight as a possible complication use a file in a location that is not indexed by Spotlight (e.g. /tmp/testfile).\\n\\nDate Created in Finder\\n\\n(shown as â\\x80\\x9cCreated:â\\x80\\x9d in Get Info windows of Finder)\\n\\nIf you have the Developer tools installed, you can use /Developer/Tools/GetFileInfo to see the HFS creationDate. I added the following lines after every print get_times(p) line:\\n\\nsys.stdout.flush()\\nos.system(\\'/Developer/Tools/GetFileInfo \\' + p)\\n\\n\\nI also changed the iteration to match your initial description ([ (a,b), (a,a), (b,a), (b,b) ]).\\n\\nThe result now looks like this:\\n\\n% rm /tmp/tempfile; python /tmp/test.py /tmp/tempfile 1\\ninitial:\\n(1269636574.0, 1269636574.0, 1269636574.0, 1269636574, 1269636574, 1269636574)\\nfile: \"/private/tmp/tempfile\"\\ntype: \"\"\\ncreator: \"\"\\nattributes: avbstclinmedz\\ncreated: 03/26/2010 15:49:34\\nmodified: 03/26/2010 15:49:34\\n\\ntest: (1000000000, 1500000000)\\n(1000000000.0, 1500000000.0, 1269636574.0, 1000000000, 1500000000, 1269636574)\\nfile: \"/private/tmp/tempfile\"\\ntype: \"\"\\ncreator: \"\"\\nattributes: avbstclinmedz\\ncreated: 03/26/2010 15:49:34\\nmodified: 07/13/2017 21:40:00\\n(1000000000.0, 1500000000.0, 1269636574.0, 1000000000, 1500000000, 1269636574)\\nfile: \"/private/tmp/tempfile\"\\ntype: \"\"\\ncreator: \"\"\\nattributes: avbstclinmedz\\ncreated: 03/26/2010 15:49:34\\nmodified: 07/13/2017 21:40:00\\n\\ntest: (1000000000, 1000000000)\\n(1000000000.0, 1000000000.0, 1269636576.0, 1000000000, 1000000000, 1269636576)\\nfile: \"/private/tmp/tempfile\"\\ntype: \"\"\\ncreator: \"\"\\nattributes: avbstclinmedz\\ncreated: 09/08/2001 20:46:40\\nmodified: 09/08/2001 20:46:40\\n(1000000000.0, 1000000000.0, 1269636576.0, 1000000000, 1000000000, 1269636576)\\nfile: \"/private/tmp/tempfile\"\\ntype: \"\"\\ncreator: \"\"\\nattributes: avbstclinmedz\\ncreated: 09/08/2001 20:46:40\\nmodified: 09/08/2001 20:46:40\\n\\ntest: (1500000000, 1000000000)\\n(1500000000.0, 1000000000.0, 1269636577.0, 1500000000, 1000000000, 1269636577)\\nfile: \"/private/tmp/tempfile\"\\ntype: \"\"\\ncreator: \"\"\\nattributes: avbstclinmedz\\ncreated: 09/08/2001 20:46:40\\nmodified: 09/08/2001 20:46:40\\n(1500000000.0, 1000000000.0, 1269636577.0, 1500000000, 1000000000, 1269636577)\\nfile: \"/private/tmp/tempfile\"\\ntype: \"\"\\ncreator: \"\"\\nattributes: avbstclinmedz\\ncreated: 09/08/2001 20:46:40\\nmodified: 09/08/2001 20:46:40\\n\\ntest: (1500000000, 1500000000)\\n(1500000000.0, 1500000000.0, 1269636578.0, 1500000000, 1500000000, 1269636578)\\nfile: \"/private/tmp/tempfile\"\\ntype: \"\"\\ncreator: \"\"\\nattributes: avbstclinmedz\\ncreated: 09/08/2001 20:46:40\\nmodified: 07/13/2017 21:40:00\\n(1500000000.0, 1500000000.0, 1269636578.0, 1500000000, 1500000000, 1269636578)\\nfile: \"/private/tmp/tempfile\"\\ntype: \"\"\\ncreator: \"\"\\nattributes: avbstclinmedz\\ncreated: 09/08/2001 20:46:40\\nmodified: 07/13/2017 21:40:00\\n\\n\\nThis seems to be consistent with your observations from your Get Info window in Finder. My interpretation (borne out by other experimentation) is that the HFS creationDate is updated by utime, but it only ever goes backwards (never forwards). If you want to update the HFS creationDate to a newer value, then you probably will have to use a Mac-specific API to do it.\\n\\nOne other note: you may have to switch windows a bit to get the Get Info window to update. On my system, its display does not automatically update unless I switch windows either to or from the Get Info window.\\n'},\n {'prompt': 'Today I needed to send email from a Python script. As always I searched Google and found the following script that fits to my need.\\n\\nimport smtplib\\n\\nSERVER = \"localhost\"\\n\\nFROM = \"sender@example.com\"\\nTO = [\"user@example.com\"] # must be a list\\n\\nSUBJECT = \"Hello!\"\\n\\nTEXT = \"This message was sent with Python\\'s smtplib.\"\\n\\n# Prepare actual message\\n\\nmessage = \"\"\"\\\\\\nFrom: %s\\nTo: %s\\nSubject: %s\\n\\n%s\\n\"\"\" % (FROM, \", \".join(TO), SUBJECT, TEXT)\\n\\n# Send the mail\\n\\nserver = smtplib.SMTP(SERVER)\\nserver.sendmail(FROM, TO, message)\\nserver.quit()\\n\\n\\nBut when I tried to run the program, I got the following error message:\\n\\nTraceback (most recent call last):\\n  File \"C:/Python26/email.py\", line 1, in <module>\\n    import smtplib\\n  File \"C:\\\\Python26\\\\lib\\\\smtplib.py\", line 46, in <module>\\n    import email.utils\\n  File \"C:/Python26/email.py\", line 24, in <module>\\n    server = smtplib.SMTP(SERVER)\\nAttributeError: \\'module\\' object has no attribute \\'SMTP\\'\\n\\n\\nHow can i solve this problem? Any one can help me?\\n\\nThanks in advance,\\nNimmy.\\n\\n\\n\\nchanged the name to emailsendin .py. But I got the following error\\n\\nTraceback (most recent call last):\\n  File \"C:\\\\Python26\\\\emailsending.py\", line 24, in <module>\\n    server = smtplib.SMTP(SERVER)\\n  File \"C:\\\\Python26\\\\lib\\\\smtplib.py\", line 239, in __init__\\n    (code, msg) = self.connect(host, port)\\n  File \"C:\\\\Python26\\\\lib\\\\smtplib.py\", line 295, in connect\\n    self.sock = self._get_socket(host, port, self.timeout)\\n  File \"C:\\\\Python26\\\\lib\\\\smtplib.py\", line 273, in _get_socket\\n    return socket.create_connection((port, host), timeout)\\n  File \"C:\\\\Python26\\\\lib\\\\socket.py\", line 512, in create_connection\\n    raise error, msg\\nerror: [Errno 10061] No connection could be made because the target machine actively refused it\\n\\n',\n  'completion': 'You\\'ve named your module the same as one of Python\\'s internal modules.  When you import smtplib, it tries to import email, and finds your module instead of the internal one.  When two modules import one another, only the variables in each module visible before the both import statements will be visible to one another.  Renaming your module will fix the problem.\\n\\nYou can see this, although it\\'s slightly obscure, in the stack trace.  The import email.utils line from smtplib.py is calling your module, in \"c:/Python26/email.py\".\\n\\nAnother note: it\\'s probably not a great idea to use your Python install directory as your working directory for Python code.\\n'},\n {'prompt': \"I've got a pile of C code that I'd like to unit test using Python's unittest library (in Windows), but I'm trying to work out the best way of interfacing the C code so that Python can execute it (and get the results back). Does anybody have any experience in the easiest way to do it?\\n\\nSome ideas include:\\n\\n\\nWrapping the code as a Python C extension using the Python API\\nWrap the C code using SWIG\\nAdd a DLL wrapper to the C code and load it into Python using ctypes\\nAdd a small XML-RPC server to the c-code and call it using xmlrpclib (yes, I know this seems a bit far-out!)\\n\\n\\nIs there a canonical way of doing this? I'm going to be doing this quite a lot, with different C modules, so I'd like to find a way which is least effort.\\n\",\n  'completion': 'Using ctypes would be my first instinct, though I must admit that if I was testing C code that was not going to be interfaced from Python in the first place, I would just use check. Check has the strong advantage of being able to properly report test cases that segfault. This is because it runs each test case in a separate process.\\n\\nNow if you are going to create a python wrapper for the C code anyway, I would simply unittest the wrapper. In addition to the methods you listed above, you could also use Cython to write such a wrapper with python-like code and then unittest it from Python.\\n'},\n {'prompt': \"I'm starting a computer graphics course, and I have to choose a language.\\n\\nChoices are between C++ and Python. I have no problem with C++, python is a work in progress. So i was thinking to go down the python road, using pyopengl for graphics part.\\n\\nI have heard though, that performance is an issue.\\n\\nIs python / pyopengl mature enough to challenge C++ on performance?\\n\\nI realize its a long shot, but I'd like to hear your thoughts, experiences on uses of pyopengl.\\n\\nThanks in advance.\\n\",\n  'completion': \"It depends a LOT on the contents of your computer graphics course. If you are doing anything like the introductory course I've taught in the past, it's basically spinning cubes and spheres, some texture mapping and some vertex animation, and that's about it. In this case, Python would be perfectly adequate, assuming you can get around the Unpythonic (and, lets be honest, un-C++) OpenGL state-machine paradigm.\\n\\nFor things like doing your matrix maths you can use Numpy, the core of which is written in C and is really quite quick. You'll be up and running faster, iterate faster and most likely have more fun.\\n\\nIf, however, you are doing some hardcore, cutting edge, millions-of-triangles-per-scene-skinned-animated-everything computer graphics course, stick with C++.\\n\\nIf your class has given you the choice it's probably a safe bet that Python will be ok.\\n\\nIf you want to leverage your knowledge into a real job in computer graphics though, pretty much every game and graphics engine is written in C or C++, while Python (or Lua) is left as a scripting language.\\n\"},\n {'prompt': 'I think this is a bit tricky, at least for me. :)\\n\\nSo I have 4 models Person, Singer, Bassist and Ninja.\\n\\nSinger, Bassist and Ninja inherit from Person.\\n\\n\\n\\nThe problem is that each Person can be any of its subclasses. \\n\\ne.g. A person can be a Singer and a Ninja. Another Person can be a Bassist and a Ninja. Another one can be all three.\\n\\nHow should I organise my models?\\n\\n\\n\\nHelp would be much appreciated!\\n',\n  'completion': 'Multiple inheritance doesn\\'t work well with databases (and your Django models do need to map down to a database in the end), and inheritance is often a bad way to model \"roles\" (because people\\'s roles do change).  I would have Singer, Bassist and Ninja as \"roles\", not as subclasses of Person, and connect them via foreign keys:\\n\\nclass Singer(models.Model):\\n    person = models.ForeignKey(\\'Person\\')\\n    # ...\\n\\nclass Person(models.Model):\\n    # ...\\n\\n'},\n {'prompt': \"I havenâ\\x80\\x99t been able to find a good solution for this problem on the net (probably because switch, position, list and Python are all such overloaded words).\\n\\nItâ\\x80\\x99s rather simple â\\x80\\x93Â\\xa0I have this list:\\n\\n['title', 'email', 'password2', 'password1', 'first_name', 'last_name', 'next', 'newsletter']\\n\\n\\nIâ\\x80\\x99d like to switch position of 'password2' and 'password1' â\\x80\\x93Â\\xa0not knowing their exact position, only that theyâ\\x80\\x99re right next to one another and password2 is first.\\n\\nIâ\\x80\\x99ve accomplished this with some rather long-winded list-subscripting, but I wondered its possible to come up with something a bit more elegant?\\n\",\n  'completion': \"    i = ['title', 'email', 'password2', 'password1', 'first_name', \\n         'last_name', 'next', 'newsletter']\\n    a, b = i.index('password2'), i.index('password1')\\n    i[b], i[a] = i[a], i[b]\\n\\n\"},\n {'prompt': \"What regular expression can I use (if any) to validate that a given string is a legal ssh rsa public key?\\n\\nI only need to validate the actual key - I don't care about the key type the precedes it or the username comment after it.\\n\\nIdeally, someone will also provide the python code to run the regex validation.\\n\\nThanks.\\n\",\n  'completion': 'A \"good enough\" check is to see if the key starts with the correct header.\\n\\nThe data portion of the keyfile should decode from base64, or it will fail with a base64.binascii.Error\\n\\nUnpack the first 4 bytes (an int), which should be 7. This is the\\nlength of the following string (I guess this could be different, but you\\'re only concerned with ssh-rsa).\\n\\nopenssh_pubkey = open(\\'keyfile\\').read()\\ntype, key_string, comment = openssh_pubkey.split()\\ndata = base64.decodestring(key_string)\\nint_len = 4\\nstr_len = struct.unpack(\\'>I\\', data[:int_len])[0] # this should return 7\\ndata[int_len:int_len+str_len] == type\\n\\n\\nAlternatively, you could forgo the binary checks, and look for AAAAB3NzaC1yc2EA at the start of an ssh-rsa key, bit I would still verify it\\'s valid base64.\\n\\n[edit] Clarification:\\nVia the specification, the first part if the key is a length prefixed string. The length is packed as a big-endian unsigned int (\\'>I\\' for a python struct). It\\'s a 7 here, because the following string, \\'ssh-rsa\\', is 7 bytes long. data[4:11] is the next 7 bytes (per the length prefix), but I edited the code above to use some descriptive variables to try and make this more clear. If you want to be thorough, you should also check for ssh-dss, and possibly pgp-sign-rsa, and pgp-sign-dss, but they are far less common.\\n'},\n {'prompt': 'I used Python to generate a CSV file. But when I open it in Excel, Excel will auto recognize a string into a number if it could be converted. \\n\\ne.g.33E105 becomes 33*10^105, which is actually an ID, not a number. \\n\\nHow to disable this in Excel while opening a CSV file? Or I need to resort to a excel-python library to output a excel file and specify the format myself?\\n\\nI also found a similar question without good answers on the web. \\n\\nThanks!\\n',\n  'completion': 'You could precede it with a single quote, forcing it to text.\\n\\nA fun answer is you could keep the first eight rows blank (it only processes the first eight rows to determine data type), although I think this may blank all your data entirely.  You could hide those empty rows.\\n'},\n {'prompt': \"How do I override a class special method?\\n\\nI want to be able to call the __str__() method of the class without creating an instance. Example:\\n\\nclass Foo:\\n    def __str__(self):\\n        return 'Bar'\\n\\nclass StaticFoo:\\n    @staticmethod\\n    def __str__():\\n        return 'StaticBar'\\n\\nclass ClassFoo:\\n    @classmethod\\n    def __str__(cls):\\n        return 'ClassBar'\\n\\nif __name__ == '__main__':\\n    print(Foo)\\n    print(Foo())\\n    print(StaticFoo)\\n    print(StaticFoo())\\n    print(ClassFoo)\\n    print(ClassFoo())\\n\\n\\nproduces:\\n\\n\\n\\n<class '__main__.Foo'>\\nBar\\n<class '__main__.StaticFoo'>\\nStaticBar\\n<class '__main__.ClassFoo'>\\nClassBar\\n\\n\\nshould be:\\n\\nBar\\nBar\\nStaticBar\\nStaticBar\\nClassBar\\nClassBar\\n\\n\\nEven if I use the @staticmethod or @classmethod the __str__ is still using the built-in Python definition for __str__. It's only working when it's Foo().__str__() instead of Foo.__str__().\\n\",\n  'completion': 'Special method __str__ defined in a class works only for the instances of that class, to have the different behavior for class objects you will have to do it in a metaclass of that class e.g. (python 2.5)\\n\\nclass Meta(type):\\n    def __str__(self):\\n        return \"Klass\"\\n\\nclass A(object):\\n    __metaclass__ = Meta\\n\\n    def __str__(self):\\n        return \"instance\"\\n\\nprint A\\nprint A()\\n\\n\\noutput:\\n\\nKlass\\ninstance\\n\\n'},\n {'prompt': 'I have an application where I want to simulate the connection between a device and a \"modem\". The device will be connected to a serial port and will talk to the software modem through that.\\n\\nFor testing purposes I want to be able to use a mock software device to test send and receive data.\\n\\nExample Python code\\n\\ndevice = Device()\\nmodem  = Modem()\\ndevice.connect(modem)\\n\\ndevice.write(\"Hello\")\\nmodem_reply = device.read()\\n\\n\\nNow, in my final app I will just pass /dev/ttyS1 or COM1 or whatever for the application to use.\\nBut how can I do this in software? I am running Linux and application is written in Python.\\n\\nI have tried making a FIFO (mkfifo ~/my_fifo) and that does work, but then I\\'ll need one FIFO for writing and one for reading. What I want is to open ~/my_fake_serial_port and read and write to that.\\n\\nI have also lpayed with the ptymodule, but can\\'t get that to work either. I can get a master and slave file descriptor from pty.openpty() but trying to read or write to them only causes IOError Bad File Descriptor error message.\\n\\nUpdate\\n\\nComments pointed me to the SO question http://stackoverflow.com/questions/2175440/are-there-some-program-like-com2com-in-linux which uses socat to setup a virtual serial connection.\\nI used it like this:\\n\\nsocat PTY,link=$HOME/COM1 PTY,link=$HOME/COM2\\n\\nTo the rest of you, thank you for giving me valuable information.\\nI chose to accept Vinay Sajips\\'s answer since that is the solution which I went for before the socat suggestion showed up. It seems to work well enough.\\n',\n  'completion': \"It's probably best to use pyserial to communicate with the serial port, and you can just create a mock version of the serial.Serial class which implements read, readline, write and any other methods you need.\\n\"},\n {'prompt': \"I'm a .NET developer who knows very little about Python, but want to give it a test drive for a small project I'm working on.\\n\\nWhat tools and packages should I install on my machine? I'm looking for a common, somewhat comprehensive, development environment.\\n\\nI'll likely run Ubuntu 9.10, but I'm flexible.  If Windows is a better option, that's fine too.\\n\\nEdit: To clarify, I'm not looking for the bare minimum to get a Python program to run.  I wouldn't expect a newbie .NET dev to use notepad and a compiler. I'd recommend Visual Studio, NUnit, SQL Server, etc.\\n\",\n  'completion': \"Your system already has Python on it. Use the text editor or IDE of your choice; I like vim. \\n\\nI can't tell you what third-party modules you need without knowing what kind of development you will be doing. Use apt as much as you can to get the libraries.\\n\\n\\n\\nTo speak to your edit:\\n\\nThis isn't minimalistic, like handing a .NET newbie notepad and a compiler: a decent text editor and the stdlib are all you really need to start out. You will likely need third-party libraries to develop whatever kind of applications you are writing, but I cannot think of any third-party modules all Python programmers will really need or want.\\n\\nUnlke the .NET/Windows programming world, there is no one set of dev tools that stands above all others. Different people use different editors a whole lot. In Python, a module namespace is fully within a single file and project organization is based on the filesystem, so people do not lean on their IDEs as hard. Different projects use different version control software, which has been booming with new faces recently. Most of these are better than TFS and all are 1000 times better than SourceSafe.\\n\\nWhen I want an interactive session, I use the vanilla Python interpreter. Various more fancy interpreters exist: bpython, ipython, IDLE. bpython is the least fancy of these and is supposed to be good about not doing weird stuff. ipython and IDLE can lead to strange bugs where code that works in them doens't work in normal Python and vice-versa; I've seen this first hand with IDLE.\\n\\nFor some of the tools you asked about and some others\\n\\n\\nIn .NET you would use NUnit. In Python, use the stdlib unittest module. There are various third-party extensions and test runners, but unittest should suit you okay. \\n\\nIf you really want to look into something beyond this, get unittest2, a backport of the 2.7 version of unittest. It has incorporated all the best things from the third-party tools and is really neat.\\n\\nIn .NET you would use SQL Server. In Python, you may use PostgreSQL, MySQL, sqlite, or some other database. Python specifies a unified API for databases and porting from one to another typically goes pretty smoothly. sqlite is in the stdlib.\\n\\nThere are various Object Relational Models to make using databases more abstracted. SQLAlchemy is the most notable of these.\\n\\nIf you are doing network programming, get Twisted.\\nIf you are doing numerical math, get numpy and scipy.\\nIf you are doing web development, choose a framework. There are about 200000: Pylons, zope, Django, CherryPy, werkzeug...I won't bother starting an argument by recommending one. Most of these will happily work with various servers with a quick setting.\\nIf you want to do GUI development, there are quite a few Python bindings. The stdlib ships with Tk bindings I would not bother with. There are wx bindings (wxpython), GTK+ bindings (pygtk), and two sets of Qt bindings. If you want to do native Windows GUI development, get IronPython and do it in .NET. There are win32 bindings, but they'll make you want to pull your hair out trying to use them directly.\\n\\n\"},\n {'prompt': 'OK I love Python\\'s zip() function. Use it all the time, it\\'s brilliant. Every now and again I want to do the opposite of zip(), think \"I used to know how to do that\", then google python unzip, then remember that one uses this magical * to unzip a zipped list of tuples. Like this:\\n\\nx = [1,2,3]\\ny = [4,5,6]\\nzipped = zip(x,y)\\nunzipped_x, unzipped_y = zip(*zipped)\\nunzipped_x\\n    Out[30]: (1, 2, 3)\\nunzipped_y\\n    Out[31]: (4, 5, 6)\\n\\n\\nWhat on earth is going on? What is that magical asterisk doing? Where else can it be applied and what other amazing awesome things in Python are so mysterious and hard to google?\\n',\n  'completion': 'The asterisk in Python is documented in the Python tutorial, under Unpacking Argument Lists.\\n'},\n {'prompt': \"Can I define a function which, when called, inserts new locals into the caller's scope? I have a feeling that passing the caller's locals() into the function might work, but is there a way to do what I want without having to do this?\\n\",\n  'completion': \"Check out the inspect module, it is used by minimock to mock the caller's scope.\\n\\nThis code ought to do what you want exactly:\\n\\nimport inspect\\ndef mess_with_caller():\\n    stack = inspect.stack()\\n    try:\\n        locals_ = stack[1][0].f_locals\\n    finally:\\n        del stack\\n    locals_['my_new_function'] = lambda : 'yaaaaaay'\\n\\n\\nmess_with_caller()\\nprint my_new_function()\\n>>> Output: 'yaaaaaay'\\n\\n\"},\n {'prompt': 'Does Python have a pool of all strings and are they (strings) singletons there?\\n\\nMore precise, in the following code one or two strings were created in memory:\\n\\na = str(num)\\nb = str(num) \\n\\n\\n?\\n',\n  'completion': 'Strings are immutable in Python, so the implementation can decide whether to intern (that\\'s a term often associated with C#, meaning that some strings are stored in a pool) strings or not.\\n\\nIn your example, you\\'re dynamically creating strings. CPython does not always look into the pool to detect whether the string is already there - it also doesn\\'t make sense because you first have to reserve memory in order to create the string, and then compare it to the pool content (inefficient for long strings).\\n\\nBut for strings of length 1, CPython does look into the pool (cf. \"stringobject.c\"):\\n\\nstatic PyStringObject *characters[UCHAR_MAX + 1];\\n\\n...\\n\\nPyObject *\\nPyString_FromStringAndSize(const char *str, Py_ssize_t size)\\n{\\n\\n...\\n\\n    if (size == 1 && str != NULL &&\\n    (op = characters[*str & UCHAR_MAX]) != NULL)\\n    {\\n        #ifdef COUNT_ALLOCS\\n            one_strings++;\\n        #endif\\n\\n        Py_INCREF(op);\\n        return (PyObject *)op;\\n    }\\n\\n...\\n\\n\\nSo:\\n\\na = str(num)\\nb = str(num)\\nprint a is b # <-- this will print False in most cases (but try str(1) is str(1))\\n\\n\\nBut when using constant strings directly in your code, CPython uses the same string instance:\\n\\na = \"text\"\\nb = \"text\"\\nprint a is b # <-- this will print True\\n\\n'},\n {'prompt': \"So, I have three tables:\\n\\nThe class defenitions:\\n\\nengine = create_engine('sqlite://test.db', echo=False)\\nSQLSession = sessionmaker(bind=engine)\\nBase = declarative_base()\\n\\nclass Channel(Base):\\n    __tablename__ = 'channel'\\n\\n    id = Column(Integer, primary_key = True)\\n    title = Column(String)\\n    description = Column(String)\\n    link = Column(String)\\n    pubDate = Column(DateTime)\\n\\nclass User(Base):\\n    __tablename__ = 'user'\\n\\n    id = Column(Integer, primary_key = True)\\n    username = Column(String)\\n    password = Column(String)\\n    sessionId = Column(String)\\n\\nclass Subscription(Base):\\n    __tablename__ = 'subscription'\\n\\n    userId = Column(Integer, ForeignKey('user.id'), primary_key=True)\\n    channelId = Column(Integer, ForeignKey('channel.id'), primary_key=True)\\n\\n\\nNOTE: I know user.username should be unique, need to fix that, and I'm not sure why SQLalchemy creates some row names with the double-quotes.\\n\\nAnd I'm trying to come up with a way to retrieve all of the channels, as well as an indication on what channels one particular user (identified by user.sessionId together with user.id) has a subscription on.\\n\\nFor example, say we have four channels: channel1, channel2, channel3, channel4; a user: user1; who has a subscription on channel1 and channel4. The query for user1 would return something like:\\n\\nchannel.id | channel.title | subscribed\\n---------------------------------------\\n1            channel1        True\\n2            channel2        False\\n3            channel3        False\\n4            channel4        True\\n\\n\\nThis is a best-case result, but since I have absolutely no clue as how to accomplish the subscribed column, I've been instead trying to get the particular users id in the rows where the user has a subscription and where a subscription is missing, just leave it blank.\\n\\nThe database engine that I'm using together with SQLalchemy atm. is sqlite3\\n\\nI've been scratching my head over this for two days now, I've no problem joining together all three by way of the subscription table but then all of the channels where the user does not have a subscription gets omitted.\\n\\nI hope I've managed to describe my problem sufficiently, thanks in advance.\\n\\nEDIT: Managed to solve this in a slightly clunky way involving a sub-query:\\n\\n# What a messy SQL query!\\nstmt = query(Subscription).filter_by(userId = uid()).join((User, Subscription.userId == User.id)).filter_by(sessionId = id()).subquery()\\nsubs = aliased(Subscription, stmt)\\nresults = query(Channel.id, Channel.title, subs.userId).outerjoin((subs, subs.channelId == Channel.id))\\n\\n\\nHowever, I'll be continuing to search for a more elegant solution, so answers are still very much welcomed.\\n\",\n  'completion': 'Option-1:\\n\\nSubscription is just a many-to-many relation object, and I would suggest that you model it as such rather then as a separate class. See Configuring Many-to-Many Relationships documentation of SQLAlchemy/declarative. \\n\\nYou model with the test code becomes:\\n\\nfrom sqlalchemy import create_engine, Column, Integer, DateTime, String, ForeignKey, Table\\nfrom sqlalchemy.orm import relation, scoped_session, sessionmaker, eagerload\\nfrom sqlalchemy.ext.declarative import declarative_base\\n\\nengine = create_engine(\\'sqlite:///:memory:\\', echo=True)\\nsession = scoped_session(sessionmaker(bind=engine, autoflush=True))\\nBase = declarative_base()\\n\\nt_subscription = Table(\\'subscription\\', Base.metadata,\\n    Column(\\'userId\\', Integer, ForeignKey(\\'user.id\\')),\\n    Column(\\'channelId\\', Integer, ForeignKey(\\'channel.id\\')),\\n)\\n\\nclass Channel(Base):\\n    __tablename__ = \\'channel\\'\\n\\n    id = Column(Integer, primary_key = True)\\n    title = Column(String)\\n    description = Column(String)\\n    link = Column(String)\\n    pubDate = Column(DateTime)\\n\\nclass User(Base):\\n    __tablename__ = \\'user\\'\\n\\n    id = Column(Integer, primary_key = True)\\n    username = Column(String)\\n    password = Column(String)\\n    sessionId = Column(String)\\n\\n    channels = relation(\"Channel\", secondary=t_subscription)\\n\\n# NOTE: no need for this class\\n# class Subscription(Base):\\n    # ...\\n\\nBase.metadata.create_all(engine)\\n\\n\\n# ######################\\n# Add test data\\nc1 = Channel()\\nc1.title = \\'channel-1\\'\\nc2 = Channel()\\nc2.title = \\'channel-2\\'\\nc3 = Channel()\\nc3.title = \\'channel-3\\'\\nc4 = Channel()\\nc4.title = \\'channel-4\\'\\nsession.add(c1)\\nsession.add(c2)\\nsession.add(c3)\\nsession.add(c4)\\nu1 = User()\\nu1.username =\\'user1\\'\\nsession.add(u1)\\nu1.channels.append(c1)\\nu1.channels.append(c3)\\nu2 = User()\\nu2.username =\\'user2\\'\\nsession.add(u2)\\nu2.channels.append(c2)\\nsession.commit()\\n\\n\\n# ######################\\n# clean the session and test the code\\nsession.expunge_all()\\n\\n# retrieve all (I assume those are not that many)\\nchannels = session.query(Channel).all()\\n\\n# get subscription info for the user\\n#q = session.query(User)\\n# use eagerload(...) so that all \\'subscription\\' table data is loaded with the user itself, and not as a separate query\\nq = session.query(User).options(eagerload(User.channels))\\nfor u in q.all():\\n    for c in channels:\\n        print (c.id, c.title, (c in u.channels))\\n\\n\\nwhich produces following output:\\n\\n(1, u\\'channel-1\\', True)\\n(2, u\\'channel-2\\', False)\\n(3, u\\'channel-3\\', True)\\n(4, u\\'channel-4\\', False)\\n(1, u\\'channel-1\\', False)\\n(2, u\\'channel-2\\', True)\\n(3, u\\'channel-3\\', False)\\n(4, u\\'channel-4\\', False)\\n\\n\\nPlease note the use of eagerload, which will issue only 1 SELECT statement instead of 1 for each User when channels are asked for.\\n\\nOption-2:\\n\\nBut if you want to keep you model and just create an SA query that would give you the columns as you ask, following query should do the job:\\n\\nfrom sqlalchemy import and_\\nfrom sqlalchemy.sql.expression import case\\n#...\\nq = (session.query(#User.username, \\n                   Channel.id, Channel.title, \\n                   case([(Subscription.channelId == None, False)], else_=True)\\n                  ).outerjoin((Subscription, \\n                                and_(Subscription.userId==User.id, \\n                                     Subscription.channelId==Channel.id))\\n                             )\\n    )\\n# optionally filter by user\\nq = q.filter(User.id == uid()) # assuming uid() is the function that provides user.id\\nq = q.filter(User.sessionId == id()) # assuming uid() is the function that provides user.sessionId\\nres = q.all()\\nfor r in res:\\n    print r\\n\\n\\nThe output is absolutely the same as in the option-1 above.\\n'},\n {'prompt': 'Is it possible for python to accept input like this:\\n\\n\\nFolder name: Download\\n\\n\\nBut instead of the user typing \"Download\" it is already there as a initial value. If the user wants to edit it as \"Downloads\" all he has to do is add a \\'s\\' and press enter.\\n\\nUsing normal input command:\\n\\nfolder=input(\\'Folder name: \\')\\n\\n\\nall I can get is a blank prompt:\\n\\n\\nFolder name:\\n\\n\\nIs there a simple way to do this that I\\'m missing?\\n',\n  'completion': \"The standard library functions input() and raw_input() don't have this functionality. If you're using Linux you can use the readline module to define an input function that uses a prefill value and advanced line editing:\\n\\ndef rlinput(prompt, prefill=''):\\n   readline.set_startup_hook(lambda: readline.insert_text(prefill))\\n   try:\\n      return raw_input(prompt)\\n   finally:\\n      readline.set_startup_hook()\\n\\n\"},\n {'prompt': \"I'm debugging from the python console and would like to reload a module every time I make a change so I don't have to exit the console and re-enter it.  I'm doing:\\n\\n>>> from project.model.user import *\\n>>> reload(user)\\n\\n\\nbut I receive:\\n\\n>>>NameError: name 'user' is not defined\\n\\n\\nWhat is the proper way to reload the entire user class?  Is there a better way to do this, perhaps auto-updating while debugging?\\n\\nThanks.\\n\",\n  'completion': \"As asked, the best you can do is\\n\\n>>> from project.models.user import *\\n>>> import project # get module reference for reload\\n>>> reload(project.models.user) # reload step 1\\n>>> from project.models.user import * # reload step 2\\n\\n\\nit would be better and cleaner if you used the user module directly, rather than doing import * (which is almost never the right way to do it). Then it would just be\\n\\n>>> from project.models import user\\n>>> reload(user)\\n\\n\\nThis would do what you want. But, it's not very nice. If you really need to reload modules so often, I've got to ask: why?\\n\\nMy suspicion (backed up by previous experience with people asking similar questions) is that you're testing your module. There are lots of ways to test a module out, and doing it by hand in the interactive interpreter is among the worst ways. Save one of your sessions to a file and use doctest, for a quick fix. Alternatively, write it out as a program and use python -i. The only really great solution, though, is using the unittest module.\\n\\nIf that's not it, hopefully it's something better, not worse. There's really no good use of reload (in fact, it's removed in 3.x). It doesn't work effectively-- you might reload a module but leave leftovers from previous versions. It doesn't even work on all kinds of modules-- extension modules will not reload properly, or sometimes even break horribly, when reloaded.\\n\\nThe context of using it in the interactive interpreter doesn't leave a lot of choices as to what you are doing, and what the real best solution would be. Outside it, sometimes people used reload() to implement plugins etc. This is dangerous at best, and can frequently be done differently using either exec (ah the evil territory we find ourselves in), or a segregated process.\\n\"},\n {'prompt': \"What is the difference between ',' and 'as' in except statements, eg:\\n\\ntry:\\n    pass\\nexcept Exception, exception:\\n    pass\\n\\n\\nand:\\n\\ntry:\\n    pass\\nexcept Exception as exception:\\n    pass\\n\\n\\nIs the second syntax legal in 2.6?  It works in CPython 2.6 on Windows but the 2.5 interpreter in cygwin complains that it is invalid.\\n\\nIf they are both valid in 2.6 which should I use?\\n\",\n  'completion': \"The definitive document is PEP-3110: Catching Exceptions\\n\\nSummary:\\n\\n\\nIn Python 3.x, using as is required.\\nIn Python 2.6+, use the as syntax, since it is far less ambiguous and forward compatible with Python 3.x.\\nIn Python 2.5 and earlier, use the comma version, since as isn't supported.\\n\\n\"},\n {'prompt': \"In Python under Linux, what is the easiest way to check the existence of a user, given his/her login?\\n\\nAnything better than issuing 'ls ~login-name' and checking the exit code?\\n\\nAnd if running under Windows?\\n\",\n  'completion': \"This answer builds upon the answer by Brian. It adds the necessary try...except block.\\n\\nCheck if a user exists:\\n\\nimport pwd\\n\\ntry:\\n    pwd.getpwnam('someusr')\\nexcept KeyError:\\n    print('User someusr does not exist.')\\n\\n\\nCheck if a group exists:\\n\\nimport grp\\n\\ntry:\\n    grp.getgrnam('somegrp')\\nexcept KeyError:\\n    print('Group somegrp does not exist.') \\n\\n\"},\n {'prompt': 'I am trying to get a list of elements with a specific xsd type with lxml 2.x and I can\\'t figure out how to traverse the xsd for specific types.\\n\\nExample of schema:\\n\\n<xsd:element name=\"ServerOwner\" type=\"srvrs:string90\" minOccurs=\"0\">\\n<xsd:element name=\"HostName\" type=\"srvrs:string35\" minOccurs=\"0\">\\n\\n\\nExample xml data:\\n\\n<srvrs:ServerOwner>John Doe</srvrs:ServerOwner>\\n<srvrs:HostName>box01.example.com</srvrs:HostName>\\n\\n\\nThe ideal function would look like:\\n\\n    elements = getElems(xml_doc, \\'string90\\')\\n\\n    def getElems(xml_doc, xsd_type):\\n      ** xpath or something to find the elements and build a dict\\n      return elements\\n\\n',\n  'completion': 'Really the only special support lxml has for XML Schema, as seen here, is to tell you if some document is valid according to some schema or not. Anything more sophisticated you\\'ll have to do yourself.\\n\\nThis should be a relatively simple two-phase process, I\\'d think -- get all the xsd:element elements in the schema that match the type you care about, and look at their names:\\n\\ndef getElems(schemaDoc, xmlDoc, typeName):\\n    names = schemaDoc.xpath(\"//xsd:element[@type = $n]/@name\",\\n                            namespaces={\"xsd\": \\n                                        \"http://www.w3.org/2001/XMLSchema\"},\\n                            n=typeName)\\n\\n\\nThen, fetch all the elements with each name from the document.\\n\\n    elements = []\\n    for name in names: \\n        namedElements = xmlDoc.xpath(\"//*[local-name() = $name]\", name=name)\\n        elements.extend(namedElements)\\n\\n\\nNow you have a list of elements with the names that matched the type in the schema.\\n\\n    return elements\\n\\n\\nNote that the xpath expression for searching the document has to look at every element, so if you can tighten that up to only look in the subsection of the document you care about it\\'ll go faster.\\n'},\n {'prompt': \"When using python-daemon, I'm creating subprocesses likeso:\\n\\nimport multiprocessing\\n\\nclass Worker(multiprocessing.Process):\\n   def __init__(self, queue):\\n      self.queue = queue # we wait for things from this in Worker.run()\\n\\n   ...\\n\\nq = multiprocessing.Queue()\\n\\nwith daemon.DaemonContext():\\n    for i in xrange(3):\\n       Worker(q)\\n\\n    while True: # let the Workers do their thing\\n       q.put(_something_we_wait_for())\\n\\n\\nWhen I kill the parent daemonic process (i.e. not a Worker) with a Ctrl-C or SIGTERM, etc., the children don't die. How does one kill the kids?\\n\\nMy first thought is to use atexit to kill all the workers, likeso:\\n\\n with daemon.DaemonContext():\\n    workers = list()\\n    for i in xrange(3):\\n       workers.append(Worker(q))\\n\\n    @atexit.register\\n    def kill_the_children():\\n        for w in workers:\\n            w.terminate()\\n\\n    while True: # let the Workers do their thing\\n       q.put(_something_we_wait_for())\\n\\n\\nHowever, the children of daemons are tricky things to handle, and I'd be obliged for thoughts and input on how this ought to be done.\\n\\nThank you.\\n\",\n  'completion': \"Your options are a bit limited. If doing self.daemon = True in the constructor for the Worker class does not solve your problem and trying to catch signals in the Parent (ie, SIGTERM, SIGINT) doesn't work, you may have to try the opposite solution - instead of having the parent kill the children, you can have the children commit suicide when the parent dies.\\n\\nThe first step is to give the constructor to Worker the PID of the parent process (you can do this with os.getpid()). Then, instead of just doing self.queue.get() in the worker loop, do something like this:\\n\\nwaiting = True\\nwhile waiting:\\n    # see if Parent is at home\\n    if os.getppid() != self.parentPID:\\n        # woe is me! My Parent has died!\\n        sys.exit() # or whatever you want to do to quit the Worker process\\n    try:\\n        # I picked the timeout randomly; use what works\\n        data = self.queue.get(block=False, timeout=0.1)\\n        waiting = False\\n    except queue.Queue.Empty:\\n        continue # try again\\n# now do stuff with data\\n\\n\\nThe solution above checks to see if the parent PID is different than what it originally was (that is, if the child process was adopted by init or lauchd because the parent died) - see reference. However, if that doesn't work for some reason you can replace it with the following function (adapted from here):\\n\\ndef parentIsAlive(self):\\n    try:\\n        # try to call Parent\\n        os.kill(self.parentPID, 0)\\n    except OSError:\\n        # *beeep* oh no! The phone's disconnected!\\n        return False\\n    else:\\n        # *ring* Hi mom!\\n        return True\\n\\n\\nNow, when the Parent dies (for whatever reason), the child Workers will spontaneously drop like flies - just as you wanted, you daemon! :-D\\n\"},\n {'prompt': 'Something like:\\n\\nfor (a,b) in kwargs.iteritems():\\n    if not b : del kwargs[a]\\n\\n\\nThis code raise exception because changing of dictionary when iterating.\\n\\nI discover only non pretty solution with another dictionary:\\n\\nres ={}\\nres.update((a,b) for a,b in kwargs.iteritems() if b is not None)\\n\\n\\nThanks\\n',\n  'completion': 'Another way to write it is\\n\\nres = dict((k,v) for k,v in kwargs.iteritems() if v is not None)\\n\\n\\nIn Python3, this becomes\\n\\nres = {k:v for k,v in kwargs.items() if v is not None}\\n\\n'},\n {'prompt': 'Recently i have developed a billing application for my company with Python/Django. For few months everything was fine but now i am observing that the performance is dropping because of more and more users using that applications. Now the problem is that the application is now very critical for the finance team. Now the finance team are after my life for sorting out the performance issue. I have no other option but to find a way to increase the performance of the billing application. \\n\\nSo do you guys know any performance optimization techniques in python that will really help me   with the scalability issue\\n\\nGuys we are using mysql database and its hosted on apache web server on Linux box. Secondly what i have noticed more is the over all application is slow and not the database transactional part. For example once the application is loaded then it works fine but if they navigate to other link on that application then it takes a whole lot of time.\\n\\nAnd yes we are using HTML, CSS and Javascript\\n',\n  'completion': \"As I said in comment, you must start by finding what part of your code is slow.\\n\\nNobody can help you without this information.\\n\\nYou can profile your code with the Python profilers then go back to us with the result.\\n\\nIf it's a Web app, the first suspect is generally the database. If it's a calculus intensive GUI app, then look first at the calculations algo first.\\n\\nBut remember that perf issues car be highly unintuitive and therefor, an objective assessment is the only way to go.\\n\"},\n {'prompt': 'How can one create animated diagrams using popular matplotlib library? I am particularly interested in animated gifs.\\n',\n  'completion': 'The matplotlib docs provide an entire section of examples on animation (see this scipy tutorial also).  Most, however, involve using the various GUI widget backends.  There is one in there, \"movie demo\", that shows how to produce an avi of a series of PNGS.  \\n\\nTo produce animated GIFs, I think your options are pretty limited.  Last I checked, PIL didn\\'t support them.  You could however generate a series of PNGs using pyplot\\'s savefig and then stitch them together using a call to ImageMagick or mencoder.\\n'},\n {'prompt': \"Ok, so I've read both PEP 8 and PEP 257, and I've written lots of docstrings for functions and classes, but I'm a little unsure about what should go in a module docstring.  I figured, at a minimum, it should document the functions and classes that the module exports, but I've also seen a few modules that list author names, copyright information, etc.  Does anyone have an example of how a good python docstring should be structured?\\n\",\n  'completion': 'Think about somebody doing help(yourmodule) at the interactive interpreter\\'s prompt -- what do they want to know?  (Other methods of extracting and displaying the information are roughly equivalent to help in terms of amount of information).  So if you have in x.py:\\n\\n\"\"\"This module does blah blah.\"\"\"\\n\\nclass Blah(object):\\n  \"\"\"This class does blah blah.\"\"\"\\n\\n\\nthen:\\n\\n>>> import x; help(x)\\n\\n\\nshows:\\n\\nHelp on module x:\\n\\nNAME\\n    x - This module does blah blah.\\n\\nFILE\\n    /tmp/x.py\\n\\nCLASSES\\n    __builtin__.object\\n        Blah\\n\\n    class Blah(__builtin__.object)\\n     |  This class does blah blah.\\n     |  \\n     |  Data and other attributes defined here:\\n     |  \\n     |  __dict__ = <dictproxy object>\\n     |      dictionary for instance variables (if defined)\\n     |  \\n     |  __weakref__ = <attribute \\'__weakref__\\' of \\'Blah\\' objects>\\n     |      list of weak references to the object (if defined)\\n\\n\\nAs you see, the detailed information on the classes (and functions too, though I\\'m not showing one here) is already included from those components\\' docstrings; the module\\'s own docstring should describe them very summarily (if at all) and rather concentrate on a concise summary of what the module as a whole can do for you, ideally with some doctested examples (just like functions and classes ideally should have doctested examples in theit docstrings).\\n\\nI don\\'t see how metadata such as author name and copyright / license helps the module\\'s user -- it can rather go in comments, since it could help somebody considering whether or not to reuse or modify the module.\\n'},\n {'prompt': \"Google's heavy usage of Python, is it just a matter of taste or does it give them a competitive advantage?\\n\",\n  'completion': 'I can\\'t really give a definitive answer, because by the time I interviewed at Google in 2004 Python was already prominent at Google.\\n\\nIndeed, there\\'s one apparently attractive explanation that I can definitely deny: it\\'s not that Google uses Python because it employs so many prominent Pythonistas -- rather, most \"prominent Pythonista\" googlers joined Google, at least in part, because we knew about Python\\'s prominence there (possible exceptions include Peter Norvig and Jeremy Hylton, but historically Google\\'s choice of Python predated even them).\\n\\nThat\\'s definitely why I first got interested (my publisher let me know about the large amount of copies of my book that Google was purchasing -- at first, I thought of it as a good opportunity to sell my freelance consulting service...;-), how I was later able to convince Guido to join us, and, I believe, part of the motivation for such Pythonistas as Greg Stein, Wesley Chun, Fredrik Lundh, Thomas Wouters, Collin Winters, Jeffrey Yasskin, ...\\n\\nIt all got started, I believe, because the very earliest Googlers (Sergey, Larry, Craig, ...) made a good engineering decision: \"Python where we can, C++ where we must\" -- they used (a subset of) C++ for the parts of the software stack where very low latency and/or tight control of memory were crucial, and Python, allowing more rapid delivery and maintenance of programs, for other parts.  At the time, late \\'90s, the choice for the latter role was essentially between Python and Perl: other scripting languages were either unripe (I don\\'t think Ruby was around yet, for example) or had other issues and limitations.  Perl was more mature (especially in terms of its ecosystem of available add-ons via CPAN), but Python was deemed to be more readable and maintainable, and interfacing to C++ libraries (via SWIG) was easier.\\n\\nJava came in later, covering an intermediate niche -- and more recently of course Go was developed (though I don\\'t believe there\\'s much production work in it yet, as it\\'s still evolving and maturing).  Some specialized languages such as sawzall are also in the mix for very specific tasks, and of course Javascript is very important for browser-side work.\\n\\nOther languages, including the ones that Greg mentioned back in \\'06, are either \"kind of accidental\" or used for other specific tasks (e.g., Objective C for clients on iPhones or Macs) -- e.g., when Google hired its first system administrators, those employees inevitably came with very strong mastery of Perl and Bash, and often used either of those languages to develop some complex internal system; recoding those in Python (for easier deployment and maintainability) has often happened.  Others (such as C#) may have been in the mix temporarily due to acquisitions, but, again, recoding in one of the \"main Google languages\" is always a pretty high priority (in C#\\'s case, recoding would typically be mostly in Java, as the two languages address similar areas in terms of levels of abstraction).\\n'},\n {'prompt': 'I have a problem with open files under my Ubuntu 9.10 when running server in Python2.6\\nAnd main problem is that, that i don\\'t know why it so.. \\n\\nI have set \\n\\nulimit -n = 999999\\n\\nnet.core.somaxconn = 999999\\n\\nfs.file-max = 999999\\n\\nand lsof gives me about 12000 open files when server is running.\\n\\nAnd also i\\'m using epoll.\\n\\nBut after some time it\\'s start giving exeption:\\n\\nFile \"/usr/lib/python2.6/socket.py\", line 195, in accept\\nerror: [Errno 24] Too many open files\\n\\nAnd i don\\'t know how it can reach file limit when it isn\\'t reached.\\n\\nThanks for help)\\n',\n  'completion': 'Params that configure max open connections.\\n\\nat /etc/sysctl.conf\\n\\nadd:\\n\\nnet.core.somaxconn=131072\\nfs.file-max=131072\\n\\n\\nand then: \\n\\nsudo sysctl -p\\n\\n\\nat /usr/include/linux/limits.h \\n\\nchange:\\n\\nNR_OPEN = 65536\\n\\n\\nat /etc/security/limits.conf\\n\\nadd:\\n\\n*                soft    nofile          65535\\n*                hard    nofile          65535\\n\\n'},\n {'prompt': \"I'm a bit at a loss as to how to find a clean algorithm for doing the following:\\n\\nSuppose I have a dict k:\\n\\n>>> k = {'A': 68, 'B': 62, 'C': 47, 'D': 16, 'E': 81}\\n\\n\\nI now want to randomly select one of these keys, based on the 'weight' they have in the total (i.e. sum) amount of keys. \\n\\n>>> sum(k.values()) \\n>>> 274\\n\\n\\nSo that there's a \\n\\n>>> 68.0/274.0\\n>>> 0.24817518248175183\\n\\n\\n24.81% percent change that A is selected.\\n\\nHow would you write an algorithm that takes care of this? In other words, that makes sure that on 10.000 random picks, A will be selected 2.481 times?\\n\",\n  'completion': \"This should do the trick:\\n\\n>>> k = {'A': 68, 'B': 62, 'C': 47, 'D': 16, 'E': 81}\\n>>> import random\\n>>> def weighted_pick(dic):\\n...     total = sum(dic.itervalues())\\n...     pick = random.randint(0, total-1)\\n...     tmp = 0\\n...     for key, weight in dic.iteritems():\\n...         tmp += weight\\n...         if pick < tmp:\\n...             return key\\n\\n\"},\n {'prompt': 'I have a list containing version strings, such as things:\\n\\nversions_list = [\"1.1.2\", \"1.0.0\", \"1.3.3\", \"1.0.12\", \"1.0.2\"]\\n\\n\\nI would like to sort it, so the result would be something like this:\\n\\nversions_list = [\"1.0.0\", \"1.0.2\", \"1.0.12\", \"1.1.2\", \"1.3.3\"]\\n\\n\\nThe order of precendece for the digits should obviously be from left to right, and it should be descending. So 1.2.3 comes before 2.2.3 and 2.2.2 comes before 2.2.3.\\n\\nHow do I do this in Python?\\n',\n  'completion': 'You can also use distutils.version module of standard library:\\n\\nfrom distutils.version import StrictVersion\\nversions = [\"1.1.2\", \"1.0.0\", \"1.3.3\", \"1.0.12\", \"1.0.2\"]\\nversions.sort(key=StrictVersion)\\n\\n\\nGives you:\\n\\n[\\'1.0.0\\', \\'1.0.2\\', \\'1.0.12\\', \\'1.1.2\\', \\'1.3.3\\']\\n\\n\\nIt can also handle versions with pre-release tags, for example:\\n\\nversions = [\"1.1\", \"1.1b1\", \"1.1a1\"]\\nversions.sort(key=StrictVersion)\\n\\n\\nGives you:\\n\\n[\"1.1a1\", \"1.1b1\", \"1.1\"]\\n\\n'},\n {'prompt': 'How can I look up a hostname given an IP address?  Furthermore, how can I specify a timeout in case no such reverse DNS entry exists?  Trying to keep things as fast as possible.  Or is there a better way?  Thank you!\\n',\n  'completion': '>>> import socket\\n>>> socket.gethostbyaddr(\"69.59.196.211\")\\n(\\'stackoverflow.com\\', [\\'211.196.59.69.in-addr.arpa\\'], [\\'69.59.196.211\\'])\\n\\n\\nFor implementing the timeout on the function, this stackoverflow thread has answers on that.\\n'},\n {'prompt': 'I have to develop a site which has to accomodate around 2000 users a day and speed is a criterion for it. Moreover, the site is a user oriented one where the user will be able to log in and check his profile, register for specific events he/she wants to participate in. The site is to be hosted on a VPS server.Although I have pretty good experience with python and PHP but I have no idea how to use either of the framework. We have plenty of time to experiment and learn one of the above frameworks.Could you please specify which one would be preferred for such a scenario considering speed, features, and security of the site. \\n\\nThanks,\\nniting\\n',\n  'completion': \"This is a very subjective question but personally I'd recommend Django. Python is a very nice language to use and the Django framework is small, easy to use, well documented and also has a pretty active community.\\n\\nThis choice was made partly because of my dislike for PHP though, so take the recommendation with a pinch of salt.\\n\"},\n {'prompt': 'I need to convert a zope 2 DateTime object into a Python datetime object. What is the best way to do that? Thanks, Erika\\n',\n  'completion': 'Newer DateTime implementations (2.11 and up) have a asdatetime method that returns a python datetime.datetime instance:\\n\\nmodernthingy = zopethingy.asdatetime()\\n\\n'},\n {'prompt': 'Using get/set seems to be a common practice in Java (for various reasons), but I hardly see Python code that uses this.\\n\\nWhy do you use or avoid get/set methods in Python?\\n',\n  'completion': 'In python, you can just access the attribute directly because it is public:\\n\\nclass MyClass(object):\\n\\n    def __init__(self):\\n        self.my_attribute = 0  \\n\\nmy_object = MyClass()\\nmy_object.my_attribute = 1 # etc.\\n\\n\\nIf you want to do something on access or mutation of the attribute, you can use properties:\\n\\nclass MyClass(object):\\n\\n    def __init__(self):\\n        self._my_attribute = 0\\n\\n    @property\\n    def my_attribute(self):\\n        # Do something if you want\\n        return self._my_attribute\\n\\n    @my_attribute.setter\\n    def my_attribute(self, value):\\n        # Do something if you want\\n        self._my_attribute = value\\n\\n\\nCrucially, the client code remains the same.    \\n'},\n {'prompt': 'I am attempting to have mechanize select a form from a page, but the form in question has no \"name\" attribute in the html. What should I do? when I try to use\\n\\nbr.select_form(name = \"\")\\n\\n\\nI get errors that no form is declared with that name, and the function requires a name input. There is only one form on the page, is there some other way I can select that form?\\n',\n  'completion': 'Try:\\n\\nbr.select_form(nr=0)\\n\\n\\nto select the first form\\n\\nIn Mechanize source,\\n\\ndef select_form(self, name=None, predicate=None, <b>nr=None</b>):\\n    \"\"\"\\n    ...\\n    nr, if supplied, is the sequence number of the form (where 0 is the\\n    first).\\n    \"\"\"\\n\\n'},\n {'prompt': \"I need to dynamically create class attributes from a DEFAULTS dictionary.\\n\\ndefaults = {\\n    'default_value1':True,\\n    'default_value2':True,\\n    'default_value3':True,\\n}\\n\\nclass Settings(object):\\n    default_value1 = some_complex_init_function(defaults[default_value1], ...)\\n    default_value2 = some_complex_init_function(defaults[default_value2], ...)\\n    default_value3 = some_complex_init_function(defaults[default_value3], ...)\\n\\n\\nI could also achive this by having sth. like __init__ for class creation, in order to dynamically create these attributes from dictionary and save a lot of code and stupid work.\\n\\nHow would you do this?\\n\\nThank you very much in advance!\\n\",\n  'completion': 'You could do it without metaclasses using decorators. This way is a bit more clear IMO:\\n\\ndef apply_defaults(cls):\\n    defaults = {\\n        \\'default_value1\\':True,\\n        \\'default_value2\\':True,\\n        \\'default_value3\\':True,\\n    }\\n    for name, value in defaults.items():\\n        setattr(cls, name, some_complex_init_function(value, ...))\\n    return cls\\n\\n@apply_defaults\\nclass Settings(object):\\n    pass\\n\\n\\nPrior to Python 2.6 class decorators were unavailable. So you can write:\\n\\nclass Settings(object):\\n    pass\\nSettings = apply_defaults(Settings)\\n\\n\\nin older versions of python.\\n\\nIn the provided example apply_defaults is reusableâ\\x80¦ Well, except that the defaults are hard-coded in the decorator\\'s body :) If you have just a single case you can even simplify your code to this:\\n\\ndefaults = {\\n    \\'default_value1\\':True,\\n    \\'default_value2\\':True,\\n    \\'default_value3\\':True,\\n}\\n\\nclass Settings(object):\\n    \"\"\"Your implementation goes here as usual\"\"\"\\n\\nfor name, value in defaults.items():\\n    setattr(Settings, name, some_complex_init_function(value, ...))\\n\\n\\nThis is possible since classes (in the sense of types) are objects themselves in Python.\\n'},\n {'prompt': 'I\\'m wondering how to remove a dynamic word from a string within Python.\\n\\nIt will always have a \":\" at the end of the word, and sometimes there\\'s more than one within the string. I\\'d like to remove all occurrences of \"word:\".\\n\\nThanks! :-)\\n',\n  'completion': 'Use regular expressions.\\n\\nimport re\\nblah = \"word word: monty py: thon\"\\nanswer = re.sub(r\\'\\\\w+:\\\\s?\\',\\'\\',blah)\\nprint answer\\n\\n\\nThis will also pull out a single optional space after the colon.\\n'},\n {'prompt': \"In Python, I'd like to be able to create a function that behaves both as a class function and an instance method, but with the ability to change behaviors. The use case for this is for a set of serializable objects and types. As an example:\\n\\n>>> class Thing(object):\\n    #...\\n>>> Thing.to_json()\\n'A'\\n>>> Thing().to_json()\\n'B'\\n\\n\\nI know that given the definition of classmethod() in funcobject.c in the Python source, this looks like it'd be simple with a C module. Is there a way to do this from within python?\\n\\nThanks!\\n\\nWith the hint of descriptors, I was able to do it with the following code:\\n\\nclass combomethod(object):\\n    def __init__(self, method):\\n        self.method = method\\n\\n    def __get__(self, obj=None, objtype=None):\\n        @functools.wraps(self.method)\\n        def _wrapper(*args, **kwargs):\\n            if obj is not None:\\n                return self.method(obj, *args, **kwargs)\\n            else:\\n                return self.method(objtype, *args, **kwargs)\\n        return _wrapper\\n\\n\\nThank you Alex!\\n\",\n  'completion': \"Sure, you just need to define your own descriptor type.  There's an excellent tutorial on Python descriptors here.\\n\"},\n {'prompt': \"I've written a small console application that can perform certain tasks. The user interface is similar to things like version control systems or yum etc. So basically you can think of it as a domain specific language. Now I'd like to write a (bash like) shell that can execute and auto-complete this language and has a command history (so I do not have to load and save the quite large xml files on each command). In a nutshell I want something like ipython but not for executing python code but my own DSL.\\n\\nAre there any libraries that help me doing this? I see that there is a readline and rlcompleter module in python but its documentation seems to indicate that this is only for use with the python shell itself, or did I miss something there?\\n\",\n  'completion': 'You should check out the cmd and cmd2 modules. I think they will do what you want. There was a PyCon talk about these.\\n'},\n {'prompt': 'I am having some trouble with a very basic string issue in Python (that I can\\'t figure out). Basically, I am trying to do  the following:\\n\\n\\'# read file into a string \\nmyString =  file.read()\\n\\n\\'# Attempt to remove non breaking spaces \\nmyString = myString.replace(\"\\\\u00A0\",\" \")\\n\\n\\'# however, when I print my string to output to console, I get: \\nFoo **<C2><A0>** Bar\\n\\n\\nI thought that the \"\\\\u00A0\" was the escape code for unicode non breaking spaces, but apparently I am not doing this properly. Any ideas on what I am doing wrong?\\n',\n  'completion': 'You don\\'t have a unicode string, but a UTF-8 list of bytes (which are what strings are in Python 2.x).\\n\\nTry\\n\\nmyString = myString.replace(\"\\\\xc2\\\\xa0\", \" \")\\n\\n\\nBetter would be two switch to unicode -- see this article for ideas.  Thus you could say\\n\\nuniString = unicode(myString, \"UTF-8\")\\nuniString = uniString.replace(u\"\\\\u00A0\", \" \")\\n\\n\\nand it should also work (caveat: I don\\'t have Python 2.x available right now), although you will need to translate it back to bytes (binary) when sending it to a file or printing it to a screen.\\n'},\n {'prompt': 'I\\'m trying to create a custom object that behaves properly in set operations.\\n\\nI\\'ve generally got it working, but I want to make sure I fully understand the implications. In particular, I\\'m interested in the behavior when there is additional data in the object that is not included in the equal / hash methods. It seems that in the \\'intersection\\' operation, it returns the set of objects that are being compared to, where the \\'union\\' operations returns the set of objects that are being compared.\\n\\nTo illustrate:\\n\\nclass MyObject:\\n    def __init__(self,value,meta):\\n        self.value = value\\n        self.meta = meta\\n    def __eq__(self,other):\\n        return self.value == other.value\\n    def __hash__(self):\\n        return hash(self.value)\\n\\na = MyObject(\\'1\\',\\'left\\')\\nb = MyObject(\\'1\\',\\'right\\')\\nc = MyObject(\\'2\\',\\'left\\')\\nd = MyObject(\\'2\\',\\'right\\')\\ne = MyObject(\\'3\\',\\'left\\')\\nprint a == b # True\\nprint a == c # False\\n\\nfor i in set([a,c,e]).intersection(set([b,d])):\\n    print \"%s %s\" % (i.value,i.meta)\\n#returns:\\n#1 right\\n#2 right\\n\\n for i in set([a,c,e]).union(set([b,d])):\\n    print \"%s %s\" % (i.value,i.meta)\\n#returns:\\n#1 left\\n#3 left\\n#2 left\\n\\n\\nIs this behavior documented somewhere and deterministic? If so, what is the governing principle?\\n',\n  'completion': 'Nope, it\\'s not deterministic. The problem is that you\\'ve broken equals\\' and hash\\'s invariant, that two objects are equivalent when they are equal. Fix your object, don\\'t try to be clever and abuse how set\\'s implementation works. If the meta value is part of MyObject\\'s identity, it should be included in eq and hash.\\n\\nYou can\\'t rely on set\\'s intersection to follow any order, so there is no way to easily do what you want. What you would end up doing is taking the intersection by value only, then look through all your objects for an older one to replace it with, for each one. No nice way to do it algorithmically.\\n\\nUnions are not so bad:\\n\\n##fix the eq and hash to work correctly\\nclass MyObject:\\n    def __init__(self,value,meta):\\n        self.value = value\\n        self.meta = meta\\n    def __eq__(self,other):\\n        return self.value, self.meta == other.value, other.meta\\n    def __hash__(self):\\n        return hash((self.value, self.meta))\\n    def __repr__(self):\\n        return \"%s %s\" % (self.value,self.meta)\\n\\na = MyObject(\\'1\\',\\'left\\')\\nb = MyObject(\\'1\\',\\'right\\')\\nc = MyObject(\\'2\\',\\'left\\')\\nd = MyObject(\\'2\\',\\'right\\')\\ne = MyObject(\\'3\\',\\'left\\')\\n\\nunion =  set([a,c,e]).union(set([b,d]))\\nprint union\\n#set([2 left, 2 right, 1 left, 3 left, 1 right])\\n\\n##sort the objects, so that older objs come before the newer equivalents\\nsl = sorted(union, key= lambda x: (x.value, x.meta) )\\nprint sl\\n#[1 left, 1 right, 2 left, 2 right, 3 left]\\nimport itertools\\n##group the objects by value, groupby needs the objs to be in order to do this\\nfiltered = itertools.groupby(sl, lambda x: x.value)\\n##make a list of the oldest (first in group)\\noldest = [ next(group) for key, group in filtered]\\nprint oldest\\n#[1 left, 2 left, 3 left]\\n\\n'},\n {'prompt': 'Thanks to some great folks on SO, I discovered the possibilities offered by collections.defaultdict, notably in readability and speed. I have put them to use with success.\\n\\nNow I would like to implement three levels of dictionaries, the two top ones being defaultdict and the lowest one being int. I don\\'t find the appropriate way to do this. Here is my attempt:\\n\\nfrom collections import defaultdict\\nd = defaultdict(defaultdict)\\na = [(\"key1\", {\"a1\":22, \"a2\":33}),\\n     (\"key2\", {\"a1\":32, \"a2\":55}),\\n     (\"key3\", {\"a1\":43, \"a2\":44})]\\nfor i in a:\\n    d[i[0]] = i[1]\\n\\n\\nNow this works, but the following, which is the desired behavior, doesn\\'t:\\n\\nd[\"key4\"][\"a1\"] + 1\\n\\n\\nI suspect that I should have declared somewhere that the second level defaultdict is of type int, but I didn\\'t find where or how to do so.\\n\\nThe reason I am using defaultdict in the first place is to avoid having to initialize the dictionary for each new key.\\n\\nAny more elegant suggestion?\\n\\nThanks pythoneers!\\n',\n  'completion': 'Use:\\n\\nd = defaultdict(lambda: defaultdict(int))\\n\\n\\nThis will create a new defaultdict(int) whenever a new key is accessed in d.\\n'},\n {'prompt': 'I am trying to extract Meta Description for fetched webpages. But here I am facing the problem of case sensitivity of BeautifulSoup. \\n\\nAs some of the pages have <meta name=\"Description and some have <meta name=\"description. \\n\\nMy problem is very much similar to that of Question on Stackoverflow\\n\\nThe only difference is that I can\\'t use lxml .. I have to stick with Beautifulsoup. \\n',\n  'completion': 'You can give BeautifulSoup a regular expression to match attributes against.  Something like\\n\\nsoup.findAll(\\'meta\\', name=re.compile(\"^description$\", re.I))\\n\\n\\nmight do the trick.  Cribbed from the BeautifulSoup docs.\\n'},\n {'prompt': 'Looking in my /usr/local/lib/python.../dist-package directory, I have .egg directories and .egg files. \\n\\nWhy does the installer choose to extra packages to the .egg directory, yet leave other files with .egg extensions? \\n',\n  'completion': \"If the package contains only pure-Python code, it can stay as just an egg file.  The Python interpreter can load the Python modules directly from the egg.  If the package contains modules written in C or other data, then egg needs to be extracted so the C modules and/or data can be accessed.  That's the default behavior of packages, I believe.  Newer versions of Python might be able to load C modules from egg files; I'm not sure about that part.\\n\\nThe creator of the package can also specifically instruct the installer to unzip the package, by passing zip_safe = False to setup() in their setup.py.\\n\\nFinally, the person doing the installing can tell easy_install explicitly to unpack eggs by passing it the -Z option or by setting zip_ok = false in the pydistutils.cfg.\\n\"},\n {'prompt': \"I can't find a correct way to get the environment variable for the appdata path in python.\\n\\nThe problem is that my user name includes special characters (the german ae and ue).\\nI made a workaround wit PyQt for Vista and Windows 7 but it doesn't work for XP Systems.\\n\\nDoes anybody know the correct encoding of these environment variables or another solution for this problem?\\n\",\n  'completion': \"As Mike says, you can get the system codepage from getfilesystemencoding. This encoding is used to convert Windows's native Unicode strings into bytes for all C stdio functions used by Python, including the filesystem calls that use byte string filepaths, and os.environ.\\n\\nWhat this means is that you will be able to read a string with non-ASCII characters from os.environ and use it directly as a filepath without any special encode/decode step.\\n\\nUnfortunately, if the %APPDATA% variable contains Unicode characters that are not present in the system codepageâ\\x80\\x89â\\x80\\x94â\\x80\\x89for example, if on a German (cp1252) Windows install, your path was C:\\\\Documents and Settings\\\\Î±Î²Î³\\\\Application Dataâ\\x80\\x89â\\x80\\x94â\\x80\\x89then those characters will have already been mangled before you get the chance to use them. Decoding the byte string you get to Unicode using the filesystemencoding won't help in that case.\\n\\nHere's a function you can use on recent Python versions that have the ctypes extension, to read Windows native Unicode environment variables.\\n\\ndef getEnvironmentVariable(name):\\n    name= unicode(name) # make sure string argument is unicode\\n    n= ctypes.windll.kernel32.GetEnvironmentVariableW(name, None, 0)\\n    if n==0:\\n        return None\\n    buf= ctypes.create_unicode_buffer(u'\\\\0'*n)\\n    ctypes.windll.kernel32.GetEnvironmentVariableW(name, buf, n)\\n    return buf.value\\n\\n\\nIn Python 3, the os.environ dictionary contains Unicode strings taken directly from Windows with no codepage encoding, so you don't have to worry about this problem there.\\n\"},\n {'prompt': \"I want to create an application that runs on the users computer, a stand-alone application, with installation and what-not, but I want the interface to be a browser, either internal and displayed as an OS window or external accessible using the browser (i.e. some http server).\\n\\nThe reason would be because I know a little about Python, but I think I can manage as long as I have some basic roots that I can use and manipulate, and those would be HTML, CSS, and Javascript.\\n\\nI've yet to find a good GUI tool which I can use, and always abandon the idea after trying to mess around and eventually not getting anything.\\n\",\n  'completion': \"Python offers two things that should be of your interest:\\n\\n\\na web server in the standard library\\na standartized interface for web applications, called WSGI\\n\\n\\nSo it is relatively easy to add a web interface to your application. For example in Mercurial (the versioning system), you have a command hg serve that launches a web server.\\n\\nTo see python launching a web server, and a WSGI app, just do:\\n\\npython -m 'wsgiref.simple_server'\\n\\n\\nYou can look at the wsgiref source code or some WSGI tutorial to do a simple app.\\n\\nAfter that, you may want to use a web framework (for templating & co), but that is another question...\\n\"},\n {'prompt': 'How do you set/get the values of attributes of t given by x. \\n\\nclass test():\\n   attr1 = int\\n   attr2 = int\\n\\nt = test()\\nx = \"attr1\"\\n\\n',\n  'completion': 'There is built-in functions called getattr and setattr\\n\\ngetattr(object, attrname)\\nsetattr(object, attrname, value)\\n\\n\\nIn this case \\n\\nx = getattr(t, \"attr1\")\\nsetattr(t, \\'attr1\\', 21)\\n\\n'},\n {'prompt': 'I would like to perform a bitwise exclusive or of two strings in python, but xor of strings are not allowed in python. How can I do it ?\\n',\n  'completion': \"You can convert the characters to integers and xor those instead:\\n\\nl = [ord(a) ^ ord(b) for a,b in zip(s1,s2)]\\n\\n\\nHere's an updated function in case you need a string as a result of the XOR:\\n\\ndef sxor(s1,s2):    \\n    # convert strings to a list of character pair tuples\\n    # go through each tuple, converting them to ASCII code (ord)\\n    # perform exclusive or on the ASCII code\\n    # then convert the result back to ASCII (chr)\\n    # merge the resulting array of characters as a string\\n    return ''.join(chr(ord(a) ^ ord(b)) for a,b in zip(s1,s2))\\n\\n\\nSee it working online: ideone\\n\"},\n {'prompt': \"I created a little web spider in Python which I'm using to collect URLs. I'm not interested in the content. Right now I'm keeping all the visited URLs in a set in memory, because I don't want my spider to visit URLs twice. Of course that's a very limited way of accomplishing this.\\n\\nSo what's the best way to keep track of my visited URLs? \\n\\nShould I use a database?\\n\\n\\nwhich one? MySQL, SQLite, PostgreSQL? \\nhow should I save the URLs? As a primary key trying to insert every URL before visiting it?\\n\\n\\nOr should I write them to a file?\\n\\n\\none file?\\nmultiple files? how should I design the file-structure?\\n\\n\\nI'm sure there are books and a lot of papers on this or similar topics. Can you give me some advice what I should read?\\n\",\n  'completion': \"I've written a lot of spiders. To me, a bigger problem than running out of memory is the potential of losing all the URLs you've spidered already if the code or machine crashes or you decide you need to tweak the code. If you run out of RAM most machines and OSes these days will page so you'll slow down but still function. Having to rebuild a set of URLs gathered over hours and hours of run-time because its no longer available can be a real blow to productivity.\\n\\nKeeping information in RAM that you do NOT want to lose is bad. Obviously a database is the way to go at that point because you need fast random access to see if you've already found a URL. Of course in-memory lookups are faster but the trade-off of figuring out WHICH urls to keep in memory adds overhead. Rather than try writing code to determine which URLs I need/don't-need, I keep it in the database and concentrate on making my code clean and maintainable and my SQL queries and schemas sensible. Make your URL field a unique index and the DBM will be able to find them in no time while automatically avoiding redundant links.\\n\\nYour connection to the internet and sites you're accessing will probably be a lot slower than your connection to a database on a machine on your internal network. A SQLite database on the same machine might be the fastest, though the DBM itself isn't as sophisticated as Postgres, which is my favorite. I found that putting the database on another machine on the same switch as my spidering machine to be extremely fast; Making one machine handle the spidering, parsing, and then the database reads/writes is pretty intensive so if you have an old box throw Linux on it, install Postgres, and go to town. Throw some extra RAM in the box if you need more speed. Having that separate box for database use can be very nice.\\n\"},\n {'prompt': 'An odd error here, perhaps someone can help track down source as it\\'s attempting to extend the Django CMS project & attempts to use uses some logic written as part of that project which I\\'m not fully clear on. In short, using:\\n\\nurls.py\\n======================\\nfrom django.conf.urls.defaults import *\\nfrom cmsplugin_flat_news.models import News\\n\\n\\'\\'\\'RETURNING _CLONE ERROR WHEN IMPLEMENTED\\ndef get_news():\\n    return News.published.all()\\n\\nnews_dict = {\\n    \\'queryset\\': get_news,\\n}\\n\\nnews_list_dic = {\\n    \\'queryset\\': get_news,\\n    \\'paginate_by\\': 50,\\n}\\n\\'\\'\\'\\n# NEXT SECTION FUNCTIONS BUT NEEDS SERVER RESTART TO SEE NEW POSTS.\\n#CHANGING TO JUST News.published.all RAISES SAME ISSUE AS USING WRAPPER\\n#SOLUTION ABOVE. SEE: http://docs.djangoproject.com/en/dev/topics/db/queries/#caching-and-querysets\\n#& EXAMPLE HERE: http://docs.djangoproject.com/en/dev/topics/generic-views/#adding-extra-context\\n\\nnews_dict = {\\n    \\'queryset\\': News.published.all(),\\n}\\n\\nnews_list_dic = {\\n    \\'queryset\\': News.published.all(),#SAME ISSUE\\n    \\'paginate_by\\': 50,\\n}\\n\\nurlpatterns = patterns(\\'django.views.generic.list_detail\\',\\n    (r\\'^$\\', \\'object_list\\', news_list_dic),\\n    (r\\'^(?P<page>[0-9]+)/$\\', \\'object_list\\', dict(news_list_dic)),\\n    url(r\\'^(?P<slug>[-\\\\w]+)/$\\', \\'object_detail\\', news_dict, name=\\'news_view\\'),\\n)\\n\\nmodels.py\\n======================\\nclass PublishedNewsManager(models.Manager):\\n    #Filters out all unpublished news and news with a publication date in the future\\n    def get_query_set(self):\\n        return super(PublishedNewsManager, self).get_query_set() \\\\\\n                    .filter(is_published=True) \\\\\\n                    .filter(pub_date__lte=datetime.datetime.now())\\n\\nclass News(models.Model):\\n    title           = models.CharField(_(\\'Title\\'), max_length=255)\\n    slug            = models.SlugField(_(\\'Slug\\'), unique_for_date=\\'pub_date\\')\\n    author          = models.ForeignKey(User)\\n    description     = models.TextField(_(\\'Description\\'), blank=True)\\n    image           = generic.GenericRelation(\\'NewsImage\\', blank=True, null=True)\\n    content         = models.TextField(_(\\'Content\\'), blank=True)\\n    tags            = TagField()\\n    is_published    = models.BooleanField(_(\\'Published\\'), default=False)\\n    pub_date        = models.DateTimeField(_(\\'Publication date\\'), default=datetime.datetime.now())\\n    created         = models.DateTimeField(auto_now_add=True, editable=False)\\n    updated         = models.DateTimeField(auto_now=True, editable=False)\\n    published       = PublishedNewsManager()\\n    objects         = models.Manager()\\n\\n\\nSee issue in comments: basically, error raised by implementing the \\'correct\\' solution to add extra context to the views. Error is Attribute Error: \"\\'function\\' object has no attribute \\'_clone\\'\"\\n\\nTrying: News.published.all instead of News.published.all() raises the error whether used as part of a wrapper function or directly in the queryset part of the urlpattern.\\n\\nMust be missing something obvious? Think it is to do with the PublishedNewsManager not returning objects as a dictionary, or tweaking the code to correctly return the objects to the view.\\n',\n  'completion': \"The _clone errors are a red herring caused by you passing a function as an argument to a generic view where a QuerySet is expected. The version of your code which passes News.published.all() to the generic views is correct, as generic views will try to clone the QuerySet they are given, to avoid caching the first lot of data they query for (hence the error when you pass in a function).\\n\\nYour problem seems to be that your custom get_query_set method is returning a QuerySet filtered based on the current date and time when the method was called.\\n\\nI can't see anything in the documentation about filter arguments being callable, but I did find this ticket which suggests that filter can take callable arguments, so try changing your manager to pass in the function to be called to get the current date/time, rather than calling it immediately:\\n\\nclass PublishedNewsManager(models.Manager):\\n    def get_query_set(self):\\n        return super(PublishedNewsManager, self).get_query_set() \\\\\\n                    .filter(is_published=True) \\\\\\n                    .filter(pub_date__lte=datetime.datetime.now)\\n\\n\"},\n {'prompt': \"how can I output text to the console without new line at the end?\\nfor example:\\n\\nprint 'temp1'\\nprint 'temp2'\\n\\n\\noutput:\\n\\ntemp1 \\ntemp2\\n\\n\\nAnd I need:\\n\\ntemp1temp2\\n\\n\",\n  'completion': 'Add a comma after the last argument:\\n\\nprint \\'temp1\\',\\nprint \\'temp2\\'\\n\\n\\nAlternatively, Call sys.stdout.write:\\n\\nimport sys\\nsys.stdout.write(\"Some output\")\\n\\n'},\n {'prompt': 'I\\'d like to parallelize my Python program so that it can make use of multiple processors on the machine that it runs on.  My parallelization is very simple, in that all the parallel \"threads\" of the program are independent and write their output to separate files.  I don\\'t need the threads to exchange information but it is imperative that I know when the threads finish since some steps of my pipeline depend on their output.\\n\\nPortability is important, in that I\\'d like this to run on any Python version on Mac, Linux and Windows. Given these constraints, which is the most appropriate Python module for implementing this? I am trying to decide between thread, subprocess and multiprocessing, which all seem to provide related functionality.\\n\\nAny thoughts on this?  I\\'d like the simplest solution that\\'s portable.\\n\\nThanks.\\n',\n  'completion': 'For me this is actually pretty simple:\\n\\nThe subprocess option:\\n\\nsubprocess is for running other executables --- it\\'s basically a wrapper around os.fork() and os.execve() with some support for optional plumbing (setting up PIPEs to and from the subprocesses.  (Obviously other OS inter-process communications (IPC) mechanisms, such as sockets, SysV shared memory and message queues can be used --- but usually you\\'re using subprocess to run third party binary executables and are going to be stuck with whatever interfaces and IPC channels those support).\\n\\nCommonly one uses subprocess synchronously --- simply calling some external utility and reading back its output or awaiting its completion (perhaps reading its results from a temporary file, or after its posted them to some database).  However one can spawn hundreds of subprocesses and poll them.  My own personal favorite utility does exactly that.  The biggest disadvantage of the subprocess module is that its I/O support is generally blocking.  There is a draft PEP-3145 to fix that in some future version of Python 3.x and an alternative asyncproc (Warning that leads right to the download, not to any sort of documentation nor README).  I\\'ve also found that it\\'s relatively easy to just import fcntl and manipulate your Popen PIPE file descriptors directly --- though I don\\'t know if this is portable to non-UNIX platforms.\\n\\nsubprocess has almost no event handling support ... though you can use the signal module and plain old-school UNIX/Linux signals --- killing your processes softly, as it were.\\n\\nThe multiprocessing option:\\n\\nmultiprocessing is for running functions within your existing (Python) code with support for more flexible communications among the family of processes.  In particular it\\'s best to build your multiprocessing IPC around the module\\'s Queue objects where possible, but you can also use Event objects and various other features (some of which are, presumably, built around mmap support on platforms where that support is sufficient).\\n\\nPython\\'s multiprocessing module is intended to provide interfaces and features which are very similar to threading while allowing CPython to scale your processing among multiple CPUs/cores despite the GIL.  It leverages all the fine-grained SMP locking and coherency effort that was done by developers of your OS kernel.\\n\\nThe threading option:\\n\\nthreading is for a fairly narrow range of applications which are I/O bound (don\\'t need to scale across multiple CPU cores) and which benefit from the extremely low latency and switching overhead of thread switching (with shared core memory) vs. process/context switching.  On Linux this is almost the empty set (Linux process switch times are extremely close to its thread-switches).\\n\\nthreading suffers from two major disadvantages in Python.  One, of course, is implementation specific --- mostly affecting CPython.  That\\'s the GIL (Global Interpreter Lock).  For the most part, most CPython programs will not benefit from the availability of more than two CPUs (cores) and often performance will suffer from the GIL locking contention.  The larger issue which is not implementation specific, is that threads share the same memory, signal handlers, file descriptors and certain other OS resources.  Thus the programmer must be extremely careful about object locking, exception handling and other aspects of their code which are both subtle and which can kill, stall, or deadlock the entire process (suite of threads).\\n\\nBy comparison the multiprocessing model gives each process its own memory, file descriptors, etc.  A crash or unhandled exception in any one of them will only kill that resource and robustly handling the disappearance of a child or sibling process can be considerably easier than debugging, isolating and fixing or working around similar issues in threads.\\n\\n\\n(Note: use of threading with major Python systems, such as Numpy, may suffer considerably less from GIL contention then most of your own Python code would.  That\\'s because they\\'ve been specifically engineered to do so).\\n\\n\\nThe twisted option:\\n\\nIt\\'s also worth noting that Twisted offers yet another alternative which is both elegant and very challenging to understand.  Basically, at the risk of over simplifying to the point where fans of Twisted may storm my home with pitchforks and torches, Twisted provides and event-driven co-operative multi-tasking within any (single) process.\\n\\nTo understand how this is possible one should read about the features of select() (which can be built around the select() or poll() or similar OS system calls).  Basically it\\'s all driven by the ability to make a request of the OS to sleep pending any activity on a list of file descriptors or some timeout.  The awakening from each of these calls to select() is an event --- either one involving input available (readable) on some number of sockets or file descriptors, or buffering space becoming available on some other descriptors or sockets (writable), or some exceptional conditions (TCP out-of-band PUSH\\'d packets, for example), or a TIMEOUT.\\n\\nThus the Twisted programming model is built around handling these events then looping on the resulting \"main\" handler, allowing it to dispatch the events to your handlers.\\n\\nI personally think of the name, Twisted as evocative of the programming model ... since your approach to the problem must be, in some sense, \"twisted\" inside out.  Rather than conceiving of your program as a series of operations on input data and outputs or results, you\\'re writing your program as a service or daemon and defining how it reacts to various events.  (In fact the core \"main loop\" of a Twisted program is (usually?  always?) a reactor().\\n\\nThe major challenges to using Twisted involve twisting your mind around the event driven model and also eschewing the use of any class libraries or toolkits which are not written to co-operate within the Twisted framework.  This is why Twisted supplies its own modules for SSH protocol handling, for curses, and its own subprocess/popen functions, and many other modules and protocol handlers which, at first blush, would seem to duplicate things in the Python standard libraries.\\n\\nI think it\\'s useful to understand Twisted on a conceptual level even if you never intend to use it.  It may give insights into performance, contention, and event handling in your threading, multiprocessing and even subprocess handling as well as any distributed processing you undertake. \\n\\nThe distributed option:\\n\\nYet another realm of processing you haven\\'t asked about, but which is worth considering, is that of distributed processing.  There are many Python tools and frameworks for distributed processing and parallel computation.  Personally I think the easiest to use is one which is least often considered to be in that space.\\n\\nIt is almost trivial to build distributed processing around Redis.  The entire key store can be used to store work units and results, Redis LISTs can be used as Queue() like object, and the PUB/SUB support can be used for Event-like handling. You can hash your keys and use values, replicated across a loose cluster of Redis instances, to store the topology and hash-token mappings to provide consistent hashing and fail-over for scaling beyond the capacity of any single instance for co-ordinating your workers and marshaling data (pickled, JSON, BSON, or YAML) among them.\\n\\nOf course as you start to build a larger scale and more sophisticated solution around Redis you are re-implementing many of the features that have already been solved using Hadoop, Zookeeper, Cassandra and so on.  Those also have modules for Python access to their services.\\n\\nConclusion\\n\\nThere you have the gamut of processing alternatives for Python, from single threaded, with simple synchronous calls to sub-processes, pools of polled subprocesses, threaded and multiprocessing, event-driven co-operative multi-tasking, and out to distributed processing.\\n'},\n {'prompt': \"I am opening a file which has 100,000 url's.  I need to send an http request to each url and print the status code. I am using Python 2.6, and so far looked at the many confusing ways Python implements threading/concurrency.  I have even looked at the python concurrence library, but cannot figure out how to write this program correctly.  Has anyone come across a similar problem?  I guess generally I need to know how to perform thousands of tasks in Python as fast as possible - I suppose that means 'concurrently'.\\n\\nThank you,\\nIgor\\n\",\n  'completion': 'Twistedless solution:\\n\\nfrom urlparse import urlparse\\nfrom threading import Thread\\nimport httplib, sys\\nfrom Queue import Queue\\n\\nconcurrent = 200\\n\\ndef doWork():\\n    while True:\\n        url = q.get()\\n        status, url = getStatus(url)\\n        doSomethingWithResult(status, url)\\n        q.task_done()\\n\\ndef getStatus(ourl):\\n    try:\\n        url = urlparse(ourl)\\n        conn = httplib.HTTPConnection(url.netloc)   \\n        conn.request(\"HEAD\", url.path)\\n        res = conn.getresponse()\\n        return res.status, ourl\\n    except:\\n        return \"error\", ourl\\n\\ndef doSomethingWithResult(status, url):\\n    print status, url\\n\\nq = Queue(concurrent * 2)\\nfor i in range(concurrent):\\n    t = Thread(target=doWork)\\n    t.daemon = True\\n    t.start()\\ntry:\\n    for url in open(\\'urllist.txt\\'):\\n        q.put(url.strip())\\n    q.join()\\nexcept KeyboardInterrupt:\\n    sys.exit(1)\\n\\n\\nThis one is slighty faster than the twisted solution and uses less CPU.\\n'},\n {'prompt': \"I use the following code to log a map, it is fast when it only contains zeroes, but as soon as there is actual data in the map it becomes unbearably slow... Is there any way to do this faster?\\n\\nlog_file = open('testfile', 'w')\\nfor i, x in ((i, start + i * interval) for i in range(length)):\\n    log_file.write('%-5d %8.3f %13g %13g %13g %13g %13g %13g\\\\n' % (i, x,\\n        map[0][i], map[1][i], map[2][i], map[3][i], map[4][i], map[5][i]))\\n\\n\",\n  'completion': 'I suggest you run your code using the cProfile module and postprocess the results as described on http://docs.python.org/library/profile.html . This will let you know exactly how much time is spent in the call to str.__mod__ for the string formatting and how much is spent doing other things, like writing the file and doing the __getitem__ lookups for map[0][i] and such.\\n'},\n {'prompt': 'I want to parse HTML with lxml using XPath expressions. My problem is matching for the contents of a tag:\\n\\nFor example given the \\n\\n<a href=\"http://something\">Example</a>\\n\\n\\nelement I can match the href attribute using \\n\\n.//a[@href=\\'http://something\\']\\n\\n\\nbut the given the expression\\n\\n.//a[.=\\'Example\\']\\n\\n\\nor even\\n\\n.//a[contains(.,\\'Example\\')]\\n\\n\\nlxml throws the \\'invalid node predicate\\' exception.\\n\\nWhat am I doing wrong?\\n\\nEDIT:\\n\\nExample code:\\n\\nfrom lxml import etree\\nfrom cStringIO import StringIO\\n\\nhtml = \\'<a href=\"http://something\">Example</a>\\'\\nparser = etree.HTMLParser()\\ntree   = etree.parse(StringIO(html), parser)\\n\\nprint tree.find(\".//a[text()=\\'Example\\']\").tag\\n\\n\\nExpected output is \\'a\\'. I get \\'SyntaxError: invalid node predicate\\'\\n',\n  'completion': 'I would try with:\\n\\n.//a[text()=\\'Example\\']\\n\\nusing xpath() method:\\n\\ntree.xpath(\".//a[text()=\\'Example\\']\")[0].tag\\n\\n\\nIf case you would like to use iterfind(), findall(), find(), findtext(), keep in mind that advanced features like value comparison and functions are not available in ElementPath.\\n\\n\\n  lxml.etree supports the simple path\\n  syntax of the find, findall and\\n  findtext methods on ElementTree and\\n  Element, as known from the original\\n  ElementTree library (ElementPath). As\\n  an lxml specific extension, these\\n  classes also provide an xpath() method\\n  that supports expressions in the\\n  complete XPath syntax, as well as\\n  custom extension functions.\\n\\n'},\n {'prompt': 'I\\'m writing a custom dice rolling parser (snicker if you must) in python. Basically, I want to use standard math evaluation but add the \\'d\\' operator:\\n\\n#xdy\\nsum = 0\\nfor each in range(x):\\n    sum += randInt(1, y)\\nreturn sum\\n\\n\\nSo that, for example, 1d6+2d6+2d6-72+4d100 = (5)+(1+1)+(6+2)-72+(5+39+38+59) = 84\\n\\nI was using regex to replace all \\'d\\'s with the sum and then using eval, but my regex fell apart when dealing with parentheses on either side. Is there a faster way to go about this than implementing my own recursive parsing? Perhaps adding an operator to eval?\\n\\nEdit: I seem to have given a bad example, as the above example works with my current version. What I\\'m looking for is some way to evaluate, say, (5+(6d6))d(7-2*(1d4)).\\nBy \"fell apart\", I just meant that my current regex expression failed.\\nI have been too vague about my failure, sorry for the confusion. Here\\'s my current code:\\n\\ndef evalDice(roll_matchgroup):\\n    roll_split = roll_matchgroup.group(\\'roll\\').split(\\'d\\')\\n    print roll_split\\n    roll_list = []\\n\\n    for die in range(int(roll_split[0])):\\n        roll = random.randint(1,int(roll_split[1]))\\n        roll_list.append(roll)\\n\\ndef EvalRoll(roll):\\n    if not roll: return 0\\n    rollPattern = re.compile(\\'(?P<roll>\\\\d*d\\\\d+)\\')\\n    roll_string = rollPattern.sub(evalDice, roll.lower())\\n\\n\\nfor this, \"1d6+4d100\" works just fine, but \"(1d6+4)d100\" or even \"1d6+4d(100)\" fails.\\n',\n  'completion': 'You could use a callback function with re.sub. When you follow the link, search down to the paragraph beginning with \"If repl is a function...\"\\n\\nimport re\\nimport random\\n\\ndef xdy(matchobj):\\n    x,y=map(int,matchobj.groups())\\n    s = 0\\n    for each in range(x):\\n        s += random.randint(1, y)\\n    return str(s)\\ns=\\'1d6+2d6+2d6-72+4d100\\'\\nt=re.sub(\\'(\\\\d+)d(\\\\d+)\\',xdy,s)\\nprint(t)\\n# 5+10+8-72+197\\nprint(eval(t))\\n# 148\\n\\n'},\n {'prompt': \"I want to count how many members of an iterable meet a given condition. I'd like to do it in a way that is clear and simple and preferably reasonably optimal.\\n\\nMy current best ideas are:\\n\\nsum(meets_condition(x) for x in my_list)\\n\\n\\nand\\n\\nlen([x for x in my_list if meets_condition(x)])\\n\\n\\nThe first one being iterator based is presumably faster for big lists. And it's the same form as you'd use for testing any and all. However it depends on the fact that int(True) == 1, which is somewhat ugly.\\n\\nThe second one seems easier to read to me, but it is different from the any and all forms.\\n\\nDoes anyone have any better suggestions? is there a library function somewhere that I am missing?\\n\",\n  'completion': 'The iterator based approach is just fine. There are some slight modifications that can emphasize the fact that you are counting:\\n\\nsum(1 if meets_condition(x) else 0 for x in my_list)\\n# or \\nsum(1 for x in my_list if meets_condition(x))\\n\\n\\nAnd as always, if the intent isn\\'t apparent from the code, encapsulate it in descriptively named function:\\n\\ndef count_matching(condition, seq):\\n    \"\"\"Returns the amount of items in seq that return true from condition\"\"\"\\n    return sum(1 for item in seq if condition(item))\\n\\ncount_matching(meets_condition, my_list)\\n\\n'},\n {'prompt': 'When implementing the interpreter for my programming language I first thought of a simple console window which allows the user to enter some code which is then executed as a standalone program as a shell.\\n\\nBut there are severe problems: If every line of code the user enters is handled as a standalone program, it has to go through the tokenizer and parser and is then just executed by the interpreter - what about functions then? \\n\\n\\nHow can the Python/Ruby interactive consoles (IDLE, irb) \"share\" the code? How is the code entered handled?\\n\\n\\nExample:\\n\\n>> def x:\\n>>  print(\"Blah\")\\n>> \\n>> x()\\n\\n\\nWhere is the function stored so it can be called at any time again?\\n\\nHow can the interactive console take everything entered as obviously one program without executing everything over and over again?\\n',\n  'completion': \"For Python, an expression isn't complete until all parentheses, brackets, etc. match up. This is fairly easy to detect. A function/class definition isn't complete until a completely blank line is entered. The compiler then compiles the entered expression or definition, and runs it.\\n\\nMuch like a normal function, class, module, etc., the REPL has its own local scope. It's this scope that is used for variables and definitions entered into the REPL.\\n\"},\n {'prompt': \"This is related to this question here, but with a slight twist: instead of just passing 'yes' or 'no', I need Fabric to pass an arbitrary string to the remote shell.\\n\\nFor instance, if the remote shell prompts for 'what is your name?' then I need to feed it 'first,last'.\\n\\nClarification: I know I said arbitrary input, but I was really trying to use it for the SSH key passwd prompt when I try to do a git pull.\\n\\nUpdate #1: Got a response from Jeff Forcier @bitprophet\\n\\n\\nthatâ\\x80\\x99s like the #1 wart right now :( Either tunnelling to send a key agent out-of-band, or remote prompting, is needed.\\nI meant adding support for those things in Fabric, is what we need to do to get network-borne git ops working\\nAdding an easy way to kick off an OOB ssh agent-friendly tunnel is going to be easier/faster, most likely. Soon probably\\n\\n\",\n  'completion': 'Interaction with remote servers is finally supported in Fabric 1.0. See this page for details.\\n'},\n {'prompt': \"I'm looking for a fast, clean, pythonic way to divide a list into exactly n nearly-equal partitions.\\n\\npartition([1,2,3,4,5],5)->[[1],[2],[3],[4],[5]]\\npartition([1,2,3,4,5],2)->[[1,2],[3,4,5]] (or [[1,2,3],[4,5]])\\npartition([1,2,3,4,5],3)->[[1,2],[3,4],[5]] (there are other ways to slice this one too)\\n\\n\\nThere are several answers in here http://stackoverflow.com/questions/1335392/iteration-over-list-slices that run very close to what I want, except they are focused on the size of the list, and I care about the number of the lists (some of them also pad with None).  These are trivially converted, obviously, but I'm looking for a best practice.\\n\\nSimilarly, people have pointed out great solutions here http://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks-in-python for a very similar problem, but I'm more interested in the number of partitions than the specific size, as long as it's within 1.  Again, this is trivially convertible, but I'm looking for a best practice.\\n\",\n  'completion': \"Here's a version that's similar to Daniel's:  it divides as evenly as possible, but puts all the larger partitions at the start:\\n\\ndef partition(lst, n):\\n    q, r = divmod(len(lst), n)\\n    indices = [q*i + min(i, r) for i in xrange(n+1)]\\n    return [lst[indices[i]:indices[i+1]] for i in xrange(n)]\\n\\n\\nIt also avoids the use of float arithmetic, since that always makes me uncomfortable.  :)\\n\\nEdit:  an example, just to show the contrast with Daniel Stutzbach's solution\\n\\n>>> print [len(x) for x in partition(range(105), 10)]\\n[11, 11, 11, 11, 11, 10, 10, 10, 10, 10]\\n\\n\"},\n {'prompt': '\\n  Possible Duplicates:\\n  Accurate timing of functions in python\\n  accurately measure time python function takes  \\n\\n\\n\\n\\nHow can i mesure and compare the running times of my algorithms written in python .Also point me to a nice algorithms site/forum like stackoverflow if you can.\\n',\n  'completion': \"The module timeit is useful for this and is included in the standard Python distribution.\\n\\nExample:\\n\\nimport timeit\\ntimeit.Timer('for i in xrange(10): oct(i)').timeit()\\n\\n\"},\n {'prompt': 'What\\'s the easiest way to count the longest consecutive repeat of a certain character in a string?  For example, the longest consecutive repeat of \"b\" in the following string:\\n\\nmy_str = \"abcdefgfaabbbffbbbbbbfgbb\"\\n\\n\\nwould be 6, since other consecutive repeats are shorter (3 and 2, respectively.) How can I do this in Python?\\n\\nthanks.\\n',\n  'completion': 'How about a regex example:\\n\\nimport re\\nmy_str = \"abcdefgfaabbbffbbbbbbfgbb\"\\nlen(max(re.compile(\"(b+b)*\").findall(my_str))) #changed the regex from (b+b) to (b+b)*\\n# max([len(i) for i in re.compile(\"(b+b)\").findall(my_str)]) also works\\n\\n\\nEdit, Mine vs. interjays\\n\\nx=timeit.Timer(stmt=\\'import itertools;my_str = \"abcdefgfaabbbffbbbbbbfgbb\";max(len(list(y)) for (c,y) in itertools.groupby(my_str) if c==\"b\")\\')\\nx.timeit()\\n22.759046077728271\\n\\nx=timeit.Timer(stmt=\\'import re;my_str = \"abcdefgfaabbbffbbbbbbfgbb\";len(max(re.compile(\"(b+b)\").findall(my_str)))\\')\\nx.timeit()\\n8.4770550727844238\\n\\n'},\n {'prompt': 'I\\'ve been having difficulty getting anything more than a simple index / to return correctly using bottle.py in a CGI environment.  When I try to return /hello I get a 404 response.  However, if I request /index.py/hello\\n\\nimport bottle\\nfrom bottle import route\\n\\n@route(\\'/\\')\\ndef index():\\n    return \\'Index\\'\\n\\n@route(\\'/hello\\')\\ndef hello():\\n    return \\'Hello\\'\\n\\nif __name__ == \\'__main__\\':\\n    from wsgiref.handlers import CGIHandler\\n    CGIHandler().run(bottle.default_app())\\n\\n\\nAnd here is my .htaccess file\\n\\nDirectoryIndex index.py\\n<ifmodule mod_rewrite.c=\"\">\\nRewriteEngine on\\nRewriteBase /\\nRewriteCond %{REQUEST_FILENAME} !-f\\nRewriteRule ^(.*)$ /index.py/$1  [L]\\n</ifmodule>\\n\\n\\nI copied much of the code from here as I\\'m using DH and it seemed relevant: http://blog.coderonfire.com/2010/02/running-bottle-python-micro-framework.html\\n\\nThanks for helping.\\n',\n  'completion': 'The problem is that the <ifmodule> block is not relevant to your Apache server and the directives to mod_rewrite are not working. Start with the following .htaccess and then if you have a need, add the block according to your current apache version.\\n\\nDirectoryIndex index.py\\nRewriteEngine on\\nRewriteCond %{REQUEST_FILENAME} !-f\\nRewriteRule ^(.*)$ /index.py/$1  [L]\\n\\n'},\n {'prompt': 'I\\'ve got a CSV file with a format that looks like this:\\n\\n\\n  \"FieldName1\", \"FieldName2\", \"FieldName3\", \"FieldName4\"\\n  \"04/13/2010 14:45:07.008\", \"7.59484916392\", \"10\", \"6.552373\"\\n  \"04/13/2010 14:45:22.010\", \"6.55478493312\", \"9\", \"3.5378543\"\\n  ...\\n\\n\\nNote that there are double quote characters at the start and end of each line in the CSV file, and the \",\" string is used to delimit fields within each line.  The number of fields in the CSV file can vary from file to file.\\n\\nWhen I try to read this into numpy via:\\nimport numpy as np\\ndata = np.genfromtxt(csvfile, dtype=None, delimiter=\\',\\', names=True)\\nall the data gets read in as string values, surrounded by double-quote characters.  Not unreasonable, but not much use to me as I then have to go back and convert every column to its correct type\\n\\nWhen I use delimiter=\\'\",\"\\' instead, everything works as I\\'d like, except for the 1st and last fields.  As the start of line and end of line characters are a single double-quote character, this isn\\'t seen as a valid delimiter for the 1st and last fields, so they get read in as e.g. \"04/13/2010 14:45:07.008 and 6.552373\" - note the leading and trailing double-quote characters respectively.  Because of these redundant characters, numpy assumes the 1st and last fields are both String types; I don\\'t want that to be the case\\n\\nIs there a way of instructing numpy to read in files formatted in this fashion as I\\'d like, without having to go back and \"fix\" the structure of the numpy array after the initial read?\\n',\n  'completion': 'The basic problem is that NumPy doesn\\'t understand the concept of stripping quotes (whereas the csv module does).  When you say delimiter=\\'\",\"\\', you\\'re telling NumPy that the column delimiter is literally a quoted comma, i.e. the quotes are around the comma, not the value, so the extra quotes you get on he first and last columns are expected.\\n\\nLooking at the function docs, I think you\\'ll need to set the converters parameter to strip quotes for you (the default does not):\\n\\nimport re\\nimport numpy as np\\n\\nfieldFilter = re.compile(r\\'^\"?([^\"]*)\"?$\\')\\ndef filterTheField(s):\\n    m = fieldFilter.match(s.strip())\\n    if m:\\n        return float(m.group(1))\\n    else:\\n        return 0.0 # or whatever default\\n\\n#...\\n\\n# Yes, sorry, you have to know the number of columns, since the NumPy docs\\n# don\\'t say you can specify a default converter for all columns.\\nconvs = dict((col, filterTheField) for col in range(numColumns))\\ndata = np.genfromtxt(csvfile, dtype=None, delimiter=\\',\\', names=True, \\n    converters=convs)\\n\\n\\nOr abandon np.genfromtxt() and let csv.csvreader give you the file\\'s contents a row at a time, as lists of strings, then you just iterate through the elements and build the matrix:\\n\\nreader = csv.csvreader(csvfile)\\nresult = np.array([[float(col) for col in row] for row in reader])\\n# BTW, column headings are in reader.fieldnames at this point.\\n\\n\\nEDIT: Okay, so it looks like your file isn\\'t all floats.  In that case, you can set convs as needed in the genfromtxt case, or create a vector of conversion functions in the csv.csvreader case:\\n\\nreader = csv.csvreader(csvfile)\\nconverters = [datetime, float, int, float]\\nresult = np.array([[conv(col) for col, conv in zip(row, converters)] \\n    for row in reader])\\n# BTW, column headings are in reader.fieldnames at this point.\\n\\n\\nEDIT 2: Okay, variable column count... Your data source just wants to make life difficult.  Luckily, we can just use magic...\\n\\nreader = csv.csvreader(csvfile)\\nresult = np.array([[magic(col) for col in row] for row in reader])\\n\\n\\n... where magic() is just a name I got off the top of my head for a function.  (Psyche!)\\n\\nAt worst, it could be something like:\\n\\ndef magic(s):\\n    if \\'/\\' in s:\\n        return datetime(s)\\n    elif \\'.\\' in s:\\n        return float(s)\\n    else:\\n        return int(s)\\n\\n\\nMaybe NumPy has a function that takes a string and returns a single element with the right type.  numpy.fromstring() looks close, but it might interpret the space in your timestamps as a column separator.\\n\\nP.S. One downside with csvreader I see is that it doesn\\'t discard comments; real csv files don\\'t have comments.\\n'},\n {'prompt': \"In Python scripts, there are many cases where a keyboard interrupt (Ctrl-C) fails to kill the process because of a bare except clause somewhere in the code:\\n\\ntry:\\n    foo()\\nexcept:\\n    bar()\\n\\n\\nThe standard solution in Python 2.5 or higher is to catch Exception rather than using bare except clauses:\\n\\ntry:\\n    foo()\\nexcept Exception:\\n    bar()\\n\\n\\nThis works because, as of Python 2.5, KeyboardInterrupt and SystemExit inherit from BaseException, not Exception. However, some installations are still running Python 2.4. How can this problem be handled in versions prior to Python 2.5?\\n\\n(I'm going to answer this question myself, but putting it here so people searching for it can find a solution.)\\n\",\n  'completion': \"According to the Python documentation, the right way to handle this in Python versions earlier than 2.5 is:\\n\\ntry:\\n    foo()\\nexcept (KeyboardInterrupt, SystemExit):\\n    raise\\nexcept:\\n    bar()\\n\\n\\nThat's very wordy, but at least it's a solution.\\n\"},\n {'prompt': \"There are plenty of 'pretty-printing' visualization libraries for Javascript. E.g. those listed here.\\n\\nGoogling for 'python visualization libraries' only turns up stuff like VTK and mayavi, which are primarily more for no-nonsense scientific use.\\n\\nSo, do you know of any Python libraries similar to those Javascript ones in the above link? I particularly like the Javascript Infovis Toolkit.\\n\",\n  'completion': 'For Python there really isn\\'t \"one viz library to rule them all\". There are different libraries and toolkits for different purposes. For graphs in Python you may find igraph useful. For other types of scientific or data visualizations matplotlib is also good.\\n'},\n {'prompt': \"In Windows the Dropbox client uses python25.dll and the MS C runtime libraries (msvcp71.dll, etc). On OS X the Python code is compiled bytecode (pyc).\\n\\nMy guess is they are using a common library they have written then just have to use different hooks for the different platforms.\\n\\nWhat method of development is this? It clearly isn't IronPython or PyObjC. This paradigm is so appealing to me, but my CS foo and Google foo are failing me.\\n\",\n  'completion': \"Dropbox uses a combination of wxPython and PyObjC on the Mac (less wxPython in the 0.8 series).  It looks like they've built a bit of a UI abstraction layer but nothing overwhelmingâ\\x80\\x94i.e., they're doing their cross-platform app the right way.\\n\\nThey include their own Python mainly because the versions of Python included on the Mac vary by OS version (and Dropbox supports back to 10.4 IIRC); also, they've customized the Python interpreter a bit to improve threading and I/O behavior.\\n\\n(I do not work for Dropbox or have any inside knowledge; all I did was read their forums and examine the filenames in site-packages.zip in the Dropbox app bundle.)\\n\"},\n {'prompt': 'I\\'m trying to do a very simple search from a list of terms \\n\\nterms = [\\'term1\\', \\'term2\\', \\'term3\\']\\n\\n\\nHow do I programmatically go through the list of terms and construct the \"conditions\" from the list of terms so that I can make the query using filter and or_ or _and?\\n\\ne.g. query.filter(or_(#something constructed from terms))\\n\\n',\n  'completion': 'If you have a list of terms and want to find rows where a field matches one of them, then you could use the in_() method:\\n\\nterms = [\\'term1\\', \\'term2\\', \\'term3\\']\\nquery.filter(Cls.field.in_(terms))\\n\\n\\nIf you want to do something more complex, then or_() and and_() take ClauseElement objects as parameters. ClauseElement and it\\'s subclasses basically represent the SQL AST of your query. Typically you create clause elements by invoking a comparison operator on Column or InstrumentedAttribute objects:\\n\\n# Create the clause element\\nclause = (users_table.columns[\\'name\\'] == \"something\")\\n#    you can also use the shorthand users_table.c.name\\n\\n# The clause is a binary expression ...\\nprint(type(clause))\\n#    <class \\'sqlalchemy.sql.expression._BinaryExpression\\'>\\n# ... that compares a column for equality with a bound value.\\nprint(type(clause.left), clause.operator, type(clause.right))\\n#    <class \\'sqlalchemy.schema.Column\\'>, <built-in function eq>,\\n#    <class \\'sqlalchemy.sql.expression._BindParamClause\\'>\\n\\n# str() compiles it to SQL\\nprint(str(clause)) \\n# users.name = ?\\n\\n# You can also do that with ORM attributes\\nclause = (User.name == \"something\")\\nprint(str(clause))\\n# users.name = ?\\n\\n\\nYou can handle clause elements representing your conditions like any Python objects, put them into lists, compose them into other clause elements, etc. So you can do something like this:\\n\\n# Collect the separate conditions to a list\\nconditions = []\\nfor term in terms:\\n    conditions.append(User.name == term)\\n\\n# Combine them with or to a BooleanClauseList\\ncondition = or_(*conditions)\\n\\n# Can now use the clause element as a predicate in queries\\nquery = query.filter(condition)\\n# or to view the SQL fragment\\nprint(str(condition))\\n#    users.name = ? OR users.name = ? OR users.name = ?\\n\\n'},\n {'prompt': 'can i create a case insensitive string column in sqlalchemy?  im using sqlite, and theres probaby a way to do it through DB by changing collation, but i want to keep it in sqlalchemy/python.\\n',\n  'completion': 'SQLAlchemy doesn\\'t seem to allow COLLATE clauses at the table creation (DDL) stage by default, but I finally figured out a way to get this working on SQLAlchemy 0.6+. Unfortunately, it involves a bit of subclassing and decorating, but it\\'s reasonably compact. \\n\\nfrom sqlalchemy import *\\nfrom sqlalchemy.ext.compiler import compiles\\nfrom sqlalchemy.types import TypeDecorator\\n\\nclass CI_String(TypeDecorator): \\n  \"\"\" Case-insensitive String subclass definition\"\"\"\\n  impl = String \\n  def __init__(self, length, **kwargs):\\n      if kwargs.get(\\'collate\\'):\\n          if kwargs[\\'collate\\'].upper() not in [\\'BINARY\\',\\'NOCASE\\',\\'RTRIM\\']:\\n              raise TypeError(\"%s is not a valid SQLite collation\" % kwargs[\\'collate\\'])\\n          self.collation = kwargs.pop(\\'collate\\').upper()\\n      super(CI_String, self).__init__(length=length, **kwargs)\\n\\n@compiles(CI_String, \\'sqlite\\')\\ndef compile_ci_string(element, compiler, **kwargs):\\n  base_visit = compiler.visit_string(element, **kwargs) \\n  if element.collation:\\n      return \"%s COLLATE %s\" % (base_visit, element.collation) \\n  else:\\n      return base_visit\\n\\n\\nThe new string type can then be used normally for creating tables:\\n\\njust_a_table = Table(\\'table_name\\', metadata,\\n               Column(\\'case_insensitive\\', CI_String(8, collate=\\'NOCASE\\'), nullable=False))\\n\\n\\nHope someone finds this useful!\\n'},\n {'prompt': \"How might one extract all images from a pdf document, at native resolution and format? (Meaning extract tiff as tiff, jpeg as jpeg, etc. and without resampling). Layout is unimportant, I don't care were the source image is located on the page.\\n\\nI'm using python 2.7 but can use 3.x if required.\\n\",\n  'completion': 'Often in a PDF, the image is simply stored as-is.  For example, a PDF with a jpg inserted will have a range of bytes somewhere in the middle that when extracted is a valid jpg file.  You can use this to very simply extract byte ranges from the PDF.  I wrote about this some time ago, with sample code: Extracting JPGs from PDFs.\\n'},\n {'prompt': 'I have following:\\n\\ntemp = \"aaaab123xyz@+\"\\n\\nlists = [\"abc\", \"123.35\", \"xyz\", \"AND+\"]\\n\\nfor list in lists\\n  if re.match(list, temp, re.I):\\n    print \"The %s is within %s.\" % (list,temp)\\n\\n\\nThe re.match is only match the beginning of the string, How to I match substring in between too.\\n',\n  'completion': \"You can use re.search instead of re.match.\\n\\nIt also seems like you don't really need regular expressions here. Your regular expression 123.35 probably doesn't do what you expect because the dot matches anything.\\n\\nIf this is the case then you can do simple string containment using x in s.\\n\"},\n {'prompt': \"I have a string a and I would like to split it in half depending on its length, so I have\\n\\na-front = len(a) / 2 + len(a) % 2\\n\\n\\nthis works fine in the interpreter but when i run the module from the command line python gives me a SyntaxError: can't assign to operator. What could be the issue here.\\n\",\n  'completion': 'You might mistype hyphen and underscore, try\\n\\na_front = len(a) / 2 + len(a) % 2\\n\\n'},\n {'prompt': 'I was working the following example from Doug Hellmann tutorial on multiprocessing:\\n\\nimport multiprocessing\\n\\ndef worker():\\n    \"\"\"worker function\"\"\"\\n    print \\'Worker\\'\\n    return\\n\\nif __name__ == \\'__main__\\':\\n    jobs = []\\n    for i in range(5):\\n        p = multiprocessing.Process(target=worker)\\n        jobs.append(p)\\n        p.start()\\n\\n\\nWhen I tried to run it outside the if statement:\\n\\nimport multiprocessing\\n\\ndef worker():\\n    \"\"\"worker function\"\"\"\\n    print \\'Worker\\'\\n    return\\n\\njobs = []\\nfor i in range(5):\\n    p = multiprocessing.Process(target=worker)\\n    jobs.append(p)\\n    p.start()\\n\\n\\nIt started spawning processes non-stop, and the only way to stop it was reboot!\\n\\nWhy would that happen? Why it did not generate 5 processes and exit? Why do I need the if statement?\\n',\n  'completion': 'On Windows there is no fork() routine, so multiprocessing imports the current module to get access to the worker function. Without the if statement the child process starts its own children and so on.\\n'},\n {'prompt': \"I have a function foo(i) that takes an integer and takes a significant amount of time to execute.  Will there be a significant performance difference between any of the following ways of initializing a:\\n\\na = [foo(i) for i in xrange(100)]\\n\\na = map(foo, range(100))\\n\\nvfoo = numpy.vectorize(foo)\\na = vfoo(range(100))\\n\\n\\n(I don't care whether the output is a list or a numpy array.)\\n\\nIs there a better way?\\n\",\n  'completion': '\\nWhy are you optimizing this? Have you written working, tested code, then examined your algorithm profiled your code and found that optimizing this will have an effect? Are you doing this in a deep inner loop where you found you are spending your time? If not, don\\'t bother.\\nYou\\'ll only know which works fastest for you by timing it. To time it in a useful way, you\\'ll have to specialize it to your actual use case. For example, you can get noticeable performance differences between a function call in a list comprehension versus an inline expression; it isn\\'t clear whether you really wanted the former or if you reduced it to that to make your cases similar.\\nYou say that it doesn\\'t matter whether you end up with a numpy array or a list, but if you\\'re doing this kind of micro-optimization it does matter, since those will perform differently when you use them afterward. Putting your finger on that could be tricky, so hopefully it will turn out the whole problem is moot as premature.\\nIt is typically better to simply use the right tool for the job for clarity, readability, and so forth. It is rare that I would have a hard time deciding between these things.\\n\\n\\nIf I needed numpy arrays, I would use them. I would use these for storing large homogeneous arrays or multidimensional data. I use them a lot, but rarely where I think I\\'d want to use a list.\\n\\nIf I was using these, I\\'d do my best to write my functions already vectorized so I didn\\'t have to use numpy.vectorize. For example, times_five below can be used on a numpy array with no decoration.\\n\\nIf I didn\\'t have cause to use numpy, that is to say if I wasn\\'t solving numerical math problems or using special numpy features or storing multidimensional arrays or whatever...\\n\\nIf I had an already-existing function, I would use map. That\\'s what it\\'s for.\\nIf I had an operation that fit inside a small expression and I didn\\'t need a function, I\\'d use a list comprehension.\\nIf I just wanted to do the operation for all the cases but didn\\'t actually need to store the result, I\\'d use a plain for loop.\\nIn many cases, I\\'d actually use map and list comprehensions\\' lazy equivalents: itertools.imap and generator expressions. These can reduce memory usage by a factor of n in some cases and can avoid performing unnecessary operations sometimes.\\n\\n\\n\\n\\n\\n\\nIf it does turn out this is where performance problems lie, getting this sort of thing right is tricky. It is very common that people time the wrong toy case for their actual problems. Worse, it is extremely common people make dumb general rules based on it.\\n\\nConsider the following cases (timeme.py is posted below)\\n\\npython -m timeit \"from timeme import x, times_five; from numpy import vectorize\" \"vectorize(times_five)(x)\"\\n1000 loops, best of 3: 924 usec per loop\\n\\npython -m timeit \"from timeme import x, times_five\" \"[times_five(item) for item in x]\"\\n1000 loops, best of 3: 510 usec per loop\\n\\npython -m timeit \"from timeme import x, times_five\" \"map(times_five, x)\"\\n1000 loops, best of 3: 484 usec per loop\\n\\n\\nA naÃ¯ve obsever would conclude that map is the best-performing of these options, but the answer is still \"it depends\". Consider the power of using the benefits of the tools you are using: list comprehensions let you avoid defining simple functions; numpy lets you vectorize things in C if you\\'re doing the right things. \\n\\npython -m timeit \"from timeme import x, times_five\" \"[item + item + item + item + item for item in x]\"\\n1000 loops, best of 3: 285 usec per loop\\n\\npython -m timeit \"import numpy; x = numpy.arange(1000)\" \"x + x + x + x + x\"\\n10000 loops, best of 3: 39.5 usec per loop\\n\\n\\nBut that\\'s not allâ\\x80\\x94there\\'s more. Consider the power of an algorithm change. It can be even more dramatic.\\n\\npython -m timeit \"from timeme import x, times_five\" \"[5 * item for item in x]\"\\n10000 loops, best of 3: 147 usec per loop\\n\\npython -m timeit \"import numpy; x = numpy.arange(1000)\" \"5 * x\"\\n100000 loops, best of 3: 16.6 usec per loop\\n\\n\\nSometimes an algorithm change can be even more effective. This will be more and more effective as the numbers get bigger.\\n\\npython -m timeit \"from timeme import square, x\" \"map(square, x)\"\\n10 loops, best of 3: 41.8 msec per loop\\n\\npython -m timeit \"from timeme import good_square, x\" \"map(good_square, x)\"\\n1000 loops, best of 3: 370 usec per loop\\n\\n\\nAnd even now, this all may have little bearing on your actual problem. It looks like numpy is so great if you can use it right, but it has its limitations: none of these numpy examples used actual Python objects in the arrays. That complicates what must be done; a lot even. And what if we do get to use C datatypes? These are less robust than Python objects. They aren\\'t nullable. The integers overflow. You have to do some extra work to retrieve them. They\\'re statically typed. Sometimes these things prove to be problems, even unexpected ones. \\n\\nSo there you go: a definitive answer. \"It depends.\"\\n\\n\\n\\n# timeme.py\\n\\nx = xrange(1000)\\n\\ndef times_five(a):\\n    return a + a + a + a + a\\n\\ndef square(a):\\n    if a == 0:\\n        return 0\\n\\n    value = a\\n    for i in xrange(a - 1):\\n        value += a\\n    return value\\n\\ndef good_square(a):\\n    return a ** 2\\n\\n'},\n {'prompt': 'How can I get running process list using Python on Linux?\\n',\n  'completion': \"IMO looking at the /proc filesystem is less nasty than hacking the text output of ps.\\n\\nimport os\\npids = [pid for pid in os.listdir('/proc') if pid.isdigit()]\\n\\nfor pid in pids:\\n    try:\\n        print open(os.path.join('/proc', pid, 'cmdline'), 'rb').read()\\n    except IOError: # proc has already terminated\\n        continue\\n\\n\"},\n {'prompt': \"I want my class to implement Save and Load functions which simply do a pickle of the class. But apparently you cannot use 'self' in the fashion below. How can you do this?\\n\\n    self = cPickle.load(f)\\n\\n    cPickle.dump(self,f,2)\\n\\n\",\n  'completion': \"This is what I ended up doing. Updating the __dict__ means we keep any new member variables I add to the class and just update the ones that were there when the object was last pickle'd. It seems the simplest while maintaining the saving and loading code inside the class itself so calling code just does an object.Save().\\n\\ndef Load(self):\\n    f = open(self.filename,'rb')\\n    tmp_dict = cPickle.load(f)\\n    f.close()          \\n\\n    self.__dict__.update(tmp_dict) \\n\\n\\ndef Save(self):\\n    f = open(self.filename,'wb')\\n    cPickle.dump(self.__dict__,f,2)\\n    f.close()\\n\\n\"},\n {'prompt': \"I've always thought of the if not x is None version to be more clear, but Google's style guide implies (based on this excerpt) that they use if x is not None. Is there any minor performance difference (I'm assuming not), and is there any case where one really doesn't fit (making the other a clear winner for my convention)?*\\n\\n*I'm referring to any singleton, rather than just None.\\n\\n\\n  ...to compare singletons like\\n  None. Use is  or is not.\\n\\n\",\n  'completion': \"There's no performance difference, as they compile to the same bytecode:\\n\\nPython 2.6.2 (r262:71600, Apr 15 2009, 07:20:39)\\n>>> import dis\\n>>> def f(x):\\n...    return x is not None\\n...\\n>>> dis.dis(f)\\n  2           0 LOAD_FAST                0 (x)\\n              3 LOAD_CONST               0 (None)\\n              6 COMPARE_OP               9 (is not)\\n              9 RETURN_VALUE\\n>>> def g(x):\\n...   return not x is None\\n...\\n>>> dis.dis(g)\\n  2           0 LOAD_FAST                0 (x)\\n              3 LOAD_CONST               0 (None)\\n              6 COMPARE_OP               9 (is not)\\n              9 RETURN_VALUE\\n\\n\\nStylistically, I try to avoid not x is y.  Although the compiler will always treat it as not (x is y), a human reader might misunderstand the construct as (not x) is y.  If I write x is not y then there is no ambiguity.\\n\"},\n {'prompt': \"I'm interested in filling out existing PDF forms programatically. All I really need to do is pull information from user input and then place the appropriate text over an existing PDF in the appropriate locations. I can already do this with reportlab by feeding the same sheet of paper into a printer, twice, but this just really rubs me the wrong way.\\n\\nI'm tempted to just personally reverse engineer each existing PDF and draw every line and character myself before adding the user-inputted text, but I wanted to check to see if there was an easy way to take an existing PDF and set it as a background for some extra text. I'd really prefer to use python as it's the only language I feel comfortable with.\\n\\nI also realize that I could just scan the document itself and use the resulting raster image as a background, but I would prefer the precision of vector graphics.\\n\\nIt seems like ReportLab has a commercial product with this functionality, and the specific function I'm looking for is in it (copyPages) - but it seems like overkill to pay for a 4 figure product for a single, simple function for a nonprofit use. \\n\",\n  'completion': 'If the PDF forms are real AcroForms you can use iText to fill them. I don\\'t know if there\\'s other port than iText (java, original) and iTextSharp (c#) but it\\'s easy to use and free if you don\\'t mind to open-source your solution. You can take a look at this sample code or (java snippet):\\n\\nString formFile = \"/path/to/myform.pdf\"\\nString newFile = \"/path/to/output.pdf\"\\nPdfReader reader = new PdfReader(formFile);\\nFileOutputStream outStream = new FileOutputStream(newFile);\\nPdfStamper stamper = new PdfStamper(reader, outStream);\\nAcroFields fields = stamper.getAcroFields();\\n\\n// fill the form\\nfields.setField(\"name\", \"Shane\");\\nfields.setField(\"url\", \"http://stackoverflow.com\");\\n\\n// PDF infos\\nHashMap<String, String> infoDoc = new HashMap<String, String>();\\ninfoDoc.put(\"Title\", \"your title here\");\\ninfoDoc.put(\"Author\", \"JRE ;)\");\\nstamper.setMoreInfo(infoDoc);\\n\\n// Flatten the PDF & cleanup\\nstamper.setFormFlattening(true);\\nstamper.close();\\nreader.close();\\noutStream.close();\\n\\n'},\n {'prompt': 'One particular quirk of the (otherwise quite powerful) re module in Python is that re.split() will never split a string on a zero-length match, for example if I want to split a string along word boundaries: \\n\\n>>> re.split(r\"\\\\s+|\\\\b\", \"Split along words, preserve punctuation!\")\\n[\\'Split\\', \\'along\\', \\'words,\\', \\'preserve\\', \\'punctuation!\\']\\n\\n\\ninstead of \\n\\n[\\'\\', \\'Split\\', \\'along\\', \\'words\\', \\',\\', \\'preserve\\', \\'punctuation\\', \\'!\\']\\n\\n\\nWhy does it have this limitation? Is it by design? Do other regex flavors behave like this?\\n',\n  'completion': 'It\\'s a design decision that was made, and could have gone either way. Tim Peters made this post to explain:\\n\\n\\n  For example, if you split \"abc\" by the pattern x*, what do you \\n  expect?  The pattern matches (with length 0) at 4 places, \\n  but I bet most people would be surprised to get\\n  \\n  [\\'\\', \\'a\\', \\'b\\', \\'c\\', \\'\\']\\n  \\n  back instead of (as they do get)\\n  \\n  [\\'abc\\'] \\n\\n\\nSome others disagree with him though. Guido van Rossum doesn\\'t want it changed due to backwards compatibility issues. He did say:\\n\\n\\n  I\\'m okay with adding a flag to enable this behavior though.\\n\\n\\nEdit:\\n\\nThere is a workaround posted by Jan Burgy:\\n\\n>>> s = \"Split along words, preserve punctuation!\"\\n>>> re.sub(r\"\\\\s+|\\\\b\", \\'\\\\f\\', s).split(\\'\\\\f\\')\\n[\\'\\', \\'Split\\', \\'along\\', \\'words\\', \\',\\', \\'preserve\\', \\'punctuation\\', \\'!\\']\\n\\n\\nWhere \\'\\\\f\\' can be replaced by any unused character.\\n'},\n {'prompt': 'I have a python function that has a deterministic result. It takes a long time to run and generates a large output:\\n\\ndef time_consuming_function():\\n    # lots_of_computing_time to come up with the_result\\n    return the_result\\n\\n\\nI modify time_consuming_function from time to time, but I would like to avoid having it run again while it\\'s unchanged. [time_consuming_function only depends on functions that are immutable for the purposes considered here; i.e. it might have functions from Python libraries but not from other pieces of my code that I\\'d change.] The solution that suggests itself to me is to cache the output and also cache some \"hash\" of the function. If the hash changes, the function will have been modified, and we have to re-generate the output.\\n\\nIs this possible or ridiculous?\\n\\n\\n\\nUpdated: based on the answers, it looks like what I want to do is to \"memoize\" time_consuming_function, except instead of (or in addition to) arguments passed into an invariant function, I want to account for a function that itself will change.\\n',\n  'completion': \"If I understand your problem, I think I'd tackle it like this. It's a touch evil, but I think it's more reliable and on-point than the other solutions I see here.\\n\\nimport inspect\\nimport functools\\nimport json\\n\\ndef memoize_zeroadic_function_to_disk(memo_filename):\\n    def decorator(f):\\n        try:\\n            with open(memo_filename, 'r') as fp:\\n                cache = json.load(fp)\\n        except IOError:\\n            # file doesn't exist yet\\n            cache = {}\\n\\n        source = inspect.getsource(f)\\n\\n        @functools.wraps(f)\\n        def wrapper():\\n            if source not in cache:\\n                cache[source] = f()\\n                with open(memo_filename, 'w') as fp:\\n                    json.dump(cache, fp)\\n\\n            return cache[source]\\n        return wrapper\\n    return decorator\\n\\n@memoize_zeroadic_function_to_disk(...SOME PATH HERE...)\\ndef time_consuming_function():\\n    # lots_of_computing_time to come up with the_result\\n    return the_result\\n\\n\"},\n {'prompt': \"In Python, if you want to programmatically import a module, you can do:\\n\\nmodule = __import__('module_name')\\n\\n\\nIf you want to import a submodule, you would think it would be a simple matter of:\\n\\nmodule = __import__('module_name.submodule')\\n\\n\\nOf course, this doesn't work; you just get module_name again. You have to do:\\n\\nmodule = __import__('module_name.submodule', fromlist=['blah'])\\n\\n\\nWhy? The actual value of fromlist don't seem to matter at all, as long as it's non-empty. What is the point of requiring an argument, then ignoring its values?\\n\\nMost stuff in Python seems to be done for good reason, but for the life of me, I can't come up with any reasonable explanation for this behavior to exist.\\n\",\n  'completion': 'In fact, the behaviour of __import__() is entirely because of the implementation of the import statement, which calls __import__(). There\\'s basically five slightly different ways __import__() can be called by import (with two main categories):\\n\\nimport pkg\\nimport pkg.mod\\nfrom pkg import mod, mod2\\nfrom pkg.mod import func, func2\\nfrom pkg.mod import submod\\n\\n\\nIn the first and the second case, the import statement should assign the \"left-most\" module object to the \"left-most\" name: pkg. After import pkg.mod you can do pkg.mod.func() because the import statement introduced the local name pkg, which is a module object that has a mod attribute. So, the __import__() function has to return the \"left-most\" module object so it can be assigned to pkg. Those two import statements thus translate into:\\n\\npkg = __import__(\\'pkg\\')\\npkg = __import__(\\'pkg.mod\\')\\n\\n\\nIn the third, fourth and fifth case, the import statement has to do more work: it has to assign to (potentially) multiple names, which it has to get from the module object. The __import__() function can only return one object, and there\\'s no real reason to make it retrieve each of those names from the module object (and it would make the implementation a lot more complicated.) So the simple approach would be something like (for the third case):\\n\\ntmp = __import__(\\'pkg\\')\\nmod = tmp.mod\\nmod2 = tmp.mod2\\n\\n\\nHowever, that won\\'t work if pkg is a package and mod or mod2 are modules in that package that are not already imported, as they are in the third and fifth case. The __import__() function needs to know that mod and mod2 are names that the import statement will want to have accessible, so that it can see if they are modules and try to import them too. So the call is closer to:\\n\\ntmp = __import__(\\'pkg\\', fromlist=[\\'mod\\', \\'mod2\\'])\\nmod = tmp.mod\\nmod2 = tmp.mod2\\n\\n\\nwhich causes __import__() to try and load pkg.mod and pkg.mod2 as well as pkg (but if mod or mod2 don\\'t exist, it\\'s not an error in the __import__() call; producing an error is left to the import statement.) But that still isn\\'t the right thing for the fourth and fifth example, because if the call were so:\\n\\ntmp = __import__(\\'pkg.mod\\', fromlist=[\\'submod\\'])\\nsubmod = tmp.submod\\n\\n\\nthen tmp would end up being pkg, as before, and not the pkg.mod module you want to get the submod attribute from. The implementation could have decided to make it so the import statement does extra work, splitting the package name on . like the __import__() function already does and traversing the names, but this would have meant duplicating some of the effort. So, instead, the implementation made __import__() return the right-most module instead of the left-most one if and only if fromlist is passed and not empty.\\n\\n(The import pkg as p and from pkg import mod as m syntax doesn\\'t change anything about this story except which local names get assigned to -- the __import__() function sees nothing different when as is used, it all remains in the import statement implementation.)\\n'},\n {'prompt': 'I have an array like:\\n\\na = array([[1,2,3],[3,4,5],[4,5,6]])\\n\\n\\nwhat\\'s the most efficient way to slice out a 1x2 array out of this that has only the first two columns of \"a\"?\\n\\nI.e.,\\n\\narray([[2,3],[4,5],[5,6]]) in this case.\\n\\n\\nthanks.\\n',\n  'completion': 'Two dimensional numpy arrays are indexed using a[i,j] (not a[i][j]), but you can use the same slicing notation with numpy arrays and matrices as you can with ordinary matrices in python (just put them in a single []):\\n\\n\\n>>> from numpy import array\\n>>> a = array([[1,2,3],[3,4,5],[4,5,6]])\\n>>> a[:,1:]\\narray([[2, 3],\\n       [4, 5],\\n       [5, 6]])\\n\\n'},\n {'prompt': \"I want count the same elements of two lists. Lists can have duplicate elements, so I can't convert this to sets and use & operator.\\n\\na=[2,2,1,1]\\nb=[1,1,3,3]\\n\\n\\nset(a) & set(b) work\\na & b don't work  \\n\\nIt is possible to do it withoud set and dictonary?\\n\",\n  'completion': \"In Python 3.x (and Python 2.7, when it's released), you can use collections.Counter for this:\\n\\n>>> from collections import Counter\\n>>> list((Counter([2,2,1,1]) & Counter([1,3,3,1])).elements())\\n[1, 1]\\n\\n\\nHere's an alternative using collections.defaultdict (available in Python 2.5 and later).  It has the nice property that the order of the result is deterministic (it essentially corresponds to the order of the second list).\\n\\nfrom collections import defaultdict\\n\\ndef list_intersection(list1, list2):\\n    bag = defaultdict(int)\\n    for elt in list1:\\n        bag[elt] += 1\\n\\n    result = []\\n    for elt in list2:\\n        if elt in bag:\\n            # remove elt from bag, making sure\\n            # that bag counts are kept positive\\n            if bag[elt] == 1:\\n                del bag[elt]\\n            else:\\n                bag[elt] -= 1\\n            result.append(elt)\\n\\n    return result\\n\\n\\nFor both these solutions, the number of occurrences of any given element x in the output list is the minimum of the numbers of occurrences of x in the two input lists.  It's not clear from your question whether this is the behavior that you want.\\n\"},\n {'prompt': 'I have an uniform list of objects in python:\\n\\nclass myClass(object):\\n    def __init__(self, attr):\\n        self.attr = attr\\n        self.other = None\\n\\nobjs = [myClass (i) for i in range(10)]\\n\\n\\nNow I want to extract a list with some attribute of that class (let\\'s say attr), in order to pass it so some function (for plotting that data for example)\\n\\nWhat is the pythonic way of doing it,\\n\\nattr=[o.attr for o in objsm]\\n\\n\\n?\\n\\nMaybe derive list and add a method to it, so I can use some idiom like\\n\\nobjs.getattribute(\"attr\")\\n\\n\\n?\\n',\n  'completion': \"attrs = [o.attr for o in objs] was the right code for making a list like the one you describe. Don't try to subclass list for this. Is there something you did not like about that snippet?\\n\"},\n {'prompt': \"I've written a fairly simple filter in python using ElementTree to munge the contexts of some xml files. And it works, more or less. \\n\\nBut it reorders the attributes of various tags, and I'd like it to not do that.\\n\\nDoes anyone know a switch I can throw to make it keep them in specified order?\\n\\nContext for this\\n\\nI'm working with and on a particle physics tool that has a complex, but oddly limited configuration system based on xml files. Among the many things setup that way are the paths to various static data files. These paths are hardcoded into the existing xml and there are no facilities for setting or varying them based on environment variables, and in our local installation they are necessarily in a different place.\\n\\nThis isn't a disaster because the combined source- and build-control tool we're using allows us to shadow certain files with local copies. But even thought the data fields are static the xml isn't, so I've written a script for fixing the paths, but with the attribute rearrangement diffs between the local and master versions are harder to read than necessary.\\n\\n\\n\\nThis is my first time taking ElementTree for a spin (and only my fifth or sixth python project) so maybe I'm just doing it wrong.\\n\\nAbstracted for simplicity the code looks like this:\\n\\ntree = elementtree.ElementTree.parse(inputfile)\\ni = tree.getiterator()\\nfor e in i:\\n    e.text = filter(e.text)\\ntree.write(outputfile)\\n\\n\\nReasonable or dumb?\\n\\n\\n\\nRelated links:\\n\\n\\nHow can I get the order of an element attribute list using Python xml.sax?\\nPreserve order of attributes when modifying with minidom\\n\\n\",\n  'completion': 'Nope. ElementTree uses a dictionary to store attribute values, so it\\'s inherently unordered.\\n\\nEven DOM doesn\\'t guarantee you attribute ordering, and DOM exposes a lot more detail of the XML infoset than ElementTree does. (There are some DOMs that do offer it as a feature, but it\\'s not standard.)\\n\\nCan it be fixed? Maybe. Here\\'s a stab at it that replaces the dictionary when parsing with an ordered one (collections.OrderedDict()).\\n\\nfrom xml.etree import ElementTree\\nfrom collections import OrderedDict\\nimport StringIO\\n\\nclass OrderedXMLTreeBuilder(ElementTree.XMLTreeBuilder):\\n    def _start_list(self, tag, attrib_in):\\n        fixname = self._fixname\\n        tag = fixname(tag)\\n        attrib = OrderedDict()\\n        if attrib_in:\\n            for i in range(0, len(attrib_in), 2):\\n                attrib[fixname(attrib_in[i])] = self._fixtext(attrib_in[i+1])\\n        return self._target.start(tag, attrib)\\n\\n>>> xmlf = StringIO.StringIO(\\'<a b=\"c\" d=\"e\" f=\"g\" j=\"k\" h=\"i\"/>\\')\\n\\n>>> tree = ElementTree.ElementTree()\\n>>> root = tree.parse(xmlf, OrderedXMLTreeBuilder())\\n>>> root.attrib\\nOrderedDict([(\\'b\\', \\'c\\'), (\\'d\\', \\'e\\'), (\\'f\\', \\'g\\'), (\\'j\\', \\'k\\'), (\\'h\\', \\'i\\')])\\n\\n\\nLooks potentially promising.\\n\\n>>> s = StringIO.StringIO()\\n>>> tree.write(s)\\n>>> s.getvalue()\\n\\'<a b=\"c\" d=\"e\" f=\"g\" h=\"i\" j=\"k\" />\\'\\n\\n\\nBah, the serialiser outputs them in canonical order.\\n\\nThis looks like the line to blame, in ElementTree._write:\\n\\n            items.sort() # lexical order\\n\\n\\nSubclassing or monkey-patching that is going to be annoying as it\\'s right in the middle of a big method.\\n\\nUnless you did something nasty like subclass OrderedDict and hack items to return a special subclass of list that ignores calls to sort(). Nah, probably that\\'s even worse and I should go to bed before I come up with anything more horrible than that.\\n'},\n {'prompt': \"yolk -l gives me information that I've got 114 packages installed on my Ubuntu 10.04. After creating new virtualenv directory using \\n\\nvirtualenv virt_env/virt1 --no-site-packages --clear\\n\\nI switched to that, my prompt changed and then yolk -l gives me again the same 114 packages. \\n\\nWhat is going on there?\\n\",\n  'completion': 'Activating a virtualenv works by changing your shell PATH so the virtualenv\\'s bin/ directory is first. This is all it does. This means that when you run \"python\" it runs the virtualenv\\'s copy of the Python binary instead of your global system python.\\n\\nIf you have yolk installed globally, however, the only \"yolk\" binary on your PATH is /usr/local/bin/yolk or some such; activating the virtualenv doesn\\'t change this (because there\\'s no \"yolk\" script in your virtualenv bin/ dir). And the /usr/local/bin/yolk script naturally has your system Python interpreter in its shebang line.\\n\\nThis is why installing yolk into the virtualenv fixes the problem; because it adds a yolk script in your virtualenv bin/ dir that has the virtualenv\\'s python in its shebang line.\\n\\nIf you don\\'t want to install yolk in each virtualenv, you could also just copy the yolk script-wrapper from /usr/local/bin or wherever it is into your virtualenv\\'s bin dir, and manually change the shebang line to point to your virtualenv\\'s python. This won\\'t work with a --no-site-packages virtualenv, though, because the script wrapper then won\\'t be able to find the actual yolk packages it needs to import! If you want to use yolk within a --no-site-packages virtualenv, really your only choice is to install it there.\\n'},\n {'prompt': 'I have a string of HTML stored in a database. Unfortunately it contains characters such as Â®\\nI want to replace these characters by their HTML equivalent, either in the DB itself or using a Find Replace in my Python / Django code.\\n\\nAny suggestions on how I can do this? \\n',\n  'completion': \"You can use that the ASCII characters are the first 128 ones, so get the number of each character with ord and strip it if it's out of range\\n\\n# -*- coding: utf-8 -*-\\n\\ndef strip_non_ascii(string):\\n    ''' Returns the string without non ASCII characters'''\\n    stripped = (c for c in string if 0 < ord(c) < 127)\\n    return ''.join(stripped)\\n\\n\\ntest = u'Ã©Ã¡Ã©123456tgreÃ¡Ã©@â\\x82¬'\\nprint test\\nprint strip_non_ascii(test)\\n\\n\\nResult\\n\\nÃ©Ã¡Ã©123456tgreÃ¡Ã©@â\\x82¬\\n123456tgre@\\n\\n\\nPlease note that @ is included because, well, after all it's an ASCII character. If you want to strip a particular subset (like just numbers and uppercase and lowercase letters), you can limit the range looking at a ASCII table\\n\\nEDITED: After reading your question again, maybe you need to escape your HTML code, so all those characters appears correctly once rendered. You can use the escape filter on your templates.\\n\"},\n {'prompt': \"I wrote a short script that never terminates. This script continuously generates output that I have to check on every now and then. I'm running it on a lab computer through SSH, and redirecting the output to a file in my public_html folder on that machine.\\n\\npython script.py > ~/public_html/results.txt\\n\\n\\nHowever, the results don't show up immediately when I refresh the address. The results show up when I terminate the program, but as I said, it doesn't halt by itself. Is that redirect (>) being lazy with with writing? Is there a way to continuously (or with an interval) update the results in the file?\\n\\nOr is it the webserver that doesn't update the file while it is still being written? \\n\",\n  'completion': 'You need to flush the output sys.stdout.flush() (or smth) if you want to see it immediately. See this\\n'},\n {'prompt': 'When I try it I get:\\n\\n\\n  ImportError: dlopen(/Library/Frameworks/Python.framework/Versions/2.5/lib/python2.5/site-packages/cscalelib.so, 2): Symbol not found: _glBindFramebufferEXT\\n    Referenced from: /Library/Frameworks/Python.framework/Versions/2.5/lib/python2.5/site-packages/cscalelib.so\\n    Expected in: dynamic lookup\\n\\n\\nI\\'ve tried all sort of things in the setup.py file. What do I actually need to put in it to link to OpenGL properly? My code compiles fine so there\\'s no point putting that on there. Here is setup.py\\n\\nfrom distutils.core import setup, Extension\\n\\nmodule1 = Extension(\\'cscalelib\\',\\n              extra_compile_args = [\"-framework OpenGL\", \"-lm\", \"-lGL\", \"-lGLU\"],\\n                    sources = [\\'cscalelib.cpp\\'])\\n\\nsetup (name = \\'cscalelib\\',\\n       version = \\'0.1\\',\\n       description = \\'Test for setup_framebuffer\\',\\n       ext_modules = [module1])\\n\\n',\n  'completion': \"I didn't realise I had to remove the build directory. Now it imports correctly. \\n\\nFor anyone that needs to know you need: extra_link_args=['-framework', 'OpenGL'] Delete the build directory and try it again. It will work. \\n\"},\n {'prompt': 'I\\'m using construction like this:\\n\\ndoc = parse(url).getroot()\\nlinks = doc.xpath(\"//a[text()=\\'some text\\']\")\\n\\n\\nBut I need to select all links which have text beginning with \"some text\", so I\\'m wondering is there any way to use regexp here? Didn\\'t find anything in lxml documentation\\n',\n  'completion': 'You can do this (although you don\\'t need regular expressions for the example). Lxml supports regular expressions from the EXSLT extension functions. (see the lxml docs for the XPath class, but it also works for the xpath() method)\\n\\ndoc.xpath(\"//a[re:match(text(), \\'some text\\')]\", \\n        namespaces={\"re\": \"http://exslt.org/regular-expressions\"})\\n\\n\\nNote that you need to give the namespace mapping, so that it knows what the \"re\" prefix in the xpath expression stands for.\\n'},\n {'prompt': 'I had written a scipt in Java with Webdriver and it worked fine and below is the code for the sample\\n\\nimport org.junit.After;\\nimport org.junit.AfterClass;\\nimport org.junit.Before;\\nimport org.junit.BeforeClass;\\nimport org.openqa.selenium.WebDriver;\\nimport org.openqa.selenium.WebDriverBackedSelenium;\\nimport org.openqa.selenium.firefox.FirefoxDriver;\\nimport com.thoughtworks.selenium.Selenium;\\nimport java.util.*;\\nimport java.lang.Thread.*;\\n\\npublic class Login {\\n\\n @BeforeClass\\n public static void setUpBeforeClass() throws Exception {\\n }\\n\\n @AfterClass\\n public static void tearDownAfterClass() throws Exception {\\n }\\n\\n @Before\\n public void setUp() throws Exception {\\n }\\n\\n @After\\n public void tearDown() throws Exception {\\n }\\n\\n    public static void main(String[] args) {\\n         WebDriver driver = new FirefoxDriver();\\n         Selenium selenium = new WebDriverBackedSelenium(driver,     \"http://192.168.10.10:8080/\");\\n         selenium.open(\"/\");\\n   selenium.keyPress(\"name=user_id\", \"admin\");\\n   }\\n     }\\n\\n}\\n\\n\\nBut my requirement is to implement the same in python with webdriver, can you please let me know how this can be done with the above example and webdriver binaries and how to do setup for the same\\n',\n  'completion': 'Did you read the instructions at python bindings for WebDriver ?\\n\\nexample2.py is clear, although not a direct translation of your code:\\n\\nimport unittest\\nfrom google_one_box import GoogleOneBox\\nfrom selenium.firefox.webdriver import WebDriver\\n\\nclass ExampleTest2(unittest.TestCase):\\n    \"\"\"This example shows how to use the page object pattern.\\n\\n    For more information about this pattern, see:\\n    http://code.google.com/p/webdriver/wiki/PageObjects\\n    \"\"\"\\n\\n    def setUp(self):\\n        self._driver = WebDriver()\\n\\n    def tearDown(self):\\n        self._driver.quit()\\n\\n    def testSearch(self):\\n        google = GoogleOneBox(self._driver, \"http://www.google.com\")\\n        res = google.search_for(\"cheese\")\\n        self.assertTrue(res.link_contains_match_for(\"Wikipedia\"))\\n\\nif __name__ == \"__main__\":\\n    unittest.main()\\n\\n\\nA test module, GoogleOneBox, models a page that has a google search bar\\n(the url moved a little).\\n'},\n {'prompt': 'I need to match two cases by one reg expression and do replacement\\n\\n\\'long.file.name.jpg\\' -> \\'long.file.name_suff.jpg\\'\\n\\n\\'long.file.name_a.jpg\\' -> \\'long.file.name_suff.jpg\\'\\n\\nI\\'m trying to do the following\\n\\nre.sub(\\'(\\\\_a)?\\\\.[^\\\\.]*$\\' , \\'_suff.\\',\"long.file.name.jpg\")\\n\\n\\nBut this is cut the extension \\'.jpg\\' and I\\'m getting\\n\\nlong.file.name_suff. instead of long.file.name_suff.jpg\\nI understand that this is because of [^.]*$ part, but I can\\'t exclude it, because\\nI have to find last occurance of \\'_a\\' to replace or last \\'.\\' \\n\\nIs there a way to replace only part of the match? \\n',\n  'completion': 'Put a capture group around the part that you want to preserve, and then include a reference to that capture group within your replacement text.\\n\\nre.sub(r\\'(\\\\_a)?\\\\.([^\\\\.]*)$\\' , r\\'_suff.\\\\2\\',\"long.file.name.jpg\")\\n\\n'},\n {'prompt': 'I have such code in Python:\\n\\ndef send_start(self, player):\\n    for p in self.players:\\n        player[\"socket\"].send_cmd(\\'<player id=\"%s\" name=\"%s\" you=\"%s\" avatar=\"*.png\" bank=\"%s\" />\\'%(self.players.index(p)+1, p[\\'name\\'], int(player[\"pid\"]==p[\"pid\"]), 0))\\n    player[\"socket\"].send_cmd(\\'<game playerid=\"%s\" />\\'%(self.turnnow))\\n    player[\"socket\"].send_cmd(\"<start />\")\\n\\n\\nAnd the error is in the title of this post. What\\'s wrong?\\n',\n  'completion': 'Your code would fail if self.turnnow is an empty tuple:\\n\\n>>> var = ()\\n>>> print \"%s\" % (var)\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 2, in <module>\\nTypeError: not enough arguments for format string\\n>>> print \"%s\" % (var,)\\n()\\n\\n\\nThis is because a parenthesized expression in Python does not automatically become a tuple if the tuple would have only one element. (expr) is equivalent to expr. (expr, ) is equivalent to a one-element tuple holding expr as the first element. So, try adding a comma after self.turnnow in the second print statement.\\n'},\n {'prompt': 'I am trying to figure out a way where I can create a tab-delimited file containing data from user-defined fields and allow the user to download that file on google app engine.\\n\\nThe sandbox environment that the app runs in does not allow the application to write to disk.  Is there another way where I can create a downloadable file?\\n',\n  'completion': \"Sure there is! You can output your data as csv, for instance. All you need to do is to change the Content-Type header.\\n\\nIt's something like this:\\n\\nclass Test(webapp.RequestHandler):\\n    def get(self, upload_type):\\n        self.response.headers['Content-Type'] = 'text/csv'\\n        self.response.out.write(','.join(['a', 'cool', 'test']))\\n\\n\"},\n {'prompt': \"The Ruby LESS gem looks awesome - and I am working on a Python/Pylons web project where it would be highly useful.  CSS is, as someone we're all familiar with recently wrote about, clunky in some important ways.  So I'd like to make it easier on myself.\\n\\nIs there an existing Python module or library that provides parallel functionality?\\n\",\n  'completion': 'I have need for a Python lesscss compiler too, so have started work on one here: http://code.google.com/p/lesscss-python/\\n\\nVersion 0.0.1 has been released, with no support for namespaces/accessors. It is probably riddled with bugs too.\\n\\nPlease feel free to chip in with bug reports/coding or have a look at less-js http://fadeyev.net/2010/06/19/lessjs-will-obsolete-css/.\\n'},\n {'prompt': 'Is it possible to have multiple models included in a single ModelForm in django?  I am trying to create a profile edit form.  So I need to include some fields from the User model and the UserProfile model.  Currently I am using 2 forms like this\\n\\nclass UserEditForm(ModelForm):\\n\\n    class Meta:\\n        model = User\\n        fields = (\"first_name\", \"last_name\")\\n\\nclass UserProfileForm(ModelForm):\\n\\n    class Meta:\\n        model = UserProfile\\n        fields = (\"middle_name\", \"home_phone\", \"work_phone\", \"cell_phone\")\\n\\n\\nIs there a way to consolidate these into one form or do I just need to create a form and handle the db loading and saving myself?\\n',\n  'completion': \"You can just show both forms in the template inside of one <form> html element. Then just process the forms separately in the view. You'll still be able to use form.save() and not have to process db loading and saving yourself.\\n\\nIn this case you shouldn't need it, but if you're going to be using forms with the same field names, look into the prefix kwarg for django forms. (I answered a question about it here).\\n\"},\n {'prompt': \"I'm trying to sync my db from a view, something like this:\\n\\nfrom django import http\\nfrom django.core import management\\n\\ndef syncdb(request):\\n    management.call_command('syncdb')\\n    return http.HttpResponse('Database synced.')\\n\\n\\nThe issue is, it will block the dev server by asking for user input from the terminal. How can I pass it the '--noinput' option to prevent asking me anything?\\n\\nI have other ways of marking users as super-user, so there's no need for the user input, but I really need to call syncdb (and flush) programmatically, without logging on to the server via ssh. Any help is appreciated.\\n\",\n  'completion': \"management.call_command('syncdb', interactive=False)\\n\\n\"},\n {'prompt': \"I'm writing a crossplatform python script on windows using Eclipse with the Pydev plugin. The script makes use of the os.symlink() and os.readlink() methods if the current platform isn't NT. \\n\\nSince the os.symlink() and os.readlink() methods aren't available on the Windows platform Pydev flags them as undefined variables--like so: \\n\\n\\n\\nQuestion:\\n\\nIs there a way to ignore specific undefined variable name errors without modifying my source file?   \\n\\nedit: I found a way to ignore undefined variable errors from this answer on stackoverflow.\\nI'll leave the question open in case there is a way to solve this using project file or Pydev setting.\\n\",\n  'completion': 'I use pydev + pylint.  \\n\\nWith pylint you can add which messages to ignore in the Preferences>Pydev>Pylint>\"Aggruments to pass to pylint\" section.\\n\\n--disable-msg=W0232,F0401\\n\\n\\nYou can ignore messages in-line as well with comments:\\n\\nos.symlink(target, symlink) # IGNORE:<MessageID> \\n\\n\\nMouse-over the \"x\" where the line numbers are to see the message id.\\n'},\n {'prompt': 'I\\'m trying to create a custom TCP stack using Python 2.6.5 on Windows 7 to serve valid http page requests on port 80 locally.  But, I\\'ve run into a snag with what seems like Windows 7 tightened up security.  This code worked on Vista.\\n\\nHere\\'s my sample code:\\n\\nimport SocketServer\\nimport struct\\n\\nclass MyTCPHandler(SocketServer.BaseRequestHandler):\\n    def handle(self):\\n        headerText = \"\"\"HTTP/1.0 200 OK\\n                        Date: Fri, 31 Dec 1999 23:59:59 GMT\\n                        Content-Type: text/html\\n                        Content-Length: 1354\"\"\"\\n        bodyText = \"<html><body>some page</body></html>\"\\n        self.request.send(headerText + \"\\\\n\" + bodyText)\\n\\nif __name__ == \"__main__\":\\n    HOST, PORT = \"localhost\", 80\\n    server = SocketServer.TCPServer((HOST, PORT), MyTCPHandler)\\n    server.serve_forever()\\n\\n\\n\\n  C:\\\\python>python TestServer.py\\n  Traceback (most recent call last):\\n  File \"TestServer.py\", line 19, in\\n  \\n      server = SocketServer.TCPServer((HOST, PORT),\\n  MyTCPHandler)   File\\n  \"C:\\\\Python26\\\\lib\\\\SocketServer.py\",\\n  line 400, in init\\n      self.server_bind()   File \"C:\\\\Python26\\\\lib\\\\SocketServer.py\",\\n  line 411, in server_bind\\n      self.socket.bind(self.server_address) \\n  File \"\", line 1, in bind\\n  \\n  socket.error: [Errno 10013] An attempt\\n  was made to access a socket in a way\\n  forbidden by its access permissions\\n\\n\\nHow exactly do I get this to work on Windows 7?\\n\\n[Edit on 5/5/2010 @ 2344 PDT]  This answer explains that the error is caused by the need for elevated / superuser privileges when accessing ports lower than 1024.  I\\'m going to try using a higher port number to see if that works.  However, I still would like to know why my local admin account can\\'t access port 80.  \\n',\n  'completion': 'I just encountered the same issue, my system is Win7. just use the command on terminal like: netstat -na|findstr port, you will see the port has been used. So if you want to start the server without this message, you can change other port that not been used.\\n'},\n {'prompt': 'I am experiencing an error running django unit tests, I\\'ve not experienced this before, and have been googling it all afternoon.\\n\\nI am getting this error in terminal after running django manage.py test:\\n\\nError: Database test_unconvention couldn\\'t be flushed. Possible reasons:\\n  * The database isn\\'t running or isn\\'t configured correctly.\\n  * At least one of the expected database tables doesn\\'t exist.\\n  * The SQL was invalid.\\nHint: Look at the output of \\'django-admin.py sqlflush\\'. That\\'s the SQL this command wasn\\'t able to run.\\nThe full error: (1146, \"Table \\'test_unconvention.media_image\\' doesn\\'t exist\")\\n\\n\\nThe media_images table is referenced when running django-admin.py sqlflush and generates ok when I run django manage.py syncdb.\\n\\nThis is the Image model which appears to be troublesome:\\n\\nfrom django.db import models\\nfrom django.contrib.contenttypes.models import ContentType\\nfrom django.contrib.contenttypes import generic\\n\\nclass Image(models.Model):\\n  local_image = models.ImageField(upload_to=\"uploads/%Y/%m/%d/\", height_field=\"height\", width_field=\"width\", max_length=255, null=True, blank=True)\\n  remote_image = models.CharField(editable=False, max_length=255, null=True, blank=True)\\n  thirdparty_page = models.CharField(editable=False, max_length=255, blank=True, null=True)\\n  size = models.CharField(editable=False, max_length=25, blank=True, null=True)\\n  content_type = models.ForeignKey(ContentType)\\n  object_id = models.PositiveIntegerField()\\n  content_object = generic.GenericForeignKey(\\'content_type\\', \\'object_id\\')\\n  height = models.PositiveIntegerField(editable=False, blank=True, null=True)\\n  width = models.PositiveIntegerField(editable=False, blank=True, null=True)\\n  created_at = models.DateTimeField(editable=False, auto_now_add=True)\\n  updated_at = models.DateTimeField(editable=False, auto_now=True)\\n\\n  def __unicode__(self):\\n    if self.local_image:\\n      return self.local_image.name\\n    else:\\n      return self.remote_image\\n\\n\\nI appreciate any help, please let me know if I should provide more information!\\n',\n  'completion': 'Solution: Make sure you explicitly define submodules (e.g. common.media) in INSTALLED_APPS and not just the parent module (e.g. common) to make sure that the models are picked up and the test is able to run.\\n'},\n {'prompt': 'how do i add code to an existing function, either before or after?\\n\\nfor example, i have a class:\\n\\n class A(object):\\n     def test(self):\\n         print \"here\"\\n\\n\\nhow do i edit the class wit metaprogramming so that i do this\\n\\n class A(object):\\n     def test(self):\\n         print \"here\"\\n\\n         print \"and here\"\\n\\n\\nmaybe some way of appending another function to test?\\n\\nadd another function such as\\n\\n def test2(self):\\n      print \"and here\"\\n\\n\\nand change the original to\\n\\n class A(object):\\n     def test(self):\\n         print \"here\"\\n         self.test2()\\n\\n\\nis there a way to do this?\\n',\n  'completion': 'You can use a decorator to modify the function if you want.  However, since it\\'s not a decorator applied at the time of the initial definition of the function, you won\\'t be able to use the @ syntactic sugar to apply it.\\n\\n>>> class A(object):\\n...     def test(self):\\n...         print \"orig\"\\n...\\n>>> first_a = A()\\n>>> first_a.test()\\norig\\n>>> def decorated_test(fn):\\n...     def new_test(*args, **kwargs):\\n...         fn(*args, **kwargs)\\n...         print \"new\"\\n...     return new_test\\n...\\n>>> A.test = decorated_test(A.test)\\n>>> new_a = A()\\n>>> new_a.test()\\norig\\nnew\\n>>> first_a.test()\\norig\\nnew\\n\\n\\nDo note that it will modify the method for existing instances as well.\\n\\nEDIT: modified the args list for the decorator to the better version using args and kwargs\\n'},\n {'prompt': 'Here\\'s my code:\\n\\nimport urllib2.request\\n\\nresponse = urllib2.urlopen(\"http://www.google.com\")\\nhtml = response.read()\\nprint(html)\\n\\n\\nAny help?\\n',\n  'completion': 'As stated in the urllib2 documentation at http://docs.python.org/library/urllib2.html:\\n\\n\\n  The urllib2 module has been split across several modules in Python 3.0 named urllib.request and urllib.error. The 2to3 tool will automatically adapt imports when converting your sources to 3\\n\\n\\nSo you should instead be saying\\n\\nfrom urllib.request import urlopen\\nhtml = urlopen(\"http://www.google.com/\")\\nprint(html)\\n\\n\\nYour current, now-edited code sample is incorrect because you are saying urllib.urlopen(\"http://www.google.com/\") instead of just urlopen(\"http://www.google.com/\").\\n'},\n {'prompt': 'I need to write a module which will be used from both CPython and IronPython. What\\'s the best way to detect IronPython, since I need a slightly different behaviour in that case?\\n\\nI noticed that sys.platform is \"win32\" on CPython, but \"cli\" on IronPython.\\n\\nIs there another preferred/standard way of detecting it?\\n',\n  'completion': \"New in Python 2.6 is platform.python_implementation:\\n\\n\\n  Returns a string identifying the Python implementation. Possible return values are: â\\x80\\x98CPythonâ\\x80\\x99, â\\x80\\x98IronPythonâ\\x80\\x99, â\\x80\\x98Jythonâ\\x80\\x99.\\n\\n\\nThat's probably the cleanest way to do it, and that's about as standard as it gets.  However, I believe Jython is still running 2.5, so I'm not sure you can rely on this to detect Jython just yet (but that wasn't part of your question anyway).\\n\"},\n {'prompt': \"I've been playing with google visualization annotated timeline and so far I'm comfortable displaying the data and adding annotations, but I'm fairly confused about how to implement getting additional data when the user zooms the chart using either the zoom links at the top of the chart or the timeline below.\\n\\nA great example of the implementation I'm after is google finance. When you zoom the scale at the bottom shifts and shows the overall trend for the range that is appropriate to the user.\\n\\nThe documentation google provides is fairly basic and dry for a novice such as myself:\\nhttp://code.google.com/apis/visualization/documentation/gallery/annotatedtimeline.html\\n\\nDoes anyone know of a good tutorial on this subject? A python-based tutorial would be awesome!\\n\",\n  'completion': 'Here is a simple example. Unfortunately, it is in Java, but it has the benefit of being simple.\\n'},\n {'prompt': 'Basically, I want to take a \\n\\nDictionary like { \"a\":\"bar\", \"b\":\"blah\", \"c\":\"abc\", \"d\":\"nada\" }\\n\\nand use it to set variables (in an Object) which have the same name as a key in the dictionary.\\n\\nclass Foo(object)\\n{\\n    self.a = \"\"\\n    self.b = \"\"\\n    self.c = \"\"\\n}\\n\\n\\nSo in the the end self.a = \"bar\", self.b = \"blah\", etc... (and key \"d\" is ignored)\\n\\nAny ideas?\\n',\n  'completion': \"Translating your class statement to Python,\\n\\nclass Foo(object):\\n  def __init__(self):\\n    self.a = self.b = self.c = ''\\n  def fromdict(self, d):\\n    for k in d:\\n      if hasattr(self, k):\\n        setattr(self, k, d[k])\\n\\n\\nthe fromdict method seems to have the functionality you request.\\n\"},\n {'prompt': \"Is there any way to make pip play well with multiple versions of Python? For example, I want to use pip to explicitly install things to either my site 2.5 installation or my site 2.6 installation.\\n\\nFor example, with easy_install, I use easy_install-2.{5,6}.\\n\\nAnd, yes â\\x80\\x94 I know about virtualenv, and no â\\x80\\x94 it's not a solution to this particular problem.\\n\",\n  'completion': 'Since version 0.8, Pip supports pip-{version}. You can use it the same as easy_install-{version}:\\n\\n$ pip-2.5 install myfoopackage\\n$ pip-2.6 install otherpackage\\n$ pip-2.7 install mybarpackage\\n\\n\\n\\n\\nEDIT: pip changed its schema to use pipVERSION instead of pip-VERSION in version 1.5. You should use the following if you have pip >= 1.5:\\n\\n$ pip2.6 install otherpackage\\n$ pip2.7 install mybarpackage\\n\\n\\nCheck https://github.com/pypa/pip/pull/1053 for more details\\n\\n\\n\\nReferences:\\n\\n\\nhttps://github.com/pypa/pip/issues/200\\nhttp://www.pip-installer.org/docs/pip/en/0.8.3/news.html#id4\\n\\n'},\n {'prompt': 'I\\'m using BeautifulSoup - python module. I have to find any reference to the div\\'s with id like: \\'post-#\\'.\\nFor example:\\n\\n<div id=\"post-45\">...</div>\\n<div id=\"post-334\">...</div>\\n\\n\\nHow can I filter this?\\n\\nhtml = \\'<div id=\"post-45\">...</div> <div id=\"post-334\">...</div>\\'\\nsoupHandler = BeautifulSoup(html)\\nprint soupHandler.findAll(\\'div\\', id=\\'post-*\\')\\n> []\\n\\n',\n  'completion': 'You can pass a function to findAll:\\n\\n>>> print soupHandler.findAll(\\'div\\', id=lambda x: x and x.startswith(\\'post-\\'))\\n[<div id=\"post-45\">...</div>, <div id=\"post-334\">...</div>]\\n\\n\\nOr a regular expression:\\n\\n>>> print soupHandler.findAll(\\'div\\', id=re.compile(\\'^post-\\'))\\n[<div id=\"post-45\">...</div>, <div id=\"post-334\">...</div>]\\n\\n'},\n {'prompt': \"Was looking to write a little web crawler in python. I was starting to investigate writing it as a multithreaded script, one pool of threads downloading and one pool processing results. Due to the GIL would it actually do simultaneous downloading? How does the GIL affect a web crawler? Would each thread pick some data off the socket, then move on to the next thread, let it pick some data off the socket, etc..? \\n\\nBasically I'm asking is doing a multi-threaded crawler in python really going to buy me much performance vs single threaded?\\n\\nthanks!\\n\",\n  'completion': 'The GIL is not held by the Python interpreter when doing network operations. If you are doing work that is network-bound (like a crawler), you can safely ignore the effects of the GIL.\\n\\nOn the other hand, you may want to measure your performance if you create lots of threads doing processing (after downloading). Limiting the number of threads there will reduce the effects of the GIL on your performance.\\n'},\n {'prompt': 'I have a regression model in which the dependent variable is continuous but ninety percent of the independent variables are categorical(both ordered and unordered) and around thirty percent of the records have missing values(to make matters worse they are missing randomly without any pattern, that is, more that forty five percent of the data hava at least one missing value). There is no a priori theory to choose the specification of the model so one of the key tasks is dimension reduction before running the regression. While I am aware of several methods for dimension reduction for continuous variables I am not aware of a similar statical literature for categorical data (except, perhaps, as a part of correspondence analysis which is basically a variation of principal component analysis on frequency table). Let me also add that the dataset is of moderate size 500000 observations with 200 variables. I have two questions.\\n\\n\\nIs there a good statistical reference out there for dimension reduction for categorical data along with robust imputation (I think the first issue is imputation and then dimension reduction)?\\nThis is linked to implementation of above problem. I have used R extensively earlier and tend to use transcan and impute function heavily for continuous variables and use a variation of tree method to impute categorical values. I have a working knowledge of Python so if something is nice out there for this purpose then I will use it. Any implementation pointers in python or R will be of great help.\\nThank you.\\n\\n',\n  'completion': 'Regarding imputation of categorical data, I would suggest to check the mice package. Also take a look at this presentation which explains how it imputes multivariate categorical data. Another package for Mutliple Imputation of Incomplete Multivariate Data is Amelia. Amelia includes some limited capacity to deal with ordinal and nominal variables. \\n\\nAs for dimensionality reduction for categorical data (i.e. a way to arrange variables into homogeneous clusters), I would suggest the method of Multiple Correspondence Analysis which will give you the latent variables that maximize the homogeneity of the clusters. Similarly to what is done in Principal Component Analysis (PCA) and Factor Analysis, the MCA solution can also be rotated to increase the components simplicity. The idea behind a rotation is to find subsets of variables which coincide more clearly with the rotated components. This implies that maximizing components simplicity can help in factor interpretation and in variables clustering. In R MCA methods are included in packages ade4, MASS, FactoMineR and ca (at least). As for FactoMineR, you can use it through a graphical interface if you add it as an extra menu to the ones already proposed by the Rcmdr package, installing the RcmdrPlugin.FactoMineR\\n'},\n {'prompt': 'I\\'m currently persisting filenames in a sqlite database for my own purposes. Whenever I try to insert a file that has a special character (like Ã© etc.), it throws the following error: \\n\\npysqlite2.dbapi2.ProgrammingError: You must not use 8-bit bytestrings unless you use a text_factory that can interpret 8-bit bytestrings (like text_factory = str). It is highly recommended that you instead just switch your application to Unicode strings.\\n\\n\\nWhen I do \"switch my application over to Unicode strings\" by wrapping the value sent to pysqlite with the unicode method like: unicode(filename), it throws this error: \\n\\nUnicodeDecodeError: \\'ascii\\' codec can\\'t decode byte 0xc3 in position 66: ordinal not in range(128)\\n\\n\\nIs there something I can do to get rid of this? Modifying all of my files to conform isn\\'t an option. \\n\\nUPDATE\\nIf I decode the text via filename.decode(\"utf-8\"), I\\'m still getting the ProgrammingError above. \\n\\nMy actual code looks like this:\\n\\ncursor.execute(\"select * from musiclibrary where absolutepath = ?;\",\\n    [filename.decode(\"utf-8\")])\\n\\n\\nWhat should my code here look like?\\n',\n  'completion': \"You need to specify the encoding of filename for conversion to Unicode, for example: filename.decode('utf-8').  Just using unicode(...) picks the console encoding, which is often unreliable (and often ascii).\\n\"},\n {'prompt': 'Iâ\\x80\\x99ve a bash script Iâ\\x80\\x99ve been using for a Linux environment but now I have to use it on a Windows platform and want to convert the bash script to a python script which I can run.\\n\\nThe bash script is rather simple (I think) and Iâ\\x80\\x99ve tried to convert it by google by way around but canâ\\x80\\x99t convert it successfully.\\n\\nThe bash script looks like this:\\n\\nruns=5\\n\\nqueries=50\\n\\noutfile=outputfile.txt\\n\\ndate  >> $outfile\\n\\n\\necho -e \"\\\\n---------------------------------\"\\necho -e \"\\\\n----------- Normal --------------\"\\necho -e \"\\\\n---------------------------------\"\\necho -e \"\\\\n----------- Normal --------------\" >> $outfile\\nfor ((r = 1; r < ($runs + 1); r++))\\ndo\\n    echo -e \"Run $r of $runs\\\\n\"\\n\\n    db2 FLUSH PACKAGE CACHE DYNAMIC\\n\\n    python reads.py -r1 -pquery1.sql -q$queries -shotelspec -k6 -a5 >> $outfile\\ndone\\n\\n\\nThe main command, the python read.py â\\x80¦ etc. is another python file Iâ\\x80\\x99ve been given and have the arguments as you see.\\n\\nI know it is a lot to ask for, but it would really help me out if someone could convert this to a python script I can use or at least give me some hints and directions.\\n\\nSincerely\\n\\nMestika\\n\\nAdded per request:\\n\\nThis is what I\\'ve written but without success:\\n\\nruns=5\\nqueries=50\\noutfile=ReadsAgain.txt\\nfile = open(\"results.txt\", \"ab\")\\n\\nprint \"\\\\n---------------------------------\"\\nprint \"\\\\n----------- Normal --------------\"\\nprint \"\\\\n---------------------------------\"\\nfile.write(\"\\\\n----------- Normal --------------\\\\n\")\\nprint \"\\\\n------------- Query without Index --------------\"\\nfile.write(\"\\\\n------------- Query without Index --------------\\\\n\")\\nfor r = 1; r < (%s + 1); r++ % runs\\n    print \"Run %s of %s \\\\n\" % r % runs\\n\\n    db2 FLUSH PACKAGE CACHE DYNAMIC\\n\\n    output = python reads.py -r1 -pquery1.sql -q$queries -shotelspec -k6 -a5\\n    file.write(output)\\n\\nfile.close()\\n\\n',\n  'completion': 'Answer\\n\\nLet\\'s break it down into pieces. Especially the pieces you got wrong. :)\\n\\n\\n\\nAssignment\\n\\n\\noutfile=ReadsAgain.txt\\n\\n\\n\\nIt should come to little surprise that you need to put quotes around strings. On the other hand, you have the luxury of putting spaces around the = for readability.\\n\\noutfilename = \"ReadsAgain.txt\"\\n\\n\\n\\n\\nVariable expansion â\\x86\\x92 str.format (or, the % operation)\\n\\n\\npython reads.py <snip/> -q$queries <snip/>\\n\\n\\n\\nSo you know how to do the redirection already, but how do you do the variable expansion? You can use the format method (v2.6+):\\n\\ncommand = \"python reads.py -r1 -pquery1.sql -q{0} -shotelspec -k6 -a5\".format(queries)\\n\\n\\nYou can alternatively use the % operator:\\n\\n#since queries is a number, use %d as a placeholder\\ncommand = \"python reads.py -r1 -pquery1.sql -q%d -shotelspec -k6 -a5\" % queries\\n\\n\\n\\n\\nC-style loop â\\x86\\x92 Object-oriented-style loop\\n\\n\\nfor ((r = 1; r < ($runs + 1); r++)) do done\\n\\n\\n\\nLooping in Python is different from C-style iteration. What happens in Python is you iterate over an iterable object, like for example a list. Here, you are trying to do something runs times, so you would do this:\\n\\nfor r in range(runs):\\n  #loop body here\\n\\n\\nrange(runs) is equivalent to [0,1,...,runs-1], a list of runs = 5 integer elements. So you\\'ll be repeating the body runs times. At every cicle, r is assigned the next item of the list. This is thus completely equivalent to what you are doing in Bash.\\n\\nIf you\\'re feeling daring, use xrange instead. It\\'s completely equivalent but uses more advanced language features (so it is harder to explain in layman\\'s terms) but consumes less resources.\\n\\n\\n\\nOutput redirection â\\x86\\x92 the subprocess module\\n\\nThe \"tougher\" part, if you will: executing a program and getting its output. Google to the rescue! Obviously, the top hit is a stackoverflow question: this one. You can hide all the complexity behind it with a simple function:\\n\\nimport subprocess, shlex\\ndef get_output_of(command):\\n  args = shlex.split(command)\\n  return subprocess.Popen(args,\\n                          stdout=subprocess.PIPE).communicate()[0]\\n  # this only returns stdout\\n\\n\\nSo:\\n\\n\\npython reads.py -r1 -pquery1.sql -q$queries -shotelspec -k6 -a5 >> $outfile\\n\\n\\n\\nbecomes:\\n\\ncommand = \"python reads.py -r1 -pquery1.sql -q%s -shotelspec -k6 -a5\" % queries\\nread_result = get_output_of(command)\\n\\n\\n\\n\\nDon\\'t over-subprocess, batteries are included\\n\\nOptionally, consider that you can get pretty much the same output of date with the following:\\n\\nimport time\\ntime_now = time.strftime(\"%c\", time.localtime()) # Sat May 15 15:42:47 2010\\n\\n\\n(Note the absence of the time zone information. This should be the subject of another question, if it is important to you.)\\n\\n\\n\\nHow your program should look like\\n\\nThe final result should  then look like this:\\n\\nimport subprocess, shlex, time\\ndef get_output_of(command):\\n  #... body of get_output_of\\n#... more functions ...\\nif __name__ = \"__main__\":\\n  #only execute the following if you are calling this .py file directly,\\n  #and not, say, importing it\\n  #... initialization ...\\n  with file(\"outputfile.txt\", \"a\") as output_file: #alternative way to open files, v2.5+\\n    #... write date and other stuff ...\\n    for r in range(runs):\\n      #... loop body here ...\\n\\n\\n\\n\\nPost scriptum\\n\\nThat must look pretty horrible when compared to the relatively simple and short Bash script, right? Python is not a specialized language: it aims to do everything reasonably well, but isn\\'t built directly for running programs and getting the output of those.\\n\\nStill, you wouldn\\'t normally write a database engine in Bash, right? It\\'s different tools for different jobs. Here, unless you\\'re planning to make some changes that would be non-trivial to write with that language, [Ba]sh was definitely the right choice.\\n'},\n {'prompt': \"I'm looking for a tool to nicely generate single-page PDFs. My needs are:\\n\\n\\nAble to put a PDF/EPS/... as a background\\nAbsolute positioning\\nAble to define tables, lists\\nAble to rotate blocks\\nReasonably easy syntax (will be used to automatically generate many similar looking documents)\\nEasily usable from Python\\nFree or very cheap\\n\\n\\nIn essence I'm looking for the tool X that is to OODraw/CorelDraw/... as LaTeX is to OOWrite/MS Word.\\n\\nI've looked at webkit2pdf and a headless OODraw, but both seem a bit of an overkill. XML-FO has some limitations such as not being able to predict how many pages your document spans. Reportlab is pricey.\\n\\nAny ideas?\\n\\nThanks!\\n\",\n  'completion': 'Definitely PGF/TikZ. Selling point:\\n\\n\\n\\nCreated by this code:\\n\\n% Rooty helix\\n% Author: Felix Lindemann\\n\\\\documentclass{minimal}\\n\\n\\\\usepackage{tikz}\\n\\\\usetikzlibrary{calc}\\n\\\\begin{document}\\n\\n\\\\pagestyle{empty}\\n\\\\pgfdeclarelayer{background}\\n\\\\pgfdeclarelayer{foreground}\\n\\\\pgfsetlayers{background,main,foreground}\\n\\n\\\\xdefinecolor{darkgreen}{RGB}{175, 193, 36}\\n\\\\newcounter{cntShader}\\n\\\\newcounter{cntRoot}\\n\\\\setcounter{cntShader}{20}\\n\\\\def\\\\couleur{darkgreen}\\n\\n\\\\begin{tikzpicture}\\n    \\\\foreach \\\\y in {86,38,15}{\\n        \\\\setcounter{cntShader}{1}\\n        \\\\coordinate (a) at (0,0);\\n        \\\\coordinate (b) at (0:1);\\n        \\\\foreach \\\\x in {1,...,\\\\y}{%\\n            \\\\coordinate (c) at ($ (b)!1cm!270:(a) $);\\n            \\\\begin{pgfonlayer}{background}\\n                \\\\draw[fill=\\\\couleur!\\\\thecntShader] (a)--(b)--(c)--cycle;\\n            \\\\end{pgfonlayer}\\n            \\\\setcounter{cntRoot}{\\\\x}\\n            \\\\addtocounter{cntRoot}{1}\\n            \\\\node[fill=white,draw,circle,inner sep=1pt] at (c)\\n                {$\\\\sqrt{\\\\thecntRoot}$};\\n            \\\\coordinate (b) at (c);\\n            \\\\pgfmathsetcounter{cntShader}{\\\\thecntShader+4}\\n            \\\\setcounter{cntShader}{\\\\thecntShader}\\n       }\\n    }\\n    \\\\node[fill=white,draw,circle,inner sep=1pt] at (0:1) {$\\\\sqrt{1}$};\\n\\\\end{tikzpicture}\\n\\n\\\\end{document} \\n\\n\\nBlatantly stolen from the examples.\\n'},\n {'prompt': \"Say I have a table People, is there a way to just quickly check if a People object exists with a name of 'Fred'? I know I can query\\n\\nPeople.objects.filter(Name='Fred')\\n\\n\\nand then check the length of the returned result, but is there a way to do it in a more elegant way?\\n\",\n  'completion': 'An exists() method in the QuerySet API is available since Django 1.2.\\n'},\n {'prompt': 'I\\'m not sure if this is a bug or I\\'m just missing something (although I have already parsed the documentation about inlines), but:\\n\\nLet\\'s say I have a model A. Model A is an inline of model B. User U has full access to model B, but only change permissions to model A (so, no add, nor delete).\\n\\nHowever, when editing model B, user U can still see the \"Add another A\" link at the bottom, although U hasn\\'t add permissions for that respective model.\\n\\nWhat\\'s wrong? Why does that link keep on showing? My logic says that if U does not have permissions to add A, the link shouldn\\'t appear anymore.\\n\\nAlso, ideally, I would like to give U only view rights to model A (so no add, delete or change - only view), but I\\'ve read about that (strange, if you ask me) philosophy according to which \"If you don\\'t trust U, just deny him access to the admin area all together\". Kind of a stupid doctrine.\\n\\nRight now, I\\'m trying to simulate this \\'view only permissions\\' by leaving U with just change rights and set all fields as read only. But I think this is kind of a stupid approach and may also cause problems like the permissions thing above...\\n\\nHow does an average Django programmer like me achieve view-only permissions, and most of all how should I get rid of the \"Add another A\" link at the bottom of the admin edit form?\\n\\nThanks in advance!\\n',\n  'completion': 'If I want a read-only version of what\\'s in the admin, I just write some normal Django views and keep them out of the admin.\\n\\nI don\\'t think the kind of thing you\\'re talking about (allowing changes to an object but not its inlines) is really supported by the admin.  Don\\'t get me wrong: the admin is very flexible and useful, but it\\'s not intended to do everything for you.\\n\\nThe only way I see you being able to have this much control in the admin is to not inline A.\\n\\n\\n  \"If you don\\'t trust U, just deny him access to the admin area all together\". Kind of a stupid doctrine.\\n\\n\\nNot really, when you consider that the admin isn\\'t intended to have the required level of security hardening to guarantee that fine-grain level of access control.  There are many, many places in the admin, due to its open and extensible nature, where bugs can lurk (usually in user-written code) that can be exploited by bad actors.  This is why untrusted users should always see all admin URLs return 404.\\n\\nAnyway, when access control requirements are that fine-grained, it becomes unlikely that a general (i.e. django.contrib) solution will fit.\\n'},\n {'prompt': 'I\\'m working on a little fitness tracker in order to teach myself Django. I want to graph my weight over time, so I\\'ve decided to use the Python Google Charts Wrapper. Google charts require that you convert your date into a x coordinate. To do this I want to take the number of days in my dataset by subtracting the first weigh-in from the last weigh-in and then using that to figure out the x coords (for example, I could 100 by the result and increment the x coord by the resulting number for each y coord.)\\n\\nAnyway, I need to figure out how to subtract Django datetime objects from one another and so far, I am striking out on both google and here at the stack. I know PHP, but have never gotten a handle on OO programming, so please excuse my ignorance. Here is what my models look like: \\n\\nclass Goal(models.Model):\\n    goal_weight = models.DecimalField(\"Goal Weight\", \\n        max_digits=4, \\n        decimal_places=1)\\n    target_date = models.DateTimeField(\"Target Date to Reach Goal\")\\n    set_date = models.DateTimeField(\"When did you set your goal?\")\\n    comments = models.TextField(blank=True)\\n\\n    def __unicode__(self):\\n        return unicode(self.goal_weight)\\n\\nclass Weight(models.Model):\\n    \"\"\" Weight at a given date and time. \"\"\"\\n\\n    goal = models.ForeignKey(Goal)\\n    weight = models.DecimalField(\"Current Weight\",\\n        max_digits=4, \\n        decimal_places=1)\\n    weigh_date = models.DateTimeField(\"Date of Weigh-In\")\\n    comments = models.TextField(blank=True)\\n\\n    def __unicode__(self):\\n        return unicode(self.weight)\\n\\n    def recorded_today(self):\\n        return self.date.date() == datetime.date.today()\\n\\n\\nAny ideas on how to proceed in the view? Thanks so much!\\n',\n  'completion': 'You can just subtract the dates directly, which will yield a datetime.timedelta object:\\n\\ndt = weight_now.weight_date - weight_then.weight_date\\n\\n\\nA timedelta object has fields for days, seconds, and microseconds. From there, you can just do the appropriate math. For example:\\n\\nhours = dt.seconds / 60 / 60    # Returns number of hours between dates\\nweeks = dt.days / 7             # number of weeks between dates\\n\\n'},\n {'prompt': 'I\\'ve a python script which works just as it should but I need to write the time for the execution. I\\'ve googled that I should use timeit but I can\\'t seem to get it to work.\\n\\nMy Python script looks like this:\\n\\nimport sys\\nimport getopt\\nimport timeit\\nimport random\\nimport os\\nimport re\\nimport ibm_db\\nimport time\\nfrom string import maketrans\\nmyfile = open(\"results_update.txt\", \"a\")\\n\\nfor r in range(100):\\n    rannumber = random.randint(0, 100)\\n\\n    update = \"update TABLE set val = %i where MyCount >= \\'2010\\' and MyCount < \\'2012\\' and number = \\'250\\'\" % rannumber\\n    #print rannumber\\n\\n    conn = ibm_db.pconnect(\"dsn=myDB\",\"usrname\",\"secretPWD\")\\n\\nfor r in range(5):\\n    print \"Run %s\\\\n\" % r        \\n    ibm_db.execute(query_stmt)\\n query_stmt = ibm_db.prepare(conn, update)\\n\\nmyfile.close()\\nibm_db.close(conn)\\n\\n\\nWhat I need it the time it takes the execution of the query and written to the file \"results_update.txt\". The purpose is to test an update statement for my database with different indexes and tuning mechanisms.\\n',\n  'completion': 'you can use time.time ot time.clock before and after the block you want to time\\n\\nimport time\\n\\nt0 = time.time()\\ncode_block\\nt1 = time.time()\\n\\ntotal = t1-t0\\n\\n\\nthis method is not as exact as timeit (it does not average several runs) but it is straighforward. \\n\\ntime.time() (in windows and linux) and time.clock(in linux) have not enough resolution for fast functions (you get total = 0). In this case or if you want to average the time elapsed by several runs, you have to manually call the function multiple times (As I think you already do in you example code and timeit does automatically when you set its number argument)\\n\\nimport time\\n\\ndef myfast():\\n   code\\n\\nn = 10000\\nt0 = time.time()\\nfor i in range(n): myfast()\\nt1 = time.time()\\n\\ntotal_n = t1-t0\\n\\n\\nin windows, as Corey stated in the comment, time.clock() has much higher precision (microsecond instead of second) and must be prefered to time.time().\\n'},\n {'prompt': 'I ran across something once upon a time and wondered if it was a Python \"bug\" or at least a misfeature.  I\\'m curious if anyone knows of any justifications for this behavior.  I thought of it just now reading \"Code Like a Pythonista,\" which has been enjoyable so far.  I\\'m only familiar with the 2.x line of Python.\\n\\nRaw strings are strings that are prefixed with an r.  This is great because I can use backslashes in regular expressions and I don\\'t need to double everything everywhere.  It\\'s also handy for writing throwaway scripts on Windows, so I can use backslashes there also.  (I know I can also use forward slashes, but throwaway scripts often contain content cut&pasted from elsewhere in Windows.)\\n\\nSo great!  Unless, of course, you really want your string to end with a backslash.  There\\'s no way to do that in a \\'raw\\' string.\\n\\nIn [9]: r\\'\\\\n\\'\\nOut[9]: \\'\\\\\\\\n\\'\\n\\nIn [10]: r\\'abc\\\\n\\'\\nOut[10]: \\'abc\\\\\\\\n\\'\\n\\nIn [11]: r\\'abc\\\\\\'\\n------------------------------------------------\\n   File \"<ipython console>\", line 1\\n     r\\'abc\\\\\\'\\n           ^\\nSyntaxError: EOL while scanning string literal\\n\\n\\nIn [12]: r\\'abc\\\\\\\\\\'\\nOut[12]: \\'abc\\\\\\\\\\\\\\\\\\'\\n\\n\\nSo one backslash before the closing quote is an error, but two backslashes gives you two backslashes!  Certainly I\\'m not the only one that is bothered by this?\\n\\nThoughts on why \\'raw\\' strings are \\'raw, except for backslash-quote\\'?  I mean, if I wanted to embed a single quote in there I\\'d just use double quotes around the string, and vice versa.  If I wanted both, I\\'d just triple quote.  If I really wanted three quotes in a row in a raw string, well, I guess I\\'d have to deal, but is this considered \"proper behavior\"?\\n\\nThis is particularly problematic with folder names in Windows, where the backslash is the path delimeter.\\n',\n  'completion': 'It\\'s a FAQ.  \\n\\nAnd in response to \"you really want your string to end with a backslash. There\\'s no way to do that in a \\'raw\\' string.\": the FAQ shows how to workaround it.\\n\\n>>> r\\'ab\\\\c\\' \\'\\\\\\\\\\' == \\'ab\\\\\\\\c\\\\\\\\\\'\\nTrue\\n>>>\\n\\n'},\n {'prompt': 'Can somebody explain to me why this works (in Python 2.5) :\\n\\nclass Foo(object):\\n    pass\\n\\nclass Bar(Foo):\\n    pass\\n\\nprint(Foo.__subclasses__())\\n\\n\\nbut this doesn\\'t :\\n\\nclass Foo():\\n    pass\\n\\nclass Bar(Foo):\\n    pass\\n\\nprint(Foo.__subclasses__())\\n\\n\\nThe latter returns \"AttributeError: class Foo has no attribute \\'__subclasses__\\'\" but i\\'m not sure why. I know this is related to old-style vs. new-style classes but i\\'m not clear on why that would make this functionality unavailable. \\n\\nClarification: I\\'m looking to understand WHY __subclasses__() isn\\'t available in old-style, i get that the method doesn\\'t exist for old-style classes but I don\\'t get what it is about new-style that makes these new functions possible.\\n',\n  'completion': 'class Foo(object):\\n    pass\\n\\n\\nThe class above is a \"new-style\" class because it inherits from the object class.  New-style classes provide a lot of extra framework that \"old-style\" classes do not have.  One particular attribute of a new-style class is to be able to determine the subclasses of the  class with the __subclasses__ method.\\n\\nThere is some good discussion about new-style classes and the __subclasses__ method which use to be completely undocumented. ( Here is an unofficial explanation from Tim Peters, though. )\\n\\n\"Each new-style class keeps a list of weak references to its immediate subclasses. This method returns a list of all those references still alive.\"\\n\\nSo to answer your question, the __subclasses__ functionality is not available because in your second example:\\n\\nclass Foo():\\n    pass\\n\\n\\nThe old-style class Foo does not inherit from object (so it\\'s not a new-style class) and there for does not inherit the __subclasses__ method.\\n\\nNote, if you don\\'t understand why an old-style class does not have the __subclasses__ method you could always fire up a python interpreter and do some inspection with dir\\n\\n>>> class Foo(object):\\n...     pass\\n...\\n>>> dir(Foo.__class__)\\n[\\'__abstractmethods__\\', \\'__base__\\', \\'__bases__\\', \\'__basicsize__\\', \\'__call__\\', \\'__class__\\', \\'__delattr__\\', \\'__dict__\\', \\'__dictoffset__\\', \\'__doc__\\', \\'__\\neq__\\', \\'__flags__\\', \\'__format__\\', \\'__ge__\\', \\'__getattribute__\\', \\'__gt__\\', \\'__hash__\\', \\'__init__\\', \\'__instancecheck__\\', \\'__itemsize__\\', \\'__le__\\', \\'__lt\\n__\\', \\'__module__\\', \\'__mro__\\', \\'__name__\\', \\'__ne__\\', \\'__new__\\', \\'__reduce__\\', \\'__reduce_ex__\\', \\'__repr__\\', \\'__setattr__\\', \\'__sizeof__\\', \\'__str__\\', \\'__s\\nubclasscheck__\\', \\'__subclasses__\\', \\'__subclasshook__\\', \\'__weakrefoffset__\\', \\'mro\\']\\n>>> class Bar():\\n...     pass\\n...\\n>>> dir(Bar.__class__)\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nAttributeError: class Bar has no attribute \\'__class__\\'\\n>>> dir(Bar)\\n[\\'__doc__\\', \\'__module__\\']\\n>>> dir(Foo)\\n[\\'__class__\\', \\'__delattr__\\', \\'__dict__\\', \\'__doc__\\', \\'__format__\\', \\'__getattribute__\\', \\'__hash__\\', \\'__init__\\', \\'__module__\\', \\'__new__\\', \\'__reduce__\\', \\'\\n__reduce_ex__\\', \\'__repr__\\', \\'__setattr__\\', \\'__sizeof__\\', \\'__str__\\', \\'__subclasshook__\\', \\'__weakref__\\']\\n\\n'},\n {'prompt': \"What's the best way to store and retrieve a python dict in a database?\\n\",\n  'completion': 'If you are not specifically interested into using a traditionally SQL database, such as MySQL, you could look into unstructured document databases where documents naturally map to python dictionaries, for example MongoDB. The MongoDB python bindings allow you to just insert dicts in the DB, and query them based on the values in the dict. See for example the code below from the tutorial:\\n\\n>>> from pymongo import Connection\\n>>> connection = Connection()\\n>>> db = connection[\\'test-database\\']\\n>>> import datetime\\n>>> post = {\"author\": \"Mike\",\\n...         \"text\": \"My first blog post!\",\\n...         \"tags\": [\"mongodb\", \"python\", \"pymongo\"],\\n...         \"date\": datetime.datetime.utcnow()}\\n>>> posts = db.posts\\n>>> posts.insert(post)\\nObjectId(\\'...\\')\\n>>> posts.find_one({\"author\": \"Mike\"})\\n{u\\'date\\': datetime.datetime(...), u\\'text\\': u\\'My first blog post!\\', u\\'_id\\': ObjectId(\\'...\\'), u\\'author\\': u\\'Mike\\', u\\'tags\\': [u\\'mongodb\\', u\\'python\\', u\\'pymongo\\']}\\n\\n'},\n {'prompt': \"I'm using Django to create a stock photo site, I have a ImageField in my model, the problem is that when the user update the image field, the original image file isn't deleted from the hard disk.\\n\\nhow can I make to delete those images after an update?\\n\\nThanks!\\n\",\n  'completion': \"You'll have to delete the old image manually.\\n\\nThe absolute path to the image is stored in your_image_field.name. So you'd do something like:\\n\\nos.remove(your_image_field.name)\\n\\n\\nBut, as a convenience, you can use the associated FieldFile object, which gives easy access to the underlying file, as well as providing a few convenience methods. See http://docs.djangoproject.com/en/dev/ref/models/fields/#filefield-and-fieldfile\\n\"},\n {'prompt': 'I\\'ve been trying to \"hijack\" the Mac OS X system audio using PyAudio and save to a wav in python. That is, I do not want to record from an input device such as a microphone. I want to grab the sound output from any or all applications.\\n\\nI have followed the tutorials on the PyAudio site but these do not appear to cover my use case and when I try to read from the output stream I unsurprisingly get the paCanNotReadFromAnOutputOnlyStream exception. Fair enough! Is there a way to do what I am proposing with the PyAudio or other FOSS Python Library?\\n',\n  'completion': 'I found that an open-source project called SoundFlower got me quickly to the place I needed to be.\\n\\n\\nI installed the SoundFlower package from Google Code.\\nOpened System Preferences -> Sound\\nChose Soundflower as my Output device\\nChose Soundflower as my Input device\\n\\n\\nI was then able to record system audio from the default device using PyAudio. No sound comes from the speakers/headphones in this situation though. I wonder if you could use Jack OS X to route audio out of SoundFlower to the system audio out. \\n'},\n {'prompt': 'I \"accidentally\" came across this weird but valid syntax\\n\\ni=3\\nprint i+++i #outputs 6\\nprint i+++++i #outputs 6\\nprint i+-+i #outputs 0\\nprint i+--+i #outputs 6 \\n\\n\\n(for every even no: of minus symbol, it outputs 6 else 0, why?)\\n\\nDoes this do anything useful?\\n\\nUpdate (Don\\'t take it the wrong way..I love python):\\nOne of Python\\'s principle says \\nThere should be one-- and preferably only one --obvious way to do it. It seems there are infinite ways to do i+1\\n',\n  'completion': \"Since Python doesn't have C-style ++ or -- operators, one is left to assume that you're negating or positivating(?) the value on the left.\\n\\nE.g. what would you expect i + +5 to be?\\n\\ni=3\\nprint i + +(+i) #outputs 6\\nprint i + +(+(+(+i))) #outputs 6\\nprint i + -(+i) #outputs 0\\nprint i + -(-(+i)) #outputs 6 \\n\\n\\nNotably, from the Python Grammar Specification, you'll see the line:\\n\\nfactor: ('+'|'-'|'~') factor | power\\n\\n\\nWhich means that a factor in an expression can be a factor preceded by +, -, or ~.  I.e. it's recursive, so if 5 is a factor (which it is because factor->power->NUMBER), then -5 is a factor and so are --5 and --------5.\\n\"},\n {'prompt': \"I am using ConfigParser to read the runtime configuration of a script.\\n\\nI would like to have the flexibility of not providing a section name (there are scripts which are simple enough; they don't need a 'section'). ConfigParser will throw the NoSectionError exception, and will not accept the file.\\n\\nHow can I make ConfigParser simply retrieve the (key, value) tuples of a config file without section names? For instance:\\n\\nkey1=val1\\nkey2:val2\\n\\n\\nI would rather not write to the config file.\\n\",\n  'completion': \"Alex Martelli provided a solution for using ConfigParser to parse .properties files (which are apparently section-less config files).\\n\\nHis solution is a file-like wrapper that will automagically insert a dummy section heading to satisfy ConfigParser's requirements.\\n\"},\n {'prompt': \"I'm curious, whether there is any way to print formatted numpy.arrays, e.g., in the way similar to this:\\n\\nx = 1.23456\\nprint '%.3f' % x\\n\\n\\nIf I want to print the numpy.array of floats, it prints several decimals, often in 'scientific' format, which is rather hard to read even for low-dimensional arrays. However, numpy.array apparently has to be printed as a string, i.e., with %s. Is there any solution for this purpose? \\n\",\n  'completion': \"You can use set_printoptions to set the precision of the output:\\n\\nimport numpy as np\\nx=np.random.random(10)\\nprint(x)\\n# [ 0.07837821  0.48002108  0.41274116  0.82993414  0.77610352  0.1023732\\n#   0.51303098  0.4617183   0.33487207  0.71162095]\\n\\nnp.set_printoptions(precision=3)\\nprint(x)\\n# [ 0.078  0.48   0.413  0.83   0.776  0.102  0.513  0.462  0.335  0.712]\\n\\n\\nAnd suppress suppresses the use of scientific notation for small numbers:\\n\\ny=np.array([1.5e-10,1.5,1500])\\nprint(y)\\n# [  1.500e-10   1.500e+00   1.500e+03]\\nnp.set_printoptions(suppress=True)\\nprint(y)\\n# [    0.      1.5  1500. ]\\n\\n\\nSee the docs for set_printoptions for other options.\\n\\n\\n\\nTo apply print options locally, you could use a contextmanager:\\n\\nimport numpy as np\\nimport contextlib\\n\\n@contextlib.contextmanager\\ndef printoptions(*args, **kwargs):\\n    original = np.get_printoptions()\\n    np.set_printoptions(*args, **kwargs)\\n    yield \\n    np.set_printoptions(**original)\\n\\n\\nFor example, inside the with-suite precision=3 and suppress=True are set:\\n\\nx = np.random.random(10)\\nwith printoptions(precision=3, suppress=True):\\n    print(x)\\n    # [ 0.073  0.461  0.689  0.754  0.624  0.901  0.049  0.582  0.557  0.348]\\n\\n\\nBut outside the with-suite the print options are back to default settings:\\n\\nprint(x)    \\n# [ 0.07334334  0.46132615  0.68935231  0.75379645  0.62424021  0.90115836\\n#   0.04879837  0.58207504  0.55694118  0.34768638]\\n\\n\\n\\n\\nTo prevent zeros from being stripped from the end of floats:\\n\\nnp.set_printoptions now has a formatter parameter which allows you to specify a format function for each type.\\n\\nnp.set_printoptions(formatter={'float': '{: 0.3f}'.format})\\nprint(x)\\n\\n\\nwhich prints\\n\\n[ 0.078  0.480  0.413  0.830  0.776  0.102  0.513  0.462  0.335  0.712]\\n\\n\\ninstead of \\n\\n[ 0.078  0.48   0.413  0.83   0.776  0.102  0.513  0.462  0.335  0.712]\\n\\n\"},\n {'prompt': 'I have the following functions for colorizing my screen messages:\\n\\ndef error(string):\\n    return \\'\\\\033[31;1m\\' + string + \\'\\\\033[0m\\'\\n\\ndef standout(string):\\n    return \\'\\\\033[34;1m\\' + string + \\'\\\\033[0m\\'\\n\\n\\nI use them as follows:\\n\\nprint error(\\'There was a problem with the program\\')\\nprint \"This is normal \" + standout(\"and this stands out\")\\n\\n\\nI want to log the output to a file (in addition to STDOUT) WITHOUT the ANSI color codes, hopefully without having to add a second \"logging\" line to each print statement.\\n\\nThe reason is that if you simply python program.py > out then the file out will have the ANSI color codes, which look terrible if you open in a plain text editor.\\n\\nAny advice?\\n',\n  'completion': \"The sys.stdout.isatty function might be able to help:\\n\\nfrom sys import stdout\\n\\ndef error(string, is_tty=stdout.isatty()):\\n    return ('\\\\033[31;1m' + string + '\\\\033[0m') if is_tty else string\\n\\ndef standout(string, is_tty=stdout.isatty()):\\n    return ('\\\\033[34;1m' + string + '\\\\033[0m') if is_tty else string\\n\\n\\nThat's actually one of the few uses I can think of to use a default argument that isn't set to None because default arguments are evaluated at compile time in Python rather than at runtime like in C++...\\n\\nAlso the behaviour can be explicitly overridden if you really need to, though that doesn't let you manipulate stdout itself when it's redirected.  Is there any reason why you're not using the logging module (perhaps you didn't know about it)?\\n\"},\n {'prompt': \"I'm trying to define my own (very simple) exception class in Python 2.6, but no matter how I do it I get some warning.\\n\\nFirst, the simplest way:\\n\\nclass MyException(Exception):\\n    pass\\n\\n\\nThis works, but prints out a warning at runtime: DeprecationWarning: BaseException.message has been deprecated as of Python 2.6 OK, so that's not the way. I then tried:\\n\\nclass MyException(Exception):\\n    def __init__(self, message):\\n        self.message = message\\n\\n\\nThis also works, but PyLint reports a warning: W0231: MyException.__init__: __init__ method from base class 'Exception' is not called. So I tried calling it:\\n\\nclass MyException(Exception):\\n    def __init__(self, message):\\n        super(Exception, self).__init__(message)\\n        self.message = message\\n\\n\\nThis works, too! But now PyLint reports an error: E1003: MyException.__init__: Bad first argument 'Exception' given to super class\\n\\nHow the hell do I do such a simple thing without any warnings?\\n\",\n  'completion': 'When you call super, you need the subclass/derived class as the first argument, not the main/base class.\\n\\nFrom the Python online documentation:\\n\\nclass C(B):\\n    def method(self, arg):\\n        super(C, self).method(arg)\\n\\n\\nSo your exception would be defined as follows:\\n\\nclass MyException(Exception):\\n    def __init__(self, message):\\n        super(MyException, self).__init__(message)\\n        self.message = message\\n\\n'},\n {'prompt': \"I am trying to find tutorials on how to write buildout recipes. I haven't found any, except the one on buildout site. But it is very rudimentary. Is there a good tutorial for writing buildout recipes?\\n\",\n  'completion': \"http://pypi.python.org/pypi/ZopeSkel/ has a template for a buildout recipe.  That at least gets you started regarding having a skeleton for adding your own code.\\n\\nhttp://pypi.python.org/pypi/zc.buildout#id1 has some information on which methods you need to implement.\\n\\nBest way to learn it is by looking at an existing recipe to see how it gets done. I'd suggest my own recipe :-) :\\n\\nhttps://svn.plone.org/svn/collective/buildout/collective.recipe.backup/trunk/\\n\"},\n {'prompt': 'After some big frustration I did it! I converted my django app to an \"exe\" one to run as a single standalone app on windows (using cherrypy as a WSGI server)\\nBut When I try to to set py2exe\\'s option \"bundle_files\" to \"1\" (i.e. bundle the python interpreter Python25.dll inside the generated exe) the generated exe crashes with a message talking about kernel32.dll\\n\\nBut when I use \"bundle_file\" = \"2\", the generated exe is runing like a charm, but must -of course- have Python25.dll as a separate file beside it.\\n\\nAnyone experienced a similar behavior, can you please tell me what I\\'m missing?\\n\\nThank you! :)\\n',\n  'completion': \"Maybe you can try pyinstaller instead.\\n\\nI did have this problem before and didn't find a solution ever, but pyinstaller meets my need too and works perfectly.\\n\"},\n {'prompt': 'I have a main thread that waits for connection. It spawns client threads that will echo the response from the client (telnet in this case). But say that I want to close down all sockets and all threads after some time, like after 1 connection. How would I do? If I do clientSocket.close() from the main thread, it won\\'t stop doing the recv. It will only stop if I first send something through telnet, then it will fail doing further sends and recvs.\\n\\nMy code look like this:\\n\\n# Echo server program\\nimport socket\\nfrom threading import Thread\\nimport time\\n\\nclass ClientThread(Thread):\\n    def __init__(self, clientSocket):\\n            Thread.__init__(self)\\n            self.clientSocket = clientSocket\\n\\n    def run(self):\\n            while 1:\\n                    try:\\n                            # It will hang here, even if I do close on the socket\\n                            data = self.clientSocket.recv(1024)\\n                            print \"Got data: \", data\\n                            self.clientSocket.send(data)\\n                    except:\\n                            break\\n\\n            self.clientSocket.close()\\n\\nHOST = \\'\\'\\nPORT = 6000\\nserverSocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\nserverSocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\\nserverSocket.bind((HOST, PORT))\\nserverSocket.listen(1)\\n\\nclientSocket, addr = serverSocket.accept()\\nprint \\'Got a new connection from: \\', addr\\nclientThread = ClientThread(clientSocket)\\nclientThread.start()\\n\\ntime.sleep(1)\\n\\n# This won\\'t make the recv in the clientThread to stop immediately,\\n# nor will it generate an exception\\nclientSocket.close()\\n\\n',\n  'completion': \"I know this is an old thread and that Samuel probably fixed his issue a long time ago. However, I had the same problem and came across this post while google'ing. Found a solution and think it is worthwhile to add.\\n\\nYou can use the shutdown method on the socket class. It can prevent further sends, receives or both.\\n\\n\\n  socket.shutdown(socket.SHUT_WR)\\n\\n\\nThe above prevents future sends, as an example.\\n\\nSee Python docs for more info.\\n\"},\n {'prompt': 'Python\\'s sys module provides a function setrecursionlimit that lets you change Python\\'s maximum recursion limit. The docs say:\\n\\n\\n  The highest possible limit is platform-dependent.\\n\\n\\nMy question is: What is the highest possible limits for various platforms, under CPython? I would like to know the values for Linux, Mac and Windows.\\n\\nUPDATE: Can we please avoid \"You\\'re doing it wrong\" answers? I know that trying to do very deep recursion is usually a bad idea. I\\'ve considered the pros and cons in my specific situation and decided that I want to do it.\\n',\n  'completion': \"On Windows (at least), sys.setrecursionlimit isn't the full story.  The hard limit is on a per-thread basis and you need to call threading.stack_size and create a new thread once you reach a certain limit. (I think 1MB, but not sure)  I've used this approach to increase it to a 64MB stack.\\n\\nimport sys\\nimport threading\\n\\nthreading.stack_size(67108864) # 64MB stack\\nsys.setrecursionlimit(2 ** 20) # something real big\\n                               # you actually hit the 64MB limit first\\n                               # going by other answers, could just use 2**32-1\\n\\n# only new threads get the redefined stack size\\nthread = threading.Thread(target=main)\\nthread.start()\\n\\n\\nI haven't tried to see what limits there might be on threading.stack_size, but feel free to try... that's where you need to look.\\n\\nIn summary, sys.setrecursionlimit is just a limit enforced by the interpreter itself.  threading.stack_size lets you manipulate the actual limit imposed by the OS.  If you hit the latter limit first, Python will just crash completely.\\n\"},\n {'prompt': 'cache.set(key, value, 9999999)\\n\\n\\nBut this is not infinite time...\\n',\n  'completion': 'def _get_memcache_timeout(self, timeout):\\n    \"\"\"\\n    Memcached deals with long (> 30 days) timeouts in a special\\n    way. Call this function to obtain a safe value for your timeout.\\n    \"\"\"\\n    timeout = timeout or self.default_timeout\\n    if timeout > 2592000: # 60*60*24*30, 30 days\\n        # See http://code.google.com/p/memcached/wiki/FAQ\\n        # \"You can set expire times up to 30 days in the future. After that\\n        # memcached interprets it as a date, and will expire the item after\\n        # said date. This is a simple (but obscure) mechanic.\"\\n        #\\n        # This means that we have to switch to absolute timestamps.\\n        timeout += int(time.time())\\n    return timeout\\n\\n\\nAnd from the FAQ:\\n\\n\\n  What are the limits on setting expire time? (why is there a 30 day limit?)\\n  \\n  You can set expire times up to 30 days in the future. After that memcached interprets it as a date, and will expire the item after said date. This is a simple (but obscure) mechanic.\\n\\n'},\n {'prompt': \"I'm trying to find some sort of a good, fuzzy string matching algorithm. Direct matching doesn't work for me â\\x80\\x94 this isn't too good because unless my strings are a 100% similar, the match fails. The Levenshtein method doesn't work too well for strings as it works on a character level. I was looking for something along the lines of word level matching e.g.\\n\\n\\n  String A: The quick brown fox.\\n  \\n  String B: The quick brown fox jumped\\n  over the lazy dog.\\n  \\n  These should match as all words in\\n  string A are in string B.\\n\\n\\nNow, this is an oversimplified example but would anyone know a good, fuzzy string matching algorithm that works on a word level.\\n\",\n  'completion': \"I like Drew's answer.  \\n\\nYou can use difflib to find the longest match:\\n\\n>>> a = 'The quick brown fox.'\\n>>> b = 'The quick brown fox jumped over the lazy dog.'\\n>>> import difflib\\n>>> s = difflib.SequenceMatcher(None, a, b)\\n>>> s.find_longest_match(0,len(a),0,len(b))\\nMatch(a=0, b=0, size=19) # returns NamedTuple (new in v2.6)\\n\\n\\nOr pick some minimum matching threshold. Example:\\n\\n>>> difflib.SequenceMatcher(None, a, b).ratio()\\n0.61538461538461542\\n\\n\"},\n {'prompt': \"I'd like a good method that matches the interface of subprocess.check_call -- ie, it throws CalledProcessError when it fails, is synchronous, &c -- but instead of returning the return code of the command (if it even does that) returns the program's output, either only stdout, or a tuple of (stdout, stderr).\\n\\nDoes somebody have a method that does this?\\n\",\n  'completion': 'Python 2.7+\\n\\nfrom subprocess import check_output as qx\\n\\n\\nPython < 2.7\\n\\nFrom subprocess.py:\\n\\nimport subprocess\\ndef check_output(*popenargs, **kwargs):\\n    if \\'stdout\\' in kwargs:\\n        raise ValueError(\\'stdout argument not allowed, it will be overridden.\\')\\n    process = subprocess.Popen(stdout=subprocess.PIPE, *popenargs, **kwargs)\\n    output, unused_err = process.communicate()\\n    retcode = process.poll()\\n    if retcode:\\n        cmd = kwargs.get(\"args\")\\n        if cmd is None:\\n            cmd = popenargs[0]\\n        raise subprocess.CalledProcessError(retcode, cmd, output=output)\\n    return output\\n\\nclass CalledProcessError(Exception):\\n    def __init__(self, returncode, cmd, output=None):\\n        self.returncode = returncode\\n        self.cmd = cmd\\n        self.output = output\\n    def __str__(self):\\n        return \"Command \\'%s\\' returned non-zero exit status %d\" % (\\n            self.cmd, self.returncode)\\n# overwrite CalledProcessError due to `output` keyword might be not available\\nsubprocess.CalledProcessError = CalledProcessError\\n\\n\\nSee also Capturing system command output as a string for another example of possible check_output() implementation.\\n'},\n {'prompt': 'I\\'m still a bit slow with Python, so I haven\\'t got this figured out beyond what\\'s obviously in the docs, etc. \\n\\nI\\'ve worked with Django a bit, where they\\'ve added some datetime formatting options via template tags, but in regular python code how can I get the 12-hour hour without a leading zero? \\n\\nIs there a straightforward way to do this? I\\'m looking at the 2.5 and 2.6 docs for \"strftime()\" and there doesn\\'t seem to be a formatting option there for this case. \\n\\nShould I be using something else? \\n\\nFeel free to include any other time-formatting tips that aren\\'t obvious from the docs. =)\\n',\n  'completion': 'Nothing built-in to datetime will do it.  You\\'ll need to use something like:\\n\\ndatetime.time(1).strftime(\\'%I:%M%p\\').lstrip(\\'0\\')\\n\\n\\nAddendum\\n\\nAs @naktinis points out, this is tailored to the use of this particular strftime parameter. Unfortunately, there is no generic solution if the content of the strftime parameter is unknown or unspecified (e.g. an external parameter), because it becomes a \"do what I mean, not what I say\" problem.\\n\\nThus, given that you have to know what\\'s in your strftime parameter, in a more complex case you could solve this as parts:\\n\\ntval = datetime.time(1)\\ntval_str = (tval.strftime(\\'%A, %B \\') + tval.strftime(\\'%d\\').lstrip(\\'0\\') \\n    + tval.strftime(\\' %Y, \\') + tval.strftime(\\'%I:%M\\').lstrip(\\'0\\') \\n    + tval.strftime(\\'%p\\').lower())\\n\\n\\nor with the re module:\\n\\ntval = datetime.time(1)\\ntval_str = re.sub(r\"^0|(?<=\\\\s)0\", \"\", \\n    re.sub(r\"(?<=[0-9])[AP]M\", lambda m: m.group().lower(), \\n    tval.strftime(\\'%A, %B %d %Y, %I:%M%p\\')))\\n\\n\\nThat said, bear in mind that if the \"%p\" term gives you uppercase letters, it may be because the user set their locale to work that way, and by changing case you are overriding user preferences, which sometimes leads to bug reports. Also, the user may want something other than \"am\" or \"pm\", such as \"a.m.\" and \"p.m.\". Also note that these are different for different locales (e.g. en_US locale gives AM or PM for %p, but de_DE gives am or pm) and you might not be getting characters in the encoding you assume.\\n\\nFrom the documentation on strftime behavior:\\n\\n\\n  Because the format depends on the current locale, care should be taken when making assumptions about the output value. Field orderings will vary (for example, â\\x80\\x9cmonth/day/yearâ\\x80\\x9d versus â\\x80\\x9cday/month/yearâ\\x80\\x9d), and the output may contain Unicode characters encoded using the localeâ\\x80\\x99s default encoding (for example, if the current locale is js_JP, the default encoding could be any one of eucJP, SJIS, or utf-8; use locale.getlocale() to determine the current localeâ\\x80\\x99s encoding).\\n\\n\\nSo, in short, if you think you need to override locale settings, make sure you have a good reason why, so you don\\'t just end up creating new bugs.\\n'},\n {'prompt': \"I'm wondering about some details of how for ... in works in Python.\\n\\nMy understanding is for var in iterable on each iteration creates a variable, var, bound to the current value of iterable. So, if you do for c in cows; c = cows[whatever], but changing c within the loop does not affect the original value. However, it seems to work differently if you're assigning a value to a dictionary key.\\n\\ncows=[0,1,2,3,4,5]\\nfor c in cows:\\n  c+=2\\n\\n#cows is now the same - [0,1,2,3,4,5]\\n\\ncows=[{'cow':0},{'cow':1},{'cow':2},{'cow':3},{'cow':4},{'cow':5}]\\nfor c in cows:\\n  c['cow']+=2\\n\\n# cows is now [{'cow': 2}, {'cow': 3}, {'cow': 4}, {'cow': 5}, {'cow': 6}, {'cow': 7}\\n#so, it's changed the original, unlike the previous example\\n\\n\\nI see one can use enumerate to make the first example work, too, but that's a different story, I guess.\\n\\ncows=[0,1,2,3,4,5]\\nfor i,c in enumerate(cows):\\n  cows[i]+=1\\n\\n# cows is now [1, 2, 3, 4, 5, 6]\\n\\n\\nWhy does it affect the original list values in the second example but not the first?\\n\\n[edit]\\n\\nThanks for the answers. I was looking at this from a PHP point of view, where you can use the & symbol in foreach to specify whether you are operating on a reference to or a copy of the iterable.  I see now that the real difference is a basic detail of how python works regarding immutable objects.\\n\",\n  'completion': \"It helps to picture what happens to the reference held by c in each iteration:\\n\\n[ 0, 1, 2, 3, 4, 5 ]\\n  ^\\n  |\\n  c\\n\\n\\nc holds a reference pointing to the first element in the list. When you do c += 2 (i.e., c = c + 2, the temporary variable c is reassigned a new value. This new value is 2, and c is rebound to this new value. The original list is left alone.\\n\\n[ 0, 1, 2, 3, 4, 5 ]\\n\\n  c -> 2\\n\\n\\nNow, in the dictionary case, here's what c is bound to during the first iteration:\\n\\n[ {'cow':0}, {'cow':1}, {'cow':2}, {'cow':3}, {'cow':4}, {'cow':5} ]\\n     ^\\n     |\\n     c\\n\\n\\nHere, c points to the dictionary object {'cow':0}. When you do c['cow'] += 2 (i.e., c['cow'] = c['cow'] + 2), the dictionary object itself is changed, as c is not rebound to an unrelated object. That is, c still points to that first dictionary object.\\n\\n[ {'cow':2}, {'cow':1}, {'cow':2}, {'cow':3}, {'cow':4}, {'cow':5} ]\\n     ^\\n     |\\n     c\\n\\n\"},\n {'prompt': \"I'd like to dynamically create a module from a dictionary, and I'm wondering if adding an element to sys.modules is really the best way to do this.  EG\\n\\ncontext = { a: 1, b: 2 }\\nimport types\\ntest_context_module = types.ModuleType('TestContext', 'Module created to provide a context for tests')\\ntest_context_module.__dict__.update(context)\\nimport sys\\nsys.modules['TestContext'] = test_context_module\\n\\n\\nMy immediate goal in this regard is to be able to provide a context for timing test execution:\\n\\nimport timeit\\ntimeit.Timer('a + b', 'from TestContext import *')\\n\\n\\nIt seems that there are other ways to do this, since the Timer constructor takes objects as well as strings.  I'm still interested in learning how to do this though, since a) it has other potential applications; and b) I'm not sure exactly how to use objects with the Timer constructor; doing so may prove to be less appropriate than this approach in some circumstances.\\n\\nEDITS/REVELATIONS/PHOOEYS/EUREKAE:\\n\\n\\nI've realized that the example code relating to running timing tests won't actually work, because import * only works at the module level, and the context in which that statement is executed is that of a function in the testit module.  In other words, the globals dictionary used when executing that code is that of __main__, since that's where I was when I wrote the code in the interactive shell.  So that rationale for figuring this out is a bit botched, but it's still a valid question.\\nI've discovered that the code run in the first set of examples has the undesirable effect that the namespace in which the newly created module's code executes is that of the module in which it was declared, not its own module.  This is like way weird, and could lead to all sorts of unexpected rattlesnakeic sketchiness.  So I'm pretty sure that this is not how this sort of thing is meant to be done, if it is in fact something that the Guido doth shine upon.\\nThe similar-but-subtly-different case of dynamically loading a module from a file that is not in python's include path is quite easily accomplished using imp.load_source('NewModuleName', 'path/to/module/module_to_load.py').  This does load the module into sys.modules.  However this doesn't really answer my question, because really, what if you're running python on an embedded platform with no filesystem?\\n\\n\\nI'm battling a considerable case of information overload at the moment, so I could be mistaken, but there doesn't seem to be anything in the imp module that's capable of this.\\n\\nBut the question, essentially, at this point is how to set the global (ie module) context for an object.  Maybe I should ask that more specifically?  And at a larger scope, how to get Python to do this while shoehorning objects into a given module?\\n\",\n  'completion': 'Hmm, well one thing I can tell you is that the timeit function actually executes its code using the module\\'s global variables. So in your example, you could write\\n\\nimport timeit\\ntimeit.a = 1\\ntimeit.b = 2\\ntimeit.Timer(\\'a + b\\').timeit()\\n\\n\\nand it would work. But that doesn\\'t address your more general problem of defining a module dynamically.\\n\\nRegarding the module definition problem, it\\'s definitely possible and I think you\\'ve stumbled on to pretty much the best way to do it. For reference, the gist of what goes on when Python imports a module is basically the following:\\n\\nmodule = imp.new_module(name)\\nexecfile(file, module.__dict__)\\n\\n\\nThat\\'s kind of the same thing you do, except that you load the contents of the module from an existing dictionary instead of a file. (I don\\'t know of any difference between types.ModuleType and imp.new_module other than the docstring, so you can probably use them interchangeably) What you\\'re doing is somewhat akin to writing your own importer, and when you do that, you can certainly expect to mess with sys.modules.\\n\\nAs an aside, even if your import * thing was legal within a function, you might still have problems because oddly enough, the statement you pass to the Timer doesn\\'t seem to recognize its own local variables. I invoked a bit of Python voodoo by the name of extract_context() (it\\'s a function I wrote) to set a and b at the local scope and ran\\n\\nprint timeit.Timer(\\'print locals(); a + b\\', \\'sys.modules[\"__main__\"].extract_context()\\').timeit()\\n\\n\\nSure enough, the printout of locals() included a and b:\\n\\n{\\'a\\': 1, \\'b\\': 2, \\'_timer\\': <built-in function time>, \\'_it\\': repeat(None, 999999), \\'_t0\\': 1277378305.3572791, \\'_i\\': None}\\n\\n\\nbut it still complained NameError: global name \\'a\\' is not defined. Weird.\\n'},\n {'prompt': 'What do I pass as the first parameter \"object\" to the function setattr(object, name, value), to set variables on the current module?\\n\\nFor example:\\n\\nsetattr(object, \"SOME_CONSTANT\", 42);\\n\\n\\ngiving the same effect as:\\n\\nSOME_CONSTANT = 42\\n\\n\\nwithin the module containing these lines (with the correct object).\\n\\nI\\'m generate several values at the module level dynamically, and as I can\\'t define __getattr__ at the module level, this is my fallback.\\n',\n  'completion': \"import sys\\n\\nthismodule = sys.modules[__name__]\\n\\nsetattr(thismodule, name, value)\\n\\n\\nor, without using setattr (which breaks the letter of the question but satisfies the same practical purposes;-):\\n\\nglobals()[name] = value\\n\\n\\nNote: at module scope, the latter is equivalent to:\\n\\nvars()[name] = value\\n\\n\\nwhich is a bit more concise, but doesn't work from within a function (vars() gives the variables of the scope it's called at: the module's variables when called at global scope, and then it's OK to use it R/W, but the function's variables when called in a function, and then it must be treated as R/O -- the Python online docs can be a bit confusing about this specific distinction).\\n\"},\n {'prompt': \"I was wondering if anyone ever tried to extract/follow RSS item links using\\nSgmlLinkExtractor/CrawlSpider. I can't get it to work...\\n\\nI am using the following rule:\\n\\n\\n\\n   rules = (\\n       Rule(SgmlLinkExtractor(tags=('link',), attrs=False),\\n           follow=True,\\n           callback='parse_article'),\\n       )\\n\\n\\n\\n(having in mind that rss links are located in the link tag).\\n\\nI am not sure how to tell SgmlLinkExtractor to extract the text() of\\nthe link and not to search the attributes ...\\n\\nAny help is welcome,\\nThanks in advance\\n\",\n  'completion': 'CrawlSpider rules don\\'t work that way. You\\'ll probably need to subclass BaseSpider and implement your own link extraction in your spider callback. For example:\\n\\nfrom scrapy.spider import BaseSpider\\nfrom scrapy.http import Request\\nfrom scrapy.selector import XmlXPathSelector\\n\\nclass MySpider(BaseSpider):\\n    name = \\'myspider\\'\\n\\n    def parse(self, response):\\n        xxs = XmlXPathSelector(response)\\n        links = xxs.select(\"//link/text()\").extract()\\n        return [Request(x, callback=self.parse_link) for x in links]\\n\\n\\nYou can also try the XPath in the shell, by running for example:\\n\\nscrapy shell http://blog.scrapy.org/rss.xml\\n\\n\\nAnd then typing in the shell:\\n\\n>>> xxs.select(\"//link/text()\").extract()\\n[u\\'http://blog.scrapy.org\\',\\n u\\'http://blog.scrapy.org/new-bugfix-release-0101\\',\\n u\\'http://blog.scrapy.org/new-scrapy-blog-and-scrapy-010-release\\']\\n\\n'},\n {'prompt': 'I recently wrote a simple and tiny embedded HTTP server for my C++ app (QT) and I played a little bit with Ry\\'s http-parser and loved it. This guy is crazy.\\n\\nSo I told to myself: \"Hey! Why not port the django template engine to C?\" That\\'d be awesome! \\nI know, it won\\'t be an easy task (not at all, I know) but I\\'d really love to implement this. So I came here for inspiration, ideas, opinions... \\n\\nI\\'d really love to have some pointers on the subject, ideas, what is already done, which major problems I\\'ll encounter (and how to solve them) - How not to reinvent the wheel... anyway, you got the idea :)\\n\\nThanks a million times!\\n\\nP.S. Simple code snippets, and links to tools and libs are very welcome!\\n\\nP.P.S. I\\'m already aware of grantlee, I took a look into its sources. Well... that\\'s C++ and it\\'s specific to Qt.\\n',\n  'completion': 'Hmm, I don\\'t see why anything in the django templates code would be hard to implement in C.  The template syntax looks a bit pythonic, but it\\'s not actually python; they implemented their own parser for it.  So the first place to look would be the django template implementation in python.  It\\'s really not much code, and it\\'s reasonably easy to understand.\\n\\nOf course, C will be much more verbose.  What you\\'re writing is exactly a compiler: it reads in some code (the django templates) and writes out some code in another language (the html).  So all the documentation you can find about writing compilers in C (ie. tokenizers + parsers + code generators) is relevant.\\n\\nFirst you\\'ll probably want to generate a syntax tree.  The syntax of django templates is very regular... every {% whatever %} block has a corresponding {% endwhatever %} block, so your parser could actually generate the tree without actually knowing what all the whatever keywords might be.\\n\\nThen, you walk through the tree, doing the \"code gen\" phase for each block.  For example, you\\'d codegen {% if %} by checking the value of the if parameter, and printing either its contents or nothing, depending whether the if clause is true or false.  And so on with while loops, filters, blocks, etc.\\n\\nMind you, all this is a lot of work... have you considered just embedding a python interpreter into your C program?  (Seriously!  It\\'s not that hard to do, since the python interpreter is open source.)\\n'},\n {'prompt': 'Bottle can use several webservers:\\n\\n\\n  Build-in HTTP development server and support for paste, fapws3, flup, cherrypy or any other WSGI capable server.\\n\\n\\nI am using Bottle for a desktop-app and I guess that the development server is enough in this case. I would like to know if some of you have experience with one of the alternative server.\\n\\nWhich server for which purpose?\\n',\n  'completion': 'Python WSGI web apps work fine in Apache, using mod_wsgi.\\n\\nOn Windows, I have WSGI web apps in production on IIS using isapi-wsgi\\n'},\n {'prompt': \"I have the following code in Django:\\n\\nimport locale \\nlocale.setlocale( locale.LC_ALL, '' )\\n\\ndef format_currency(i):\\n    return locale.currency(float(i), grouping=True)\\n\\n\\nIt work on some computers in dev mode, but as soon as I try to deploy it on production I get this error:\\n\\nException Type: TemplateSyntaxError\\nException Value: Caught ValueError while rendering: Currency formatting is not possible using the 'C' locale.\\nException Location: /usr/lib/python2.6/locale.py in currency, line 240\\n\\n\\nThe weird thing is that I can do this on the production server and it will work without any errors:\\n\\npython manage.py shell\\n>>> import locale \\n>>> locale.setlocale( locale.LC_ALL, '' )\\n'en_CA.UTF-8'\\n>>> locale.currency(1, grouping=True)\\n'$1.00'\\n\\n\\nI .. don't get it.i\\n\",\n  'completion': \"On the production server, try\\n\\nlocale.setlocale( locale.LC_ALL, 'en_CA.UTF-8' )\\n\\n\\ninstead of\\n\\nlocale.setlocale( locale.LC_ALL, '' )\\n\\n\\nWhen you use '', the locale is set to the user's default (usually specified by the LANG environment variable). On the production server, that appears to be 'C', while as a test user it appears to be 'en_CA.UTF-8'.\\n\"},\n {'prompt': 'I am interested in knowing what is the Python convention for new lines between the program? For example, consider this:\\n\\nimport os\\n\\ndef func1():\\n\\ndef func2():\\n\\n\\nWhat should be the ideal new line separation between:\\n\\n\\nthe import modules and the\\nfunctions?\\nthe functions themselves? \\n\\n\\nI have read PEP8, but I wanted to confirm the above two points.\\n',\n  'completion': 'two blank lines between the import statements and other code\\ntwo blank lines between each function\\n\\n'},\n {'prompt': \"what's the easiest way to take the intersection of N-many lists in python?\\n\\nif I have two lists a and b, I know I can do:\\n\\na = set(a)\\nb = set(b)\\nintersect = a.intersection(b)\\n\\n\\nbut I want to do something like a & b & c & d & ... for an arbitrary set of lists (ideally without converting to a set first, but if that's the easiest / most efficient way, I can deal with that.)\\n\\nI.e. I want to write a function intersect(*args) that will do it for arbitrarily many sets efficiently.  What's the easiest way to do that?\\n\\nEDIT: My own solution is reduce(set.intersection, [a,b,c]) -- is that good?\\n\\nthanks.\\n\",\n  'completion': 'This works for 1 or more lists. The 0 lists case is not so easy, because it would have to return a set that contains all possible values.\\n\\ndef intersection(first, *others):\\n    return set(first).intersection(*others)\\n\\n'},\n {'prompt': \"I'm using the fractions module in Python v3.1 to compute the greatest common divisor. I would like to know what algorithm is used. I'm guessing the Euclidean method, but would like to be sure. The docs (http://docs.python.org/py3k/library/fractions.html?highlight=fractions.gcd#fractions.gcd) don't help. Can anybody clue me in?\\n\",\n  'completion': 'According to the 3.1.2 source code online, here\\'s gcd as defined in Python-3.1.2/Lib/fractions.py:\\n\\ndef gcd(a, b):\\n    \"\"\"Calculate the Greatest Common Divisor of a and b.\\n\\n    Unless b==0, the result will have the same sign as b (so that when\\n    b is divided by it, the result comes out positive).\\n    \"\"\"\\n    while b:\\n        a, b = b, a%b\\n    return a\\n\\n\\nSo yes, it\\'s the Euclidean algorithm, written in pure Python.\\n'},\n {'prompt': 'The objective is to have two simple ways to source some code, say func.R, containing a function. Calling R CMD BATCH func.R initializes the function and evaluates is. Within a session, issuing source(\"func.R\") simply initializes the function.\\nAny idea?\\n',\n  'completion': 'I think that the interactive() function might work.\\n\\nThis function returns TRUE when R is being used interactively and FALSE otherwise. So just use if(interactive())\\n'},\n {'prompt': \"What's the best way to count the number of occurrences of a given string, including overlap in python? is it the most obvious way:\\n\\ndef function(string, str_to_search_for):\\n      count = 0\\n      for x in xrange(len(string) - len(str_to_search_for) + 1):\\n           if string[x:x+len(str_to_search_for)] == str_to_search_for:\\n                count += 1\\n      return count\\n\\n\\nfunction('1011101111','11')\\nreturns 5\\n\\n\\n?\\n\\nor is there a better way in python?\\n\",\n  'completion': 'Well, this might be faster since it does the comparing in C:\\n\\ndef occurrences(string, sub):\\n    count = start = 0\\n    while True:\\n        start = string.find(sub, start) + 1\\n        if start > 0:\\n            count+=1\\n        else:\\n            return count\\n\\n'},\n {'prompt': 'Every day I love python more and more. \\n\\nToday, I was writing some code like:\\n\\nfor i in xrange(N):\\n    do_something()\\n\\n\\nI had to do something N times. But each time didn\\'t depend on the value of i (index variable).\\nI realized that I was creating a variable I never used (i), and I thought \"There surely is a more pythonic way of doing this without the need for that useless index variable.\"\\n\\nSo... the question is: do you know how to do this simple task in a more (pythonic) beautiful way?\\n',\n  'completion': 'A slightly faster approach than looping on xrange(N) is:\\n\\nimport itertools\\n\\nfor _ in itertools.repeat(None, N):\\n    do_something()\\n\\n'},\n {'prompt': 'If you call the same logging handler from two different python threads, is there a need for locking?\\n',\n  'completion': 'The logging module is thread-safe; it handles the locking for you. See the docs.\\n'},\n {'prompt': 'I\\'m trying to parse an xml file using lxml. xml.etree allowed me to simply pass the file name as a parameter to the parse function, so I attempted to do the same with lxml.\\n\\nMy code:\\n\\nfrom lxml import etree\\nfrom lxml import objectify\\n\\nfile = \"C:\\\\Projects\\\\python\\\\cb.xml\"\\ntree = etree.parse(file)\\n\\n\\nbut I get the error:\\n\\nTraceback (most recent call last):\\n  File \"cb.py\", line 5, in <module>\\n    tree = etree.parse(file)\\n  File \"lxml.etree.pyx\", line 2698, in lxml.etree.parse (src/lxml/lxml.etree.c:4\\n9590)\\n  File \"parser.pxi\", line 1491, in lxml.etree._parseDocument (src/lxml/lxml.etre\\ne.c:71205)\\n  File \"parser.pxi\", line 1520, in lxml.etree._parseDocumentFromURL (src/lxml/lx\\nml.etree.c:71488)\\n  File \"parser.pxi\", line 1420, in lxml.etree._parseDocFromFile (src/lxml/lxml.e\\ntree.c:70583)\\n  File \"parser.pxi\", line 975, in lxml.etree._BaseParser._parseDocFromFile (src/\\nlxml/lxml.etree.c:67736)\\n  File \"parser.pxi\", line 539, in lxml.etree._ParserContext._handleParseResultDo\\nc (src/lxml/lxml.etree.c:63820)\\n  File \"parser.pxi\", line 625, in lxml.etree._handleParseResult (src/lxml/lxml.e\\ntree.c:64741)\\n  File \"parser.pxi\", line 565, in lxml.etree._raiseParseError (src/lxml/lxml.etr\\nee.c:64084)\\nlxml.etree.XMLSyntaxError: AttValue: \" or \\' expected, line 2, column 26\\n\\n\\nWhat am I doing wrong?\\n',\n  'completion': 'What you are doing wrong is (1) not checking whether you got the same outcome by using xml.etree on the same file (2) not reading the error message, which indicates a syntax error in line 2 of the file, way down stream from any file-opening issue\\n'},\n {'prompt': 'I see what seems like a majority of Python developers on StackOverflow endorsing the use of concise functional tools like lambdas, maps, filters, etc., while others say their code is clearer and more maintainable by not using them.  What is your preference?\\n\\nAlso, if you are a die-hard functional programmer or hardcore into OO, what other specific programming practices do you use that you think are best for your style?\\n\\nThanks in advance for your opinions!\\n',\n  'completion': 'I mostly use Python using object-oriented and procedural styles. Python is actually not particularly well-suited to functional programming.\\n\\nA lot of people think they are writing functional Python code by using lots of lambda, map, filter, and reduce, but this is a bit over-simplified. The hallmark feature of functional programming is a lack of state or side effects. Important elements of a functional style are pure functions, recursive algorithms, and first class functions.\\n\\nHere are my thoughts on functional programming and Python:\\n\\n\\nPure functions are great. I do my best to make my module-level functions pure.\\n\\n\\nPure functions can be tested. Since they do not depend on outside state, they are much easier to test.\\nPure functions are able to support other optimizations, such as memoization and trivial parallelization.\\n\\nClass-based programming can be pure. If you want an equivalent to pure functions using Python classes (which is sometimes but not always what you want), \\n\\n\\nMake your instances immutable. In particular, this mainly means to make your methods always return new instances of your class rather than changing the current one.\\nUse dependency injection rather than getting stuff (like imported module) from global scope.\\nThis might not always be exactly what you want.\\n\\nDon\\'t try to avoid state all together. This isn\\'t a reasonable strategy in Python. For example, use some_list.append(foo) rather than new_list = some_list + [foo], the former of which is more idiomatic and efficient. (Indeed, a ton of the \"functional\" solutions I see people use in Python are algorithmically suboptimal compared to just-as-simple or simpler solutions that are not functional or are just as functional but don\\'t use the functional-looking tools.)\\nLearn the best lessons from functional programming, for example mutable state is dangerous. Ask yourself, Do I really want to change this X or do I want a new X?\\n\\n\\nOne really common place this comes up is when processing a list. I would use\\n\\nfoo = [bar(item.baz()) for item in foo]\\n\\n\\nrather than\\n\\nfor index, _ in enumerate(foo):\\n    foo[index] = bar(foo[index].baz())\\n\\n\\nand stuff like it. This avoids confusing bugs where the same list object is stored elsewhere and shouldn\\'t be changed. (If it should be changed, then there is a decent chance you have a design error. Mutating some list you have referenced multiple places isn\\'t a great way to share state.)\\n\\nDon\\'t use map and friends gratuitously. There is nothing more functional about doing this.\\n\\n\\nmap/filter are not  more functional than list comprehensions. List comprehensions were borrowed from Haskell, a pure functional language. map and especially filter can be harder to understand than a list comprehension. I would never use map or filter with a lambda but might if I had a function that already existed; I use map a decent bit.\\nThe same goes for itertools.imap/ifilter compared to generator expressions. (These things are somewhat lazy, which is something great we can borrow from the functional world.)\\nDon\\'t use map and filter for side effects. I see this with map a lot, which both makes hard-to-understand code, unneeded lists, and is decidedly not functional (despite people thinking it must be because of map.) Just use a for loop.\\nreduce is confusing except for very simple cases. Python has for loops and there is no hurt in using them.\\n\\nDon\\'t use recursive algorithms. This is one part of functional programming Python just does not support well. CPython (and I think all other Pythons) do not support tail call optimization. Use iteration instead.\\nOnly use lambda when you are defining functions on the fly. Anonymous functions aren\\'t better than named functions, the latter of which are often more robust, maintainable, and documented.\\n\\n'},\n {'prompt': 'i am kind of confused why python add some additional decimal number in this case, please help to explain\\n\\n>>> mylist = [\"list item 1\", 2, 3.14]\\n>>> print mylist [\\'list item 1\\', 2, 3.1400000000000001]\\n\\n',\n  'completion': \"Floating point numbers are an approximation, they cannot store decimal numbers exactly.  Because they try to represent a very large range of numbers in only 64 bits, they must approximate to some extent.\\n\\nIt is very important to be aware of this, because it results in some weird side-effects.  For example, you might very reasonably think that the sum of ten lots of 0.1 would be 1.0.  While this seems logical, it is also wrong when it comes to floating point:\\n\\n>>> f = 0.0\\n>>> for _ in range (10):\\n...  f += 0.1\\n...\\n>>> print f == 1.0\\nFalse\\n>>> f\\n0.99999999999999989\\n>>> str(f)\\n1.0\\n\\n\\nYou might think that n / m * m == n.  Once again, floating-point world disagrees:\\n\\n>>> (1.0 / 103.0) * 103.0\\n0.99999999999999989\\n\\n\\nOr perhaps just as strangely, one might think that for all n, n + 1 != n.  In floating point land, numbers just don't work like this:\\n\\n>>> 10.0**200\\n9.9999999999999997e+199\\n>>> 10.0**200 == 10.0**200 + 1\\nTrue\\n# How much do we have to add to 10.0**200 before its \\n# floating point representation changes?\\n>>> 10.0**200 == 10.0**200 + 10.0**183\\nTrue\\n>>> 10.0**200 == 10.0**200 + 10.0**184\\nFalse\\n\\n\\nSee What every computer scientist should know about floating point numbers for an excellent summary of the issues.\\n\\nIf you need exact decimal representation, check out the decimal module, part of the python standard library since 2.4.  It allows you to specify the number of significant figures.  The downside is, it is much slower than floating point, because floating point operations are implemented in hardware whereas decimal operations happen purely in software.  It also has its own imprecision issues, but if you need exact representation of decimal numbers (e.g. for a financial application) it's ideal.\\n\\nFor example:\\n\\n>>> 3.14\\n3.1400000000000001\\n>>> import decimal\\n>>> decimal.Decimal('3.14')\\n>>> print decimal.Decimal('3.14')\\n3.14\\n# change the precision:\\n>>> decimal.getcontext().prec = 6\\n>>> decimal.Decimal(1) / decimal.Decimal(7)\\nDecimal('0.142857')\\n>>> decimal.getcontext().prec = 28\\n>>> decimal.Decimal(1) / decimal.Decimal(7)\\nDecimal('0.1428571428571428571428571429')\\n\\n\"},\n {'prompt': 'What are the options for achieving parallelism in Python?  I want to perform a bunch of CPU bound calculations over some very large rasters, and would like to parallelise them.  Coming from a C background, I am familiar with three approaches to parallelism:\\n\\n\\nMessage passing processes, possibly distributed across a cluster, e.g. MPI.\\nExplicit shared memory parallelism, either using pthreads or fork(), pipe(), et. al\\nImplicit shared memory parallelism, using OpenMP.\\n\\n\\nDeciding on an approach to use is an exercise in trade-offs.\\n\\nIn Python, what approaches are available and what are their characteristics?  Is there a clusterable MPI clone?  What are the preferred ways of achieving shared memory parallelism?  I have heard reference to problems with the GIL, as well as references to tasklets.  \\n\\nIn short, what do I need to know about the different parallelization strategies in Python before choosing between them?\\n',\n  'completion': \"Generally, you describe a CPU bound calculation.  This is not Python's forte.  Neither, historically, is multiprocessing.\\n\\nThreading in the mainstream Python interpreter has been ruled by a dreaded global lock.  The new multiprocessing API works around that and gives a worker pool abstraction with pipes and queues and such.\\n\\nYou can write your performance critical code in C or Cython, and use Python for the glue.\\n\"},\n {'prompt': 'Think the title summarizes the question :-)\\n',\n  'completion': 'A script is generally a directly executable piece of code, run by itself.  A module is generally a library, imported by other pieces of code.\\n\\nNote that there\\'s no internal distinction -- both are executable and importable, although library code often won\\'t do anything (or will just run its unit tests) when executed directly and importing code designed to be a script will cause it to execute, hence the common if __name__ == \"__main__\" test.\\n'},\n {'prompt': 'I read this post last night and it got me thinking. I like python and \"batteries\", pypi and such. But I\\'ve only done python solo. Never tried it in a team.\\n\\nAre the points that Ted mentions valid? If they are how do teams cope with them? Does Python work in teams or even large teams? Or it kills productivity?\\n\\nI personally see the problems he mentions when I come back to my old code. Even when working with other modules sometimes I need to peek inside. I would like to hear people with experience on this.\\n',\n  'completion': 'Python works fine in teams. Whether a language works in large teams is largely a factor of how well the team works together, and has little to do with the language.\\n'},\n {'prompt': 'Building on another SO question, how can one check whether two well-formed XML snippets are semantically equal.  All I need is \"equal\" or not, since I\\'m using this for unit tests.\\n\\nIn the system I want, these would be equal (note the order of \\'start\\'\\nand \\'end\\'):\\n\\n<?xml version=\\'1.0\\' encoding=\\'utf-8\\' standalone=\\'yes\\'?>\\n<Stats start=\"1275955200\" end=\"1276041599\">\\n</Stats>\\n\\n# Reordered start and end\\n\\n<?xml version=\\'1.0\\' encoding=\\'utf-8\\' standalone=\\'yes\\'?>\\n<Stats end=\"1276041599\" start=\"1275955200\" >\\n</Stats>\\n\\n\\nI have lmxl and other tools at my disposal, and a simple function that only allows reordering of attributes would work fine as well!  \\n\\n\\n\\nWorking snippet based on IanB\\'s answer:\\n\\nfrom formencode.doctest_xml_compare import xml_compare\\n# have to strip these or fromstring carps\\nxml1 = \"\"\"    <?xml version=\\'1.0\\' encoding=\\'utf-8\\' standalone=\\'yes\\'?>\\n    <Stats start=\"1275955200\" end=\"1276041599\"></Stats>\"\"\"\\nxml2 = \"\"\"     <?xml version=\\'1.0\\' encoding=\\'utf-8\\' standalone=\\'yes\\'?>\\n    <Stats end=\"1276041599\" start=\"1275955200\"></Stats>\"\"\"\\nxml3 = \"\"\" <?xml version=\\'1.0\\' encoding=\\'utf-8\\' standalone=\\'yes\\'?>\\n    <Stats start=\"1275955200\"></Stats>\"\"\"\\n\\nfrom lxml import etree\\ntree1 = etree.fromstring(xml1.strip())\\ntree2 = etree.fromstring(xml2.strip())\\ntree3 = etree.fromstring(xml3.strip())\\n\\nimport sys\\nreporter = lambda x: sys.stdout.write(x + \"\\\\n\")\\n\\nassert xml_compare(tree1,tree2,reporter)\\nassert xml_compare(tree1,tree3,reporter) is False\\n\\n',\n  'completion': 'You can use formencode.doctest_xml_compare -- the xml_compare function compares two ElementTree or lxml trees.\\n'},\n {'prompt': 'I\\'d like to be able to do:\\n\\n>>> class a(str):\\n...     pass\\n...\\n>>> b = a()\\n>>> b.__class__ = str\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nTypeError: __class__ assignment: only for heap types\\n\\n',\n  'completion': \"I've solved it in this way:\\n\\n>>> class C(str):\\n...     def __getattribute__(self, name):\\n...         if name == '__class__':\\n...             return str\\n...         else:\\n...             return super(C, self).__getattribute__(name)\\n...         \\n>>> c = C()\\n>>> c.__class__\\n<type 'str'>\\n\\n\"},\n {'prompt': \"Suppose I have a numpy array x = [5, 2, 3, 1, 4, 5], y = ['f', 'o', 'o', 'b', 'a', 'r']. I want to select the elements in y corresponding to elements in x that are greater than 1 and less than 5.\\n\\nI tried\\n\\nx = array([5, 2, 3, 1, 4, 5])\\ny = array(['f','o','o','b','a','r'])\\noutput = y[x > 1 & x < 5] # desired output is ['o','o','a']\\n\\n\\nbut this doesn't work. How would I do this?\\n\",\n  'completion': \"Your expression works if you add parentheses:\\n\\n>>> y[(1 < x) & (x < 5)]\\narray(['o', 'o', 'a'], \\n      dtype='|S1')\\n\\n\"},\n {'prompt': 'I am trying to understand the advantages of multiprocessing over threading. I know that multiprocessing gets around the Global Interpreter Lock, but what other advantages are there, and can threading not do the same thing?\\n',\n  'completion': \"Here are some pros/cons I came up with.\\n\\nMultiprocessing\\n\\nPros\\n\\n\\nSeparate memory space\\nCode is usually straightforward\\nTakes advantage of multiple CPUs & cores\\nAvoids GIL limitations for cPython\\nEliminates most needs for synchronization primitives unless if you use shared memory (instead, it's more of a communication model for IPC)\\nChild processes are interruptible/killable\\nPython multiprocessing module includes useful abstractions with an interface much like threading.Thread\\nA must with cPython for CPU-bound processing\\n\\n\\nCons\\n\\n\\nIPC a little more complicated with more overhead (communication model vs. shared memory/objects)\\nLarger memory footprint\\n\\n\\nThreading\\n\\nPros\\n\\n\\nLightweight - low memory footprint\\nShared memory - makes access to state from another context easier\\nAllows you to easily make responsive UIs\\ncPython C extension modules that properly release the GIL will run in parallel\\nGreat option for I/O-bound applications\\n\\n\\nCons\\n\\n\\ncPython - subject to the GIL\\nNot interruptible/killable\\nIf not following a command queue/message pump model (using the Queue module), then manual use of synchronization primitives become a necessity (decisions are needed for the granularity of locking)\\nCode is usually harder to understand and to get right - the potential for race conditions increases dramatically \\n\\n\"},\n {'prompt': \"\\n  Possible Duplicate:\\n  is python slower than java/C#?  \\n\\n\\n\\n\\nIgnoring all the characteristics of each languages and focusing SOLELY on speed, which language is better performance-wise?\\n\\nYou'd think this would be a rather simple question to answer, but I haven't found a decent one.\\n\\nI'm aware that some types of operations may be faster with python, and vice-versa, but I cannot find any detailed information on this. Can anyone shed some light on the performance differences?\\n\",\n  'completion': \"Java is faster than Python. Easily.\\n\\nPython is favorable for many things; speed isn't necessarily one of them.\\n\\nReferences\\n\\n\\npython.org/Language Comparisons\\n\\nC++ vs Java vs Python vs Ruby : a first impression\\nA subjective analysis of two high-level, object-oriented languages: Comparing Python to Java\\n\\n\\n\"},\n {'prompt': \"I have a model form that I use to update a model.\\n\\nclass Turtle(models.Model):\\n    name = models.CharField(max_length=50, blank=False)\\n    description = models.TextField(blank=True)\\n\\nclass TurtleForm(forms.ModelForm):\\n    class Meta:\\n        model = Turtle\\n\\n\\nSometimes I don't need to update the entire model, but only want to update one of the fields.  So when I POST the form only has information for the description.  When I do that the model never saves because it thinks that the name is being blanked out while my intent is that the name not change and just be used from the model.\\n\\n    turtle_form = TurtleForm(request.POST, instance=object)\\n    if turtle_form.is_valid():\\n        turtle_form.save()\\n\\n\\nIs there any way to make this happen?  Thanks!\\n\",\n  'completion': \"Only use specified fields:\\n\\nclass FirstModelForm(forms.ModelForm):\\n    class Meta:\\n        model = TheModel\\n        fields = ('title',)\\n    def clean_title(self....\\n\\n\\nSee http://docs.djangoproject.com/en/dev/topics/forms/modelforms/#controlling-which-fields-are-used-with-fields-and-exclude\\n\\nIt is common to use different ModelForms for a model in different views, when you need different features. So creating another form for the model that uses the same behaviour (say clean_<fieldname> methods etc.) use:\\n\\nclass SecondModelForm(FirstModelForm):\\n    class Meta:\\n        model = TheModel\\n        fields = ('title', 'description')\\n\\n\"},\n {'prompt': \"I'm trying to use python to determine if one (small) image is within another (large) image.  \\n\\nAny suggestions before I take myself completely down the wrong path?\\n\\n/edit: Ok, some ideas:  I'm using PIL, and I'm converting each image to the 'P' mode so I can compare each pixel as an integer.  I'm trying to implement something like a Boyerâ\\x80\\x93Moore string search or the Knuthâ\\x80\\x93Morrisâ\\x80\\x93Pratt algorithm, but in 2 dimensions.\\n\\nMaybe this will help: instead of searching for ABC in XXXABCXXX (answer=4) we are searching for    \\n\\nABC    \\nDEF    \\nGHI    \\n\\n\\nin    \\n\\nXXXXX        \\nXABCX        \\nXDEFX       \\nXGHIX    \\nXXXXX  \\n\\n\\n(answer=(2,2)) \\n\",\n  'completion': 'Sikuli does it using OpenCV, see here how match_by_template works and then use the Python OpenCV bindings to do the same. Doing it without OpenCV should be hard, take a look at OpenCV documentation, search for template matching, etc...\\n'},\n {'prompt': 'In the django admin you can set the search_fields for the ModelAdmin to be able to search over the properties given there. My model class has a property that is not a real model property, means it is not within the database table. The property relates to another database table that is not tied to the current model through relations.\\nBut I want to be able to search over it, so I have to somehow customize the query the admin site creates to do the filtering when the search field was filled - is this possible and if, how?\\nI can query the database table of my custom property and it then returns the ids of the model classes fitting the search. This then, as I said, has to flow into the admin site search query.\\n\\nThanks!\\n',\n  'completion': \"Since django 1.6, you can customize the search by defining a get_search_results method in your ModelAdmin subclass.\\n\\nIt is well explained in django documentation. The following example is copied for this doc.\\n\\nclass PersonAdmin(admin.ModelAdmin):\\n    list_display = ('name', 'age')\\n    search_fields = ('name',)\\n\\n    def get_search_results(self, request, queryset, search_term):\\n        queryset, use_distinct = super(PersonAdmin, self).get_search_results(request, queryset, search_term)\\n        try:\\n            search_term_as_int = int(search_term)\\n            queryset |= self.model.objects.filter(age=search_term_as_int)\\n        except:\\n            pass\\n        return queryset, use_distinct\\n\\n\"},\n {'prompt': 'It\\'s not the first time I\\'m having this problem, and it\\'s really bugging me.\\nWhenever I open a pipe using the Python subprocess module, I can only communicate with it once, as the documentation specifies: Read data from stdout and stderr, until end-of-file is reached\\n\\nproc = sub.Popen(\"psql -h darwin -d main_db\".split(),stdin=sub.PIPE,stdout=sub.PIPE)\\nprint proc.communicate(\"select a,b,result from experiment_1412;\\\\n\")[0]\\nprint proc.communicate(\"select theta,zeta,result from experiment_2099\\\\n\")[0]\\n\\n\\nThe problem here is that the second time, Python isn\\'t happy. Indeed, he decided to close the file after the first communicate:\\n\\nTraceback (most recent call last):\\nFile \"a.py\", line 30, in <module>\\n    print proc.communicate(\"select theta,zeta,result from experiment_2099\\\\n\")[0]\\nFile \"/usr/lib64/python2.5/subprocess.py\", line 667, in communicate\\n    return self._communicate(input)\\nFile \"/usr/lib64/python2.5/subprocess.py\", line 1124, in _communicate\\n     self.stdin.flush()\\nValueError: I/O operation on closed file\\n\\n\\nAre multiple communications allowed?\\n',\n  'completion': \"I think you misunderstand communicate...\\n\\nhttp://docs.python.org/library/subprocess.html#subprocess.Popen.communicate\\n\\ncommunicate sends a string to the other process and then waits on it to finish... (Like you said waits for the EOF listening to the stdout & stderror)\\n\\nWhat you should do instead is:\\n\\nproc.stdin.write('message')\\n\\n# ...figure out how long or why you need to wait...\\n\\nproc.stdin.write('message2')\\n\\n\\n(and if you need to get the stdout or stderr you'd use proc.stdout or proc.stderr)\\n\"},\n {'prompt': 'I use django flatpages for a lot of content on our site, I\\'d like to extend it to accept django template tags in the content as well.\\n\\nI found this snippet but after much larking about I couldn\\'t get it to work. Am I correct in assuming that you would need too \"subclass\" the django flatpages app to get this to work? Is this best way of doing it? I\\'m not quite sure how to structure it, as I don\\'t really want to directly modify the django distribution. \\n',\n  'completion': '1. A simple page view wich will render template tags by loading a template for each page:\\n\\nin url.py\\n\\nurl(r\\'^page/(?P<slug>.*)/$\\',\\'my_app.views.page_detail\\', name=\\'page_url\\'),\\n\\n\\nin my_app/views.py\\n\\ndef page_detail (request, slug):\\n    return render_to_response(\\'page/\\' + slug + \\'.html\\', {},\\n                              context_instance=RequestContext(request))\\n\\n\\n2. Another method with flat pages stored in database, is to use a \"template evaluation tag\" in your template like this one.\\n\\nedit You just have to modify flatpages template like this:\\n\\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"\\n    \"http://www.w3.org/TR/REC-html40/loose.dtd\">\\n<html>\\n<head>\\n<title>{{ flatpage.title }}</title>\\n</head>\\n<body>\\n{% load evaluate_tag %} \\n{% evaluate flatpage.content %} \\n</body>\\n</html>\\n\\n'},\n {'prompt': 'import urllib2\\n\\nwebsite = \"WEBSITE\"\\nopenwebsite = urllib2.urlopen(website)\\nhtml = getwebsite.read()\\n\\nprint html\\n\\n\\nSo far so good. \\n\\nBut I want only href links from the plain text HTML. How can I solve this problem? \\n',\n  'completion': 'Try with Beautifulsoup:\\n\\nfrom BeautifulSoup import BeautifulSoup\\nimport urllib2\\nimport re\\n\\nhtml_page = urllib2.urlopen(\"http://www.yourwebsite.com\")\\nsoup = BeautifulSoup(html_page)\\nfor link in soup.findAll(\\'a\\'):\\n    print link.get(\\'href\\')\\n\\n\\nIn case you just want links starting with http://, you should use:\\n\\nsoup.findAll(\\'a\\', attrs={\\'href\\': re.compile(\"^http://\")})\\n\\n'},\n {'prompt': 'I have some very large C files, having lots of functions. I need to trace the execution path at run time. There is no way I can trace it through debugging as its a hypervisor code currently running over qemu and doing a lot of binary translations.\\n\\nCan anyone point me to some script in Perl or Python which can add a printf at the starting of all functions and the text could be something like \"I am in < function name >\"?\\n',\n  'completion': 'Just pass -finstrument-functions to gcc when compiling. See the gcc(1) man page for details.\\n'},\n {'prompt': 'I\\'m trying to use [SymPy][1] to substitute multiple terms in an expression at the same time. I tried the [subs function][2] with a dictionary as parameter, but found out that it substitutes sequentially.\\n\\nIn : a.subs({a:b, b:c})\\nOut: c\\n\\n\\nThe problem is the first substitution resulted in a term that can be substituted by the second substitution, but it should not (for my cause). \\n\\nAny idea on how to perform the substitutions simultaneously, without them interfering with each other?\\n\\nEdit:\\nThis is a real example\\n\\nIn [1]: I_x, I_y, I_z = Symbol(\"I_x\"), Symbol(\"I_y\"), Symbol(\"I_z\")\\n\\nIn [2]: S_x, S_y, S_z = Symbol(\"S_x\"), Symbol(\"S_y\"), Symbol(\"S_z\")\\n\\nIn [3]: J_is = Symbol(\"J_IS\")\\n\\nIn [4]: t = Symbol(\"t\")\\n\\nIn [5]: substitutions = (\\n(2 * I_x * S_z, 2 * I_x * S_z * cos(2 * pi * J_is * t) + I_y * sin(2 * pi * J_is * t)),\\n(I_x,  I_x * cos(2 * pi * J_is * t) + 2 * I_x * S_z * sin(2 * pi * J_is * t)),\\n(I_y,  I_y * cos(2 * pi * J_is * t) - 2 * I_x * S_z * sin(2 * pi * J_is * t))\\n)\\n\\nIn [6]: (2 * I_x * S_z).subs(substitutions)\\nOut[7]: (I_y*cos(2*pi*J_IS*t) - 2*I_x*S_z*sin(2*pi*J_IS*t))*sin(2*pi*J_IS*t) + 2*S_z*(I_x*cos(2*pi*J_IS*t) + 2*I_x*S_z*sin(2*pi*J_IS*t))*cos(2*pi*J_IS*t)\\n\\n\\nOnly the appropriate substitution should happen, in this case only the first one. So the expected output should be the following:\\n\\nIn [6]: (2 * I_x * S_z).subs(substitutions)\\nOut[7]: I_y*sin(2*pi*J_IS*t) + 2*I_x*S_z*cos(2*pi*J_IS*t)\\n\\n',\n  'completion': 'The current version of sympy provides the keyword simultaneous. The complicated operations in the previous answers are no more necessary:\\n\\nIn [1]: (x*sin(y)).subs([(x,y),(y,x)],simultaneous=True)\\nOut[1]: yâ\\x8b\\x85sin(x)\\n\\n'},\n {'prompt': \"I'm starting to develop a facebook application using Django.\\n\\nI'm trying to choose the appropriate API wrapper for my application and I can't decide whether to use PyFacebook (very well documented but no official release) or the official Facebook Python SDK (which is surprisingly poorly documented). \\n\\nAre there any major differences between the two that I'm missing?\\n\\nThank you,\\nLiz\\n\",\n  'completion': 'I believe PyFacebook was made for the old Facebook API (used to be the way to go) while the Facebook Platform Python SDK is a new official library from facebook and is aimed towards the new Graph API\\n\\nSo I suggest you start using the latter. And yeah the documentation totally sucks in both cases, took me a while to figure it out.\\n\\nUPDATE:\\n\\nFor you latecomers: The most recent up-to-date seems to be: https://github.com/pythonforfacebook/facebook-sdk/\\n'},\n {'prompt': 'Musing over a recently asked question, I started to wonder if there is a really simple way to deal with XML documents in Python. A pythonic way, if you will.\\n\\nPerhaps I can explain best if i give example: let\\'s say the following - which i think is a good example of how XML is (mis)used in web services - is the response i get from http request to http://www.google.com/ig/api?weather=94043\\n\\n<xml_api_reply version=\"1\">\\n  <weather module_id=\"0\" tab_id=\"0\" mobile_row=\"0\" mobile_zipped=\"1\" row=\"0\" section=\"0\" >\\n    <forecast_information>\\n      <city data=\"Mountain View, CA\"/>\\n      <postal_code data=\"94043\"/>\\n      <latitude_e6 data=\"\"/>\\n      <longitude_e6 data=\"\"/>\\n      <forecast_date data=\"2010-06-23\"/>\\n      <current_date_time data=\"2010-06-24 00:02:54 +0000\"/>\\n      <unit_system data=\"US\"/>\\n    </forecast_information>\\n    <current_conditions>\\n      <condition data=\"Sunny\"/>\\n      <temp_f data=\"68\"/>\\n      <temp_c data=\"20\"/>\\n      <humidity data=\"Humidity: 61%\"/>\\n      <icon data=\"/ig/images/weather/sunny.gif\"/>\\n      <wind_condition data=\"Wind: NW at 19 mph\"/>\\n    </current_conditions>\\n    ...\\n    <forecast_conditions>\\n      <day_of_week data=\"Sat\"/>\\n      <low data=\"59\"/>\\n      <high data=\"75\"/>\\n      <icon data=\"/ig/images/weather/partly_cloudy.gif\"/>\\n      <condition data=\"Partly Cloudy\"/>\\n    </forecast_conditions>\\n  </weather>\\n</xml_api_reply>\\n\\n\\nAfter loading/parsing such document, i would like to be able to access the information as simple as say \\n\\n>>> xml[\\'xml_api_reply\\'][\\'weather\\'][\\'forecast_information\\'][\\'city\\'].data\\n\\'Mountain View, CA\\'\\n\\n\\nor\\n\\n>>> xml.xml_api_reply.weather.current_conditions.temp_f[\\'data\\']\\n\\'68\\'\\n\\n\\nFrom what I saw so far, seems that ElementTree is the closest to what I dream of. But it\\'s not there, there is still some fumbling to do when consuming XML. OTOH, what I am thinking is not that complicated - probably just thin veneer on top of a parser - and yet it can decrease annoyance of dealing with XML. Is there such a magic? (And if not - why?)\\n\\nPS. Note I have tried BeautifulSoup already and while I like its approach, it has real issues with empty <element/>s - see below in comments for examples.\\n',\n  'completion': 'lxml has been mentioned. You might also check out lxml.objectify for some really simple manipulation.\\n\\n>>> from lxml import objectify\\n>>> tree = objectify.fromstring(your_xml)\\n>>> tree.weather.attrib[\"module_id\"]\\n\\'0\\'\\n>>> tree.weather.forecast_information.city.attrib[\"data\"]\\n\\'Mountain View, CA\\'\\n>>> tree.weather.forecast_information.postal_code.attrib[\"data\"]\\n\\'94043\\'\\n\\n'},\n {'prompt': 'this is my first question on StackOverflow, so please tell me how I can improve it in the comments.\\n\\nI am writing a program to find adapters, and have made a class called \\'Adapter\\'. When I pass in two arguments IDLE gives me an error saying I passed in three! Here is the code and stack trace:\\n\\n#This is the adapter class for the adapter finder script\\n\\nclass Adapter:\\n    side1 = (None,None)\\n    side2 = (None,None)\\n    \\'\\'\\'The class that holds both sides of the adapter\\'\\'\\'\\n    def __init__((pType1,pMF1),(pType2,pMF2)):\\n        \\'\\'\\'Initiate the adapter.\\n\\n        Keyword Arguments:\\n        pType1 -- The passed type of one side of the adapter. ex: BNC, RCA\\n        pMF1 -- The passed gender of pType1. ex: m, f\\n\\n        pType2 -- The passed type of one side of the adapter. ex: BNC, RCA\\n        pMF2 -- The passed gender of pType2. ex: m, f\\n\\n        \\'\\'\\'\\n\\n        print \\'assigining now\\'\\n        side1 = (pType1,pMF1)\\n        print side1\\n        side2 = (pType2,pMF2)\\n        print side2\\n\\nsideX = (\\'rca\\',\\'m\\')\\nsideY = (\\'bnc\\',\\'f\\')\\n\\nx = Adapter(sideX,sideY)\\nprint x.side1\\nprint x.side2\\n\\n\\nError:\\nTraceback (most recent call last):\\n  File \"C:\\\\Users\\\\Cody\\\\Documents\\\\Code\\\\Python\\\\Adapter Finder\\\\adapter.py\", line 28, in <module>\\n    x = Adapter(sideX,sideY)\\nTypeError: __init__() takes exactly 2 arguments (3 given)\\n\\nI dont understand what the problem is because I\\'ve only entered two args!\\n\\nEdit: Im new to the python language, though I know Java.\\nIm using this page as a tutorial: http://docs.python.org/tutorial/classes.html\\n',\n  'completion': \"Yes, the OP missed the self, but I don't even know what those tuples-as-arguments mean and I'm intentionally not bothering to figure it out, it's just a bad construction.\\n\\nCodysehi, please contrast your code with:\\n\\nclass Adapter:\\n    def __init__(self, side1, side2):\\n        self.side1 = side1\\n        self.side2 = side2\\n\\nsideX = ('rca', 'm')\\nsideY = ('bnc', 'f')\\nx = Adapter(sideX, sideY)\\n\\n\\nand see that it is both more readable, and does what I think you intend.\\n\"},\n {'prompt': 'I have one y variable, which I am trying to plot against two related x axes, on the top and bottom of the figure (e.g. y=\"number of things in cube\", x1=\"side length of cube\", x2=\"volume of cube\"). I have y, x1, x2 in numpy arrays. The relationship between my x1 and x2 is one-to-one and monotonic, but not simple, and they increase in different directions, like \"side length\" and \"inverse volume\". I\\'ve tried using twiny() and twin(), but these seem to be designed for plotting different y variables. Any ideas? Thanks everyone!\\n\\nBelow is an example of the kind of thing I\\'m trying to do, except with a single line rather than symbols. The idea is that, say, sigma=0.4 and M=2e15 are equivalent and interchangeable labels for one point.\\n\\n\\n',\n  'completion': 'For different x-scales use twiny() (think of this as \"shared y-axes\"). An example slightly adapted from the matplotlib documentation:\\n\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# plot f(x)=x for two different x ranges\\nx1 = np.linspace(0, 1, 50)\\nx2 = np.linspace(0, 2, 50)\\nfig = plt.figure()\\n\\nax1 = fig.add_subplot(111)\\nax1.plot(x1, x1,\\'b--\\')\\n\\nax2 = ax1.twiny()\\nax2.plot(x2, x2, \\'go\\')\\n\\nplt.show()\\n\\n\\nIf you just wanted a second axis plot the second data set as invisible.\\n\\nax2.plot(x2, x2, alpha=0)\\n\\n'},\n {'prompt': 'I am looking for the most pythonic way of splitting a list of numbers into smaller lists based on a number missing in the sequence.  For example, if the initial list was:\\n\\nseq1 = [1, 2, 3, 4, 6, 7, 8, 9, 10]\\n\\n\\nthe function would yield:\\n\\n[[1, 2, 3, 4], [6, 7, 8, 9, 10]]\\n\\n\\nor\\n\\nseq2 = [1, 2, 4, 5, 6, 8, 9, 10]\\n\\n\\nwould result in:\\n\\n[[1, 2], [4, 5, 6], [8, 9, 10]]\\n\\n',\n  'completion': \"From the python documentation:\\n\\n>>> # Find runs of consecutive numbers using groupby.  The key to the solution\\n>>> # is differencing with a range so that consecutive numbers all appear in\\n>>> # same group.\\n>>> data = [ 1,  4,5,6, 10, 15,16,17,18, 22, 25,26,27,28]\\n>>> for k, g in groupby(enumerate(data), lambda (i,x):i-x):\\n...     print map(itemgetter(1), g)\\n...\\n[1]\\n[4, 5, 6]\\n[10]\\n[15, 16, 17, 18]\\n[22]\\n[25, 26, 27, 28]\\n\\n\\nThe groupby() function from the itertools module generates a break every time the key function changes its return value. The trick is that the return value is the number in the list minus the position of the element in the list. This difference changes when there is a gap in the numbers.\\n\\nThe itemgetter() function  is from the operator module, you'll have to import this and the itertools module for this example to work.\\n\\nFull example with your data:\\n\\n>>> from operator import itemgetter\\n>>> from itertools import *\\n>>> seq2 = [1, 2, 4, 5, 6, 8, 9, 10]\\n>>> list = []\\n>>> for k, g in groupby(enumerate(seq2), lambda (i,x):i-x):\\n...     list.append(map(itemgetter(1), g))\\n... \\n>>> print list\\n[[1, 2], [4, 5, 6], [8, 9, 10]]\\n\\n\\nOr as a list comprehension:\\n\\n>>> [map(itemgetter(1), g) for k, g in groupby(enumerate(seq2), lambda (i,x):i-x)]\\n[[1, 2], [4, 5, 6], [8, 9, 10]]\\n\\n\"},\n {'prompt': 'I am enormously impressed with the ease of use of XLWT, but there is one thing I have not figured out how to do.  I am trying to adjust certain rows to the minimum width they would need to display all characters (in other words, what excel would do if you double clicked on the divider between cells).  \\n\\nI know how to adjust the column widths to a predetermined amount, but I am not certain how to determine the minimum width needed to display everything.\\n',\n  'completion': 'Width is 1/256 the width of the zero character for the default font. A good enough approximation is:\\n\\ndef get_width(num_characters):\\n    return int((1+num_characters) * 256)\\n\\n'},\n {'prompt': 'I am looking for references (tutorials, books, academic literature) concerning structuring unstructured text in a manner similar to the google calendar quick add button.\\n\\nI understand this may come under the NLP category, but I am interested only in the process of going from something like \"Levi jeans size 32 A0b293\"\\n\\nto: Brand: Levi, Size: 32, Category: Jeans, code: A0b293\\n\\nI imagine it would be some combination of lexical parsing and machine learning techniques.\\n\\nI am rather language agnostic but if pushed would prefer python, Matlab or C++ references\\n\\nThanks\\n',\n  'completion': \"You need to provide more information about the source of the text (the web? user input?), the domain (is it just clothes?), the potential formatting and vocabulary...\\n\\nAssuming worst case scenario you need to start learning NLP. A very good free book is the documentation of NLTK: http://www.nltk.org/book . It is also a very good introduction to Python and the SW is free (for various usages). Be warned: NLP is hard. It doesn't always work. It is not fun at times. The state of the art is no where near where you imagine it is.\\n\\nAssuming a better scenario (your text is semi-structured) - a good free tool is pyparsing. There is a book, plenty of examples and the resulting code is extremely attractive.\\n\\nI hope this helps...\\n\"},\n {'prompt': \"I've gotten used to writing functions that work like this:\\n\\ndef f():\\n  if sunny:\\n    return\\n  #do non-sunny stuff\\n\\n\\nI'm trying to figure out the equivalent syntax to use within a module. I want to do something like this:\\n\\nif sunny:\\n  import tshirt\\n  #do something here to skip the rest of the file\\nimport raincoat\\nimport umbrella\\n#continue defining the module for non-sunny conditions\\n\\n\\nI know I can write this as an if/else but it seems silly to indent the entire rest of my module.\\n\\nI could move the rest of the code into a separate module and conditionally import it, but that seems painful.\\n\",\n  'completion': 'Separate files and extra indentation are probably reasonable given that this is a weird thing to be doing to begin with.\\n\\nDepending on what you actually need, you might go ahead and process all of the module body and then delete anything that isn\\'t appropriate at some point later.\\n\\ndef foo(): \\n  print \"foo\"\\ndef bar(): \\n  print \"bar\"\\n\\nif sunny:\\n  del foo\\nelse:\\n  del bar\\n\\n'},\n {'prompt': \"I do know that cherrypy is a multithreaded and also has a threadpool implementation.\\nSo I wanted to try an example showing multithreaded behaviour.\\nNow lets say I've my some function in the root class and rest all things are configured\\n\\ndef testPage(self, *args, **kwargs):\\n    current = threading.currentThread()\\n    print 'Starting ' , current\\n    time.sleep(5)\\n    print 'Ending ' ,current\\n    return '<html>Hello World</html>'\\n\\n\\nNow lets say I run my page as http://localhost:6060/root/testPage in 3-4 tabs of browser.\\nWhat result I get is\\n\\nStarting <WorkerThread(CP WSGIServer Thread-10, started 4844)>\\nEnding <WorkerThread(CP WSGIServer Thread-10, started 4844)>\\nStarting <WorkerThread(CP WSGIServer Thread-7, started 4841)>\\nEnding <WorkerThread(CP WSGIServer Thread-7, started 4841)>\\nStarting <WorkerThread(CP WSGIServer Thread-10, started 4844)>\\nEnding <WorkerThread(CP WSGIServer Thread-10, started 4844)>\\n\\n\\nThe thing I can clearly understand that it's creating new threads for processing every new request but I cannot figure out why every time I get starting...ending..starting..ending\\nand why not starting...starting..ending..ending sometimes\\nBecause what my assumption is that time.sleep will make some thread to suspend and other one can execute at that time.\\n\",\n  'completion': 'This is almost certainly a limitation of your browser and not of CherryPy. Firefox 2, for example, will make no more than 2 concurrent requests to the same domain, even with multiple tabs. And if each tab is also fetching a favicon...that leaves one hit at a time on your handler.\\n\\nSee http://www.cherrypy.org/ticket/550 for a ticket with similar source code, and a longer proof.\\n'},\n {'prompt': \"I am calling different processes with the subprocess module. However, I have a question.\\n\\nIn the following codes:\\n\\ncallProcess = subprocess.Popen(['ls', '-l'], shell=True)\\n\\n\\nand \\n\\ncallProcess = subprocess.Popen(['ls', '-l']) # without shell\\n\\n\\nBoth work. After reading the docs, I came to know that shell=True means executing the code through the shell. So that means in absence, the process is directly started. \\n\\nSo what should I prefer for my case - I need to run a process and get its output. What benefit do I have from calling it from within the shell or outside of it.\\n\",\n  'completion': 'The benefit of not calling via the shell is that you are not invoking a \\'mystery program.\\'  On POSIX, the environment variable SHELL controls which binary is invoked as the \"shell.\"  On Windows, there is no bourne shell descendent, only cmd.exe.\\n\\nSo invoking the shell invokes a program of the user\\'s choosing and is platform-dependent.  Generally speaking, avoid invocations via the shell.\\n\\nInvoking via the shell does allow you to expand environment variables and file globs according to the shell\\'s usual mechanism.  On POSIX systems, the shell expands file globs to a list of files.  On Windows, a file glob (e.g., \"*.*\") is not expanded by the shell, anyway (but environment variables on a command line are expanded by cmd.exe).\\n\\nIf you think you want environment variable expansions and file globs, research the ILS attacks of 1992-ish on network services which performed subprogram invocations via the shell.  Examples include the various sendmail backdoors involving ILS.\\n\\nIn summary, use shell=False.\\n'},\n {'prompt': 'Is there a good way to do the following?\\n\\nI wrote a simple console app to upload and download files from an FTP server using the ftplib.\\n\\nEach time some data chunks are downloaded, I want to update a text progress bar, even if it\\'s just a number.\\n\\nBut I don\\'t want to erase all the text that\\'s been printed to the console. (Doing a \"clear\" and then printing the updated percentage.)\\n',\n  'completion': 'Writing \\'\\\\r\\' will move the cursor back to the beginning of the line.\\n\\nThis displays a percentage counter:\\n\\nimport time\\nimport sys\\n\\nfor i in range(100):\\n    time.sleep(1)\\n    sys.stdout.write(\"\\\\r%d%%\" % i)\\n    sys.stdout.flush()\\n\\n'},\n {'prompt': 'I am trying to change the matplotlib font to helvetica, which I\\'d like to use in a PDF plot.  I try the following:\\n\\nimport matplotlib\\nmatplotlib.use(\\'PDF\\')\\nimport matplotlib.pylab as plt\\nfrom matplotlib import rc\\nplt.rcParams[\\'ps.useafm\\'] = True\\nrc(\\'font\\',**{\\'family\\':\\'sans-serif\\',\\'sans-serif\\':[\\'Helvetica\\']})\\nplt.rcParams[\\'pdf.fonttype\\'] = 42\\n\\n\\nThis does not work -- when I run my code with --verbose-debug, I get the error:\\n\\nbackend WXAgg version 2.8.10.1\\n/Library/Frameworks/Python.framework/Versions/6.2/lib/python2.6/site-packages/matplotlib/__init__.py:833: UserWarning:  This call to matplotlib.use() has no effect\\nbecause the the backend has already been chosen;\\nmatplotlib.use() must be called *before* pylab, matplotlib.pyplot,\\nor matplotlib.backends is imported for the first time.\\nfindfont: Could not match :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=medium. Returning /Library/Frameworks/Python.framework/Versions/6.2/lib/python2.6/site-packages/matplotlib/mpl-data/fonts/ttf/Vera.ttf\\nAssigning font /F1 = /Library/Frameworks/Python.framework/Versions/6.2/lib/python2.6/site-packages/matplotlib/mpl-data/fonts/ttf/Vera.ttf\\nEmbedding font /Library/Frameworks/Python.framework/Versions/6.2/lib/python2.6/site-packages/matplotlib/mpl-data/fonts/ttf/Vera.ttf\\nWriting TrueType font\\n\\n\\nSo apparently it cannot find Helvetica.  I am not sure why.  I have Helvetica in the afm directory of mpl-data, and when matplotlib initiates it reads it and outputs:\\n\\ncreateFontDict: /Library/Frameworks/Python.framework/Versions/6.2/lib/python2.6/site-packages/matplotlib/mpl-data/fonts/afm/Helvetica.afm\\n\\n\\nDo I need a special .ttf Helvetica font in addition?  If so, how can I get it?  I know I have Helvetica on my system since I see it in Illustrator and many other programs.  \\n\\nI am using Enthought Python distribution as follows:\\n\\n$ python\\nEnthought Python Distribution -- http://www.enthought.com\\nVersion: 6.2-2 (32-bit)\\n\\nPython 2.6.5 |EPD 6.2-2 (32-bit)| (r265:79063, May 28 2010, 15:13:03) \\n[GCC 4.0.1 (Apple Inc. build 5488)] on darwin\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> import matplotlib\\n>>> matplotlib.__version__\\n\\'0.99.3\\'\\n\\n\\nAny ideas how this can be fixed?\\n\\nthanks.\\n',\n  'completion': 'The solution is to use fondu to convert the .dfont Helvetica font from Mac OS X into .ttf, and then place that in the mpl-data/fonts directory that Matplotlib looks in.  That solved the issue.\\n'},\n {'prompt': 'I want to catch a specific http error and not any one of the entire family..\\nwhat I was trying to do is --\\n\\nimport urllib2\\ntry:\\n   urllib2.urlopen(\"some url\")\\nexcept urllib2.HTTPError:\\n   <whatever>\\n\\n\\nbut what I end up is catching any kind of http error, but I want to catch only if the specified webpage doesn\\'t exist!! probably that\\'s HTTP error 404..but I don\\'t know how to specify that catch only error 404 and let the system run the default handler for other events..ny suggestions??\\n',\n  'completion': 'Just catch urllib2.HTTPError, handle it, and if it\\'s not Error 404, simply use raise to re-raise the exception. \\n\\nSee the Python tutorial.\\n\\nSo you could do:\\n\\nimport urllib2\\ntry:\\n   urllib2.urlopen(\"some url\")\\nexcept urllib2.HTTPError as err:\\n   if err.code == 404:\\n       <whatever>\\n   else:\\n       raise\\n\\n'},\n {'prompt': \"I am still writing on a python interface for my c code with ctypes. Today I substituted my file reading function with a python version, which was programmed by somebody else usind NumPy. The 'old' c version was called with a byref(p_data) while p_data=PFloat() (see below). The main function takes the p_data.\\n\\nOld file reading:\\n\\np_data=POINTER(c_float)\\nfoo.read(filename,byref(p_data))\\nresult=foo.pymain(p_data)\\n\\n\\nThe python file reading function on the other hand returns a NumPy array. My question now is: \\n\\nHow do I convert a NumPy array to POINTER(c_float)?\\n\\nI googled but only found the other way around: C arrays through ctypes accessed as NumPy arrays and things I didn't understand: C-Types Foreign Function Interface (numpy.ctypeslib)\\n\\n[update]\\ncorrected a mistake in the example code\\n\",\n  'completion': \"Your code looks like it has some confusion in it -- ctypes.POINTER() creates a new ctypes pointer class, not a ctypes instance.  Anyway, the easiest way to pass a NumPy array to ctypes code is to use the numpy.ndarray's ctypes attribute's data_as method.  Just make sure the underlying data is the right type first.  For example:\\n\\nc_float_p = ctypes.POINTER(ctypes.c_float)\\ndata = numpy.array([[0.1, 0.1], [0.2, 0.2], [0.3, 0.3]])\\ndata = data.astype(numpy.float32)\\ndata_p = data.ctypes.data_as(c_float_p)\\n\\n\"},\n {'prompt': 'Are there any Python built-ins or widely used Python libraries to perform a search in a sorted sequence?\\n',\n  'completion': \"bisect is part of the standard library - is that the sort of thing you're looking for?\\n\"},\n {'prompt': 'When I run this code\\n\\nfrom pylab import *\\n\\nfigure()\\nax1 = subplot(121)\\nplot([1, 2, 3], [1, 2, 3])\\nsubplot(122, sharex=ax1, sharey=ax1)\\nplot([1, 2, 3], [1, 2, 3])\\ndraw()\\nshow()\\n\\n\\nI get two subplots which are \"squished\" in the X-dimension. How do I get these subplots such that the height of the Y-axis equals the width of the X-axis, for both subplots?\\n\\nI am using matplotlib v.0.99.1.2 on Ubuntu 10.04.\\n\\nUpdate 2010-07-08: Let\\'s look at some things that don\\'t work.\\n\\nAfter Googling around all day, I thought that it might be related to auto-scaling. So I tried fiddling with that.\\n\\nfrom pylab import *\\n\\nfigure()\\nax1 = subplot(121, autoscale_on=False)\\nplot([1, 2, 3], [1, 2, 3])\\nsubplot(122, sharex=ax1, sharey=ax1)\\nplot([1, 2, 3], [1, 2, 3])\\ndraw()\\nshow()\\n\\n\\nmatplotlib insists on auto-scaling.\\n\\nfrom pylab import *\\n\\nfigure()\\nax1 = subplot(121, autoscale_on=False)\\nplot([1, 2, 3], [1, 2, 3])\\nsubplot(122, sharex=ax1, sharey=ax1, autoscale_on=False)\\nplot([1, 2, 3], [1, 2, 3])\\ndraw()\\nshow()\\n\\n\\nIn this one, the data completely disappears. WTF, matplotlib? Just WTF?\\n\\nOkay, well maybe if we fix the aspect ratio?\\n\\nfrom pylab import *\\n\\nfigure()\\nax1 = subplot(121, autoscale_on=False)\\nplot([1, 2, 3], [1, 2, 3])\\naxes().set_aspect(\\'equal\\')\\nsubplot(122, sharex=ax1, sharey=ax1)\\nplot([1, 2, 3], [1, 2, 3])\\ndraw()\\nshow()\\n\\n\\nThis one causes the first subplot to disappear entirely. That\\'s hilarious! Who came up with that one?\\n\\nIn all seriousness, now... should this really be such a hard thing to accomplish?\\n',\n  'completion': 'Your problem in setting the aspect of the plots is coming in when you\\'re using sharex and sharey.  \\n\\nOne workaround is to just not used shared axes.  For example, you could do this:\\n\\nfrom pylab import *\\n\\nfigure()\\nsubplot(121, aspect=\\'equal\\')\\nplot([1, 2, 3], [1, 2, 3])\\nsubplot(122, aspect=\\'equal\\')\\nplot([1, 2, 3], [1, 2, 3])\\nshow()\\n\\n\\nHowever, a better workaround is to change the \"adjustable\" keywarg... You want adjustable=\\'box\\', but when you\\'re using shared axes, it has to be adjustable=\\'datalim\\' (and setting it back to \\'box\\' gives an error).\\n\\nHowever, there\\'s a third option for adjustable to handle exactly this case: adjustable=\"box-forced\".\\n\\nFor example:\\n\\nfrom pylab import *\\n\\nfigure()\\nax1 = subplot(121, aspect=\\'equal\\', adjustable=\\'box-forced\\')\\nplot([1, 2, 3], [1, 2, 3])\\nsubplot(122, aspect=\\'equal\\', adjustable=\\'box-forced\\', sharex=ax1, sharey=ax1)\\nplot([1, 2, 3], [1, 2, 3])\\nshow()\\n\\n\\nOr in more modern style (note: this part of the answer wouldn\\'t have worked in 2010):\\n\\nimport matplotlib.pyplot as plt\\n\\nfig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\\nfor ax in axes:\\n    ax.plot([1, 2, 3], [1, 2, 3])\\n    ax.set(adjustable=\\'box-forced\\', aspect=\\'equal\\')\\n\\nplt.show()\\n\\n\\nEither way, you\\'ll get something similar to:\\n\\n\\n'},\n {'prompt': \"I need to extract the meta keywords from a web page using Python. I was thinking that this could be done using urllib or urllib2, but I'm not sure. Anyone have any ideas?\\n\\nI am using Python 2.6 on Windows XP\\n\",\n  'completion': 'lxml is faster than BeautifulSoup (I think) and has much better functionality, while remaining relatively easy to use. Example:\\n\\n52> from urllib import urlopen\\n53> from lxml import etree\\n\\n54> f = urlopen( \"http://www.google.com\" ).read()\\n55> tree = etree.HTML( f )\\n61> m = tree.xpath( \"//meta\" )\\n\\n62> for i in m:\\n..>     print etree.tostring( i )\\n..>\\n<meta http-equiv=\"content-type\" content=\"text/html; charset=ISO-8859-2\"/>  \\n\\n\\nEdit: another example.\\n\\n75> f = urlopen( \"http://www.w3schools.com/XPath/xpath_syntax.asp\" ).read()\\n76> tree = etree.HTML( f )\\n85> tree.xpath( \"//meta[@name=\\'Keywords\\']\" )[0].get(\"content\")\\n85> \"xml,tutorial,html,dhtml,css,xsl,xhtml,javascript,asp,ado,vbscript,dom,sql,colors,soap,php,authoring,programming,training,learning,b\\neginner\\'s guide,primer,lessons,school,howto,reference,examples,samples,source code,tags,demos,tips,links,FAQ,tag list,forms,frames,color table,w3c,cascading\\n style sheets,active server pages,dynamic html,internet,database,development,Web building,Webmaster,html guide\"\\n\\n\\nBTW: XPath is worth knowing.\\n\\nAnother edit:\\n\\nAlternatively, you can just use regexp:\\n\\n87> f = urlopen( \"http://www.w3schools.com/XPath/xpath_syntax.asp\" ).read()\\n88> import re\\n101> re.search( \"<meta name=\\\\\"Keywords\\\\\".*?content=\\\\\"([^\\\\\"]*)\\\\\"\", f ).group( 1 )\\n101>\"xml,tutorial,html,dhtml,css,xsl,xhtml,javascript,asp,ado,vbscript,dom,sql, ...etc...\\n\\n\\n...but I find it less readable and more error prone (but involves only standard module and still fits on one line).\\n'},\n {'prompt': \"This may sound like a stupid question, since the very purpose of virtualenv is to this exactly: Installing some specific version of a package (in this case Django) inside the virtual environment. But it's exactly what I want to do, and I can't figure it out.\\n\\nI'm on Windows XP, and I created the virtual environment successfully, and I'm able to run it, but how am I supposed to install the Django version I want into it? I mean, I know to use the newly-created easy_install script, but how do I make it install Django 1.0.7? If I do easy_install django, it will install the latest version. I tried putting the version number 1.0.7 into this command in various ways, but nothing worked.\\n\\nHow do I do this?\\n\",\n  'completion': \"There was never a Django 1.0.7. The 1.0 series only went up to 1.0.4. You can see all the releases in the tags section of the Django code repository.\\n\\nHowever to answer your question, don't use easy_install, use pip. (If it's not already installed, do easy_install pip, then never touch easy_install again). Now you can do:\\n\\npip install Django==1.0.4\\n\\n\"},\n {'prompt': 'Normally, I code as follows for getting a particular item in a variable as follows\\n\\ntry:\\n    config = ConfigParser.ConfigParser()\\n    config.read(self.iniPathName)\\nexcept ConfigParser.MissingSectionHeaderError, e:\\n    raise WrongIniFormatError(`e`)\\n\\ntry:\\n    self.makeDB = config.get(\"DB\",\"makeDB\")\\nexcept ConfigParser.NoOptionError:\\n    self.makeDB = 0\\n\\n\\nIs there any way to read all the contents in a python dictionary? \\n\\nFor example\\n\\n\\n[A]\\nx=1\\ny=2\\nz=3\\n[B]\\nx=1\\ny=2\\nz=3\\n\\n\\nis written into \\n\\n\\nval[\"A\"][\"x\"] = 1\\n...\\nval[\"B\"][\"z\"] = 3\\n\\n',\n  'completion': 'I suggest subclassing ConfigParser.ConfigParser (or SafeConfigParser, &c) to safely access the \"protected\" attributes (names starting with single underscore -- \"private\" would be names starting with two underscores, not to be accessed even in subclasses...):\\n\\nimport ConfigParser\\n\\nclass MyParser(ConfigParser.ConfigParser):\\n\\n    def as_dict(self):\\n        d = dict(self._sections)\\n        for k in d:\\n            d[k] = dict(self._defaults, **d[k])\\n            d[k].pop(\\'__name__\\', None)\\n        return d\\n\\n\\nThis emulates the usual logic of config parsers, and is guaranteed to work in all versions of Python where there\\'s a ConfigParser.py module (up to 2.7, which is the last of the 2.* series -- knowing that there will be no future Python 2.any versions is how compatibility can be guaranteed;-).\\n\\nIf you need to support future Python 3.* versions (up to 3.1 and probably the soon forthcoming 3.2 it should be fine, just renaming the module to all-lowercase configparser instead of course) it may need some attention/tweaks a few years down the road, but I wouldn\\'t expect anything major.\\n'},\n {'prompt': \"I have a generator function and want to get the first ten items from it; my first attempt was:\\n\\nmy_generator()[:10]\\n\\n\\nThis doesn't work because generators aren't subscriptable, as the error tells me. Right now I have worked around that with:\\n\\nlist(my_generator())[:10]\\n\\n\\nThis works since it converts the generator to a list; however, it's inefficient and defeats the point of having a generator. Is there some built-in, Pythonic equivalent of [:10] for generators?\\n\",\n  'completion': 'import itertools\\n\\nitertools.islice(mygenerator(), 10)\\n\\n\\nitertools has a number of utilities for working with iterators.  islice takes start, stop, and step arguments to slice an iterator just as you would slice a list.\\n'},\n {'prompt': \"I am using thread locals to store the current user and request objects.  This way I can have easy access to the request from anywhere in the programme (e.g. dynamic forms) without having to pass them around.\\n\\nTo implement the thread locals storage in a middleware, I followed a tutorial on the Django site:\\nhttp://code.djangoproject.com/wiki/CookBookThreadlocalsAndUser?version=18\\n\\nThis document has since been modified to suggest avoiding this technique:\\nhttp://code.djangoproject.com/wiki/CookBookThreadlocalsAndUser?version=20\\n\\nFrom the article:\\n\\n\\n  From a design point of view, threadlocals are essentially global variables, and are subject to all the usual problems of portability and predictability that global variables usually entail.\\n  \\n  More importantly, from a security point of view, threadlocals pose a huge risk. By providing an data store that exposes the state of other threads, you provide a way for one thread in your web server to potentially modify the state of another thread in the system. If the threadlocal data contains descriptions of users or other authentication-related data, that data could be used as the basis for an attack that grants access to an unauthorized user, or exposes private details of a user. While it is possible to build a threadlocal system that is safe from this sort of attack, it's a lot easier to be defensive and build a system that isn't subject to any such vulnerability in the first place.\\n\\n\\nI understand why global variables can be bad, but in this case I'm running my own code on my own server so I can't see what danger two global variables pose.\\n\\nCan someone explain the security issue involved?  I have asked many people how they would hack my application if they read this article and know I'm using thread locals, yet no one has been able to tell me.  I am starting to suspect that this is an opinion held by hair-splitting purists who love to pass objects explicitly.\\n\",\n  'completion': \"I disagree entirely.  TLS is extremely useful.  It should be used with care, just as globals should be used with care; but saying it shouldn't be used at all is just as ridiculous as saying globals should never be used.\\n\\nFor example, I store the currently active request in TLS.  This makes it accessible from my logging class, without having to pass the request around through every single interface--including many that don't care about Django at all.  It lets me make log entries from anywhere in the code; the logger outputs to a database table, and if a request happens to be active when a log is made, it logs things like the active user and what was being requested.\\n\\nIf you don't want one thread to have the capability of modifying another thread's TLS data, then set your TLS up to prohibit this, which probably requires using a native TLS class.  I don't find that argument convincing, though; if an attacker can execute arbitrary Python code as your backend, your system is already fatally compromised--he could monkey patch anything to be run later as a different user, for example.\\n\\nObviously, you'll want to clear any TLS at the end of a request; in Django, that means clearing it in process_response and process_exception in a middleware class.\\n\"},\n {'prompt': \"I'm trying to get the name of all methods in my class.\\nWhen testing how the inspect module works, i extraced one of my methods by obj = MyClass.__dict__['mymethodname']. \\n\\nBut now inspect.ismethod(obj) returns False while inspect.isfunction(obj) returns True, and i don't understand why. Is there some strange way of marking methods as methods that i am not aware of? I thought it was just that it is defined in the class and takes self as its first argument.\\n\",\n  'completion': 'You are seeing some effects of the behind-the-scenes machinery of Python.\\n\\nWhen you write f = MyClass.__dict__[\\'mymethodname\\'], you get the raw implementation of \"mymethodname\", which is a plain function. To call it, you need to pass in an additional parameter, class instance.\\n\\nWhen you write f = MyClass.mymethodname (note the absence of parentheses after mymethodname), you get an unbound method of class MyClass, which is an instance of MethodType that wraps the raw function you obtained above. To call it, you need to pass in an additional parameter, class instance.\\n\\nWhen you write f = MyClass().mymethodname (note that i\\'ve created an object of class MyClass before taking its method), you get a bound method of an instance of class MyClass. You do not need to pass an additional class instance to it, since it\\'s already stored inside it.\\n\\nTo get wrapped method (bound or unbound) by its name given as a string, use getattr, as noted by gnibbler. For example:\\n\\nunbound_mth = getattr(MyClass, \"mymethodname\")\\n\\n\\nor\\n\\nbound_mth = getattr(an_instance_of_MyClass, \"mymethodname\")\\n\\n'},\n {'prompt': \"I just learned about list comprehension, which is a great fast way to get data in a single line of code. But something's bugging me.\\n\\nIn my test I have this kind of dictionaries inside the list:\\n\\n[{'y': 72, 'x': 94, 'fname': 'test1420'}, {'y': 72, 'x': 94, 'fname': 'test277'}]\\n\\n\\nThe list comprehension s = [ r for r in list if r['x'] > 92 and r['x'] < 95 and r['y'] > 70 and r['y'] < 75 ] works perfectly on that (it is, in fact, the result of this line)\\n\\nAnyway, I then realised I'm not really using a list in my other project, I'm using a dictionary. Like so:\\n\\n{'test1420': {'y': '060', 'x': '070', 'fname': 'test1420'}}\\n\\n\\nThat way I can simply edit my dictionary with var['test1420'] = ...\\n\\nBut list comprehensions don't work on that!\\nAnd I can't edit lists this way because you can't assign an index like that.\\n\\nIs there another way?\\n\",\n  'completion': \"You can do this:\\n\\ns = dict([ (k,r) for k,r in mydict.iteritems() if r['x'] > 92 and r['x'] < 95 and r['y'] > 70 and r['y'] < 75 ])\\n\\n\\nThis takes a dict as you specified and returns a 'filtered' dict.\\n\"},\n {'prompt': 'I\\'m using ftplib to transfer files.  Everything is working great.  Now I\\'m trying to get the size of the target file before downloading.\\n\\n\\nFirst, I tried just getting size with ftp.size(filename).  Server complained that I can\\'t do that in ascii mode.\\nThen I tried setting binary mode using ftp.sendcmd(\"binary\") and ftp.sendcmd(\"bin\").  In both cases the server complained \"500 binary Not understood\"\\n\\n\\nCan ftplib get size of a file before downloading in this instance?  I don\\'t control the FTP server and can\\'t change how it\\'s behaving.\\n\\nThanks\\n',\n  'completion': 'Very late reply, but here\\'s the correct answer. This works with ProFTPD.\\n\\nftp.sendcmd(\"TYPE i\")    # Switch to Binary mode\\nftp.size(\"/some/file\")   # Get size of file\\n\\n'},\n {'prompt': \"I'm interested in subclassing the built-in int type in Python (I'm using v. 2.5), but having some trouble getting the initialization working.\\n\\nHere's some example code, which should be fairly obvious.\\n\\nclass TestClass(int):\\n    def __init__(self):\\n        int.__init__(self, 5)\\n\\n\\nHowever, when I try to use this I get:\\n\\n>>> a = TestClass()\\n>>> a\\n0\\n\\n\\nwhere I'd expect the result to be 5.\\n\\nWhat am I doing wrong? Google, so far, hasn't been very helpful, but I'm not really sure what I should be searching for\\n\",\n  'completion': \"int is immutable so you can't modify it after they are created, use __new__ instead\\n\\nclass TestClass(int):\\n    def __new__(cls, *args, **kwargs):\\n        return  super(TestClass, cls).__new__(cls, 5)\\n\\nprint TestClass()\\n\\n\"},\n {'prompt': 'In my script I build a dictionary of keys(albums) mapped to artists(values) so that I can do a quick lookup of what artists made what albums. However, I want the user to be able to find all albums which contain a substring. For example a search on \"Light\" should return \\n\\n[Light Chasers] = Cloud Cult and also [Night Light] = Au Revoir Simone\\n\\nWhat\\'s the best way to do this? Should I even be using a dictionary?\\n',\n  'completion': \"[(k, v) for (k, v) in D.iteritems() if 'Light' in k]\\n\\n\"},\n {'prompt': \"Since there is a python 3.x, why don't we use it?\\nWhy do we still use 2.x?What's the difference?\\n\",\n  'completion': 'Python 2.6 and 2.7 have been written to ease the transition to Python 3.\\nIt will take some more time to port the more complex packages (i.e. those with many dependencies, or libraries written in C).\\n\\nSo if you are starting new projects, and all the libraries you need are there, it makes sense to start with 3.1. One of the more welcome changes is the handling of Unicode strings by default - it will prevent a lot of bugs.\\n\\nBut if you were to port a complete ERP application, or anything big, from 2.6 to 3.x, it could be a bloodbath right now. The unicode changes for instance are the hardest to apply from 2.x -> 3.x, and the low level C APIs have changed a lot as well.\\n'},\n {'prompt': \"I have a hex value in a string like \\n\\nh = '00112233aabbccddee'\\n\\n\\nI know I can convert this to binary with:\\n\\nh = bin(int(h, 16))[2:]\\n\\n\\nHowever, this loses the leading 0's. Is there anyway to do this conversion without losing the 0's? Or is the best way to do this just to count the number of leading 0's before the conversion then add it in afterwards.\\n\",\n  'completion': \"I don't think there is a way to keep those leading zeros by default.\\n\\nEach hex digit translates to 4 binary digits, so the length of the new string should be exactly 4 times the size of the original.\\n\\nh_size = len(h) * 4\\n\\n\\nThen, you can use .zfill to fill in zeros to the size you want:\\n\\nh = ( bin(int(h, 16))[2:] ).zfill(h_size)\\n\\n\"},\n {'prompt': \"So I have an array that holds several numbers. As my script runs, more and more numbers are appended to this array. However, I am not interested in all the numbers but just want to keep track of the last 5 numbers.\\n\\nCurrently, I just store all the numbers in the array. However, this array gets really big and it's full of unnecessary information. \\n\\nI have thought about making a function that when it adds an element to the array, also removes the last element if the array already contains 5 numbers. \\n\\nI also thought about making a new class to create a data structure that does what I want. However, I only need to reference this array occasionally and is only a small part of the script. So I think it is overkill if I create a whole new class to do this. \\n\\nWhat is the best way to do this?\\n\",\n  'completion': 'Try using a deque:\\nhttp://docs.python.org/library/collections.html#deque-objects\\n\\n\"If maxlen is not specified or is None, deques may grow to an arbitrary length. Otherwise, the deque is bounded to the specified maximum length. Once a bounded length deque is full, when new items are added, a corresponding number of items are discarded from the opposite end. Bounded length deques provide functionality similar to the tail filter in Unix. They are also useful for tracking transactions and other pools of data where only the most recent activity is of interest.\"\\n'},\n {'prompt': 'Can I reset an iterator / generator in Python?  I am using DictReader and would like to reset it (from the csv module) to the beginning of the file.\\n',\n  'completion': 'I see many answers suggesting itertools.tee, but that\\'s ignoring one crucial warning in the docs for it:\\n\\n\\n  This itertool may require significant\\n  auxiliary storage (depending on how\\n  much temporary data needs to be\\n  stored). In general, if one iterator\\n  uses most or all of the data before\\n  another iterator starts, it is faster\\n  to use list() instead of tee().\\n\\n\\nBasically, tee is designed for those situation where two (or more) clones of one iterator, while \"getting out of sync\" with each other, don\\'t do so by much -- rather, they say in the same \"vicinity\" (a few items behind or ahead of each other).  Not suitable for the OP\\'s problem of \"redo from the start\".\\n\\nL = list(DictReader(...)) on the other hand is perfectly suitable, as long as the list of dicts can fit comfortably in memory.  A new \"iterator from the start\" (very lightweight and low-overhead) can be made at any time with iter(L), and used in part or in whole without affecting new or existing ones; other access patterns are also easily available.\\n\\nAs several answers rightly remarked, in the specific case of csv you can also .seek(0) the underlying file object (a rather special case).  I\\'m not sure that\\'s documented and guaranteed, though it does currently work;  it would probably be worth considering only for truly huge csv files, in which the list I recommmend as the general approach would have too large a memory footprint.\\n'},\n {'prompt': 'The following snippet is annotated with the output (as seen on ideone.com):\\n\\nprint \"100\" < \"2\"      # True\\nprint \"5\" > \"9\"        # False\\n\\nprint \"100\" < 2        # False\\nprint 100 < \"2\"        # True\\n\\nprint 5 > \"9\"          # False\\nprint \"5\" > 9          # True\\n\\n\\nCan someone explain why the output is as such?\\n\\n\\n\\nImplementation details\\n\\n\\nIs this behavior mandated by the language spec, or is it up to implementors?\\nAre there differences between any of the major Python implementations?\\nAre there differences between versions of the Python language?\\n\\n',\n  'completion': 'From the manual:\\n\\n\\n  CPython implementation detail: Objects of different types except numbers are ordered by their type names; objects of the same types that donâ\\x80\\x99t support proper comparison are ordered by their address.\\n\\n\\nWhen you order two strings or two numeric types the ordering is done in the expected way (lexicographic ordering for string, numeric ordering for integers).\\n\\nWhen you order a numeric and a non-numeric type, the numeric type comes first.\\n\\n>>> 5 < \\'foo\\'\\nTrue\\n>>> 5 < (1, 2)\\nTrue\\n>>> 5 < {}\\nTrue\\n>>> 5 < [1, 2]\\nTrue\\n\\n\\nWhen you order two incompatible types where neither is numeric, they are ordered by the alphabetical order of their typenames:\\n\\n>>> [1, 2] > \\'foo\\'   # \\'list\\' < \\'str\\' \\nFalse\\n>>> (1, 2) > \\'foo\\'   # \\'tuple\\' > \\'str\\'\\nTrue\\n\\n>>> class Foo(object): pass\\n>>> class Bar(object): pass\\n>>> Bar() < Foo()\\nTrue\\n\\n\\nOne exception is old-style classes that always come before new-style classes.\\n\\n>>> class Foo: pass           # old-style\\n>>> class Bar(object): pass   # new-style\\n>>> Bar() < Foo()\\nFalse\\n\\n\\n\\n\\n\\nIs this behavior mandated by the language spec, or is it up to implementors?\\n\\n\\nThere is no language specification. The language reference says:\\n\\n\\n  Otherwise, objects of different types always compare unequal, and are ordered consistently but arbitrarily. \\n\\n\\nSo it is an implementation detail.\\n\\n\\nAre there differences between any of the major Python implementations?\\n\\n\\nI can\\'t answer this one because I have only used the official CPython implementation, but there are other implementations of Python such as PyPy.\\n\\n\\nAre there differences between versions of the Python language?\\n\\n\\nIn Python 3.x the behaviour has been changed so that attempting to order an integer and a string will raise an error:\\n\\n\\n>>> \\'10\\' > 5\\nTraceback (most recent call last):\\n  File \"\", line 1, in \\n    \\'10\\' > 5\\nTypeError: unorderable types: str() > int()\\n\\n'},\n {'prompt': \"Virtualenv is great: it lets me keep a number of distinct Python installations so that different projects' dependencies aren't all thrown together into a common pile.\\n\\nBut if I want to install a package on Windows that's packaged as a .exe installer, how can I direct it to install into the virtualenv?  For example, I have pycuda-0.94rc.win32-py2.6.exe.  When I run it, it examines the registry, and finds only one Python26 to install into, the common one that my virtualenv is based off of.\\n\\nHow can I direct it to install into the virtualenv?\\n\",\n  'completion': \"Yes, you can. All you need is\\n\\n\\n  easy_install\\n  binary_installer_built_with_distutils.exe\\n\\n\\nSurprised? It looks like binary installers for Windows made with distutils combine .exe with .zip into one .exe file. Change extension to .zip to see it's a valid zip file. I discovered this after reading answers to my question Where can I download binary eggs with psycopg2 for Windows?\\n\\nUPDATE\\n\\nAs noted by Tritium21 in his answer nowadays you should use pip instead of easy_install. Pip can't install binary packages created by distutils but it can install binary packages in the new wheel format. You can convert from old format to the new one using wheel package, which you have to install first.\\n\"},\n {'prompt': 'I\\'m using this line in a SPARQL query in my python program:\\n\\nFILTER regex(?name, \"%s\", \"i\" )\\n\\n\\n(where %s is the search text entered by the user)\\n\\nI want this to match if either ?name or ?featurename contains %s, but I can\\'t seem to find any documentation or tutorial for using regex(). I tried a couple things that seemed reasonable:\\n\\nFILTER regex((?name | ?featurename), \"%s\", \"i\" )\\nFILTER regex((?name || ?featurename), \"%s\", \"i\" )\\nFILTER regex((?name OR ?featurename), \"%s\", \"i\" )\\nFILTER regex((?name, ?featurename), \"%s\", \"i\" )\\n\\n\\nand each of those without the ()\\n\\nFILTER regex(?name, \"%s\", \"i\" ) || regex(?featurename, \"%s\", \"i\" )\\n\\n\\nWhat\\'s the right way to do this?\\nThanks\\n\\nUPDATE: Using UNION works. But I figured out that it also works if you just repeat the regex() part like so:\\n\\nFILTER (regex(?name, \"%s\", \"i\") || regex(?featurename, \"%s\", \"i\" ))\\n\\n\\nBoth solutions seem a little messy in that you have to use a 2-element tuple with copies of the same string to fill in both %ss.\\n',\n  'completion': 'What about this?\\n\\nSELECT ?thing\\nWHERE {\\n  { \\n    ?thing x:name ?name .\\n    FILTER regex(?name, \"%s\", \"i\" )\\n  } UNION {\\n    ?thing x:featurename ?name .\\n    FILTER regex(?featurename, \"%s\", \"i\" )\\n  }\\n}\\n\\n'},\n {'prompt': \"I've created a simple hexbin plot with matplotlib.pyplot.  I haven't changed any default settings.  My x-axis information ranges from 2003 to 2009, while the y values range from 15 to 35.  Rather than writing out 2003, 2004, etc., matplotlib collapses it into 0, 1, 2, ... + 2.003e+03.  Is there a simple way to force matplotlib to write out the full numbers?\\n\\nThanks,\\nMark C.\\n\",\n  'completion': \"I think you can use the xticks function to set string labels:\\n\\nnums = arange(2003, 2010)\\nxticks(nums, (str(n) for n in nums))\\n\\n\\nEDIT: This is a better way:\\n\\ngca().xaxis.set_major_formatter(FormatStrFormatter('%d'))\\n\\n\\nor something like that, anyway. (In older versions of Matplotlib the method was called setMajorFormatter.)\\n\"},\n {'prompt': 'I am trying to get a value out of a HTML page using the python HTMLParser library. The value I want to get hold of is within this html element:\\n\\n...\\n<div id=\"remository\">20</div>\\n...\\n\\n\\nThis is my HTMLParser class so far:\\n\\nclass LinksParser(HTMLParser.HTMLParser):\\n  def __init__(self):\\n    HTMLParser.HTMLParser.__init__(self)\\n    self.seen = {}\\n\\n  def handle_starttag(self, tag, attributes):\\n    if tag != \\'div\\': return\\n    for name, value in attributes:\\n    if name == \\'id\\' and value == \\'remository\\':\\n      #print value\\n      return\\n\\n  def handle_data(self, data):\\n    print data\\n\\n\\np = LinksParser()\\nf = urllib.urlopen(\"http://domain.com/somepage.html\")\\nhtml = f.read()\\np.feed(html)\\np.close()\\n\\n\\nCan someone point me in the right direction? I want the class functionality to get the value 20.\\n',\n  'completion': 'class LinksParser(HTMLParser.HTMLParser):\\n  def __init__(self):\\n    HTMLParser.HTMLParser.__init__(self)\\n    self.recording = 0\\n    self.data = []\\n\\n  def handle_starttag(self, tag, attributes):\\n    if tag != \\'div\\':\\n      return\\n    if self.recording:\\n      self.recording += 1\\n      return\\n    for name, value in attributes:\\n      if name == \\'id\\' and value == \\'remository\\':\\n        break\\n    else:\\n      return\\n    self.recording = 1\\n\\n  def handle_endtag(self, tag):\\n    if tag == \\'div\\' and self.recording:\\n      self.recording -= 1\\n\\n  def handle_data(self, data):\\n    if self.recording:\\n      self.data.append(data)\\n\\n\\nself.recording counts the number of nested div tags starting from a \"triggering\" one.  When we\\'re in the sub-tree rooted in a triggering tag, we accumulate the data in self.data.\\n\\nThe data at the end of the parse are left in self.data (a list of strings, possibly empty if no triggering tag was met).  Your code from outside the class can access the list directly from the instance at the end of the parse, or you can add appropriate accessor methods for the purpose, depending on what exactly is your goal.\\n\\nThe class could be easily made a bit more general by using, in lieu of the constant literal strings seen in the code above, \\'div\\', \\'id\\', and \\'remository\\', instance attributes self.tag, self.attname and self.attvalue, set by __init__ from arguments passed to it -- I avoided that cheap generalization step in the code above to avoid obscuring the core points (keep track of a count of nested tags and accumulate data into a list when the recording state is active).\\n'},\n {'prompt': 'How can I extract the date from a string like \"monkey 2010-07-10 love banana\"? Thanks!\\n',\n  'completion': 'Using python-dateutil:\\n\\nIn [1]: import dateutil.parser as dparser\\n\\nIn [18]: dparser.parse(\"monkey 2010-07-10 love banana\",fuzzy=True)\\nOut[18]: datetime.datetime(2010, 7, 10, 0, 0)\\n\\n\\nInvalid dates raise a ValueError:\\n\\nIn [19]: dparser.parse(\"monkey 2010-07-32 love banana\",fuzzy=True)\\n# ValueError: day is out of range for month\\n\\n\\nIt can recognize dates in many formats:\\n\\nIn [20]: dparser.parse(\"monkey 20/01/1980 love banana\",fuzzy=True)\\nOut[20]: datetime.datetime(1980, 1, 20, 0, 0)\\n\\n\\nNote that it makes a guess if the date is ambiguous:\\n\\nIn [23]: dparser.parse(\"monkey 10/01/1980 love banana\",fuzzy=True)\\nOut[23]: datetime.datetime(1980, 10, 1, 0, 0)\\n\\n\\nBut the way it parses ambiguous dates is customizable:\\n\\nIn [21]: dparser.parse(\"monkey 10/01/1980 love banana\",fuzzy=True, dayfirst=True)\\nOut[21]: datetime.datetime(1980, 1, 10, 0, 0)\\n\\n'},\n {'prompt': \"Is it possible to make the fabfile stand-alone?\\nI'm not very fond of running the external tool 'fab'. If I manage to get the fabfile standalone I can run the file from within the (Eclipse / Pydev) IDE, easily debug it, use project configurations and paths etc.\\nWhy doesn't this work:\\n\\nfrom fabric.api import run\\n\\ndef host_type():\\n    run('uname -s')\\n\\nif __name__ == '__main__':\\n    host_type()    \\n\\n\",\n  'completion': \"I eventually found the solution (and it is really simple!).\\nIn my fabfile, I added:\\n\\nfrom fabric.main import main\\n\\nif __name__ == '__main__':\\n    import sys\\n    sys.argv = ['fab', '-f', __file__, 'update_server']\\n    main()\\n\\n\\nI hope this helps people...\\n\"},\n {'prompt': 'I would like to know how to simply reverse the color order of a given colormap in order to use it with plot_surface.\\n',\n  'completion': 'The standard colormaps also all have reversed versions. They have the same names with _r tacked on to the end. (Documentation here.)\\n'},\n {'prompt': \"I want to parse some emails from a user 's inbox but when I do:\\n\\ntyp, msg_data = imap_conn.fetch(uid, '(RFC822)')\\n\\n\\nIt marks the email as SEEN or read. This is not the desired functionality. Do you know how can I keep the email at its previous stare either SEEN or NOT SEEN?\\n\",\n  'completion': \"You might also set read_only to true when selecting the folder.\\n.select('Inbox', readonly=True)\\n\"},\n {'prompt': \"What's the maximum level of recursion and how do I change it in Python?\\n\",\n  'completion': 'The default is 1000 levels deep and you can change that using the setrecursionlimit function in the sys module. \\n\\nWarning:\\n\\nBeware that some operating systems may start running into problems if you go much higher due to limited stack space.\\n'},\n {'prompt': 'When the user presses a close Button that I created, some tasks are performed before exiting. However, if the user clicks on the [X] button in the top-right of the window to close the window, I cannot perform these tasks. \\n\\nHow can I override what happens when the user clicks [X] button?\\n',\n  'completion': \"It sounds as if your save window should be modal. \\n\\nIf this is a basic save window, why are you reinventing the wheel?\\nTk has a tkFileDialog for this purpose.\\n\\n\\n\\nIf what you want is to override the default behaviour of destroying the window, you can simply do:\\n\\nroot.protocol('WM_DELETE_WINDOW', doSomething)  # root is your root window\\n\\ndef doSomething():\\n    # check if saving\\n    # if not:\\n    root.destroy()\\n\\n\\nThis way, you can intercept the destroy() call when someone closes the window (by any means) and do what you like.\\n\"},\n {'prompt': 'I run the following code from a python interpreter, and expect the insert statement to fail and throw some kind of exception. But it\\'s not happening:\\n\\nPython 2.6.5 (r265:79096, Mar 19 2010, 21:48:26) [MSC v.1500 32 bit (Intel)] on win32\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> import sqlite3\\n>>> conn = sqlite3.connect(\"test.db\")\\n>>> conn.executescript(\"\"\"\\n... pragma foreign_keys=on;\\n... begin transaction;\\n... create table t1 (i integer primary key, a);\\n... create table t2 (i, a, foreign key (i) references t1(i));\\n... commit;\\n... \"\"\")\\n<sqlite3.Cursor object at 0x0229DAA0>\\n>>> c = conn.cursor()\\n>>> c.execute(\"insert into t2 values (6, 8)\")\\n<sqlite3.Cursor object at 0x0229DAD0>\\n>>> #???\\n...\\n>>> conn.commit()\\n>>> #???????????\\n...\\n>>> c.execute(\"select * from t2\")\\n<sqlite3.Cursor object at 0x0229DAD0>\\n>>> c.fetchall()\\n[(6, 8)]\\n>>> #but why!?\\n...\\n>>>\\n\\n\\nDoes anyone know why this doesn\\'t want to work? My understanding is that the insert should fail since the value I gave for t2(i) isn\\'t a primary key in t1, but it happily does it anyway...?\\n',\n  'completion': \"Working foreign key support in SQLite is very new -- it was only released in 3.6.19 on October 14th. Are you sure you're using SQLite 3.6.19 or later?\\n\\nCheck the sqlite_version constant in the sqlite3 module. E.g. on a Mac OS X 10.6 system with the default python/sqlite install:\\n\\n>>> import sqlite3\\n>>> sqlite3.sqlite_version\\n'3.6.12'\\n>>> \\n\\n\"},\n {'prompt': 'I am interested in writing a script in Python that is able to scan and show a list of nearby Wi-Fi networks. How could one do this? If possible.\\n\\nThanks.\\n\\nJake.\\n',\n  'completion': 'Yes, it is possible. As far as the how is concerned, this might help you get started.\\n'},\n {'prompt': 'How can I get the task_id value for a task from within the task? Here\\'s my code:\\n\\nfrom celery.decorators import task\\nfrom django.core.cache import cache\\n\\n@task\\ndef do_job(path):\\n    \"Performs an operation on a file\"\\n\\n    # ... Code to perform the operation ...\\n\\n    cache.set(current_task_id, operation_results)\\n\\n\\nThe idea is that when I create a new instance of the task, I retrieve the task_id from the  task object. I then use the task id to determine whether the task has completed. I don\\'t want to keep track of the task by the path value because the file is \"cleaned up\" after the task completes, and may or may not exist.\\n\\nIn the above example, how would I get the value of current_task_id?\\n',\n  'completion': \"Since Celery 2.2.0, information related to the currently executed task is saved to task.request (it's called Â«the contextÂ»). So you should get task id from this context (not from keyword arguments, which are deprecated):\\n\\n@task\\ndef do_job(path):\\n    cache.set(do_job.request.id, operation_results)\\n\\n\\nThe list of all available fields is documented here:\\nhttp://celery.readthedocs.org/en/latest/userguide/tasks.html?highlight=requestcontext#context\\n\"},\n {'prompt': \"I have an existing program that has its own main loop, and does computations based on input it receives - let's say from the user, to make it simple. I want to now do the computations remotely instead of locally, and I decided to implement the RPCs in Twisted. \\n\\nIdeally I just want to change one of my functions, say doComputation(), to make a call to twisted to perform the RPC, get the results, and return. The rest of the program should stay the same. How can I accomplish this, though? Twisted hijacks the main loop when I call reactor.run(). I also read that you don't really have threads in twisted, that all the tasks run in sequence, so it seems I can't just create a LoopingCall and run my main loop that way. \\n\",\n  'completion': \"You have a couple of different options, depending on what sort of main loop your existing program has.\\n\\nIf it's a mainloop from a GUI library, Twisted may already have support for it.  In that case, you can just go ahead and use it.\\n\\nYou could also write your own reactor.  There isn't a lot of great documentation for this, but you can look at the way that qtreactor implements a reactor plugin externally to Twisted.\\n\\nYou can also write a minimal reactor using threadedselectreactor.  The documentation for this is also sparse, but the wxpython reactor is implemented using it.  Personally I wouldn't recommend this approach as it is difficult to test and may result in confusing race conditions, but it does have the advantage of letting you leverage almost all of Twisted's default networking code with only a thin layer of wrapping.\\n\\nIf you are really sure that you don't want your doComputation to be asynchronous, and you want your program to block while waiting for Twisted to answer, do the following:\\n\\n\\nstart Twisted in another thread before your main loop starts up, with something like twistedThread = Thread(target=reactor.run); twistedThread.start()\\ninstantiate an object to do your RPC communication (let's say, RPCDoer) in your own main loop's thread, so that you have a reference to it.  Make sure to actually kick off its Twisted logic with reactor.callFromThread so you don't need to wrap all of its Twisted API calls.\\nImplement RPCDoer.doRPC to return a Deferred, using only Twisted API calls (i.e. don't call into your existing application code, so you don't need to worry about thread safety for your application objects; pass doRPC all the information that it needs as arguments).\\nYou can now implement doComputation like this:\\n\\ndef doComputation(self):\\n    rpcResult = blockingCallFromThread(reactor, self.myRPCDoer.doRPC)\\n    return self.computeSomethingFrom(rpcResult)\\n\\nRemember to call reactor.callFromThread(reactor.stop); twistedThread.join() from your main-loop's shutdown procedure, otherwise you may see some confusing tracebacks or log messages on exit.\\n\\n\\nFinally, one option that you should really consider, especially in the long term: dump your existing main loop, and figure out a way to just use Twisted's.  In my experience this is the right answer for 9 out of 10 askers of questions like this.  I'm not saying that this is always the way to go - there are plenty of cases where you really need to keep your own main loop, or where it's just way too much effort to get rid of the existing loop.  But, maintaining your own loop is work too.  Keep in mind that the Twisted loop has been extensively tested by millions of users and used in a huge variety of environments.  If your loop is also extremely mature, that may not be a big deal, but if you're writing a small, new program, the difference in reliability may be significant.\\n\"},\n {'prompt': 'When would someone use httplib and when urllib?\\n\\nWhat are the differences?\\n\\nI think I ready urllib uses httplib, I am planning to make an app that will need to make http request and so far I only used httplib.HTTPConnection in python for requests, and reading about urllib I see I can use that for request too, so whats the benefit of one or the other?\\n',\n  'completion': \"urllib (particularly urllib2) handles many things by default or has appropriate libs to do so. For example, urllib2 will follow redirects automatically and you can use cookiejar to handle login scripts. These are all things you'd have to code yourself if you were using httplib.\\n\"},\n {'prompt': 'I\\'ve been running Python scripts that make several calls to some functions, say F1(x) and F2(x), that look a bit like this:\\n\\nx = LoadData()\\n\\nfor j in range(N):\\n    y = F1(x[j])\\n    z[j] = F2(y)\\n\\n    del y\\n\\nSaveData(z)\\n\\n\\nPerformance is a lot faster if I keep the \"del y\" line. But I don\\'t understand why this is true. If I don\\'t use \"del y\", then I quickly run out of RAM and have to resort to virtual memory, and everything slows to a crawl. Buy if I use \"del y\", then I am repeatedly flushing and re-allocating the memory for y. What I would like to do is have y sit as static memory, and reuse the memory on every F1(x) call. But from what I can tell, that isn\\'t what\\'s happening.\\n\\nAlso, not sure if it\\'s relevant, but my data consists of numpy arrays.\\n',\n  'completion': 'Without the del y you might need twice as much memory. This is because for each pass through the loop, y is bound to the previous value of F1 while the next one is calculated.\\n\\nonce F1 returns y is rebound to that new value and the old F1 result can be released.\\n\\nThis would mean that the object returned by F1 occupies quite a lot of memory\\n\\nUnrolling the loop for the first couple of iterations would look like this\\n\\ny = F1(x[0])   # F1(x[0]) is calculated, then y is bound to it\\nz[j] = F2(y)\\ny = F1(x[1])   # y is still bound to F1(x[0]) while F1(x[1]) is computed\\n               # The memory for F1(X[0]) is finally freed when y is rebound\\nz[j] = F2(y)\\n\\n\\nusing del y is a good solution if this is what is happening in your case.\\n'},\n {'prompt': 'I want to write a function that determines if a sublist exists in a larger list. \\n\\nlist1 = [1,0,1,1,1,0,0]\\nlist2 = [1,0,1,0,1,0,1]\\n\\n#Should return true\\nsublistExists(list1, [1,1,1])\\n\\n#Should return false\\nsublistExists(list2, [1,1,1])\\n\\n\\nIs there a Python function that can do this?\\n',\n  'completion': \"Let's get a bit functional, shall we? :)\\n\\ndef contains_sublist(lst, sublst):\\n    n = len(sublst)\\n    return any((sublst == lst[i:i+n]) for i in xrange(len(lst)-n+1))\\n\\n\\nNote that any() will stop on first match of sublst within lst - or fail if there is no match, after O(m*n) ops\\n\"},\n {'prompt': 'I\\'ve a django powered website, and I use standard logging module to track web activity.\\n\\nThe log is done via RotatingFileHandler which is configured with 10 log files, 1000000 byte each. The log system works, but this are the log files I get:\\n\\n-rw-r--r-- 1 apache      apache          83 Jul 23 13:30 hr.log\\n-rw-r--r-- 1 apache      apache      446276 Jul 23 13:03 hr.log.1\\n-rw-r--r-- 1 apache      apache      999910 Jul 23 06:00 hr.log.10\\n-rw-r--r-- 1 apache      apache         415 Jul 23 16:24 hr.log.2\\n-rw-r--r-- 1 apache      apache      479636 Jul 23 16:03 hr.log.3\\n-rw-r--r-- 1 apache      apache         710 Jul 23 15:30 hr.log.4\\n-rw-r--r-- 1 apache      apache      892179 Jul 23 15:03 hr.log.5\\n-rw-r--r-- 1 apache      apache         166 Jul 23 14:30 hr.log.6\\n-rw-r--r-- 1 apache      apache      890769 Jul 23 14:03 hr.log.7\\n-rw-r--r-- 1 apache      apache      999977 Jul 23 12:30 hr.log.8\\n-rw-r--r-- 1 apache      apache      999961 Jul 23 08:01 hr.log.9\\n\\n\\nAs you can see it is a mess. Last log has been written to file hr.log.2 (Jul 23 16:24) instead of hr.log, and logging documentation states that:\\n\\n[...]For example, with a backupCount of 5 and a base file name of app.log, you would get app.log, app.log.1, app.log.2, up to app.log.5. The file being written to is always app.log. When this file is filled, it is closed and renamed to app.log.1, and if files app.log.1, app.log.2, etc. exist, then they are renamed to app.log.2, app.log.3 etc. respectively.\\n\\nWhat am I doing wrong?\\n\\n\\n\\nMy logging configuration file is:\\n\\nlogger.conf:\\n\\n[loggers]\\nkeys=root\\n\\n[handlers]\\nkeys=fileHandler\\n\\n[formatters]\\nkeys=simple\\n\\n#--------------------------------------------------------------------\\n# Formatters\\n[formatter_simple]\\nformat=%(asctime)s - %(name)s - %(levelname)s - %(message)s\\n\\n#--------------------------------------------------------------------\\n# Handlers\\n[handler_fileHandler]\\nclass=handlers.RotatingFileHandler\\nlevel=DEBUG\\nformatter=simple\\nargs=(\"/data/django/hr/hr.log\",\\'a\\',1000000,10)\\n\\n#--------------------------------------------------------------------\\n# Loggers\\n[logger_root]\\nlevel=DEBUG\\nhandlers=fileHandler\\n\\n\\nand my python module to set up the log system is:\\n\\nlogger.py\\n\\nimport os, logging\\n\\n# Load config file\\nlogger_config_file = \\\\\\n    os.path.join(os.path.abspath(os.path.dirname(__file__)), \\'logger.conf\\')\\nlogging.config.fileConfig(logger_config_file)\\n\\n# Create logger\\nlogger = logging.getLogger(\\'hr_Logger\\')\\n\\n# Log start message\\nlogger.info(\"Logging system started\")\\n\\n\\nthen, at the top of my views.py I have:\\n\\nimport logging\\nfrom hr import logger\\n\\nlog = logging.getLogger(\\'hr.views\\')\\nlog.info(\\'Load hr.views\\')\\n\\n[...]\\n\\n',\n  'completion': \"I've found this behavior when there are multiple precesses are running with your code.\\n\\nUnfortunatelly no perfect option exists.\\n\\nSome ideas, you can incorporate are:\\n\\n\\nuse WatchedFileHandler (new in 2.6) and rotate with external programs as logrotate\\nuse syslog or other log aggregating server\\nuse python log aggregation sentry - this is especially useful with django as you can log not only log messages, but exceptions with full stacktrace and 404s. \\n\\n\"},\n {'prompt': 'Like everyone else, I can say \"I\\'ve tried everything!\" I kind of did. I looked all over StackOverflow, and tried all the answers, but got nothing. Anyways, I am jetting to at least get some code printed by Python before I get even further in developing this.\\n\\nI want to receive UDP packets from my Garry\\'s Mod server (logaddress_add MyIP:7131), and I don\\'t seem to be receiving any of those packets. It\\'s most likely not a router firewall problem, as I can use HLSW on my other computer. I have used Wireshark, and didn\\'t see any data from my server\\'s IP. I used the Python interpreter / made some code (although example was TCP) to see if I got any data--to make sure Wireshark wasn\\'t doing anything wrong--and nothing came to it either. Am I doing something silly?\\n\\nimport socket\\n\\nsock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\\nsock.bind((\\'0.0.0.0\\', 7131))\\n\\nsock.settimeout(10)\\nsock.recv(1024)\\n\\n\\nEdit : I was doing some testing with HLSW, and found out it seems to be doing some kind of magic. When you try to logaddress_add the certain Port that is not HLSW (say 7135), it won\\'t do anything. Wireshark won\\'t do anything at all. Doesn\\'t show any logs, anything. But, when you change HLSW to use the port that you just added (7135), Wireshark suddenly gets a flow of data, including the console data that I am jetting for. Is it some kind of configuration HLSW is changing?\\n',\n  'completion': \"(Not quite an answer, but a diagnostic path that might lead to an answer. Sometimes it helps just to know that it actually worked for someone else.)\\n\\nI've entered the above into a Python console, and then typed the code below into another Python console:\\n\\nimport socket\\nsock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\\nsock.sendto('hello', 0, ('127.0.0.1', 7131))\\n\\n\\nThe message popped out on the original console. I repeated the experiment from another machine, using a '192.168...' address instead, and it popped out again.\\n\"},\n {'prompt': 'My use case is I want to initialize some functions in a file and then start up ipython with those functions defined. Is there any way to do something like ipython --run_script=myscript.py?\\n',\n  'completion': 'In recent versions of ipython you do need to add the -i option to get into the interactive environment afterwards. Without the -i it just runs the code in myfile.py and returns to the prompt.\\n\\n$ ipython -i myfile.py\\n\\n'},\n {'prompt': 'I am trying to use the Universal Encoding Detector (chardet) in Python to detect the most probable character encoding in a text file (\\'infile\\') and use that in further processing.\\n\\nWhile chardet is designed primarily for detecting the character encoding of webpages, I have found an example of it being used on individual text files.\\n\\nHowever, I cannot work out how to tell the script to set the most likely character encoding to the variable \\'charenc\\' (which is used several times throughout the script).\\n\\nMy code, based on a combination of the aforementioned example and chardet\\'s own documentation is as follows:\\n\\nimport chardet    \\nrawdata=open(infile,\"r\").read()\\nchardet.detect(rawdata)\\n\\n\\nCharacter detection is necessary as the script goes on to run the following (as well as several similar uses):\\n\\ninF=open(infile,\"rb\")\\ns=unicode(inF.read(),charenc)\\ninF.close()\\n\\n\\nAny help would be greatly appreciated.\\n',\n  'completion': 'chardet.detect returns a dictionary which provides the encoding as the value associated with the key \\'encoding\\'. So you can do this:\\n\\nimport chardet    \\nrawdata = open(infile, \"r\").read()\\nresult = chardet.detect(rawdata)\\ncharenc = result[\\'encoding\\']\\n\\n'},\n {'prompt': 'I currently work with Python for a while and I came to the point where I questioned myself whether I should use \"Properties\" in Python as often as in C#.\\nIn C# I\\'ve mostly created properties for the majority of my classes.\\n\\nIt seems that properties are not that popular in python, am I wrong?\\nHow to use properties in Python?\\n\\nregards,\\n',\n  'completion': 'Properties are often no required if all you do is set and query member variables. Because Python has no concept of encapsulation, all member variables are public and often there is no need to encapsulate accesses. However, properties are possible, perfectly legitimate and popular:\\n\\nclass C(object):\\n    def __init__(self):\\n        self._x = 0\\n\\n    @property\\n    def x(self):\\n        return self._x\\n\\n    @x.setter\\n    def x(self, value):\\n        if value <= 0:\\n            raise ValueError(\"Value must be positive\")\\n        self._x = value\\n\\no = C()\\nprint o.x\\no.x = 5\\nprint o.x\\no.x = -2\\n\\n'},\n {'prompt': \"Having a list like this:\\n\\n['foo','spam','bar']\\n\\n\\nis it possible, using list comprehension, to obtain this list as result?\\n\\n['foo','ok.foo', 'spam', 'ok.spam', 'bar', 'ok.bar']\\n\\n\",\n  'completion': \"In [67]: alist = ['foo','spam', 'bar']\\n\\nIn [70]: [prefix+elt for elt in alist for prefix in ('','ok.') ]\\nOut[70]: ['foo', 'ok.foo', 'spam', 'ok.spam', 'bar', 'ok.bar']\\n\\n\"},\n {'prompt': 'I m starting to build python application in windows platform using google appengine\\n\\nwhats the steps to debug and run my application\\n',\n  'completion': \"On Windows I use Aptana.\\n\\nOnce you've installed that, run it, go to the Plugins tab and get Pydev.\\n\\nPydev has inbuilt support for google app engine - so you can create an app engine project, and then run or debug it. See these posts for more details:\\n\\nhttp://pydev.blogspot.com/2009/05/testing-on-pydev-146-google-app-engine.html\\n\\nhttp://pydev.blogspot.com/2009/05/pydev-146-released-google-app-engine-on.html\\n\"},\n {'prompt': 'I constantly get this error using mako:\\n\\nUnicodeEncodeError: \\'ascii\\' codec can\\'t encode character u\\'\\\\xe0\\' in position 6: ordinal not in range(128)\\n\\n\\nI\\'ve told mako I\\'m using unicode in any possible way:\\n\\n    mylookup = TemplateLookup(\\n        directories=[\\'plugins/stl/templates\\'],\\n        input_encoding=\\'utf-8\\',\\n        output_encoding=\\'utf-8\\',\\n        default_filters=[\\'decode.utf8\\'],\\n        encoding_errors=\\'replace\\')\\n\\n    self.template = Template(self.getTemplate(), lookup=mylookup,\\n        module_directory=tempfile.gettempdir(),\\n        input_encoding=\\'utf-8\\',\\n        output_encoding=\\'utf-8\\',\\n        default_filters=[\\'decode.utf8\\'],\\n        encoding_errors=\\'replace\\')\\n\\n    html = self.template.render_unicode(data=self.stuff)\\n\\n\\nAll my template files starts with:\\n\\n## -*- coding: utf-8 -*-\\n\\n\\nand, inside them, all costant strings are prefixed with \"u\".\\nI know the self.stuff parameter contains unicode strings, but the way I instantiate the mako objects should take care of it (otherwise what those arguments are good for?).\\nIs there anything I forgot to do?\\n\\nOne more question: what\\'s the point of encoding_errors=\\'replace\\'?\\n\\n=EDIT=\\nI left only a single unicode string and this is the traceback:\\n\\nTraceback (most recent call last):\\n  File \"C:\\\\My Dropbox\\\\src\\\\flucso\\\\src\\\\plugins\\\\stl\\\\main.py\", line 240, in updateView\\n    flags=self.makoflags)\\n  File \"C:\\\\Python26\\\\lib\\\\site-packages\\\\mako-0.3.4-py2.6.egg\\\\mako\\\\template.py\", line 198, in render_unicode\\n    as_unicode=True)\\n  File \"C:\\\\Python26\\\\lib\\\\site-packages\\\\mako-0.3.4-py2.6.egg\\\\mako\\\\runtime.py\", line 403, in _render\\n    _render_context(template, callable_, context, *args, **_kwargs_for_callable(callable_, data))\\n  File \"C:\\\\Python26\\\\lib\\\\site-packages\\\\mako-0.3.4-py2.6.egg\\\\mako\\\\runtime.py\", line 434, in _render_context\\n    _exec_template(inherit, lclcontext, args=args, kwargs=kwargs)\\n  File \"C:\\\\Python26\\\\lib\\\\site-packages\\\\mako-0.3.4-py2.6.egg\\\\mako\\\\runtime.py\", line 457, in _exec_template\\n    callable_(context, *args, **kwargs)\\n  File \"memory:0x41317f0\", line 89, in render_body\\n  File \"C:\\\\Python26\\\\lib\\\\site-packages\\\\mako-0.3.4-py2.6.egg\\\\mako\\\\runtime.py\", line 278, in <lambda>\\n    return lambda *args, **kwargs:callable_(self.context, *args, **kwargs)\\n  File \"FriendFeed_mako\", line 49, in render_inlist_entry\\n  File \"C:\\\\Python26\\\\lib\\\\encodings\\\\utf_8.py\", line 16, in decode\\n    return codecs.utf_8_decode(input, errors, True)\\nUnicodeEncodeError: \\'ascii\\' codec can\\'t encode character u\\'\\\\u263c\\' in position 8: ordinal not in range(128)\\n\\n',\n  'completion': 'finally I saved my templates in unicode, actually (I guess) utf-16 instead of utf-8. their size on disk doubled and mako started complaining about a \"CompileException(\"Unicode decode operation of encoding \\'utf-8\\' bla bla\", so I changed the first line in all of them in:\\n\\n## -*- coding: utf-16 -*-\\n\\n\\nand removed all the \".decode(\\'utf-8\\')\" - constant strings are still prefixed by \"u\".\\n\\nthe initializations in python now are:\\n\\nmylookup = TemplateLookup(\\n    directories=[\\'plugins/stl/templates\\'],\\n    input_encoding=\\'utf-16\\',\\n    output_encoding=\\'utf-16\\',\\n    encoding_errors=\\'replace\\')\\n\\nself.template = Template(self.getTemplate(), lookup=mylookup,\\n    module_directory=tempfile.gettempdir(),\\n    input_encoding=\\'utf-16\\',\\n    output_encoding=\\'utf-16\\',\\n    encoding_errors=\\'replace\\')\\n\\n\\nit works now. looks like utf-8 was the wrong choice (or my inability to save the templates in utf-8), but I can\\'t explain why it worked from eclipse/pydev.\\n'},\n {'prompt': \"For a long time now I've been using pygccxml to parse and introspect my C++ source code: it helps me to do some clever code-generation during our build process.\\n\\nRecently I've read a lot about the benefits of the LLVM stack, and especially the benefits that the LLVM Clang parser brings to C++ compilation.  I am now wondering if there is any Python interface to Clang such that I could use it as the basis for some of my existing code generation tasks? \\n\",\n  'completion': \"After further digging I found that in the LLVM 2.7 release there could be the beginings of something useful:\\n\\n\\n  In the LLVM 2.7 time-frame, the Clang team has made many improvements....\\n  \\n  CIndex API and Python bindings: Clang now includes a C API as part of the CIndex library. Although we make make some changes to the API in the future, it is intended to be stable and has been designed for use by external projects. See the Clang doxygen CIndex documentation for more details. The CIndex API also includings an preliminary set of Python bindings.\\n\\n\\nI'm not sure how useful this is in practice, certainly it looks like it could be the foundation for building a pygccxml equivalent based on LLVM but it is not in itself such a library.\\n\"},\n {'prompt': \"I'm wanting to use some newer software that requires Python 2.6, and we currently have both 2.4 and 2.6 installed on our dedicated CentOS server, which looks like this:\\n\\n$ which python\\n/usr/local/bin/python\\n$ which python2.6\\n/usr/bin/python2.6\\n$ which python2.4\\n/usr/local/bin/python2.4\\n$ ls -l /usr/local/bin/py*\\n-rwxr-xr-x 1 root root      81 Aug  9  2007 /usr/local/bin/pydoc\\n-rwxr-xr-x 2 root root 3394082 Aug  9  2007 /usr/local/bin/python\\n-rwxr-xr-x 2 root root 3394082 Aug  9  2007 /usr/local/bin/python2.4\\n\\n\\nHow can I switch it to start using 2.6 as the default python?\\n\",\n  'completion': 'As root:\\n\\nln -sf /usr/bin/python2.6 /usr/local/bin/python\\n\\n\\nThis will make a symbolic link from /usr/local/bin/python --> /usr/bin/python2.6\\n(replacing the old hardlink).\\n'},\n {'prompt': 'I\\'m using python and beautifulsoup (new to both!), and I want to login to a suppliers website.\\n\\nSo their form looks like (simplified):\\n\\n<form name=loginform action=/index.html method=\"post\">\\n\\n<input name=user>\\n<input name=pass\">\\n\\n</form>\\n\\n\\nIs there a way to keep track for cookies?\\n',\n  'completion': \"Do some more reading. \\n\\nRead about urllib2  That's what you use to do a POST to login.  If you know the <input> names, you don't need Beautiful Soup.  http://docs.python.org/library/urllib2.html\\n\\nBeautiful Soup is what you use to parse a page of results.  After you login.  After you post the real request.\\n\"},\n {'prompt': 'I am reading in some data from the subprocess module\\'s communicate method.  It is coming in as a large string separated by \"\\\\r\\\\n\"s.  I want to split this into a list of lines.  How is this performed in python?\\n',\n  'completion': 'Use the splitlines method on the string.\\n\\nFrom the docs:\\n\\n\\n  str.splitlines([keepends])\\n      Return a list of the lines in the string, breaking at line boundaries.\\n  Line breaks are not included in the\\n  resulting list unless keepends is\\n  given and true.\\n\\n\\nThis will do the right thing whether the line endings are \"\\\\r\\\\n\", \"\\\\r\" or \"\\\\n\" regardless of the OS.\\n\\nNB a line ending of \"\\\\n\\\\r\" will also split, but you will get an empty string between each line since it will consider \"\\\\n\" as a valid line ending and \"\\\\r\" as the ending of the next line. e.g.\\n\\n>>> \"foo\\\\n\\\\rbar\".splitlines()\\n[\\'foo\\', \\'\\', \\'bar\\']\\n\\n'},\n {'prompt': \"How do I wrap long lines in Python without sacrificing indentation? \\n\\nFor example: \\n\\ndef fun():\\n    print '{0} Here is a really long sentence with {1}'.format(3, 5)\\n\\n\\nSuppose this goes over the 79 character recommended limit. The way I read it, here is how to indent it:\\n\\ndef fun():\\n    print '{0} Here is a really long \\\\\\nsentence with {1}'.format(3, 5)\\n\\n\\nHowever, with this approach, the indentation of the continued line matches the indentation of the fun(). This looks kinda ugly. If someone was to go through my code, it would look bad to have uneven indentation because of this print statement.\\n\\nHow do I indent lines like this effectively without sacrificing code readability?\\n\",\n  'completion': \"def fun():\\n    print '{0} Here is a really long ' \\\\\\n          'sentence with {1}'.format(3, 5)\\n\\n\\nAdjecent string literals are concatenated at compile time, just as in C. http://docs.python.org/reference/lexical_analysis.html#string-literal-concatenation is a good place to start for more info.\\n\"},\n {'prompt': 'I have a text file which contains a time stamp on each line. My goal is to find the time range. All the times are in order so the first line will be the earliest time and the last line will be the latest time. I only need the very first and very last line. What would be the most efficient way to get these lines in python?\\n\\nNote: These files are relatively large in length, about 1-2 million lines each and I have to do this for several hundred files. \\n',\n  'completion': \"docs for io module\\n\\nwith open(fname, 'rb') as fh:\\n    first = next(fh).decode()\\n\\n    fh.seek(-1024, 2)\\n    last = fh.readlines()[-1].decode()\\n\\n\\nThe variable value here is 1024: it represents the average string length. I choose 1024 only for example. If you have an estimate of average line length you could just use that value times 2.\\n\\nSince you have no idea whatsoever about the possible upper bound for the line length, the obvious solution would be to loop over the file:\\n\\nfor line in fh:\\n    pass\\nlast = line\\n\\n\\nYou don't need to bother with the binary flag you could just use open(fname).\\n\\nETA: Since you have many files to work on, you could create a sample of couple of dozens of files using random.sample and run this code on them to determine length of last line. With an a priori large value of the position shift (let say 1 MB). This will help you to estimate the value for the full run.\\n\"},\n {'prompt': 'I just ordered an Android smartphone and want to start playing around with creating my own applications. Now the question is which language to use, the native Java or Python using SL4A (former ASE).\\n\\nI tend to Python, as I know it much better than Java, but I\\'m wondering what I would be missing using a \"second class\" language on Android. On the SL4A website it is also stated to be alpha quality software, which is not exactly encouraging.\\n\\nI\\'m also not quite sure what the limitations of the scripting environment are and if they would be problematic.\\n',\n  'completion': 'At the moment you cannot create a releasable program with Python (or any other scripting language) using SL4A.  I have heard rumours that this is something Google is working on, but even if they do enable it Python apps are likely to be slow and power-hungry compared to Java.  Also the scripting API only gives you access to a limited subset of the native Java API.  I would not consider using SL4A for serious development work at the moment, only for one-off scripts and prototyping.\\n\\nTake a look at Scala.  It is a statically typed language on the JVM, but uses type inference to remove most of the noise that you get in Java.  It also fully supports functional programming, and has a lot of pythonish features.  Because it is statically typed it is as efficient as straight Java with none of the disadvantages.  IMHO it is the language that Java should have been in the first place.  \\n\\nA lot of people are blogging about using Scala on Android, so Google around for more information.\\n'},\n {'prompt': \"import csv\\n\\nwith open('thefile.csv', 'rb') as f:\\n  data = list(csv.reader(f))\\n  import collections\\n  counter = collections.defaultdict(int)\\n\\n  for row in data:\\n        counter[row[10]] += 1\\n\\n\\nwith open('/pythonwork/thefile_subset11.csv', 'w') as outfile:\\n    writer = csv.writer(outfile)\\n    for row in data:\\n        if counter[row[10]] >= 504:\\n           writer.writerow(row)\\n\\n\\nThis code reads thefile.csv, makes changes, and writes results to thefile_subset1.\\n\\nHowever, when I open the resulting csv in Microsoft Excel, there is an extra blank line after each record!\\n\\nIs there a way to make it not put an extra blank line?\\n\",\n  'completion': \"In Python 2, open outfile with mode 'wb' instead of 'w'.  The csv.writer writes \\\\r\\\\n into the file directly.  If you don't open the file in binary mode, it will write \\\\r\\\\r\\\\n because on Windows text mode will translate each \\\\n into \\\\r\\\\n.\\n\\nIn Python 3 the required syntax changed, so open outfile with the additional parameter newline='' instead.\\n\\nExamples:\\n\\n# Python 2\\nwith open('/pythonwork/thefile_subset11.csv', 'wb') as outfile:\\n    writer = csv.writer(outfile)\\n\\n# Python 3\\nwith open('/pythonwork/thefile_subset11.csv', 'w', newline='') as outfile:\\n    writer = csv.writer(outfile)\\n\\n\\nDocumentation Links\\n\\n\\nhttps://docs.python.org/2/library/csv.html#csv.writer\\nhttps://docs.python.org/3/library/csv.html#csv.writer\\n\\n\"},\n {'prompt': \"\\n  Possible Duplicate:\\n  Python 3 online interpreter / shell  \\n\\n\\n\\n\\nWhere can I find an online interpreter for Python 3?  I'm learning Python but can't install it at work where I'd like to do some practice.\\n\\nThanks!\\n\\nSorry to repeat the question; I can't bump earlier posts and was just hoping there is one out there now.\\n\",\n  'completion': 'Ideone.com supports several languages including both Python and Python 3.\\n'},\n {'prompt': \"I am wondering how to create forgiving dictionary (one that returns a default value if a KeyError is raised).\\n\\nIn the following code example I would get a KeyError; for example\\n\\na = {'one':1,'two':2}\\nprint a['three']\\n\\n\\nIn order not to get one I would 1. Have to catch the exeption or use get.\\n\\nI would like to not to have to do that with my dictionary...\\n\",\n  'completion': 'import collections\\na = collections.defaultdict(lambda: 3)\\na.update({\\'one\\':1,\\'two\\':2})\\nprint a[\\'three\\']\\n\\n\\nemits 3 as required.  You could also subclass dict yourself and override __missing__, but that doesn\\'t make much sense when the defaultdict behavior (ignoring the exact missing key that\\'s being looked up) suits you so well...\\n\\nEdit ...unless, that is, you\\'re worried about a growing by one entry each time you look up a missing key (which is part of defaultdict\\'s semantics) and would rather get slower behavior but save some memory.  For example, in terms of memory...:\\n\\n>>> import sys\\n>>> a = collections.defaultdict(lambda: \\'blah\\')\\n>>> print len(a), sys.getsizeof(a)\\n0 140\\n>>> for i in xrange(99): _ = a[i]\\n... \\n>>> print len(a), sys.getsizeof(a)\\n99 6284\\n\\n\\n...the defaultdict, originally empty, now has the 99 previously-missing keys that we looked up, and takes 6284 bytes (vs. the 140 bytes it took when it was empty).\\n\\nThe alternative approach...:\\n\\n>>> class mydict(dict):\\n...   def __missing__(self, key): return 3\\n... \\n>>> a = mydict()\\n>>> print len(a), sys.getsizeof(a)\\n0 140\\n>>> for i in xrange(99): _ = a[i]\\n... \\n>>> print len(a), sys.getsizeof(a)\\n0 140\\n\\n\\n...entirely saves this memory overhead, as you see.  Of course, performance is another issue:\\n\\n$ python -mtimeit -s\\'import collections; a=collections.defaultdict(int); r=xrange(99)\\' \\'for i in r: _=a[i]\\'\\n100000 loops, best of 3: 14.9 usec per loop\\n\\n$ python -mtimeit -s\\'class mydict(dict):\\n>   def __missing__(self, key): return 0\\n> \\' -s\\'a=mydict(); r=xrange(99)\\' \\'for i in r: _=a[i]\\'\\n10000 loops, best of 3: 92.9 usec per loop\\n\\n\\nSince defaultdict adds the (previously-missing) key on lookup, it gets much faster when such a key is next looked up, while mydict (which overrides __missing__ to avoid that addition) pays the \"missing key lookup overhead\" every time.\\n\\nWhether you care about either issue (performance vs memory footprint) entirely depends on your specific use case, of course.  It is in any case a good idea to be aware of the tradeoff!-)\\n'},\n {'prompt': 'Some stated that python dictionary is thread safe. Does it mean I can or cannot modify the items in a dictionary while iterating over it?\\n',\n  'completion': 'The other answers already correctly addressed what\\'s apparently your actual question:\\n\\n\\n  Does it mean I can or cannot modified\\n  the items in a dictionary while\\n  iterating over it?\\n\\n\\nby explaining that thread safety has nothing to do with the issue, and in any case, no, you cannot modify a dict while iterating over it.\\n\\nHowever, the title of your question is about thread safety, and you start with:\\n\\n\\n  Some stated that python dictionary is\\n  thread safe\\n\\n\\nI don\\'t know who the \"some\" are, but, if they did state that (rather than you misunderstanding what they did state;-) without heavy qualifications, they\\'re wrong.\\n\\nSome operations, those which don\\'t alter the set of keys in the dict, happen to be thread-safe in current CPython implementations -- but you should not count on that, unless you strictly control the Python version under which your code will run, because such thread safety is not guaranteed by Python\\'s language specification and therefore other implementations, including future versions of CPython, might not offer it.\\n\\nIf every thread is only \"reading\" the dict (indexing it, looping on it, etc), and no thread performs any assignment or deletion on it, then that situation is safe in current CPython implementations; in fact, if some thread assigns a new value to a key that was already present, that is also thread safe (other threads may see the previous value for that key, or the next one, depending on how the threads happen to be timed, but there will be no crash, no deadlock, and no appearance of crazy values out of nowhere, in current CPython implementations).\\n\\nHowever, an operation such as d[k] += 1 (assuming k was previously present, and its value a number) is not properly speaking thread safe (any more than other case of +=!) because it can be seen as d[k] = d[k] + 1 -- it might happen that two threads in a race condition both read the old value of d[k], then increment it by one, and store the same new value in the slot... so the overall effect is to increment it only by one, and not by two as would normally occur.\\n\\nBack to your other question... \"only reading\" the dict, and assigning new values to keys that already existed in the dict, are also the things you can do in the body of a loop that iterates on the dict -- you can\\'t alter the set of keys in the dict (you can\\'t add any key, nor remove any key), but the specific operation of setting a new value for an existing key is allowed.  The allowed operations in this case do include the += that would be problematic in a threading situation.  For example:\\n\\n>>> d = dict.fromkeys(range(5), 0)\\n>>> for k in d: d[k] += 1\\n... \\n>>> d\\n{0: 1, 1: 1, 2: 1, 3: 1, 4: 1}\\n\\n\\nand this behavior is guaranteed by Python\\'s standardized semantics, so different implementations of the language should all preserve it.\\n'},\n {'prompt': 'I am having problems understanding how to email an attachment using Python. I have successfully emailed simple messages with the smtplib. Could someone please explain how to send an attachment in an email. I know there are other posts online but as a Python beginner I find them hard to understand. \\n',\n  'completion': 'Here\\'s another, adapted from here:\\n\\nimport smtplib\\nfrom os.path import basename\\nfrom email.mime.application import MIMEApplication\\nfrom email.mime.multipart import MIMEMultipart\\nfrom email.mime.text import MIMEText\\nfrom email.utils import COMMASPACE, formatdate\\n\\n\\ndef send_mail(send_from, send_to, subject, text, files=None,\\n              server=\"127.0.0.1\"):\\n    assert isinstance(send_to, list)\\n\\n    msg = MIMEMultipart()\\n    msg[\\'From\\'] = send_from\\n    msg[\\'To\\'] = COMMASPACE.join(send_to)\\n    msg[\\'Date\\'] = formatdate(localtime=True)\\n    msg[\\'Subject\\'] = subject\\n\\n    msg.attach(MIMEText(text))\\n\\n    for f in files or []:\\n        with open(f, \"rb\") as fil:\\n            part = MIMEApplication(\\n                fil.read(),\\n                Name=basename(f)\\n            )\\n            part[\\'Content-Disposition\\'] = \\'attachment; filename=\"%s\"\\' % basename(f)\\n            msg.attach(part)\\n\\n\\n    smtp = smtplib.SMTP(server)\\n    smtp.sendmail(send_from, send_to, msg.as_string())\\n    smtp.close()\\n\\n\\nIt\\'s much the same as the first example... But it should be easier to drop in.\\n'},\n {'prompt': 'I have a directory structure as follows:\\n\\n| main.py\\n| scripts\\n|--| __init__.py\\n   | script1.py\\n   | script2.py\\n   | script3.py\\n\\n\\nFrom main.py, the module scripts is imported. I tried using pkgutils.walk_packages in combination with __all__, but using that, I can only import all the submodules directly under main using from scripts import *. I would like to get them all under scripts. What would be the cleanest way to import all the submodules of scripts so that I could access scripts.script1 from main?\\n\\nEDIT: I am sorry that I was a bit vague. I would like to import the submodules on run-time without specifying them explicitly in __init__.py. I can use pkgutils.walk_packages to get the submodule names (unless someone knows of a better way), but I am not sure of the cleanest way to use these names (or maybe the ImpImporters that walk_packages returns?) to import them.\\n',\n  'completion': \"Edit: Here's one way to recursively import everything at runtime... \\n\\nIt uses exec, so there's almost certainly a better way, but it does work (even for arbitrarily nested sub-packages, I think).\\n\\n(Contents of __init__.py in top package directory)\\n\\nimport pkgutil\\n\\n__all__ = []\\nfor loader, module_name, is_pkg in  pkgutil.walk_packages(__path__):\\n    __all__.append(module_name)\\n    module = loader.find_module(module_name).load_module(module_name)\\n    exec('%s = module' % module_name)\\n\\n\\nI'm not using __import__(__path__+'.'+module_name) here, as it's difficult to properly recursively import packages using it.  If you don't have nested sub-packages, and wanted to avoid the exec/eval, though, it's one way to do it.\\n\\nThere's probably a better way, but this is the best I can do, anyway.\\n\\nOriginal Answer (For context, ignore othwerwise. I misunderstood the question initially):\\n\\nWhat does your scripts/__init__.py look like?  It should be something like:\\n\\nimport script1\\nimport script2\\nimport script3\\n__all__ = ['script1', 'script2', 'script3']\\n\\n\\nYou could even do without defining __all__, but things (pydoc, if nothing else) will work more cleanly if you define it, even if it's just a list of what you imported.\\n\"},\n {'prompt': \"I have a very long list of dictionaries with string indices and integer values. Many of the keys are the same across the dictionaries, though not all. I want to generate one dictionary in which the keys are the union of the keys in the separate dictionaries and the values are the sum of all the values corresponding to that key in each of the dictionaries. (For example, the value for the key 'apple' in the combined dictionary will be the sum of the value of 'apple'  in the first, plus the sum of the value of 'apple' in the second, etc.)\\n\\nI have the following, but it's rather cumbersome and takes ages to execute. Is there a simpler way to achieve the same result?\\n\\ncomb_dict = {}  \\nfor dictionary in list_dictionaries:  \\n    for key in dictionary:  \\n        comb_dict.setdefault(key, 0)  \\n        comb_dict[key] += dictionary[key]  \\nreturn comb_dict\\n\\n\",\n  'completion': 'Here are some microbenchmarks which suggest f2 (see below) might be an improvement. f2 uses iteritems which allows you avoid an extra dict lookup in the inner loop:\\n\\nimport collections\\nimport string\\nimport random\\n\\ndef random_dict():\\n    n=random.randint(1,26)\\n    keys=list(string.letters)\\n    random.shuffle(keys)\\n    keys=keys[:n]\\n    values=[random.randint(1,100) for _ in range(n)]    \\n    return dict(zip(keys,values))\\n\\nlist_dictionaries=[random_dict() for x in xrange(100)]\\n\\ndef f1(list_dictionaries):\\n    comb_dict = {}  \\n    for dictionary in list_dictionaries:  \\n        for key in dictionary:  \\n            comb_dict.setdefault(key, 0)  \\n            comb_dict[key] += dictionary[key]  \\n    return comb_dict\\n\\ndef f2(list_dictionaries):    \\n    comb_dict = collections.defaultdict(int)\\n    for dictionary in list_dictionaries:  \\n        for key,value in dictionary.iteritems():  \\n            comb_dict[key] += value\\n    return comb_dict\\n\\ndef union( dict_list ):\\n    all_keys = set()\\n    for d in dict_list:\\n        for k in d:\\n            all_keys.add( k )\\n    for key in all_keys:\\n        yield key, sum( d.get(key,0) for d in dict_list)\\n\\ndef f3(list_dictionaries):\\n    return dict(union( list_dictionaries ))\\n\\n\\nHere are the results:\\n\\n% python -mtimeit -s\"import test\" \"test.f1(test.list_dictionaries)\"\\n1000 loops, best of 3: 776 usec per loop\\n% python -mtimeit -s\"import test\" \"test.f2(test.list_dictionaries)\"\\n1000 loops, best of 3: 432 usec per loop    \\n% python -mtimeit -s\"import test\" \"test.f3(test.list_dictionaries)\"\\n100 loops, best of 3: 2.19 msec per loop\\n\\n'},\n {'prompt': \"What are peoples' opinions on using the __call__. I've only very rarely seen it used, but I think it's a very handy tool to use when you know that a class is going to be used for some default behaviour.\\n\",\n  'completion': 'I think your intuition is about right.\\n\\nHistorically, callable objects (or what I\\'ve sometimes heard called \"functors\") have been used in the OO world to simulate closures. In C++ they\\'re frequently indispensable.\\n\\nHowever, __call__ has quite a bit of competition in the Python world:\\n\\n\\nA regular named method, whose behavior can sometimes be a lot more easily deduced from the name. Can convert to a bound method, which can be called like a function.\\nA closure, obtained by returning a function that\\'s defined in a nested block.\\nA lambda, which is a limited but quick way of making a closure.\\nGenerators and coroutines, whose bodies hold accumulated state much like a functor can.\\n\\n\\nI\\'d say the time to use __call__ is when you\\'re not better served by one of the options above. Check the following criteria, perhaps:\\n\\n\\nYour object has state.\\nThere is a clear \"primary\" behavior for your class that\\'s kind of silly to name. E.g. if you find yourself writing run() or doStuff() or go() or the ever-popular and ever-redundant doRun(), you may have a candidate.\\nYour object has state that exceeds what would be expected of a generator function.\\nYour object wraps, emulates, or abstracts the concept of a function.\\nYour object has other auxilliary methods that conceptually belong with your primary behavior.\\n\\n\\nOne example I like is UI command objects. Designed so that their primary task is to execute the comnand, but with extra methods to control their display as a menu item, for example, this seems to me to be the sort of thing you\\'d still want a callable object for.\\n'},\n {'prompt': '\\n  Possible Duplicate:\\n  check what files are open in Python  \\n\\n\\n\\n\\nHello,\\n\\nIs it possible to obtain a list of all currently open file handles, I presume that they are stored somewhere in the environment. \\n\\nI am interested in theis function as I would like to safely handle any files that are open when a fatal error is raised, i.e. close file handles and replace potentially corrupted files with the original files.\\n\\nI have the handling working but without knowing what file handles are open, I am unable to implement this idea.\\n\\nAs an aside, when a file handle is initialised, can this be inherited by another imported method?\\n\\nThank you\\n',\n  'completion': 'lsof, /proc/pid/fd/\\n'},\n {'prompt': 'Can Python be a good alternative to a web app that would otherwise be developed with Java EE? If so, which Python web app framework(s) may be a good choice? Please see details about the app below. I\\'ve asked a few people individually about this, who have worked for a good amount of time on either or both of Java EE and Python web apps, and got a few answers that indicated Python might not such a good choice, mainly due to ease of scaling, which is one of the needs. The other reason given was relative lack of Python developers in the part of the world where the app is being developed. We might be able to overcome the second one, but not sure about the first.\\n\\nThe app in question is a financial domain B2B one, with a few different types of users (as in: \"actors\" having different real-life roles - e.g. buyers, sellers), some admin users, will use an RDBMS, will have CRUD (Create/Read/Update/Delete) plus search functionality for master tables, some types of transactions involving both master and transaction tables, (with fairly straightforward, not very complex logic), and some reports to PDF for most / all of the search screens (queries). Around 80 or so features, where the features mostly map to screens in the app; not all, though. It will have a few types of batch jobs too, for which the plan is to run them at times when the users are not permitted to use the app. Will have JavaScript and AJAX on the front end. Will have the feature of sending emails to users, not just for signup or resetting passwords, but for transaction-related info as well. No programmatic reading of incoming emails though.\\n\\nThe aim is for it to eventually to get a medium level of scale in terms of numbers of (paying) users and transactions, not very high, but not too small a number - say in the range of 10,000 users, of which 2000 may be concurrently accessing the app in a time frame of 15 to 20 minutes. It will be a SaaS (Software as a Service) app.\\n\\nI know the question is very general and open ended and I expect some answers on the lines of \"It depends\" :) but still want to get some views from people who have worked on such things.\\n\\nFeel free to ask more questions if needed to answer. I\\'ll answer them except for anything that is confidential.\\n\\nThanks.\\n\\nEdit 1:\\n\\nReally appreciate all the answers. I will take a little time to think about them, and then get back with further questions (original, or in response to answers) or comments, if any.\\n',\n  'completion': \"It's a very good alternative indeed. Your project sounds to me like it'll need quite a lot of custom programming, which in the Python world would point to basing your web app from Pylons ( http://pylonshq.com/ ). Pylons is mostly a glue layer, and you'll pick a template engine and ORM (try SQLAlchemy ( http://www.sqlalchemy.org/ ) for maximum power or SQLObject ( http://www.sqlobject.org/ ) for a somewhat simpler approach) layer of your choice. You will probably want to generate the PDF's using ReporLab ( http://www.reportlab.com/ ). For the email part, you'll get a long way with Pythons built-in email functionality (see docs at Python's own website).\\n\\nEdit 1: you have almost certainly already thought of this, but..: success of course depends a lot on the competencies of the developers you have access to, i.e. if the know Python already, or are eager and quick to learn. I'd say Python is a very good beginners language, but it takes a little time to become really 'Pythonic' (roughly translatable as being proficient with Python's characteristics, e.g. using features like generators, list comprehensions, getattr and setattr etc fluently).\\n\\nEdit 2: also, take a look at PyPI, the Python package index, http://pypi.python.org/pypi to 'window shop' for modules that'll provide additional functionality for you. There's a lot of them.\\n\"},\n {'prompt': 'I don\\'t want to get into complex trigonometry to calculate rotations and things like that for my 3D world so gluLookAt seems like a nice alternative. According to the documentation all I need to do is place 3 coordinates for the cameras position, three for what I should be looking at and an \"up\" position. The last made no sense until I assumed it had to be at right angles with the line of sight in the direction the top of the screen should be.\\n\\nIt doesn\\'t work like that at all. I have some python code. This is the code which initialises some data and some mode code for when I enter this part of the game:\\n\\ndef init(self):\\n    self.game_over = False\\n    self.z = -30\\n    self.x = 0\\ndef transfer(self):\\n    #Make OpenGL use 3D\\n    game.engage_3d(45,0.1,100)\\n    gluLookAt(0,0,-30,0,0,0,0,1,0)\\n\\n\\n\"game.engage_3d(45,0.1,100)\" basically sets up the projection matrix to have a 45 degree angle of view and near and far coordinates of 0.1 and 100.\\n\\nThe first gluLookAt puts the camera in the correct position, nicely.\\n\\nI have a cube drawn with the centre of (0,0,0) and it works fine without gluLookAt. Before I draw it I have this code:\\n\\ngluLookAt(self.x,0,self.z,0,0,0,0,1,0)\\nif game.key(KEY_UP):\\n    self.z += 2.0/game.get_fps()\\nif game.key(KEY_DOWN):\\n    self.z -= 2.0/game.get_fps()\\nif game.key(KEY_LEFT):\\n    self.x += 2.0/game.get_fps()\\nif game.key(KEY_RIGHT):\\n    self.x -= 2.0/game.get_fps()\\n\\n\\nNow from that, the up position should always be the same as it\\'s always at right angles. What I\\'d have thought it would do is move forward and back the z-axis with the up and down keys and left and right through the x-axis with the left and right keys. What actually happens, is when I use the left and right keys, the cube will rotate around the \"eye\" being accelerated by the keys. The up key causes another cube from nowhere to slice through the screen and hit the first cube. THe down key brings the mysterious cloned cube back. This can be combined with the rotation to give a completely different outcome as the documentation said would arise.\\n\\nWhat on earth is wrong?\\n\\nThank you.\\n',\n  'completion': '(The intuition behind the \"up\" vector in gluLookAt is simple: Look at anything. Now tilt your head 90 degrees. Where you are hasn\\'t changed, the direction you\\'re looking at hasn\\'t changed, but the image in your retina clearly has. What\\'s the difference? Where the top of your head is pointing to. That\\'s the up vector.)\\n\\nBut to answer your question: gluLookAt calls should not be concatenated. In other words, the only pattern in which it\\'s OK to use gluLookAt if you don\\'t know exactly how it works is the following:\\n\\nglMatrixMode(GL_MODELVIEW);\\nglLoadIdentity();\\ngluLookAt(...);\\n# do not touch the modelview matrix anymore!\\n\\n\\nIt seems from your code that you\\'re doing something like this:\\n\\nglMatrixMode(GL_MODELVIEW);\\nglLoadIdentity();\\ngluLookAt(...);\\n# some stuff..\\ngluLookAt(...);\\n\\n\\nThis will generate weird results, because gluLookAt multiplies the current matrix by the viewing matrix it computes. If you want to concatenate transformations you\\'re really better off figuring out how to make glTranslate, glScale and glRotatef work for you. Even better, you should learn how the coordinate transformations work and stick to glMultMatrix.\\n'},\n {'prompt': 'I found this interesting item in a blog today:\\n\\ndef abc():\\n    try:\\n        return True\\n    finally:\\n        return False\\n\\nprint \"abc() is\", abc()\\n\\n\\nCan anyone tell why it does what it does?\\n\\nThanks,\\nKR\\n',\n  'completion': \"If the finally block contains a return or break statement the result from the try\\nblock is discarded\\n\\nit's explained in detail in the python docu\\n\"},\n {'prompt': 'I am re designing a portion of my current software project, and want to use hyperlinks instead of Buttons. I really didn\\'t want to use a Text widget, but that is all I could find when I googled the subject. Anyway, I found an example of this, but keep getting this error: \\n\\nTclError: bitmap \"blue\" not defined\\n\\n\\nWhen I add this line of code (using the IDLE)\\n\\nhyperlink = tkHyperlinkManager.HyperlinkManager(text)\\n\\n\\nThe code for the module is located here and the code for the script is located here\\n\\nAnyone have any ideas? \\n\\nThe part that is giving problems says foreground=\"blue\", which is known as a color in Tkinter, isn\\'t it?\\n',\n  'completion': 'If you don\\'t want to use a text widget, you don\\'t need to. An alternative is to use a label and bind mouse clicks to it. Even though it\\'s a label it still responds to events.\\n\\nFor example:\\n\\nimport tkinter as tk\\n\\nclass App:\\n    def __init__(self, root):\\n        self.root = root\\n        for text in (\"link1\", \"link2\", \"link3\"):\\n            link = tk.Label(text=text, foreground=\"#0000ff\")\\n            link.bind(\"<1>\", lambda event, text=text: self.click_link(event, text))\\n            link.pack()\\n\\n    def click_link(self, event, text):\\n        print(\"You clicked \\'%s\\'\" % text)\\n\\nroot = tk.Tk()\\napp = App(root)\\nroot.mainloop()\\n\\n\\nIf you want, you can get fancy and add additional bindings for <Enter> and <Leave> events so you can alter the look when the user hovers. And, of course, you can change the font so that the text is underlined if you so choose.\\n\\nTk is a wonderful toolkit that gives you the building blocks to do just about whatever you want. You just need to look at the widgets not as a set of pre-made walls and doors but more like a pile of lumbar, bricks and mortar. \\n'},\n {'prompt': \"I have an XML file that specifies an encoding, and I use UnicodeDammit to convert it to unicode (for reasons of storage, I can't store it as a string). I later pass it to lxml but it refuses to ignore the encoding specified in the file and parse it as Unicode, and it raises an exception.\\n\\nHow can I force lxml to parse the document? This behaviour seems too restrictive.\\n\",\n  'completion': \"You cannot parse from unicode strings AND have an encoding declaration in the string.\\nSo, either you make it an encoded string (as you apparently can't store it as a string, you will have to re-encode it before parsing. Or you serialize the tree as unicode with lxml yourself: etree.tostring(tree, encoding=unicode), WITHOUT xml declaration. You can easily parse the result again with etree.fromunicode\\n\\nsee http://lxml.de/parsing.html#python-unicode-strings\\n\\nEdit: If, apparently, you already have the unicode string, and can't control how that was made. You'll have to encode it again, and provide the parser with the encoding you used:\\n\\nutf8_parser = etree.XMLParser(encoding='utf-8')\\n\\ndef parse_from_unicode(unicode_str):\\n    s = unicode_str.encode('utf-8')\\n    return etree.fromstring(s, parser=utf8_parser)\\n\\n\\nThis will make sure that, whatever was inside the xml declaration gets ignored, because the parser will always use utf-8.\\n\"},\n {'prompt': 'I have a dict that looks like this\\n\\n{ \"keyword1\":3 , \"keyword2\":1 , \"keyword3\":5 , \"keyword4\":2 }\\n\\nAnd I would like to convert it DESC and create a list of just the keywords. Eg, this would return\\n\\n[\"keyword3\" , \"keyword1\" , \"keyword4\" , \"keyword2\"]\\n\\nAll examples I found use lambda and I\\'m not very strong with that. Is there a way I could loop through this, and sort them as I go? Thanks for any suggestions.\\n\\nPS: I could create the initial dict differently if it would help.\\n',\n  'completion': \"You could use\\n\\nres = list(sorted(theDict, key=theDict.__getitem__, reverse=True))\\n\\n\\n(You don't need the list in Python 2.x)\\n\\nThe theDict.__getitem__ is actually equivalent to lambda x: theDict[x].\\n\\n(A lambda is just an anonymous function. For example\\n\\n>>> g = lambda x: x + 5\\n>>> g(123)\\n128\\n\\n\\nThis is equivalent to\\n\\n>>> def h(x):\\n...   return x + 5\\n>>> h(123)\\n128\\n\\n\\n)\\n\"},\n {'prompt': 'I am trying to create a function that can convert a month number to an abbreviated month name or an abbreviated month name to a month number. I thought this might be a common question but I could not find it online. \\n\\nI was thinking about the calendar module. I see that to convert from month number to abbreviated month name you can just do calendar.month_abbr[num]. I do not see a way to go the other direction though. Would creating a dictionary for converting the other direction be the best way to handle this? Or is there a better way to go from month name to month number and vice versa?\\n',\n  'completion': \"Just for fun:\\n\\nfrom time import strptime\\n\\nstrptime('Feb','%b').tm_mon\\n\\n\"},\n {'prompt': 'Where can I find some real world typo statistics?  \\n\\nI\\'m trying to match people\\'s input text to internal objects, and people tend to make spelling mistakes.\\nThere are 2 kinds of mistakes:  \\n\\n\\ntypos - \"Helllo\" instead of \"Hello\" / \"Satudray\" instead of \"Saturday\" etc.  \\nSpelling - \"Shikago\" instead of \"Chicago\" \\n\\n\\nI use  Damerau-Levenshtein distance for the typos and Double Metaphone for spelling (Python implementations here and here).\\n\\nI want to focus on the Damerau-Levenshtein (or simply edit-distance). The textbook implementations always use \\'1\\' for the weight of deletions, insertions substitutions and transpositions. While this is simple and allows for nice algorithms it doesn\\'t match \"reality\" / \"real-world probabilities\".  \\n\\nExamples:   \\n\\n\\nI\\'m sure the likelihood of \"Helllo\" (\"Hello\") is greater than \"Helzlo\", yet they are both 1 edit distance away.\\n\"Gello\" is closer than \"Qello\" to \"Hello\" on a QWERTY keyboard.\\nUnicode transliterations: What is the \"real\" distance between \"MÃ¼nchen\" and \"Munchen\"?\\n\\n\\nWhat should the \"real world\" weights be for deletions, insertions, substitutions, and transpositions?  \\n\\nEven Norvig\\'s very cool spell corrector uses non-weighted edit distance.\\n\\nBTW- I\\'m sure the weights need to be functions and not simple floats (per the above \\nexamples)...\\n\\nI can adjust the algorithm, but where can I \"learn\" these weights? I don\\'t have access to Google-scale data...  \\n\\nShould I just guess them?\\n\\nEDIT - trying to answer user questions:\\n\\n\\nMy current non-weighted algorithm fails often when faced with typos for the above reasons. \"Return on Tursday\": every \"real person\" can easily tell Thursday is more likely than Tuesday, yet they are both 1-edit-distance away! (Yes, I do log and measure my performance).\\nI\\'m developing an NLP Travel Search engine, so my dictionary contains ~25K destinations (expected to grow to 100K), Time Expressions ~200 (expected 1K), People expressions ~100 (expected 300), Money Expressions ~100 (expected 500), \"glue logic words\" (\"from\", \"beautiful\", \"apartment\") ~2K (expected 10K) and so on...\\nUsage of the edit distance is different for each of the above word-groups. I try to \"auto-correct when obvious\", e.g. 1 edit distance away from only 1 other word in the dictionary. I have many other hand-tuned rules, e.g. Double Metaphone fix which is not more than 2 edit distance away from a dictionary word with a length > 4... The list of rules continues to grow as I learn from real world input.\\n\"How many pairs of dictionary entries are within your threshold?\": well, that depends on the \"fancy weighting system\" and on real world (future) input, doesn\\'t it? Anyway, I have extensive unit tests so that every change I make to the system only makes it better (based on past inputs, of course). Most sub-6 letter words are within 1 edit distance from a word that is 1 edit distance away from another dictionary entry.\\nToday when there are 2 dictionary entries at the same distance from the input I try to apply various statistics to better guess which the user meant (e.g. Paris, France is more likely to show up in my search than PÄ\\x81rÄ«z, Iran).\\nThe cost of choosing a wrong word is returning semi-random (often ridiculous) results  to the end-user and potentially losing a customer. The cost of not understanding is slightly less expensive: the user will be asked to rephrase.\\nIs the cost of complexity worth it? Yes, I\\'m sure it is. You would not believe the amount of typos people throw at the system and expect it to understand, and I could sure use the boost in Precision and Recall.\\n\\n',\n  'completion': \"Possible source for real world typo statistics would be in the Wikipedia's complete edit history. \\n\\nhttp://download.wikimedia.org/\\n\\nAlso, you might be interested in the AWB's RegExTypoFix\\n\\nhttp://en.wikipedia.org/wiki/Wikipedia:AWB/T\\n\"},\n {'prompt': 'Which is better for creating a settings file for Python programs, the built-in module (ConfigParser), or the independent project (ConfigObj)?\\n',\n  'completion': \"I recently switched from configparser to configobj, and I'm thrilled to have done so.\\n\\nFor me, the big difference is configobj's validator. It lets me very easily/succinctly (1) define the type and acceptable values for each entry, and (2) set defaults. \\n\\nThose two features save me a lot of code and prevent a lot from going wrong. Plus, there's really no extra overhead to using configobj in terms of the complexity of my code, and the library is quite small.\\n\"},\n {'prompt': 'I\\'m writing a silly program in python for a friend that prints \"We are the knights who say \\'Ni\\'!\". then sleeps for 3 seconds, and then prints \"Ni!\" twenty times at random intervals using the random module\\'s uniform() method. Here\\'s my code:\\n\\nfrom time import sleep\\nimport random\\n\\ndef knights_of_ni():\\n    generator = random.Random()\\n    print \"We are the knights who say \\'ni\\'.\"\\n    sleep(3)\\n    for i in range(0,20):\\n        print \"Ni!\"\\n        sleep(generator.uniform(0,2))\\n\\n\\nI\\'ve tried to import this module by typing in the interpreter from silly import knights_of_ni() and import silly, then calling the function  with either knights_of_ni() or silly.knights_of_ni() (respectively), but I always get the same exception:\\n\\n NameError: global name \\'time\\' is not defined\\n\\n\\nWhat is causing this error and how can I fix my code?\\n\\nEdit: quite frankly, I\\'m not sure what problem I was having either. I ran the code the next morning and it worked just fine. I swear that the code produced errors last night... Anyway, thanks for your insight.\\n',\n  'completion': \"That's impossible. Your code example isn't the same as the code that produced that error.\\n\\nPerhaps you had time.sleep(..) instead of sleep(..). You have done from time import sleep. To use the time.sleep(..) form you must import time\\n\"},\n {'prompt': \"Using SQLite3 in Python, I am trying to store a compressed version of a snippet of UTF-8 HTML code.\\n\\nCode looks like this:\\n\\n...\\nc = connection.cursor()\\nc.execute('create table blah (cid integer primary key,html blob)')\\n...\\nc.execute('insert or ignore into blah values (?, ?)',(cid, zlib.compress(html)))\\n\\n\\nAt which point at get the error:\\n\\nsqlite3.ProgrammingError: You must not use 8-bit bytestrings unless you use a text_factory that can interpret 8-bit bytestrings (like text_factory = str). It is highly recommended that you instead just switch your application to Unicode strings.\\n\\n\\nIf I use 'text' rather than 'blob' and don't compress the HTML snippet, it works all fine (db is to large though). When I use 'blob' and compress via Python zlib library, I get the above error message. I looked around but couldn't find a simple answer for this one.\\n\",\n  'completion': 'If you want to use 8-bit strings instead of unicode string in sqlite3, set approptiate text_factory for sqlite connection:\\n\\nconnection = sqlite3.connect(...)\\nconnection.text_factory = str\\n\\n'},\n {'prompt': 'at the start and end of my program, I have \\n\\nfrom time import strftime\\nprint int(strftime(\"%Y-%m-%d %H:%M:%S\")\\n\\n\\n\\nY1=int(strftime(\"%Y\"))\\nm1=int(strftime(\"%m\"))\\nd1=int(strftime(\"%d\"))\\nH1=int(strftime(\"%H\"))\\nM1=int(strftime(\"%M\"))\\nS1=int(strftime(\"%S\"))\\n\\n\\nY2=int(strftime(\"%Y\"))\\nm2=int(strftime(\"%m\"))\\nd2=int(strftime(\"%d\"))\\nH2=int(strftime(\"%H\"))\\nM2=int(strftime(\"%M\"))\\nS2=int(strftime(\"%S\"))\\n\\nprint \"Difference is:\"+str(Y2-Y1)+\":\"+str(m2-m1)+\":\"+str(d2-d1)\\\\\\n          +\" \"+str(H2-H1)+\":\"+str(M2-M1)+\":\"+str(S2-S1)\\n\\n\\nBut when I tried to get the difference, I get syntax errors.... I am doing a few things wrong, but I\\'m not sure what is going on...\\n\\nBasically, I just want to store a time in a variable at the start of my program, then store a 2nd time in a second variable near the end, then at the last bit of the program, compute the difference and display it. I am not trying to time a function speed. I am trying to log how long it took for a user to progress through some menus. What is the best way to do this?\\n',\n  'completion': \"The datetime module will do all the work for you:\\n\\n>>> import datetime\\n>>> a = datetime.datetime.now()\\n>>> # ...wait a while...\\n>>> b = datetime.datetime.now()\\n>>> print(b-a)\\n0:03:43.984000\\n\\n\\nIf you don't want to display the microseconds, just use (as gnibbler suggested):\\n\\n>>> a = datetime.datetime.now().replace(microsecond=0)\\n>>> b = datetime.datetime.now().replace(microsecond=0)\\n>>> print(b-a)\\n0:03:43\\n\\n\"},\n {'prompt': 'How would I use Python to determine what programs are currently running. I am on Windows. \\n',\n  'completion': \"Thanks to @hb2pencil for the WMIC command!  Here's how you can pipe the output without a file:\\n\\nimport subprocess\\ncmd = 'WMIC PROCESS get Caption,Commandline,Processid'\\nproc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\\nfor line in proc.stdout:\\n    print line\\n\\n\"},\n {'prompt': 'I have a list of integers which I need to parse into a string of ranges.\\n\\nFor example:\\n\\n [0, 1, 2, 3] -> \"0-3\"\\n [0, 1, 2, 4, 8] -> \"0-2,4,8\"\\n\\n\\nAnd so on.\\n\\nI\\'m still learning more pythonic ways of handling lists, and this one is a bit difficult for me.  My latest thought was to create a list of lists which keeps track of paired numbers:\\n\\n[ [0, 3], [4, 4], [5, 9], [20, 20] ]\\n\\n\\nI could then iterate across this structure, printing each sub-list as either a range, or a single value.\\n\\nI don\\'t like doing this in two iterations, but I can\\'t seem to keep track of each number within each iteration.  My thought would be to do something like this:\\n\\nHere\\'s my most recent attempt.  It works, but I\\'m not fully satisfied; I keep thinking there\\'s a more elegant solution which completely escapes me.  The string-handling iteration isn\\'t the nicest, I know -- it\\'s pretty early in the morning for me :)\\n\\ndef createRangeString(zones):\\n        rangeIdx = 0\\n        ranges   = [[zones[0], zones[0]]]\\n        for zone in list(zones):\\n            if ranges[rangeIdx][1] in (zone, zone-1):\\n                ranges[rangeIdx][1] = zone\\n            else:\\n                ranges.append([zone, zone])\\n                rangeIdx += 1\\n\\n        rangeStr = \"\"\\n        for range in ranges:\\n            if range[0] != range[1]:\\n                rangeStr = \"%s,%d-%d\" % (rangeStr, range[0], range[1])\\n            else:\\n                rangeStr = \"%s,%d\" % (rangeStr, range[0])\\n\\n        return rangeStr[1:]\\n\\n\\nIs there a straightforward way I can merge this into a single iteration?  What else could I do to make it more Pythonic?\\n',\n  'completion': '>>> from itertools import count, groupby\\n>>> L=[1, 2, 3, 4, 6, 7, 8, 9, 12, 13, 19, 20, 22, 23, 40, 44]\\n>>> G=(list(x) for _,x in groupby(L, lambda x,c=count(): next(c)-x))\\n>>> print \",\".join(\"-\".join(map(str,(g[0],g[-1])[:len(g)])) for g in G)\\n1-4,6-9,12-13,19-20,22-23,40,44\\n\\n\\nThe idea here is to pair each element with count(). Then the difference between the value and count() is constant for consecutive values. groupby() does the rest of the work\\n\\nAs Jeff suggests, an alternative to count() is to use enumerate(). This adds some extra cruft that needs to be stripped out in the print statement\\n\\nG=(list(x) for _,x in groupby(enumerate(L), lambda (i,x):i-x))\\nprint \",\".join(\"-\".join(map(str,(g[0][1],g[-1][1])[:len(g)])) for g in G)\\n\\n\\nUpdate: for the sample list given here, the version with enumerate runs about 5% slower than the version using count() on my computer\\n'},\n {'prompt': 'I want to get a running total from a list of numbers.\\n\\nFor demo purposes, I start with a sequential list of numbers using range\\n\\na = range(20)\\n\\nrunningTotal = []\\nfor n in range(len(a)):\\n    new = runningTotal[n-1] + a[n] if n > 0 else a[n]\\n    runningTotal.append(new)\\n\\n# This one is a syntax error\\n# runningTotal = [a[n] for n in range(len(a)) if n == 0 else runningTotal[n-1] + a[n]]\\n\\nfor i in zip(a, runningTotal):\\n    print \"{0:>3}{1:>5}\".format(*i)\\n\\n\\nyields\\n\\n  0    0\\n  1    1\\n  2    3\\n  3    6\\n  4   10\\n  5   15\\n  6   21\\n  7   28\\n  8   36\\n  9   45\\n 10   55\\n 11   66\\n 12   78\\n 13   91\\n 14  105\\n 15  120\\n 16  136\\n 17  153\\n 18  171\\n 19  190\\n\\n\\nAs you can see, I initialize an empty list [], then append() in each loop iteration. Is there a more elegant way to this, like a list comprehension?\\n',\n  'completion': \"A list comprehension has no good (clean, portable) way to refer to the very list it's building. One good and elegant approach might be to do the job in a generator:\\n\\ndef running_sum(a):\\n  tot = 0\\n  for item in a:\\n    tot += item\\n    yield tot\\n\\n\\nto get this as a list instead, of course, use list(running_sum(a)).\\n\"},\n {'prompt': 'Suppose I have a list of sets and I want to get the union over all sets in that list. Is there any way to do this using a generator expression? In other words, how can I create the union over all sets in that list directly as a frozenset?\\n',\n  'completion': 'Just use the .union() method.\\n\\n>>> l = [set([1,2,3]), set([4,5,6]), set([1,4,9])]\\n>>> frozenset().union(*l)\\nfrozenset([1, 2, 3, 4, 5, 6, 9])\\n\\n\\nThis works for any iterable of iterables.\\n'},\n {'prompt': 'I want to override __cmp__, __eq__, and __hash__ so I can do set operations on a SQLAlchemy Declarative Base model. Will this cause any conflicts with the Declarative Base Implementation?\\n',\n  'completion': \"no. It'll work just fine.\\n\"},\n {'prompt': 'I have this code that executes when a player attempts to eat something:\\n\\ndef eat(target=\\'object\\'):\\n    global current_room\\n    global locations\\n    global inventory\\n    if target in inventory:\\n        items[target][\\'on_eat\\'] #This is showing no results.\\n    else:\\n        print \\'You have no \\' + target + \\' to eat.\\'\\n\\n\\nand this code for items(trimmed)\\n\\nitems = {\\n\\'strawberry\\': {\\n    \\'weight\\': 1,\\n    \\'text\\': \\'The strawberry is red\\',\\n    \\'on_eat\\': \"normal_eat(\\'strawberry\\', \\'pretty good, but not as sweet as you expected\\')\"\\n    },\\n\\'trees\\': {\\n    \\'weight\\': 50,\\n    \\'text\\': \\'The trees are tall with large, leaf filled branches blocking out a majority of sunlight.\\',\\n    \\'on_eat\\': \"forcesay(\\'Eating trees? What the hell is your problem?\\')\"\\n    }\\n}\\n\\n\\nIs there a valid way of calling items[whatever][\\'on_eat\\'] without doing something silly like exec() or eval()? If not, alternative formatting as an example would also be appreciated.\\n\\nBefore this the items[everyitems][\\'on_eat\\'] values were not strings, but that executed the on_eat for every item as soon as the code was ran.\\n\\nI have seen many answers to similar questions, but they don\\'t deal with arguments for functions unique- to better put that, they were more like this\\n',\n  'completion': \"You can store your function and function arguments as a partial:\\n\\nfrom functools import partial\\n\\nitems = { \\n'strawberry': { \\n    'weight': 1, \\n    'text': 'The strawberry is red', \\n    'on_eat': partial(normal_eat, 'strawberry', 'pretty good, but not as sweet as you expected') \\n    }, \\n'trees': { \\n    'weight': 50, \\n    'text': 'The trees are tall with large, leaf filled branches blocking out a majority of sunlight.', \\n    'on_eat': partial(forcesay, 'Eating trees? What the hell is your problem?')\\n    } \\n\\ndef eat(target='object'):  \\n    # those globals are probably not necessary\\n    if target in inventory:  \\n        items[target]['on_eat']()  #Add ()'s to call the partial\\n    else:  \\n        print 'You have no ' + target + ' to eat.'\\n\\n\"},\n {'prompt': 'The problem I\\'m having is with Eclipse/PyCharm interpreting the results of subprocess\\'s Popen() differently from a standard terminal. All are using python2.6.1 on OSX.\\n\\nHere\\'s a simple example script:\\n\\nimport subprocess\\n\\nargs = [\"/usr/bin/which\", \"git\"]\\nprint \"Will execute %s\" % \" \".join(args)\\ntry:\\n  p = subprocess.Popen([\"/usr/bin/which\", \"git\"], shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\\n  # tuple of StdOut, StdErr is the responses, so ..\\n  ret = p.communicate()\\n  if ret[0] == \\'\\' and ret[1] <> \\'\\':\\n    msg = \"cmd %s failed: %s\" % (fullcmd, ret[1])\\n    if fail_on_error:\\n      raise NameError(msg)\\nexcept OSError, e:\\n  print >>sys.stderr, \"Execution failed:\", e\\n\\n\\nWith a standard terminal, the line:\\n\\nret = p.communicate()\\n\\n\\ngives me:\\n\\n(Pdb) print ret\\n(\\'/usr/local/bin/git\\\\n\\', \\'\\')\\n\\n\\nEclipse and PyCharm give me an empty tuple:\\n\\nret = {tuple} (\\'\\',\\'\\')\\n\\n\\nChanging the shell= value does not solve the problem either. On the terminal, setting shell=True, and passing the command in altogether (i.e., args=[\"/usr/bin/which git\"]) gives me the same result: ret = (\\'/usr/local/bin/git\\\\n\\', \\'\\'). And Eclipse/PyCharm both give me an empty tuple.\\n\\nAny ideas on what I could be doing wrong?\\n',\n  'completion': 'Ok, found the problem, and it\\'s an important thing to keep in mind when using an IDE in a Unix-type environment. IDE\\'s operate under a different environment context than the terminal user (duh, right?!). I was not considering that the subprocess was using a different environment than the context that I have for my terminal (my terminal has bash_profile set to have more things in PATH).\\n\\nThis is easily verified by changing the script as follows:\\n\\nimport subprocess\\nargs = [\"/usr/bin/which\", \"git\"]\\nprint \"Current path is %s\" % os.path.expandvars(\"$PATH\")\\ntry:\\n  p = subprocess.Popen(args, shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\\n  # tuple of StdOut, StdErr is the responses, so ..\\n  out, err = p.communicate()\\n  if err:\\n    msg = \"cmd %s failed: %s\" % (fullcmd, err)\\nexcept OSError, e:\\n  print >>sys.stderr, \"Execution failed:\", e\\n\\n\\nUnder the terminal, the path includes /usr/local/bin. Under the IDE it does not!\\n\\nThis is an important gotcha for me - always remember about environments!\\n'},\n {'prompt': 'I am interested in taking an arbitrary dict and copying it into a new dict, mutating it along the way.\\n\\nOne mutation I would like to do is swap keys and value. Unfortunately, some values are dicts in their own right. However, this generates a \"unhashable type: \\'dict\\'\" error. I don\\'t really mind just stringifying the value and giving it the key. But, I\\'d like to be able to do something like this:\\n\\nfor key in olddict:\\n  if hashable(olddict[key]):\\n    newdict[olddict[key]] = key\\n  else\\n    newdict[str(olddict[key])] = key\\n\\n\\nIs there a clean way to do this that doesn\\'t involve trapping an exception and parsing the message string for \"unhashable type\" ?\\n',\n  'completion': 'Since Python 2.6 you can use the abstract base class collections.Hashable:\\n\\nimport collections\\n>>> isinstance({}, collections.Hashable)\\nFalse\\n>> isinstance(0, collections.Hashable)\\nTrue\\n\\n\\nThis approach is also mentioned briefly in the documentation for __hash__.\\n\\n\\n  Doing so means that not only will instances of the class raise an appropriate TypeError when a program attempts to retrieve their hash value, but they will also be correctly identified as unhashable when checking isinstance(obj, collections.Hashable) (unlike classes which define their own __hash__() to explicitly raise TypeError).\\n\\n'},\n {'prompt': \"I have two models like this:\\n\\nclass Type1Profile(models.Model):\\n    user = models.OneToOneField(User, unique=True)\\n    ...\\n\\n\\nclass Type2Profile(models.Model):\\n    user = models.OneToOneField(User, unique=True)\\n    ...\\n\\n\\nI need to do something if the user has Type1 or Type2 profile:\\n\\nif request.user.type1profile != None:\\n    # do something\\nelif request.user.type2profile != None:\\n    # do something else\\nelse:\\n    # do something else\\n\\n\\nBut, for users that don't have either type1 or type2 profiles, executing code like that produces the following error:\\n\\nType1Profile matching query does not exist.\\n\\n\\nHow can I check the type of profile a user has?\\n\\nThanks\\n\",\n  'completion': \"To check if the (OneToOne) relation exists or not, you can use the hasattr function:\\n\\nif hasattr(request.user, 'type1profile'):\\n    # do something\\nelif hasattr(request.user, 'type2profile'):\\n    # do something else\\nelse:\\n    # do something else\\n\\n\"},\n ...]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_openai_format"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-06T08:25:57.663080300Z",
     "start_time": "2023-07-06T08:25:57.478406100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
